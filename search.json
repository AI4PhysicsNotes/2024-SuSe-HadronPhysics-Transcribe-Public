[
  {
    "objectID": "2024-Lecture-01.html",
    "href": "2024-Lecture-01.html",
    "title": "(2024) Lecture 1",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-01.html#lecture-logistics-and-upload-plans",
    "href": "2024-Lecture-01.html#lecture-logistics-and-upload-plans",
    "title": "(2024) Lecture 1",
    "section": "1 Lecture Logistics and Upload Plans",
    "text": "1 Lecture Logistics and Upload Plans\nYes. I will upload the lecture as well. If anything reasonable comes out of it, I will be happy to upload it.\nCertainly, what will be uploaded is the lecture content with items that I already have. There will also be references to material.\n\n\n\n\n\n\nThis initial segment is purely logistical and administrative. No specific physics concepts, variables, or mathematical relationships are being discussed here.\n\n\n\nBut let’s go to logistics in the last 15 minutes."
  },
  {
    "objectID": "2024-Lecture-01.html#the-early-universe-from-symmetry-breaking-to-hadronization",
    "href": "2024-Lecture-01.html#the-early-universe-from-symmetry-breaking-to-hadronization",
    "title": "(2024) Lecture 1",
    "section": "2 The Early Universe: From Symmetry Breaking to Hadronization",
    "text": "2 The Early Universe: From Symmetry Breaking to Hadronization\nSo we are living in a universe made of hadronic physics, but it was not always the case.\nI like thinking of the evolution of the universe on a time scale, with the origin of the universe where everything started. There was a Big Bang first, and then several epochs followed. It started with the Planck epoch, then there was the electroweak epoch, and then the quark epoch.\n\n2.0.1 The Electroweak Epoch and Symmetry Breaking\nWhat has been happening during these epochs is the part of the physics that we go through in the courses.\nLet me start with the electroweak epoch. This is where the Higgs potential V(\\phi) = \\mu^2 |\\phi|^2 + \\lambda |\\phi|^4\n—that is the field giving masses to particles and making sure that our proton doesn’t decay and our life can exist—gets a condensate.\nThe electroweak phase is where the transition happens. The entire space is filled now with a condensate, a fixed, non-moving condensate of the Higgs field, through which particles are slowed down; they get inertia and they obtain mass. That’s something known as the Higgs mechanism.\nThis process of the potential evolving is called spontaneous symmetry breaking, when one of the minima is picked. That’s how I like thinking about the electroweak stage.\nSo what happens then? Particles have masses. The universe starts evolving, and at some point we arrive at the quark epoch.\n\n\n2.0.2 The Quark Epoch and Quark-Gluon Plasma\nAt this stage, the universe is filled with a quark-gluon plasma. Essentially, quarks and gluons are making an unstructured soup of objects. There is nothing about structure formation yet. This is rather quarks disturbing—there is no yet scale that we are going to talk about.\nQuarks and gluons are together, and the universe is extremely hot. From that moment it starts cooling down. At some point the temperature is low enough that this medium starts separating, and we arrive at the quantum chromodynamics (QCD) epoch.\n\n\n\n\n\n\nThe transition to a quark-gluon plasma occurs when the temperature exceeds the QCD scale: T_{\\text{QGP}} \\sim \\Lambda_{\\text{QCD}} \\approx 150 \\text{–} 200 \\text{ MeV} . In the early universe, the age during this epoch can be estimated as t \\sim M_{\\text{Pl}} / T^2 , which for T \\sim 150 \\text{ MeV} gives t \\sim 10^{-6} \\text{ s} .\n\n\n\nThis hot medium starts forming small volumes where the interactions of quarks and gluons are confined to a small scale. You need two years to learn this in detail. This comes in particle physics, introductory nuclear physics, and a specialized course on QCD at finite temperature, since it’s a heated medium and there are different laws applied.\n\n\n2.0.3 The Hadronic Universe and Confinement\nHadrons are what we are going to focus on now. But if you think of how quickly this all happened, you’re going to be slightly surprised.\nThe timeline is incredibly brief:\n\n10^{-36} seconds for the Planck epoch\n10^{-12} seconds for the electroweak epoch\n10^{-6} seconds for the QCD transition\nThen 1 second.\n\nJust imagine there was nothing, and then the sound reached you on the back. When I clap, if you look at my palms, the time span between when I close them and you hear the sound is roughly 10 milliseconds. By that time we had already passed through all the stages and everything hadronized. That’s how quickly the universe evolved.\nIn that scale, the rest of the interval to the 13 billion years—the age of our universe—has been other interesting physics, but not as intense as this from the perspective of our hadron physics.\nWe can be talking about hadrons in the sense that we will be talking about the strong interaction. The hadrons are objects where the strong interactions are confined to the small scale of a few fermi: R_{\\text{hadron}} \\sim 1 / \\Lambda_{\\text{QCD}} \\approx 1 \\text{ fm} = 10^{-15} \\text{ m}.\nThere is essentially nothing around. There is a small chunk of volume where the quarks and gluons live. They interact with each other. There are large fractions of empty space.\nOne fermi is 10^{-15} meters. It’s difficult to imagine this scale, but this number can help you. It is a smaller scale we have, and the smallest scale where we actually can separate things.\nThe strong interaction is confined in this small scale and it stays there. By colliding hadrons we learned how to study internal structure and how to separate the subject. But there is no natural scale smaller than that."
  },
  {
    "objectID": "2024-Lecture-01.html#the-emptiness-of-matter-and-the-color-charge",
    "href": "2024-Lecture-01.html#the-emptiness-of-matter-and-the-color-charge",
    "title": "(2024) Lecture 1",
    "section": "3 The Emptiness of Matter and the Color Charge",
    "text": "3 The Emptiness of Matter and the Color Charge\nSo concerning the empty space in an atom, I wanted to sketch one of the most common elements on Earth. From the periodic table, what is the most common element? I think it’s oxygen.\nA neutral oxygen atom has eight protons and eight neutrons. Oxygen has many isotopes; one common one is oxygen-16, while oxygen-18 has eight protons and ten neutrons. The atom is neutral, so there must be electrons compensating the charge of the protons. The protons give a charge of +8e , and there are eight electrons in the configuration 1s^2 2s^2 2p^4 .\n\n\n\n\n\n\nThis notation, 1s^2 2s^2 2p^4 , is the ground-state electron configuration for a neutral oxygen atom (atomic number Z = 8 ). It describes how its 8 electrons are distributed: 2 in the 1s orbital, 2 in the 2s orbital, and 4 in the 2p orbitals.\n\n\n\nThe atom’s electrical neutrality is expressed by the condition q_{\\text{atom}} = Z e + (-e) \\sum_{i=1}^{Z} 1 = 0 . For oxygen ( Z=8 ), this is +8e - 8e = 0 .\nTo understand the scale of emptiness, let’s look at the nucleus. There is a center where protons and neutrons are packed closely together. Knowing the scale of a hadron, you can guess the core’s scale. The size of the nucleus scales as:\nR = R_0 A^{1/3}\nHere, R_0 \\approx 1.2 \\, \\text{fm} (femtometers) is a constant, and A is the mass number (protons + neutrons). This nuclear radius formula arises because nuclear volume is proportional to A , assuming nucleons are closely packed with nearly constant density. For oxygen-16 ( A = 16 ), the nuclear radius is roughly R \\approx 1.2 \\times 16^{1/3} \\, \\text{fm} \\approx 3 \\, \\text{fm} .\nBut electrons are completely different. Their wave function has a size about 3 orders of magnitude bigger. The atomic radius is roughly 50 picometers ( 5 \\times 10^{-11} \\, \\text{m} ).\nNow consider this scale difference:\n\\frac{R_{\\text{atom}}}{R_{\\text{nucleus}}} \\approx \\frac{50 \\times 10^{-12} \\, \\text{m}}{3 \\times 10^{-15} \\, \\text{m}} \\sim 10^4\nThis atomic vs. nuclear scale ratio—about 10,000—shows how empty an atom is. There is a very small core, and around it is a vast space where the electrons exist. In that space, there is no strong interaction.\nThe second item is what we know as the fundamental hardware: the Standard Model. This is the theory in particle physics that describes most known interactions. Setting aside neutrinos—where there are open questions—it describes everything well.\nThe part responsible for strong interactions is Quantum Chromodynamics (QCD). The participants are quarks and gluons. These are the only particles in the Standard Model that carry color charge, which is the charge needed to interact via the strong force.\nThis is similar to electrodynamics: only objects that are not neutral can interact. However, in strong interactions, the relevant charge is a different type—it’s not electric charge, it’s color charge. We could have invented a different word, but “color charge” is the term.\nThink of this charge as analogous to the electric charge of an electron or muon. But it’s a different quantum number; they are independent. This is the charge independence principle in the Standard Model:\nQ_{\\text{em}} \\neq Q_{\\text{color}}\n\nA particle with electric charge does not have to have color charge (e.g., an electron).\nA particle with color charge does not have to have electric charge (e.g., a gluon).\n\nWe usually measure electric charge in elementary units: the electron is -1 , the positron is +1 . For color charge, we don’t use simple units. Instead, we describe quarks and gluons by introducing their color wave function. Once they have a non-trivial color wave function, they are color-charged."
  },
  {
    "objectID": "2024-Lecture-01.html#the-origin-of-mass-and-the-constituent-quark-model",
    "href": "2024-Lecture-01.html#the-origin-of-mass-and-the-constituent-quark-model",
    "title": "(2024) Lecture 1",
    "section": "4 The Origin of Mass and the Constituent Quark Model",
    "text": "4 The Origin of Mass and the Constituent Quark Model\nTo finish with the Standard Model, I want to mention that these are the only particles that have color charge.\nLet me list other particles of the Standard Model: the electron and muon. The electron, muon, and tau lepton are kind of the same, but they have different masses. The electron is the one that is orbiting or living and compensating the charge of protons and neutrons in the nuclei. The muon is the heavier brother of the electron. The tau is a much heavier sister of the electron. All of them can be in both configurations.\nBut let’s complete the list. What else is in the Standard Model? Photons and neutrinos. That’s all. I just draw them all here to say that they don’t have color charge. They don’t have color charge, so they don’t interact with the quarks and are not influenced by the strong force. We will see them all the time, but they don’t participate in the strong interaction.\nAs I mentioned, if you don’t have a color charge, you don’t interact strongly. But if you have a color charge, you must interact strongly, though it doesn’t mean you don’t interact in other ways. All of these particles have different quantum numbers. Essentially, they are electrically charged. The electric charge of protons and neutrons is not zero for quarks.\nThere are six quarks in the Standard Model. That’s what we see: six quarks exist. They are different, but they have common properties. They are separated into groups by their electric charge.\n\nThose in the upper row have a positive charge of Q = +\\frac{2}{3}e .\nThe lower row has an electric charge of Q = -\\frac{1}{3}e .\n\nThey also split on the horizontal axis into three groups. These are generations: the first generation, second generation, and third generation. The higher the generation you go, the more difficult the particles are to produce, as the objects become heavier. This is why most of the matter we see around us is made of the first generation.\nWe produce strangeness rather easily once we collide particles. Cosmic rays have a lot of strange particle production, and less of the charm quark. The ‘C’ stands for charm. However, it also appears in cosmic rays. There is actually a hot discussion these days on whether the strange quark and the interaction of strange quarks is relevant for the equation of state when stars evolve.\nWe want to describe the maximal size of a neutron star. This maximal size is driven by the equation of state. Essentially, it depends on how the atoms are packed inside the neutron star. If there are clusters where strange particles appear, it changes the equation of state. This then changes the observable characteristics. Over the last five years, more discussion has evolved on the equation of state and the relevance of the strange quark there.\nThe charm quark is mostly studied in collisions at high energy, because you need a lot of energy to produce charm and bottom quarks. The top quark is relevant for Higgs physics. That’s the domain where these two are studied. The up and down quarks are called light quarks. The strange quark, charm quark, and bottom quark are studied a lot in colliders to see CP violation and in the search for precision physics.\nThe top quark measures very well the Standard Model quantities related to Higgs physics and electroweak interactions. We’ll be focusing on the five lighter flavors and will not talk much about the top quark because its lifetime is so short that it decays before it can form hadrons. You won’t find any hadrons that contain a top quark. But all of these other quarks can form hadrons.\nMost of the matter we know and that is abundantly present is of two types. We are going to talk about pions.\nWelcome to a lecture dedicated to the constituent quark model. Here is a sketch of the simple pictures that classify hadrons. As you see, there are two types: mesons and baryons. This model describes hadrons as compositions of a quark-antiquark pair or three quarks.\nYou may ask about gluons. I would like to come back to this picture. There is something very beautiful happening around the chiral symmetry breaking scale. Essentially, another condensation process occurs. When hadronization happens, as quarks and gluons from the soup start to confine themselves, the gluon field condenses as well.\nWhat happens is that the gluon field, similar to the Higgs field, forms a medium in which the quarks are moving. This medium is colored, and the quarks, by interacting with it, acquire energy. Effectively, gluons are now dressing the quarks, making them massive. The quarks we draw in the constituent picture are different from the Standard Model quarks; they are quarks dressed by gluons.\n\n\n\n\n\n\nIn the constituent quark model, quarks are dressed by gluons and acquire effective masses much larger than their bare masses. For light quarks: m_u^{\\text{const}} \\approx m_d^{\\text{const}} \\approx \\frac{m_p}{3} \\approx 313 \\text{ MeV}\nThis is compared to their bare masses from the Higgs mechanism, which are m_u^{\\text{bare}} \\approx m_d^{\\text{bare}} \\sim 3 \\text{ MeV} .\n\n\n\nThere is a nice way of thinking about this. Look at the masses of the light quarks. The mass of the u quark and d quark is on the order of 3 \\text{ MeV} . We will be using natural units throughout the course, where the speed of light c = 1 and \\hbar = 1 .\nIf you look at the other way of expressing \\hbar , it is a quantity with units: \\hbar = 6.6 \\times 10^{-34} \\text{ J} \\cdot \\text{s} , which is also equal to 6.6 \\times 10^{-22} \\text{ MeV} \\cdot \\text{s} . In natural units, we set \\hbar = 1 . This immediately tells you that to achieve that, you need to be able to translate meters to seconds.\nFrom that, you can take this second and move it to the other side: 1 \\text{ s} = 3 \\times 10^8 \\text{ m} . Meters are the same as seconds. Also from that, you can realize that in these units, 1 \\text{ s}^{-1} = 6.6 \\times 10^{-22} \\text{ MeV} . You can also relate joule and second. It’s important to realize these are not just relations between numbers, but also units.\nThis is the way you translate any meters to seconds and any second to mega electron volts. That’s the way to translate electron volts to seconds, and also the way to translate kilograms, because a joule can be expressed in kilograms. In these natural units, \\text{MeV} is the unit of mass, energy, and inverse distance. We will be using eV, MeV, and GeV for everything.\nJust to have a scale, in kilograms it’s 10^{-30} , which is a huge number. But what is the mass of the proton? The proton, which in the constituent model is made of u and d quarks, has a mass of roughly 1 \\text{ GeV} . To be accurate, the proton mass is around 1.67 \\times 10^{-27} \\text{ kg} .\n\n\n\n\n\n\nFigure 1: The diagram shows the contribution of different components to the visible mass of matter. Only about one percent comes from the Higgs field, which provides intrinsic fermion masses through Yukawa couplings, while the remaining ninety-nine percent arises from gluon interactions inside nucleons, where the QCD binding energy and quantum fluctuations generate the bulk of the nucleon mass.\n\n\n\nLet’s do a comparison. The Higgs mechanism involves making the condensate that gives all particles their masses. The mass that quarks get from the Higgs is a few MeV. Then another phenomenon happens. Essentially, energy gets stored in the strong quark interaction.\nAt the place where the strong interaction is happening, there is a large energy density of the gluon condensate. This large energy accounts for about 99% of the proton mass. If you think of the origin of mass, which was discussed a lot when the Higgs was discovered, the Higgs explains only a small part. It is less than 1% of the proton mass.\nI calculated the total mass. I summed the three quark masses and divided by three as well. It’s about 1%. If you think like I am around 70 kilos, what are these 70 kilos? Is it me moving through the Higgs field? It is actually gluons and quarks held together by the strong interaction. So, 69 point something kilos of me is due to strong gluon interactions."
  },
  {
    "objectID": "2024-Lecture-01.html#foundations-of-quantum-field-theory",
    "href": "2024-Lecture-01.html#foundations-of-quantum-field-theory",
    "title": "(2024) Lecture 1",
    "section": "5 Foundations of Quantum Field Theory",
    "text": "5 Foundations of Quantum Field Theory\nNow let’s move to a bit more of the equations and discuss quantum dynamics. Quantum chromodynamics is the theory of strong interactions. Quantum electrodynamics is the theory of electromagnetic interactions. I will put both of them because there is a lot in common between these two.\nI think I wrote this already. The framework that we use, starting from classical mechanics, and it turned out to be the most successful, is the Lagrangian approach. Similar to a mechanical system, in order to describe the quantum system, we will be using the Lagrangian and Lagrange equations.\nLet me start with QED. So what is QED? QED essentially is the electromagnetic field. If someone asks you about equations in QED, the first thing that comes to mind is the Maxwell equations. This is the equation of motion for the electric field.\nThe index \\mu here indicates that it’s a vector field. It means under boosts and rotations, it transforms as a vector. As the vector that we are used to, like the particle is moving in certain directions, its momentum is also a vector. The same thing is for this field.\nOnce you see the \\mu index, you know how to boost and rotate this object because it belongs to the vector representation of the Lorentz group. If someone asks you, “I give you the vector,” the zero component is the time component of the four-vector, and then the vector component. It’s the same as the regular four-vectors for momentum: the zero component is the energy and then the spatial components are the momentum. The same for the vector field.\nAgain, you see the index \\mu and then you know what it is. If I give you a four-vector for the vector field and ask you how it looks if I rotate it by 90 degrees, you know what to do. You remember the rotation matrix: 1, 0, cosine, sine. You just apply this to the vector and that’s it. You know how to boost this field as well, because it’s a vector field. There is a gamma, beta, gamma matrix that you apply and then you have it.\nThis might sound familiar already. This was in quantum mechanics and many other courses. They will be extremely useful in other field theory courses. But in our course we’ll be mostly operating with a different way. We barely will be using the four-vector. We barely will be using this, essentially four-vectors and tensor contractions.\nAnother thing to note is that here I am explicitly using Einstein notation and explicitly summing over repeated indices. \\mu here, \\mu there. They are repeated. That means if I were accurate, I should have written here a sum, and then have A_\\mu from 0 to 3, and sum all of the components. The \\nu is a repeated index again, sum.\nIf I look at this, how many terms should I sum? If I put a sum here, how many terms component-wise? If I expand this, how long will it be? It’s a 4 times 4, right? It’s 16 terms. If I also put F_{\\mu\\nu} here, and then have these two fields, for both of them there will be an extra four because it’s a two here, two there. If you multiply them, they will be 16 times 4, which is 64 terms.\nThe equation of motion for this Lagrangian is obtained using the Lagrange equation. You might remember this from classical mechanics where we had dots and the first one was the time derivative, the second one was the derivative of the field. We treat our Lagrangian as a function of the fields and their derivatives.\nWe feel the derivatives and the fields as the different objects and we first differentiate by the derivatives and second we differentiate by the field variables. In that case X is a \\mu . There should be a sum over \\mu . And then the X is the A_\\rho . It’s another Lorentz index.\nIf I take this Lagrangian and I use the Lagrange equation, I get the equation of motion, how the field is moving through space. We know that it’s Maxwell equations. So the equation of motion gives Maxwell and that is important.\nNow let me introduce the second part of the topic. This was the gauge field. It’s called A_\\mu . This is a little bit less intuitive concept that you might have seen before. But we will need it as well so that there are degrees of freedom that are not fixed for the photons, for the electromagnetic field.\nThere is an arbitrary gauge that we fix, that we can explore. This gauge is manifested in the fact that we can take A_\\mu and move it to other A'_\\mu which is A_\\mu - \\partial_\\mu \\chi . So \\chi is a scalar field. Essentially I’m taking all of my fields and I shift them by a derivative.\nUnder this transformation, F_{\\mu\\nu} goes to F'_{\\mu\\nu} . In order to find what it goes to, we have to put it here. This A becomes A' and then you have derivatives. Since this is a function of the space coordinate, you have to differentiate this term as well. You have to do this for the second term.\nIt turns out, and it’s easy to see, that the minus sign kills the extra term. So F'_{\\mu\\nu} = F_{\\mu\\nu} . Then our Lagrangian is invariant. This is the symmetry of the Lagrangian under gauge transformation.\nIf you do the exercise of the variation of the Lagrangian equations and the Maxwell Lagrangian trying to get the Maxwell equations, you won’t get immediately the known Maxwell equations, you will get them up to a gauge. So we see what this derivative does. It picks one of the terms.\nIf you differentiate F_{\\mu\\nu} by the derivative, you will get \\partial_\\rho A_\\nu - \\partial_\\nu A_\\rho and then it will be left over. Maxwell equation, as we know, is \\partial_\\mu \\partial^\\mu A_\\nu = 0 . But you will get an extra term that is easy to kill.\nIf you know that gauge invariance is present and in order to argue that this extra term vanishes, you can say that I can choose in all of my space such a function \\chi that kills the extra term. By fixing the gauge this way you get the common Maxwell equations that we have in electromagnetics.\nFine, we now introduce the fermion fields. As we do in electrodynamics, we have our leptons and the \\psi , where the \\bar{\\psi} is \\psi^\\dagger \\gamma^0 . Actually the \\psi is the four-component spinor which is built by steering degrees.\nEvery Lagrangian is a scalar quantity. It means there are no indices. It’s not a vector, not a matrix. Every Lagrangian is sort of a function, a number, and it’s made of objects of different dimensionality. The fermion field, a fermion is a particle that has spin one half.\nSince we have to deal with the particle and antiparticle components in the same vector, we have four components in the bispinor here. These are these four components. Don’t mix them up with a four-vector. It’s not legal to say \\mu because \\mu would indicate that this is an object that transforms under boosts and rotations the same way as the four-momentum. But that’s not true.\nThis field transforms differently. It still has four components, but it’s a different object. It’s called a bispinor, it’s not a four-vector.\nIn order to make a scalar quantity out of this vector, we do this transformation. We take it, we transpose it so it becomes a row. We multiply by the first matrix on the left. This is the gamma matrix. We look at this; it is a matrix as well, because the gamma is a four-by-four matrix. The mass is a scalar. But here there is a four-dimensional identity matrix in order to have the correct dimensions.\nEssentially, that way you form the Lagrangian. Then you take the Lagrange equations and you find out that the equation of motion is the Dirac equation. We like very much condensed notation. Often this contraction, these gamma matrices, is noted with a slashed symbol, a slash through the matrices.\nSo this is actually often written as: the equation of motion is (i \\not{\\partial} - m) \\psi = 0 , the Dirac equation.\n\n\n\n\n\n\nKey formulas from this section:\n\nMaxwell Lagrangian Density: \\mathcal{L}_{\\text{EM}} = -\\frac{1}{4} F_{\\mu\\nu} F^{\\mu\\nu} , where F_{\\mu\\nu} = \\partial_\\mu A_\\nu - \\partial_\\nu A_\\mu .\nGauge Transformation: A_\\mu \\rightarrow A'_\\mu = A_\\mu - \\partial_\\mu \\chi , leaving F_{\\mu\\nu} invariant.\nQED Lagrangian with Fermions: \\mathcal{L}_{\\text{QED}} = \\bar{\\psi} (i \\gamma^\\mu \\partial_\\mu - m) \\psi - e \\bar{\\psi} \\gamma^\\mu \\psi A_\\mu - \\frac{1}{4} F_{\\mu\\nu} F^{\\mu\\nu} .\nDirac Equation: (i \\gamma^\\mu \\partial_\\mu - m) \\psi = 0 or, in slash notation, (i \\not{\\partial} - m) \\psi = 0 ."
  },
  {
    "objectID": "2024-Lecture-01.html#gauge-invariance-and-the-structure-of-interactions",
    "href": "2024-Lecture-01.html#gauge-invariance-and-the-structure-of-interactions",
    "title": "(2024) Lecture 1",
    "section": "6 Gauge Invariance and the Structure of Interactions",
    "text": "6 Gauge Invariance and the Structure of Interactions\nAnd finally we arrive at an important aspect of field theory: introducing interactions. So far, we have dealt with a theory that has no interactions. Photons have been moving by themselves without interacting with charge or anything else. The fermions here are also free-moving particles. Essentially, a particle starts moving, doesn’t see anything, and just propagates. It is a free particle with no interaction.\n\n\n\n\n\n\nFigure 2: This figure represents a Feynman diagram illustrating the coupling of a fermionic field  \\psi(x)\\$  to a gauge field \\ A_$ . The interaction occurs via the electromagnetic current j^\\mu(x) = \\bar{\\psi}(x)\\,\\gamma^\\mu\\,\\psi(x), which couples to the gauge field, showing how fermions interact with gauge bosons in the Standard Model.\n\n\n\nWe now want to introduce interaction. The way to do this is guided by the gauge principle.\n\nFor the gauge invariance of the electromagnetic field, it was the shift of the field A_\\mu .\nFor fermions, gauge invariance implies changing the phase of the wave function.\n\nThe wave function \\psi for the fermion has an observable absolute value squared, but its phase is not fixed. We should be able to update this phase, which is called a phase transformation.\nThe check for gauge invariance is to perform this phase transformation and see if your Lagrangian remains invariant. It’s intuitive that you should be able to update the phase.\nWhat is tricky is that the phase can be updated differently at every point in spacetime. We are not doing a global phase rotation for all fields. Instead, we decide for every point what the phase update is.\nThis local transformation is much different because we must now account for the derivative. When we see how the Lagrangian changes under this transformation, the derivative acts not only on \\psi but also on the spacetime-dependent phase, which generates an extra term.\nSo, the Lagrangian changes to itself plus an extra term. Let’s reason through it: The derivative acting on the transformed field \\psi' = e^{i Q \\alpha(x)} \\psi will bring down a factor like -iQ \\partial_\\mu \\alpha . This extra term breaks the invariance of the free theory.\nThe solution is to replace the ordinary derivative with the covariant derivative: D_\\mu = \\partial_\\mu - i Q A_\\mu\nThe total Lagrangian for quantum electrodynamics (QED) becomes: \\mathcal{L}_{\\text{QED}} = \\bar{\\psi} (i \\gamma^\\mu D_\\mu - m) \\psi - \\frac{1}{4} F_{\\mu\\nu} F^{\\mu\\nu}\nWhat we find is that for the free Dirac theory, the Lagrangian is not gauge invariant because it changes under the phase transformation. However, if we incorporate the gauge field A_\\mu and perform the gauge transformation for both fields simultaneously, the extra term gets compensated.\n\nThe fermion field transforms as: \\psi \\rightarrow \\psi' = e^{i Q \\alpha(x)} \\psi\nThe gauge field transforms as: A_\\mu \\rightarrow A_\\mu + \\partial_\\mu \\alpha\n\nThe change in the interaction term \\bar{\\psi} i \\gamma^\\mu Q A_\\mu \\psi , due to the shift in A_\\mu , exactly cancels the unwanted term from the phase transformation of \\psi .\n\n\n\n\n\n\nThis is a super important concept: the way fields and fermions interact is driven by gauge invariance. We demand the freedom to change the phase locally at every point in spacetime, and this requirement determines how the interaction must work. The resulting interaction term in the Lagrangian is A_\\mu J^\\mu , where J^\\mu = \\bar{\\psi} \\gamma^\\mu \\psi is the fermion current.\n\n\n\nFrom this Lagrangian, if you derive the equations of motion, you won’t get just the free Dirac equation. You will have a source term, showing it’s not a free-moving field—it interacts with photons. This gives us a consistent framework for interactions.\nThe gauge principle does more than just dictate how particles interact; it determines the entire structure of the interactions. Depending on the mathematical nature of the “phase” transformation, we get different fundamental forces.\n\nIf the phase is a scalar (a simple number), you get electrodynamics (QED). There is only one type of gauge boson: the photon.\nIf the phase is a 2x2 matrix (like the Pauli matrices), you get Yang-Mills theory, which describes the weak interactions with the W ^+ , W ^- , and Z bosons.\nIf the phase is a 3x3 matrix (like the Gell-Mann matrices), you get quantum chromodynamics (QCD).\n\nThe mathematical object for the phase transformation is connected to a Lie group (U(1), SU(2), SU(3)). The dimensionality of this transformation determines the “charge space” in which the fermion field \\psi can live. For example, in electroweak theory, the left-handed quarks (up and down) form a doublet under the SU(2) transformation.\nThe general form of a non-Abelian gauge transformation is: \\psi(x) \\rightarrow \\psi'(x) = e^{i g \\alpha^a(x) T^a} \\psi(x)\nHere, T^a are the generators of the group (e.g., Pauli matrices \\sigma^a/2 for SU(2)), and \\alpha^a(x) are the spacetime-dependent parameters.\nThe corresponding covariant derivative becomes: D_\\mu = \\partial_\\mu - i g T^a A_\\mu^a\nThis ensures invariance under these more complex local transformations and leads to theories where the gauge bosons themselves carry charge and can interact with each other."
  },
  {
    "objectID": "2024-Lecture-01.html#exponential-form-and-group-closure",
    "href": "2024-Lecture-01.html#exponential-form-and-group-closure",
    "title": "(2024) Lecture 1",
    "section": "7 Exponential Form and Group Closure",
    "text": "7 Exponential Form and Group Closure\nNow, the important point when working with two exponents is to ensure we are operating within a group. If I were to write the transformations without an exponential form, I could not guarantee that combining them would yield the same type of object.\nIt is a proven result in group theory that writing a group element in exponential form ensures the result remains within the group. Therefore, if you multiply one such object by another of the same type, the product corresponds to a third object of the same exponential form.\nFor those familiar with matrix exponentials, what is e^{i \\theta_a \\lambda_a} ? To find it, you must perform a Taylor expansion: \\exp(M) = \\sum_{n=0}^{\\infty} \\frac{M^n}{n!}\nand then multiply the matrix by itself repeatedly.\nThis specific matrix follows a simple pattern. I believe once you square it, the result becomes diagonal. Consequently, you can often truncate the infinite series after a certain number of terms.\nThis leads us to an even more intricate object. Here, \\lambda represents a Gell-Mann matrix, and there are eight such matrices in the SU(3) formalism.\nLet us write \\lambda_1 : \\lambda_1 = \\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}\nSo, what is e^{i \\theta \\lambda_1} ? It should be straightforward to compute using the series expansion, noting that \\lambda_1^2 is diagonal.\n\n\n\n\n\n\nThe exponential form U = \\exp(i \\theta_a \\lambda_a) is central to group theory in quantum chromodynamics (QCD). It guarantees closure under multiplication—the product of two SU(3) group elements remains an SU(3) element. For matrices like the Gell-Mann matrices, the Taylor series for the exponential often simplifies dramatically.\n\n\n\nI am tempted to take a shortcut. You could ask either ChatGPT or Wolfram Alpha for the answer, and it would provide it quickly. However, I am confident it is easy to derive if you think about it for a moment.\nYou may not have much time now, but I encourage you to familiarize yourself with these matrices. It is both enjoyable and crucial for this course."
  },
  {
    "objectID": "2024-Lecture-01.html#qcd-lagrangian-and-confinement",
    "href": "2024-Lecture-01.html#qcd-lagrangian-and-confinement",
    "title": "(2024) Lecture 1",
    "section": "8 QCD Lagrangian and Confinement",
    "text": "8 QCD Lagrangian and Confinement\nThe last concept in this subject is that the Lagrangian for Quantum Chromodynamics (QCD) is constructed to be invariant under the SU(3) gauge transformation.\nIts structure is not entirely different from previous gauge theories, but it has a very important distinction: the proliferation of indices. The dimensionality of objects is super important.\nOnce we have a generator T^a , where T^a = \\lambda^a/2 , it is a 3 \\times 3 matrix. Contracting it with a field yields another 3 \\times 3 matrix, which is diagonal in the color dimension. We must keep track of multiple dimensions: color, Lorentz, and the gluon field A^a_\\mu .\nAn instructive exercise is to recover the familiar terms from Quantum Electrodynamics (QED) from this framework; you will see they are essentially the color-stripped versions.\nOne crucial aspect of QCD is that it is fundamentally different because it contains a term that allows gluons to interact with themselves. Even in a theory without quarks, gluons and their self-interaction terms would remain.\nThis self-interaction term in the equations of motion means gluons behave profoundly differently from photons. These gluon self-interactions lead to the phenomenon known as confinement. The screening of color forces works in the opposite way to the screening of electric forces in QED.\nIn a proper field theory course, you learn that the strength of interactions depends on the energy scale at which you probe the system, a concept related to renormalization. Depending on the energy scale of your experiment, you effectively experience a different charge.\n\n\n\n\n\n\nThe QCD Lagrangian contains the strong coupling constant g_s , which is “bare” in the Lagrangian. However, the coupling you observe in interactions is not this bare constant—it changes with the energy scale. This running is described by the QCD beta function: \\beta(\\alpha_s) = \\frac{d\\alpha_s}{d\\ln Q} = -\\frac{\\alpha_s^2}{2\\pi} \\left( 11 - \\frac{2}{3} n_f \\right) + \\mathcal{O}(\\alpha_s^3)\nwhere \\alpha_s = g_s^2/(4\\pi) and n_f is the number of quark flavors. The negative sign is key: it means \\alpha_s decreases at high energies (asymptotic freedom) and increases at low energies (confinement).\n\n\n\nFor QED, the coupling constant becomes smaller as you probe shorter distances (higher energy). For the strong interaction, the coupling constant g_s becomes stronger as you reduce the energy scale.\nThis increasing strength at low energies is the reason hadrons can form. Gluons and quarks bind into hadrons at these small energy scales.\n\n\n\n\n\n\nFigure 3: The diagram shows the dependence of the strong coupling  \\alpha\\_s(Q)\\$  on the transferred momentum \\ Q$ . At high  Q\\$ , the coupling decreases, illustrating the property of asymptotic freedom. At low \\ Q$ , the coupling grows, leading to the non-perturbative regime of QCD and the phenomenon of confinement. The transition scale is set by  \\Lambda\\_{\\text{QCD}} \\sim 300\\ \\text{MeV}\\$ , and for \\ Q  $ perturbative methods fail, marking the domain of confinement and hadronization.\n\n\n\nThe strong interaction is such that it does not allow colored objects (like individual quarks) to escape; it confines them. The high-energy regime where the coupling is small is called asymptotic freedom.\nThe root cause of both confinement and asymptotic freedom is the gluon self-interaction. There is essentially no “free” theory for QCD; even without quarks, gluons interact. This self-interaction leads to confinement at low energy and asymptotic freedom at high energy. The latter regime is where we perform calculations for processes like Higgs physics, where large momentum transfers occur.\nAn aspect not discussed in detail today is what Quantum Field Theory (QFT) tells us about performing computations in perturbation theory. In QED, or in the asymptotic freedom regime of QCD where the coupling is small, you can expand your equations of motion and iterate using the fact that the coupling is small.\nThis leads to the perturbative approach, with its diagrammatic representation known as Feynman diagrams. Using these, you compute matrix elements.\nIn this course, we will often refer to the matrix element squared |\\mathcal{M}|^2 , which is related to the cross section \\sigma of a process. The general formula for a 2 \\to N scattering cross section is: \\sigma = \\frac{1}{2E_A 2E_B |v_A - v_B|} \\int \\left( \\prod_{f=1}^N \\frac{d^3p_f}{(2\\pi)^3 2E_f} \\right) |\\mathcal{M}|^2 (2\\pi)^4 \\delta^{(4)} \\left( p_A + p_B - \\sum p_f \\right)\nHere, \\Phi represents the flux factor, and D\\Phi stands for the integration over the final-state particle phase space.\nThe matrix element in QFT is the key object that relates theory to observables. It tells you how to compute quantities you can measure in an experiment.\nIntuitively, you can understand it this way:\n\nThe matrix element \\mathcal{M} gives the quantum mechanical amplitude for a transition from an initial state to a specific final state.\n|\\mathcal{M}|^2 is proportional to the probability for that specific configuration.\nTo get the total probability, you must sum over all possible final-state configurations (integrate over phase space D\\Phi ).\n\nYou will see an example next week of how, for a two-body decay, you explicitly count the number of configurations in the final state. The total probability (or decay rate) will be this matrix element squared, summed over all possible configurations.\nIn these calculations, you must also account for particle spins:\n\nSum over the spin states of the final particles.\nAverage over the spin states of the initial particles.\n\nThis is why for a process like A + B \\to N , we include averaging factors. If you are given a correctly spin-averaged matrix element, along with the 1/(2E) factors for incoming particles, you can immediately calculate the corresponding cross section.\nThe cross section \\sigma  has units of area (e.g., cm ^2 ). It represents the effective “target area” presented by one particle to another. If the colliding particles pass within this area, the reaction is likely to occur; outside of it, the reaction does not happen.\nThe decay width \\Gamma  is related to the lifetime \\tau of an unstable particle ( \\tau = 1/\\Gamma ). For a particle of mass M decaying to N final particles, the partial width is: \\Gamma = \\frac{1}{2M} \\int \\left( \\prod_{f=1}^N \\frac{d^3p_f}{(2\\pi)^3 2E_f} \\right) |\\mathcal{M}|^2 (2\\pi)^4 \\delta^{(4)}\\left( p - \\sum p_f \\right)\nWe will discuss this formula in more detail next time."
  },
  {
    "objectID": "2024-Lecture-01.html#course-logistics-and-introduction",
    "href": "2024-Lecture-01.html#course-logistics-and-introduction",
    "title": "(2024) Lecture 1",
    "section": "9 Course Logistics and Introduction",
    "text": "9 Course Logistics and Introduction\nIt’s really nice to have you all today. We are three minutes out, but let me quickly go over the logistics for the course.\n\nI have prepared notes for 11 lectures and 11 exercises (though there will be fewer exercises due to some breaks).\nA calendar is available on Moodle listing the anticipated dates for lectures and exercises. Closer to those dates, we can discuss shifting exercise sessions, but for now, we will keep the schedule as is.\nFor the exam, we will track the points you gain through the exercise sheets during the semester. Achieving 50% of these points will admit you to the examination.\nThe exam itself is designed to be straightforward: you will receive the problem one or two weeks in advance to think about it.\nDuring the exam, you will bring your solutions, and we will have a discussion about the material.\n\nI think the most important thing is to work on the exercise sheets during the semester. Let me show them to you.\n\nThere is a barcode to scan on the sheets.\nThere will be one or two problems per homework that you must solve.\nProcess: You write your solutions down, bring the solved sheets to the lecture, and place them in a designated box. We will check them, and the teaching assistants will return the marked sheets during the Thursday exercise sessions, where they will also discuss the problems.\nSchedule: Lectures are on Tuesday, and exercise sessions are on Thursday.\n\nWe will have a certain excursion during the semester. Although it’s fully booked, we may still find one or two places if you haven’t signed up.\n\nOffice Hours: I will hold office hours on Thursdays from 9:00 to 10:00 in my office, 1 3B and B. You can come to discuss anything related to the course. This will be written down officially.\n\nThere are several summer schools happening in our field this summer. These are exciting events if you’re considering going to a different country.\n\nOne is in Zurich, Switzerland, for eight weeks.\nAnother is in Krakow, Poland, for four weeks.\nApplications for these are still open for another couple of weeks.\nWe are also organizing one in Bochum in July for two weeks, aimed at people more advanced in the field.\n\nIf you are interested, just write me an email, and I can forward you the official announcement.\nRegarding the exercise sheets, I encourage collaboration. You can solve the sheets together and feel free to use any resources—ChatGPT, books, etc. The problems are standard and are meant for learning, not for checking you. How you learn is up to you.\nHere are some of the key textbooks I will be following:\n\nHalzen and Martin\nMartin Schmaltz (dedicated to Higgs physics)\nThomson’s Particle Physics\n\nThe exercise sessions start this week. Before leaving, please take the sheets. We printed 15 copies; there are two sheets, each with two pages. Take one for yourself.\n\n\n\n\n\n\nOn Today’s Problem: The first problem involves a coupled spring-pendulum system. The pivot point from which the pendulum hangs can slide. You will start from the Lagrangian, which is the kinetic energy minus the potential energy, and work towards finding relevant equations of motion.\nA typical Lagrangian for such a coupled system is: L = \\frac{1}{2} m \\dot{x}^2 + \\frac{1}{2} m l^2 \\dot{\\theta}^2 + m l \\dot{x} \\dot{\\theta} \\cos\\theta - \\frac{1}{2} k x^2 - m g l (1 - \\cos\\theta)\nHere, \\dot{x} is the time derivative of the sliding coordinate, and the terms represent kinetic energy from sliding and rotation, a coupling term, and potential energy from the spring and gravity.\n\n\n\nThis is a fun problem. You can put the derived equations into a differential equation solver. It’s not that easy in quantum field theory, but people still do it in their research.\nI rushed a bit at the beginning and end, so let me clarify the plan. I will reintroduce the QED Lagrangian and the QCD Lagrangian. We will calculate something for QED as well, time permitting.\n\n\n\n\n\n\nKey Lagrangian for QED: The Quantum Electrodynamics (QED) Lagrangian describes the interaction between fermions (like electrons) and the electromagnetic field. It is given by: \\mathcal{L}_{\\text{QED}} = \\bar{\\psi}(i\\gamma^\\mu D_\\mu - m)\\psi - \\frac{1}{4} F_{\\mu\\nu} F^{\\mu\\nu}\nIn this formula, D_\\mu = \\partial_\\mu + i e A_\\mu is the covariant derivative, and F_{\\mu\\nu} is the electromagnetic field tensor.\n\n\n\nI think starting with a simpler case and explaining how you calculate the terms is a good approach. I’ve prepared an exercise on gauge transformations for QED. This will provide a useful comparison to understand the added complexity that QCD brings. While QED explains most electromagnetic interactions, QCD introduces further complexity.\nI think we should proceed. Let’s get started."
  },
  {
    "objectID": "2024-Lecture-02.html",
    "href": "2024-Lecture-02.html",
    "title": "(2024) Lecture 2",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-02.html#estimating-hadronic-cross-sections",
    "href": "2024-Lecture-02.html#estimating-hadronic-cross-sections",
    "title": "(2024) Lecture 2",
    "section": "1 Estimating Hadronic Cross Sections",
    "text": "1 Estimating Hadronic Cross Sections\nSo how were the problems from the homework? I think when you study particle physics, you have several courses and some problems you do a few times because they appear first in nuclear physics and then maybe in particle physics or quantum field theory. You do Clebsch-Gordan coefficients four times because that’s how it is; it’s so important. So it will be homework for this week. There will be some Clebsch-Gordan coefficients and I hope you won’t have troubles with that.\nToday’s lecture we will discuss more about the symmetries in hadron physics. We will start with QCD as we discussed before with the SU(3) group and then move to the phenomenology of the SU(3) flavor group. We will discuss isospin and then discuss SU(3) flavor by interchanging up and down quarks. We will connect this to the Lorentz group which has SU(2) as a subgroup responsible for rotations. You will see how the addition of spin has something to do with the addition of the quarks inside hadrons.\nI will remind you of a lot of material from quantum mechanics that you’ve seen already and I hope it will be easy to follow. I particularly enjoy this part because this is something you can derive once you isolate yourself from books and the Internet. You can just sit and work through this really nice spin algebra.\nLet me start by reminding you of the last lecture with a few questions. The first one I would like to ask is to remind you of the previous lecture. How would you estimate the typical cross section of hadronic reactions? Just an order of magnitude.\nIf I want just an order of magnitude, what would I do? You would take the integral over all possible configurations of the matrix element squared. If you know the matrix element, then you can calculate the cross section by summing over all final states:\n\\sigma = \\frac{1}{4\\sqrt{(p_1\\cdot p_2)^2-m_1^2m_2^2}} \\frac{1}{N_i} \\sum_{f} |\\mathcal{M}_{if}|^2 d\\Phi_n\nThis will give you an exact value for the cross section in units of inverse GeV, which you can convert to centimeters squared. That’s a good approach, and this is what we will do once we know the matrix element.\nThis is for a particular process. Here I assume that I know the initial state and the final state. This matrix element gives me the transition from the initial state to the final state. This is the particular cross section for the initial state scattering to that specific final state. If I want the total cross section, I sum over all possible final states. Since different final states are orthogonal to each other, there is no quantum coherence or interference between them, so I can just sum them up. This is the precise method.\nBut I want a number. What is the scale we are dealing with? What should we expect for the size of a cross section? The units of cross section is the barn. One barn is equal to 10^{-24} \\, \\text{cm}^2 .\nSo how do we get the order of barns? What is the cross section? Imagine that you fix your target particle, say a proton, at a certain point and you hit it with another proton. The cross section gives you the effective area in space. Once you hit this little area, the reaction happens. If you go outside, the reaction does not happen. So you can think of it literally as an area in space.\nWhat would this area be? It is the effective area of the interaction. How do I estimate this? By the scale of the strong interaction, by the size of the proton. Think of it as a solid ball. The strong interaction range is about one fermi, which is 10^{-15} meters or 10^{-13} centimeters.\nThe cross section is on the order of \\pi R^2 . That’s the area. For a radius R \\approx 1 \\, \\text{fm} , we get \\sigma \\approx \\pi \\times (10^{-13} \\, \\text{cm})^2 . This is on the order of 10^{-26} \\, \\text{cm}^2 , or about 10 millibarns. If you calculate the total cross section for hadrons, you’re going to get values around that scale because the way they interact is by essentially overlapping their densities. If they are far away from each other, they never talk to each other. The strong interaction is really strong, but it’s short-range.\n\n\n\n\n\n\nKey Estimation: The geometric cross section provides a quick order-of-magnitude estimate for hadronic reactions: \\sigma \\approx \\pi R^2 . For a proton radius R \\approx 1 \\, \\text{fm} = 10^{-13} \\, \\text{cm} , this yields \\sigma \\approx 3 \\times 10^{-26} \\, \\text{cm}^2 , or about 30 millibarns. This scale is typical because the interaction probability is essentially unity within the effective area defined by the particle’s size."
  },
  {
    "objectID": "2024-Lecture-02.html#defining-charge-via-conserved-currents",
    "href": "2024-Lecture-02.html#defining-charge-via-conserved-currents",
    "title": "(2024) Lecture 2",
    "section": "2 Defining Charge via Conserved Currents",
    "text": "2 Defining Charge via Conserved Currents\nThe second question I thought of is: how do I define charge in QED and QCD?\nFirst, what is the charge in QED? We can pick the electric charge as the prime example.\n\n2.1 Defining Charge via Noether’s Theorem\nDo you remember how I defined the charge? If I’m given a field, say a spinor \\psi , how do I figure out its charge?\nThe charge is a conserved quantity for the particles. For a free moving field, its charge isn’t changing. This conservation arises from a symmetry, and Noether’s theorem tells us there is a corresponding conserved current.\nThe charge is defined as the integral of the zero component (the time component) of this conserved current: Q = \\int d^3x \\, j^0\nFor a Dirac field \\psi in QED, this conserved current from the global U(1) symmetry is: j^\\mu = \\bar{\\psi} \\gamma^\\mu \\psi\nwhere \\bar{\\psi} = \\psi^\\dagger \\gamma^0 is the Dirac adjoint.\nIf we look specifically at the charge density j^0 : j^0 = \\bar{\\psi} \\gamma^0 \\psi = \\psi^\\dagger \\gamma^0 \\gamma^0 \\psi\nSince \\gamma^0 \\gamma^0 = I (the identity matrix), this simplifies to: j^0 = \\psi^\\dagger \\psi\nThis is a positive quantity for Dirac field solutions.\n\n\n2.2 Reconciling Theory with Convention\nThis leads to an implication: if my \\psi field represents an electron, the Noether charge Q would be positive. At first, this seems like a contradiction because we know the electron has negative electric charge.\nThe resolution is that the conserved quantity Q from field theory is what’s fundamentally conserved. How we match it to our physical observations—like the electron having charge -e —is a matter of convention.\nWe define the observed charge to match our conventions: Q_{\\text{observed}} = -e \\int d^3x \\, \\psi^\\dagger \\psi\nSo, it doesn’t matter what constant you put in front; the crucial point from field theory is that this quantity Q is conserved. Scaling it by a factor (like -e ) to match experiment is our choice.\n\n\n\n\n\n\nThis discussion focuses on electric charge in QED, arising from a U(1) symmetry. A similar logic applies to color charge in QCD, but it originates from a more complex SU(3) gauge symmetry. The conserved currents in QCD involve color indices and matrices (like the Gell-Mann matrices T^a ), leading to eight conserved color charges."
  },
  {
    "objectID": "2024-Lecture-02.html#currents-and-charges-in-qed-and-qcd",
    "href": "2024-Lecture-02.html#currents-and-charges-in-qed-and-qcd",
    "title": "(2024) Lecture 2",
    "section": "3 Currents and Charges in QED and QCD",
    "text": "3 Currents and Charges in QED and QCD\nThe electromagnetic current in QED is often denoted as J^\\mu or j^\\mu , where: j^\\mu = -e \\, \\bar{\\psi} \\gamma^\\mu \\psi\nThis is the conserved Noether current associated with the U(1) gauge symmetry of QED.\n\n\n\n\n\n\nFigure 1: This figure represents the process of probing (measuring or interacting with) electric charge using a photon. In the context of the lecture, this illustrates how, in Quantum Electrodynamics (QED), a photon couples to a charged particle (such as an electron) via an interaction vertex, allowing experimental or theoretical access to the particle’s electric charge. The wavy line corresponds to the photon, and the adjoining straight line represents the charged particle (like an electron or quark). This is a fundamental concept because the photon is the mediator of electromagnetic interactions, and its coupling directly measures the conserved electric charge associated with the U(1) symmetry of QED, as discussed when introducing conserved currents and Noether’s theorem.\n\n\n\nThe factor -e is a convention to match our common definition of electric charge (electrons have negative charge). We could have defined electrons as positively charged, but that is not our standard convention.So, how do we define the analogous charge in Quantum Chromodynamics (QCD)? We follow a similar logic. In QED, a photon couples to a fermion via a vertex with \\gamma^\\mu , probing its electric charge through the current. (see Figure 1) For QCD, we want a vertex that probes color charge.\n\n\n\n\n\n\nThe color current in QCD is the conserved non-Abelian current associated with the SU(3) gauge symmetry. It couples to the gluon fields and describes the flow of color charge, which has eight components corresponding to the eight gluons: j^{\\mu,\\,a} = g_s \\, \\bar{\\psi}_i \\gamma^\\mu (T^a)_{ij} \\psi_j\nHere, g_s is the strong coupling constant, \\psi_i is the Dirac spinor field for a quark with a color index i = 1,2,3 (representing red, green, blue), and (T^a)_{ij} are the Gell-Mann matrices (the generators of SU(3) ) with a = 1, \\dots, 8 .\n\n\n\nThe construction is very similar:\n\nThe quarks are still fermions, so we use the Dirac spinor \\psi , but now it carries a color index.\nAt the vertex, we still have a \\gamma^\\mu , but we must also include a Gell-Mann matrix T^A to account for the non-Abelian SU(3) structure.\n\nTherefore, the QCD vertex factor becomes \\gamma^\\mu T^A . Given a specific quark field \\psi , we can insert it into the current j^{\\mu,\\,a} to compute its color charge.\nA key result is that the color charge of a quark is not a single number like “red,” “green,” or “blue.” Instead, for a given quark state, you compute a vector of eight numbers, one for each gluon type (each generator T^a ).\n\nHow many color charges does QCD have? Eight, corresponding to the index a on the current j^{\\mu,\\,a} .\n\nFor example, consider a quark with a specific color state in the fundamental representation: \\psi_{\\text{color}} = \\begin{pmatrix} 1 \\\\ 2 \\\\ i\\sqrt{3} \\end{pmatrix}\nTo find its color charge, you compute the eight numbers given by the expectation value of the color charge operator Q^a_{\\text{QCD}} = g_s \\int d^3x \\, \\psi_i^\\dagger \\gamma^0 (T^a)_{ij} \\psi_j for this state. Depending on which gluon (labeled by index a ) you use to probe the quark, you will get a different component of this charge vector. All eight components are computed using the same fundamental equation for the color current."
  },
  {
    "objectID": "2024-Lecture-02.html#su2-group-representations-generators-and-physical-charges",
    "href": "2024-Lecture-02.html#su2-group-representations-generators-and-physical-charges",
    "title": "(2024) Lecture 2",
    "section": "4 SU(2) Group: Representations, Generators, and Physical Charges",
    "text": "4 SU(2) Group: Representations, Generators, and Physical Charges\nSo then this comes from group theory. Here we deal with U(1), U(2), SU(2), and SU(3). Today we will be discussing SU(2). We are finishing here with a recap and moving to the discussion of today’s SU(2) group.\nThe SU(2) group is a super important symmetry in particle physics. First, it’s a group. Let’s start by discussing a few words on what a group is.\nA group is defined by a set of elements with a composition rule. For any element G in the group, there exists an inverse G^{-1} that is also in the group. For any two elements G_1 and G_2 , their composition G_1 \\circ G_2 also belongs to the group. Finally, there is an identity element.\nSU(2) is a special unitary group. It is the group of 2 \\times 2 unitary matrices with determinant one. An element U \\in SU(2) satisfies: U^\\dagger U = U U^\\dagger = I, \\quad \\det(U) = 1\nThe letter S stands for “special,” meaning the determinant is exactly one.\n\n\n\n\n\n\nThis is the fundamental representation of SU(2). A representation is a way of realizing the group’s elements as matrices acting on a vector space. The fundamental representation acts on a 2-dimensional (complex) vector space.\n\n\n\nWe could imagine listing all matrices in the group, but it’s not possible because the group is continuous and infinite. However, if we could list them, we would know how they compose—multiplying two group elements gives another group element. To construct other representations, we find a correspondence where each group element is mapped to a matrix in a different dimension (e.g., 3 \\times 3 or 4 \\times 4 ) while preserving the group multiplication rules. SU(2) is a nice group because it has a straightforward way of constructing representations of any dimension.\nAnother key concept from group theory is the Lie algebra. All group elements near the identity can be generated from the algebra. For SU(2), the generators are the Pauli matrices, \\sigma_1, \\sigma_2, \\sigma_3 . Any group element can be written in exponential form: U = \\exp\\left(i \\sum_{i=1}^{3} \\theta_i \\sigma_i\\right)\nwhere \\theta_i are real parameters.\nThe matrix exponential is defined via its Taylor expansion: \\exp(M) = I + M + \\frac{M^2}{2!} + \\frac{M^3}{3!} + \\cdots\nFor certain matrices where M^2 = 0 , the series terminates at I + M . In general, you compute it by summing the series.\nThe generators obey the defining commutation relations of the \\mathfrak{su}(2) algebra: [\\sigma_i, \\sigma_j] = 2i \\epsilon_{ijk} \\sigma_k\nThese relations hold for the generators in any representation of SU(2). For the fundamental representation, the Pauli matrices satisfy this exactly.\nThis group is important in two major physical applications:\n\nSpin: Spin is a quantity that arises from the SU(2) symmetry related to rotations in space. For a three-vector, rotations are given by 3 \\times 3 rotation matrices. For a spinor (like an electron’s wavefunction), rotations are represented by the Pauli matrices.\nFlavor Symmetry: We can apply SU(2) to quark flavor, specifically mixing up and down quarks. Continuous transformations between up and down quark states are characterized similarly to rotating a spinor, but in flavor space.\n\nThe first application (spin) you’ve likely seen in quantum mechanics. Before moving on, let’s connect these groups to a physical concept: charge.\n\nIn QED (U(1) symmetry), the conserved charge is electric charge.\nIn QCD (SU(3) symmetry), the conserved charge is color charge.\n\nWhat is the charge for our SU(2) symmetries? We can compute it using Noether’s theorem. For a symmetry with generators T^a , the conserved charge is: Q^a = \\int d^3x \\, \\psi^\\dagger T^a \\psi\n\nFor the rotation (spin) group: We replace T^a with the Pauli matrices. The resulting charges S_1, S_2, S_3 correspond to the projections of the spin along the x, y, and z axes. They are related to the particle’s helicity, which is the projection of spin along the direction of motion: h = \\frac{\\mathbf{S} \\cdot \\mathbf{p}}{|\\mathbf{p}|} .\nFor the flavor group: We again use Pauli matrices, but now the wavefunction \\psi describes quark flavor (up and down). The resulting conserved charge is a new quantity called isospin.\n\nIn summary, the SU(2) algebra, with its commutation relations [\\sigma_i, \\sigma_j] = 2i \\epsilon_{ijk} \\sigma_k , underlies the physics of both spin and isospin."
  },
  {
    "objectID": "2024-Lecture-02.html#su2-representations-and-the-construction-of-generators",
    "href": "2024-Lecture-02.html#su2-representations-and-the-construction-of-generators",
    "title": "(2024) Lecture 2",
    "section": "5 SU(2) Representations and the Construction of Generators",
    "text": "5 SU(2) Representations and the Construction of Generators\nI am given the commutation relation [J_i, J_j] = i \\varepsilon_{ijk} J_k . This defines the Lie algebra of the SU(2) group, where \\varepsilon_{ijk} is the Levi-Civita symbol.\nLet me write it more quickly. Essentially, this means the generators J_1 , J_2 , and J_3 satisfy three fundamental relations. From this algebra, you get the three generators.\nSo \\sigma_3 is the one that will give you the Pauli matrices as well. Just to remind you, the Pauli matrices in the fundamental ( j=1/2 ) representation are: \\sigma_1 = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}, \\quad\n\\sigma_2 = \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix}, \\quad\n\\sigma_3 = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}.\nFortunately, there is no different convention for these; we all use the same.\nIt’s extremely important to ask: how many of the generators of the group have a diagonal form? This is a fundamental group theory question. All generators must be traceless because the condition for a matrix to have determinant one implies a relation between the determinant and the trace. Essentially, for these group elements, the determinant is equal to the exponential of the trace.\nBut it’s important to know how many are diagonal, because this tells you what the eigenvalues and eigenvectors are that you are going to deal with. For SU(2), there is just one matrix that is diagonal in the standard basis. That’s why the group is called rank one. If you go to a group theory class, you will see fascinating classifications of all possible groups that heavily rely on the rank of the group. For SU(2) the rank is equal to 1.\nThis diagonal matrix will be used to construct and determine physical quantities from the states.\nWe are now going to act with these matrices on the states. We will use the ket notation |J M\\rangle for the states, which implies a unit vector with only one non-zero component at the position corresponding to M .\nWe will use a lot of this notation. The label J gives you the dimension of the representation. We will discuss the spin applications of this group first, where J determines the dimension in the sense that every component corresponds to a certain possible value of the projection of the spin. There are 2J + 1 possible projections.\nThe physical picture is that we have a spin vector \\mathbf{J} and a quantization axis. Along this axis, there are several possible projections: -J, -J+1, ..., +J . The number of them is 2J+1 .\n\nJ = 1/2 corresponds to the two-dimensional representation. That’s fundamental. The basis states are |1/2, 1/2\\rangle and |1/2, -1/2\\rangle .\nThose Pauli matrices (divided by 2) are the generators for this fundamental representation, where the matrix acts on the vector space spanned by these two states.\nAny other state, like |3/2, -1/2\\rangle , lives in a larger vector space. This is just notation for the vector space. We construct any group element acting on that space using our generators. Okay, let’s look quickly at the lowering and raising operators. We define: J_+ = J_1 + i J_2, \\quad J_- = J_1 - i J_2.\nThese are the raising and lowering operators.\n\n\n\n\n\n\n\nFigure 2: This figure represents the mathematical expression for the construction of ladder operators, which are essential tools in the spin algebra of the SU(2) group discussed in the lecture. Specifically, it shows the definition of the raising and lowering operators: [ J_+ = J_1 + i J_2 ] and [ J_- = J_1 - i J_2 ] These operators act on quantum states labeled by total spin J and projection M , raising or lowering the value of M by one unit. They are fundamental for building the algebraic structure of angular momentum in quantum mechanics and are directly related to the manipulation of spin and isospin quantum numbers, as well as understanding how multiplets (like baryons and mesons) are constructed and how their quantum numbers combine. The ability to use these operators enables the calculation of Clebsch-Gordan coefficients and the systematic construction of higher spin and isospin representations, which are recurring themes of the lecture.\n\n\n\nTheir action on a state will lower or increase the projection quantum number M .\n\n\n\n\n\n\nFigure 3: This diagram represents the action of the SU(2) spin algebra operators on angular momentum eigenstates labeled by the quantum number M (the projection of total angular momentum or isospin along the quantization axis). Along the horizontal axis, different M states are shown as points. - J_3 is the operator corresponding to the projection of the angular momentum; it leaves the state unchanged except for multiplying by M . - The upward arrow labeled J_+ indicates the raising operator, which acts on a state |J, M\\rangle to increase M by one unit ( J_+ |J, M\\rangle \\propto |J, M+1\\rangle ). - The downward arrow labeled J_- indicates the lowering operator, which decreases M by one unit ( J_- |J, M\\rangle \\propto |J, M-1\\rangle ). This figure demonstrates the ladder structure of spin or isospin multiplets as dictated by the SU(2) Lie algebra: raising and lowering operators connect the different states within the same multiplet, illustrating how the total space of representations is constructed. This is crucial for understanding how quantum numbers change under these operators—an essential part of both spin and isospin algebra in particle physics.\n\n\n\nThe J_+ operator acting on a lower state will move the vector to the upper one.\nTo demonstrate their properties, consider the product: J_+ J_- = (J_1 + i J_2)(J_1 - i J_2) = J_1^2 + J_2^2 - i[J_1, J_2].\nUsing the commutation relation [J_1, J_2] = i J_3 , this becomes: J_+ J_- = J_1^2 + J_2^2 + J_3 = \\mathbf{J}^2 - J_3^2 + J_3.\n\n\n\n\n\n\nThe action of the operators on an eigenstate |J M\\rangle is defined by: J_3 |J M\\rangle = M |J M\\rangle, \\quad \\mathbf{J}^2 |J M\\rangle = J(J+1) |J M\\rangle.\nThese operators commute with each other and, in quantum mechanics, with a rotationally invariant Hamiltonian, making them conserved quantities.\n\n\n\nTherefore, J_+ J_- acting on |J M\\rangle gives [J(J+1) - M(M-1)] |J M\\rangle . From this, we find the action of the ladder operators themselves:\nJ_+ |J M\\rangle = \\sqrt{J(J+1) - M(M+1)} \\, |J, M+1\\rangle,\nJ_- |J M\\rangle = \\sqrt{J(J+1) - M(M-1)} \\, |J, M-1\\rangle.\nThe square root factors ensure the states remain normalized. This structure is very closely related to what we will see later with Clebsch-Gordan coefficients.\nSo, let’s give the method to construct an arbitrary representation. Imagine you want an analog of the Pauli matrices for, say, a four-dimensional representation.\nFirst, construct J_+ . For a dimension d=4 representation, the corresponding spin is j , where 2j+1 = 4 , so j = 3/2 . The operator J_+ acts on a state and moves the projection up by one. Therefore, its matrix will have non-zero elements only on the first off-diagonal. For example, one element would be J_+ |3/2, 1/2\\rangle = \\sqrt{3} |3/2, 3/2\\rangle .\nIt’s often easier to construct J_- first. For instance: J_- |3/2, 1/2\\rangle = \\sqrt{3} \\, |3/2, -1/2\\rangle.\nThis tells you one specific matrix element. You fill the J_- matrix with the appropriate square-root factors on the first sub-diagonal, and then J_+ is its Hermitian conjugate.\nOnce you have J_+ and J_- , you recover the original generators: J_1 = \\frac{J_+ + J_-}{2}, \\quad J_2 = \\frac{J_+ - J_-}{2i},\nand J_3 is the diagonal matrix with eigenvalues m = -j, -j+1, ..., j on the diagonal.\n\n\n\n\n\n\nGeneral Algorithm: For a representation of dimension d = 2j+1 , the diagonal entries of J_3 are m from -j to j in integer steps. Use the formula J_\\pm |j, m\\rangle = \\sqrt{j(j+1) - m(m \\pm 1)} \\, |j, m \\pm 1\\rangle to populate the J_+ and J_- matrices, then construct J_1 and J_2 .\n\n\n\nNow the fun part: to get finite rotations, you exponentiate these generators. A general SU(2) group element is given by: U(\\boldsymbol{\\alpha}) = \\exp(-i \\boldsymbol{\\alpha} \\cdot \\mathbf{J}).\nYou don’t do this manually for large representations; you use a computer. What we have discussed so far is how to construct an arbitrary matrix representation of the SU(2) group."
  },
  {
    "objectID": "2024-Lecture-02.html#the-ξ-baryons-and-isospin-symmetry",
    "href": "2024-Lecture-02.html#the-ξ-baryons-and-isospin-symmetry",
    "title": "(2024) Lecture 2",
    "section": "6 The Ξ Baryons and Isospin Symmetry",
    "text": "6 The Ξ Baryons and Isospin Symmetry\nThe Ξ baryons (the Greek letter xi) are found in the Review of Particle Physics (PDG). Their quark content consists of two strange quarks and one light quark (either up or down).\n\nThe charged state is the Ξ⁻, with quark content (s s d) .\nThe neutral state is the Ξ⁰, with quark content (s s u) .\n\nIf you look at the PDG, these two particles have very similar properties—their masses are very close, and they are essentially the same particle, just with different electric charge.\nAnother example is the Ξ_c baryons.\n\nThe upper one in the isospin doublet is the Ξ_c⁺, with quark content (c s u) .\nThe lower one is the Ξ_c⁰, with quark content (c s d) .\n\nThese are all well-known, discovered particles. They have very similar masses and very similar lifetimes; essentially, they look like the same particle.\nThe third member of this family is the Ξ_cc baryon, a doubly-charmed state.\n\nThe upper state would be the Ξ_cc^{++}, with quark content (c c u) .\nThe lower state is the Ξ_cc^{+}, with quark content (c c d) .\n\nThe Ξ_cc^{++} ** has been discovered. However, the **Ξ_cc^{+}  is frequently discussed at conferences. One experiment reported a signal-like bump, but another experiment, LHCb, did not find it at the expected mass. Moreover, LHCb found a candidate for the Ξ_cc^{+} $ with a mass that was in conflict—about 40 MeV different from the mass of the state seen previously.\n\n\n\n\n\n\nWhy is this discrepancy scandalous? Because, so far, whenever you replace an up quark with a down quark (or vice versa), the particle’s mass almost does not change and its properties remain the same. This is due to strong isospin symmetry, which arises because the strong interaction is essentially blind to the difference between up and down quarks, given their very similar masses:$ m_u m_d .\nFor the _{cc} $states, it would be impossible for them to have significantly different masses under this symmetry. They must have nearly identical properties.\n\n\n\nIf you were to do a PhD on data analysis and discover the Ξ_cc^{+}$ , you would become a superstar in particle physics. There have been several PhD projects dedicated to searching for it. The search often involves a blind analysis: researchers define the reactions and a mass window to study, but they do not look at the data in that window until all selection criteria and procedures are optimized and fixed. Only then do they “unblind” the mass range.\nFour PhD students completed this rigorous process, pressed the button to unblind their data, and unfortunately found nothing there. The challenge is likely in picking the right decay channel. The Ξ_cc^{+} $ decays through many modes, and current statistics may be insufficient to see it in some of the rarer ones. The right decay mode probably exists—we just haven’t found it yet."
  },
  {
    "objectID": "2024-Lecture-02.html#symmetry-isospin-and-combining-representations",
    "href": "2024-Lecture-02.html#symmetry-isospin-and-combining-representations",
    "title": "(2024) Lecture 2",
    "section": "7 Symmetry, Isospin, and Combining Representations",
    "text": "7 Symmetry, Isospin, and Combining Representations\n\n7.1 Symmetry of QCD\nWhen we speak about the symmetries of the Lagrangian of QCD, we have in mind the Lagrangian itself. It has a term for the gluons and a term for the quarks. This term for the quarks—the Dirac term—contains a mass parameter. If the quark masses are not the same, this mass term will break the flavor symmetry.\nFor the u and d quarks, since they have almost the same masses, this symmetry is not broken by the mass terms, and it remains a good symmetry. In contrast, the mass of the strange quark is about 100 MeV. Therefore, the symmetry between the u, d, and s quarks—the SU(3) flavor symmetry—is only approximate.\n\n\n7.2 Isospin SU(2) Symmetry\nLet’s focus on the u and d quarks. Their near-equal mass means rotations in this two-dimensional flavor space are a good symmetry. This is the SU(2) isospin symmetry.\nThe transformation under this SU(2) group for a doublet like$ (u, d) $is given by: U(\\boldsymbol{\\alpha}) = e^{-i \\boldsymbol{\\alpha} \\cdot \\boldsymbol{\\tau} / 2}\nwhere \\boldsymbol{\\alpha} are the rotation parameters and \\boldsymbol{\\tau} are the Pauli matrices. This is mathematically identical to how we describe spin rotations in quantum mechanics.\n\n\n\n\n\n\nThe particle historically named cascade is denoted by the Greek letter Ξ (Xi). Because its decay chain resembled a cascade of particles, and the Greek name can be challenging to pronounce, it’s commonly just called “cascade” in particle physics.\n\n\n\nIn this framework, treating the u and d quarks as an isospin doublet (like spin-1/2), a particle like the cascade (Ξ) can be assigned an isospin wave function.\n\nThe dimension of the representation tells us the isospin quantum number. For a representation of dimension d , the isospin I is given by d = 2I + 1 .\nA doublet ( d=2 ) corresponds to isospin I = 1/2 .\nA quartet ( d=4 ) corresponds to isospin I = 3/2 .\n\n\n\n7.3 Combining Representations: Higher Multiplets\nA natural question arises: if we only have two quarks (u and d) in an I=1/2 doublet, how do we get particles with higher isospin, like I=1 or I=3/2 ?\nThe answer is by combining quarks. When we build composite particles (like baryons and mesons) from multiple quarks, we must combine their individual isospins (and spins) to find the total isospin of the composite system. The rules for combining isospin are identical to the rules for combining angular momentum (spin).\nAngular Momentum Addition Rule: When combining two systems with spins j_1 and j_2 , the total spin j can take values: j = |j_1 - j_2|, \\, |j_1 - j_2| + 1, \\, \\dots, \\, j_1 + j_2\nThis is written as j_1 \\otimes j_2 = |j_1-j_2| \\oplus \\cdots \\oplus (j_1+j_2) .\nKey Examples:\n\nCombining two spin-1/2 particles (e.g., two quarks in an isospin doublet): \\frac{1}{2} \\otimes \\frac{1}{2} = 1 \\oplus 0\nThis yields a triplet ( I=1 , dimension 3) and a singlet ( I=0 , dimension 1).\nCombining spin-3 and spin-2: 3 \\otimes 2 = 1 \\oplus 2 \\oplus 3 \\oplus 4 \\oplus 5\n\nA powerful consistency check is that the total dimension must be conserved: \\text{Dim}(j_1) \\times \\text{Dim}(j_2) = \\sum_{j=|j_1-j_2|}^{j_1+j_2} \\text{Dim}(j)\nFor example, with j_1=3 (dimension 7) and j_2=2 (dimension 5): 7 \\times 5 = 35 , and 1+3+5+7+9+11 = 35 .\n\n\n\n\n\n\nGroup theory tells us that when we combine representations, the resulting higher-dimensional space breaks into blocks that do not mix under symmetry transformations (rotations in isospin or spin space). Each block corresponds to a distinct total spin/isospin value. This is why, for instance, a system with total spin 3 can never rotate into a state with total spin 4. ### Practical Application & Final Notes\n\n\n\n\n\n\n\n\n\nFigure 4: This figure illustrates the concept of angular momentum projection in quantum mechanics, specifically in the context of SU(2) symmetry, as used for both spin and isospin in particle physics. The arrow labeled “spin” represents the angular momentum vector \\vec{J} (or “spin”), while the slanted line labeled “projection axis” represents the quantization axis—customarily chosen as the z -axis for calculations. The diagram emphasizes how, for a system with total angular momentum J , only certain discrete projections M along the chosen axis are allowed ( M = -J, -J+1, ..., J ). This is a direct visualization of the concept behind the eigenstates |J\\, M\\rangle , with M being the quantum number corresponding to the component of \\vec{J} along the projection axis. This foundational idea underlies much of the spin algebra, angular momentum addition, and isospin formalism discussed throughout the lecture.\n\n\n\nBefore moving to practical combinations, let’s briefly introduce the concepts of parity and charge conjugation.\nCrucial Distinction: It is vital not to mix up isospin and spin.\n\nWe use isospin SU(2) when constructing the flavor wave function of quarks inside a hadron.\nWe use the rotational SU(2) (from the Lorentz group) when combining the intrinsic spin of particles to understand angular momentum and related dependencies.\n\nThe mathematical algebra and combination rules are identical for both; the only difference is the physical context in which they are applied."
  },
  {
    "objectID": "2024-Lecture-02.html#parity-charge-conjugation-and-excitations-of-the-λc-baryon",
    "href": "2024-Lecture-02.html#parity-charge-conjugation-and-excitations-of-the-λc-baryon",
    "title": "(2024) Lecture 2",
    "section": "8 Parity, Charge Conjugation, and Excitations of the Λc Baryon",
    "text": "8 Parity, Charge Conjugation, and Excitations of the Λc Baryon\nSo parity and charge conjugation quickly number 3, 4, 5. The parity operator is doing inversion. Both parity and charge conjugation are operators that act on a state and produce another state.\nThe parity operator \\hat{P} is space inversion with respect to the origin. Charge conjugation \\hat{C} is the operator flipping all charges, turning a particle into its antiparticle.\nAnswer the question: how do wave functions of the particle change when you flip the wave functions through the origin? It’s rather intuitive. You have a vector, you flip through the origin all of the spatial components, and you get the vector pointing in the opposite direction.\nFor any particle you can find out what its parity is. The parity acting on the state gives the eigenvalue. Since you act twice and get the same state—you do flip twice you get the initial configuration—the eigenvalue of this operator is modulus 1. By convention we say it’s real and then we say it’s plus or minus one, either +1 or -1 : \\hat{P} | \\psi \\rangle = \\pm | \\psi \\rangle .\nConnecting to the charge conjugation operator, acting on this state you get the same state if the particle or the wave function that you consider here is neutral, and for the charged one you get a different one. That’s what prime here stands for.\nFor any particle you can look up what its charge conjugation is, but not for every particle you find it. For every particle you can find parity. Let me give you the convention. Essentially, if the particle is the neutral one in the multiplet, the charge conjugation is the one that’s C is a member of the multiplet.\nSo the charge conjugation C of \\pi^+ or \\pi^0 is equal to—the Particle Data Group is the book that has a lot of information on all particles—would tell you these quantum numbers. For any particle you find the J^{PC} , which is the spin, total spin of the particle, parity, and charge conjugation.\nThink for all of them, for baryons, for the charged ones, for the neutral ones, you’ll find that J^{PC} is—spin is equal to 0, minus, plus 1—and for the \\pi^+ , \\pi^- you also find that charge conjugation is positive, but it’s not an eigenstate of the charge because acting with charge conjugation on \\pi^+ you get \\pi^- . Still we assign the charge conjugation. It’s convenient for many applications according to the charge conjugation of the neutral particle multiplet.\nIn order to find what are the charge conjugation, parity, and the spin, total spin for the combination of particles, you do the following:\n\nFirst you find the total J by doing the spin algebra.\nSecond, parity is multiplicative.\nThird, charge conjugation is multiplicative.\n\nFor L equals one, (-1)^L is the orbital angular momentum contribution to the parity that one has to add. The total parity for a composite system is P_{\\text{total}} = P_1 P_2 (-1)^L .\n\n\n\n\n\n\nKey Formulas for Composite Systems\n\nTotal Parity: P_{\\text{total}} = P_1 P_2 (-1)^L , where P_1 and P_2 are the intrinsic parities of the constituent particles and L is their orbital angular momentum.\nTotal Angular Momentum: \\mathbf{J} = \\mathbf{L} + \\mathbf{S}_1 + \\mathbf{S}_2 , obtained via vector addition of spins and orbital angular momentum.\nCharge Conjugation for Neutral Mesons: C = (-1)^{L+S} , where S is the total spin of the quark-antiquark pair.\n\n\n\n\nI would like to give an example before you stop because it’s one of the most important skills I would like you to have: to be able to determine what are possible combinations of the spin and parity when you combine two particles. I’m going to draw the table that would list J^{PC} , J^P .\nFor the uncharged fermions, there is no charge conjugation, so I won’t have charge conjugation here. So J^P , for the combination of particles I start following out with the orbital angular momentum equals zero. I just combine spin and charge. In that case I have 1/2 , I add a 0, I get only 1/2 . The charge is multiplicative. Parity is multiplicative.\nI go to the first row adding 1 unit of angular momentum L = 1 . Then I go to the second row by adding 2 and the parity follows from the rule of (-1)^L .\n\n\n\n\n\n\nFigure 5: This figure schematically represents the excitation spectrum of a quantum system—such as the hydrogen atom or a hadron—organized by total angular momentum quantum number J and energy E . The horizontal axis shows J , the total angular momentum, while the vertical axis represents energy levels E . Each box indicates a particular quantum state characterized by its principal and orbital quantum numbers (such as 1S, 2S, 1P, 1D ) along with superscripts labeling the total spin/parity combinations (e.g., 1/2^+ , 1^+ , 3/2^- , 5/2^+ ). The figure illustrates how states with different total angular momentum (arising from combinations of orbital angular momentum L , spin S , and their Clebsch-Gordan addition) appear at distinct energy levels. For instance, the 1S state ( J=1/2^+ ) lies at the lowest energy, the 2S state ( J=1/2^+ ) at a higher energy, and the 1P multiplet splits into J=1/2^- and J=3/2^- , with the 1D state further splitting into J=3/2^+ and J=5/2^+ . Physically, this diagram encodes the spin algebra and angular momentum addition rules discussed in the lecture. The vertical structure reflects how energy depends on the excitation (principal quantum number and angular momentum), and the splitting along the J -axis exemplifies how spin and orbital angular momentum combine according to SU(2) symmetry and group theoretical rules. This is crucial for understanding the spectrum of composite systems (like hadrons or atoms) and for deducing possible quantum numbers for excited states in experimental spectroscopy.\n\n\n\nI start with 0, I run the angular momentum, it will be minus, minus, plus. That’s pretty much the excitation spectrum for Lambda baryons. I look at the Lambda baryon in the quark model. In the quark model means that now I consider my heavy quarks. There are no gluons any longer; they all condensate. Then quarks are heavy. Among these quarks there is a charm quark that’s heavy and it’s not part of our symmetry. There is u and d from the flavor consideration of the group can be in isospin 1, or it could be in isospin 0. That’s how we combine the isospin. This is a flavor part of the group.\nThere is a symmetry that holds for baryons. Since they are the same particle, u and d , as we agreed, they have to be in symmetric combination. If they are in isospin zero, they are entered antisymmetrically. So isospin zero is minus sign here. That’s why the spin combination must from the spin. They also have to be in the spin zero to have overall antisymmetry.\nI’m mixing up overall wave function for the baryon. Since the fermions have to be antisymmetrical, there is a color wave function that we might discuss at one point; it gives a minus sign. There is the spin wave functions. As we found out for the eta and for the… So S wave is symmetric. I’m missing a minus sign somewhere. This is the right answer. I’m missing a minus sign somewhere.\nThe isospin wave function is there. Then spin wave functions would be good corresponds to that spin, spin zero of the u and d . And that’s what.\nNow we can consider how this baryon is excited. We discussed already that one way of making different particles out of this guy is to interchange U and D. But since the \\Lambda_c is isospin zero, there are no other particles in this multiplet. It’s only one \\Lambda_c .\nThe other way to make different particles out of the \\Lambda_c is to excite the system. You can excite it radially, like the hydrogen atom, to make the object bigger. You probably remember the hydrogen atom. There is an n quantum number, the principal quantum number that tells you how big the system is. Essentially, what are the orbitals of the electron. You can do the same for \\Lambda_c . You can have 1s, 2s, and so on.\nThis one will be the ground state \\Lambda_c . This next one will be an excited, bigger \\Lambda_c . You would call it \\Lambda_c^{**} . I think we found this one. It’s pretty broad.\nYou can excite the system orbitally, putting orbital angular momentum between, let’s say, the ud pair and the heavy center of this sigma. That would correspond to the orbital excitations. Then it gives these one P \\Lambda_c states. We have found what the quantum numbers of these are.\nLooking at this, this would be the ground state of \\Lambda_c . These two are orbital excitations. It’s important to realize that when we do excitation of the system, we obtain different particles.\nIf you look at the PDG, you will see the names that we know of. We have discovered in experiments around seven different \\Lambda_c ’s. So the ground one, these two guys, these two guys, and this one, I think six. Then there is one high-end spectrum that we don’t know which multiplet it belongs to. These are, although listed as different particles, sort of excitations of the ground state \\Lambda_c ."
  },
  {
    "objectID": "2024-Lecture-02.html#spin-algebra-and-decay-partial-waves",
    "href": "2024-Lecture-02.html#spin-algebra-and-decay-partial-waves",
    "title": "(2024) Lecture 2",
    "section": "9 Spin Algebra and Decay Partial Waves",
    "text": "9 Spin Algebra and Decay Partial Waves\nSuper important. Learn how to construct this table—essentially, how to do spin algebra.\n\n9.1 Constructing the S Wave and Angular Momentum Addition\nWe start by constructing the S wave, where the orbital angular momentum L = 0 . Using Clebsch-Gordan coefficients is straightforward here. Adding one unit of angular momentum is also straightforward, but you must be careful not to mix up the procedure.\n\n\n\n\n\n\nWhen combining two systems with angular momenta j_1 and j_2 , the total angular momentum j can take values: j = |j_1 - j_2|, |j_1 - j_2| + 1, \\dots, j_1 + j_2\nThis is the Clebsch-Gordan series, fundamental for constructing spin wavefunctions and determining allowed states.\n\n\n\nIf you are already in an orbital angular momentum zero combination—and there are only a few of them—you must consider them separately. One combination spans several states, and another will span several different states.\nThe same procedure applies when you want to combine angular momenta in a decay.\n\n\n9.2 Applying This to a Particle Decay\nConsider the decay of a particle A : A \\to B + C\nWe know the quantum numbers:\n\nParticle A is 0^+\nParticle B is a vector, 1^-\nParticle C is 2^-\n\nWe can ask: What is the orbital angular momentum L in this decay? The decay is analyzed in the rest frame of particle A . Particle B goes in one direction, particle C goes in the opposite direction, defining a relative angle.\n\n\n\n\n\n\nIn a decay A \\to B + C , parity is conserved: P_A = P_B \\, P_C \\, (-1)^L\nwhere (-1)^L is the parity of the orbital state.\n\n\n\nIf you combine the two final-state particles in an S wave ( L = 0 ), the possible total spin-parity J^P is only 1^- . In a P wave ( L = 1 ), the parity would be positive. To reach the 2^- state, you need a D wave ( L = 2 ).\nTherefore, the partial wave for this decay is a D wave. I hope we get to practice this calculation—it’s very important.\n\n\n9.3 A Practice Problem: Hydrogen Atom in a Magnetic Field\nLet’s work on a problem. We have a hydrogen atom placed in a strong magnetic field. The task is to determine the excitation spectrum.\nConsider the following energy levels: 1s , 2s , 2p , 3s , 3p , 3d .\n\n\n\n\n\n\nIn the hydrogen atom, the orbital angular momentum quantum number l is restricted by the principal quantum number n : l &lt; n\nThis is why, for n=3 , we have l = 0 (s), 1 (p), and 2 (d), but no f-wave ( l=3 ).\n\n\n\nWe will restrict ourselves to s, p, and d waves only, excluding the f-wave. This is a beautiful puzzle—you may have seen it before. It’s the same problem.\n\n\n\n\n\n\nIn a strong magnetic field (Paschen-Back regime), the energy shift for a state with quantum numbers n, l, m_l, m_s is approximately: \\Delta E = \\mu_B B \\, (m_l + 2m_s)\nwhere \\mu_B is the Bohr magneton, B is the field strength, m_l is the orbital magnetic quantum number, and m_s = \\pm 1/2 is the spin projection.\n\n\n\nThe skill of constructing and using the spin-algebra table is something we want to practice more. I think we’re done, except for this problem."
  },
  {
    "objectID": "2024-Lecture-03.html",
    "href": "2024-Lecture-03.html",
    "title": "(2024) Lecture 3",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-03.html#lecture-recording-and-isospin-review",
    "href": "2024-Lecture-03.html#lecture-recording-and-isospin-review",
    "title": "(2024) Lecture 3",
    "section": "1 Lecture Recording and Isospin Review",
    "text": "1 Lecture Recording and Isospin Review\nSo my experiment with recording lectures has been relatively successful, so I could recover what I was saying. There is an open large language model from OpenAI that can translate audio to text called Whisper. Since the architecture is known, there is a C implementation that even runs parallel on Mac. You just download and execute it, and then you have a transcript of your speech.\n\n\n\n\n\n\nI record the lecture for myself, but it might be converted to a document. If someone would volunteer to type the questions and the equations there and check them, that would be helpful. But I don’t know what to do with that. Just for fun and for exploring the technologies, I will keep the recordings. It records only me in the sense that it’s mostly me who speaks, so don’t hesitate to talk back because this will not appear in the recordings anyway.\n\n\n\nWe will talk today about structure functions, the structure of hadrons, their internal composition, and how we know about them. But before going there I would like to start with a recap and have a few questions.\nQuestion 1: Without looking at the PDG, just from the quark content, tell me the isospin of these particles. The quark content here is: c \\bar{s} , b \\bar{q} , b \\bar{s} , q \\bar{q} .\nQuestion 2: What is the dimensionality of the isospin matrix that acts in a space of three quarks? If I treat the quarks as a wave function in two dimensions where spin up corresponds to the u quark and spin down corresponds to the d quark, what is the dimensionality of the matrix that acts in this space?\nQuestion 3: What are the irreducible representations of this matrix acting on these quarks? Essentially, how does my matrix from the previous point split into independent blocks that don’t talk to each other?\nWhen we talk about isospin we talk about light quarks.\n\nThe first meson, c \\bar{s} , doesn’t have light quarks, so it has isospin I = 0 .\nThe B meson, b \\bar{q} , has one light quark and therefore we deal with I = \\frac{1}{2} . (Here, q means a light quark. Often people use notations: capital Q is a heavy quark, little q or l is a light quark.)\nThe b \\bar{s} meson: if you talk about SU(3) , it belongs to the light quarks. If you talk about isospin, s is not included. So again, one light quark means isospin is \\frac{1}{2} .\nNext, P_c , which is the pentaquark observed in J/\\psi p . If you speak generally about pentaquarks that have three light quarks, what is the isospin? That means it can have the same as the delta group. The three quarks are the same as the delta group. What is the isospin of \\Delta ? It is \\frac{3}{2} . It’s the length of the vector, not the projection.\n\nWhen we assign isospin to a particle, we don’t yet speak about the charge. Different charge versions of the particle form a multiplet. When we say the B meson has isospin \\frac{1}{2} , it implies there are two B mesons: B^+ ( b \\bar{u} ) and B^0 ( b \\bar{d} ). For the antiparticle doublet, you fully conjugate: \\bar{b} u is B^- and \\bar{b} d is \\bar{B^0} .\nNow, the cascade b has isospin \\frac{1}{2} . The dimensionality is 2I + 1 = 2 , so there are two particles of this type. The charges: u quark has charge +\\frac{2}{3} , d quark has charge -\\frac{1}{3} . When I combine three of the lower row like ddd , I get charge -1 . If I combine three of the upper one like uuu , I get charge +2 . For b \\bar{s} , the combination gives charge zero.\nNow we come to the last one which has three quarks, so there are several combinations. For isospin \\frac{1}{2} , the possibilities are P_c^+ and P_c^0 . For isospin \\frac{3}{2} , there are four particles in the multiplet, like for \\Delta^{++} .\n\n\n\n\n\n\nFor a particle with isospin I , the number of charge states is given by: \\text{Number of states} = 2I + 1 . This arises from the quantization of isospin in analogy with angular momentum.\n\n\n\nAn interesting question: what is the antiparticle for the P_c^+ ? For baryons especially, it’s important to distinguish baryon to anti-baryon. They have a different quark component. You put a bar under the quarks.\nLet’s go to the irreducible representation of the three quarks. We already have essentially the dimensionality of the isospin matrix acting on three quarks. How do you get to the P_c^+ and P_c^0 with isospin? We only talk about SU(2) . For SU(2) there are no decuplets; decuplets and octets are for SU(3) .\nIf you’re mixing uud , you can’t get I = \\frac{3}{2} because of the third component. There is the total isospin. The state uuu has I_3 = +\\frac{3}{2} . We also get I_3 = -\\frac{3}{2} , I_3 = +\\frac{1}{2} , and I_3 = -\\frac{1}{2} . We also have uud and ddu . In order to construct these, we are going to act with a lowering operator on the combination.\nWe expand. What we would like to do now is ask: what is the quark flavor wave function? To do that we need to construct the basis of the irreducible representations. The easiest way is to start with the state you know for sure, which is the maximum spin. For isospin, this is the I = \\frac{3}{2} state. I can talk about spin or flavor; the notation is equivalent.\nI would like to act with the isospin lowering operator I_- . What comes here is \\sqrt{j(j+1) - m(m-1)} . Since j = m here, it simplifies to \\sqrt{2j} . So, acting with I_- on |u u u\\rangle gives a combination. This operator is a sum where these operators act only in the space indicated by the index. So I write I_- = I_-^{(1)} + I_-^{(2)} + I_-^{(3)} .\n\n\n\n\n\n\nFor a state with total angular momentum j and projection m , the action of the lowering operator J_- is: J_- |j, m\\rangle = \\sqrt{j(j+1) - m(m-1)} \\, |j, m-1\\rangle\nThis is used to construct states with lower isospin or spin projections from the highest-weight state.\n\n\n\nTo ensure we are dealing with a normalized state |\\frac{3}{2}, \\frac{1}{2}\\rangle , we calculate the product with itself. You use the fact that \\langle u|d \\rangle = 0 and \\langle u|u \\rangle = \\langle d|d \\rangle = 1 . Same flavor is normalized and different flavors are orthogonal.\nWe’ve got that combination and we can follow by acting with more lowering operators. Essentially, that way you find the wave function. It is \\frac{1}{\\sqrt{6}}(2|uud\\rangle + 2|udu\\rangle + 2|duu\\rangle - |uud\\rangle' - ...) . It’s super easy with the highest spin.\nRemember we discussed last time the spin of \\frac{4}{2} . That gave us the dimensionality 2S + 1 = 5 . Imagine I want to build this from spin \\frac{1}{2} particles. How many spin \\frac{1}{2} particles do I need? Essentially, I have many legs. If I ask you to give me S = \\frac{3}{2} , you use the creation and apply the lowering operator many times. One can automate the process.\nIt gets trickier when I ask for \\frac{9}{2} . Out of this combination I can have different spins. We agreed that simple spin algebra works. Essentially, when I combine many spin \\frac{1}{2} particles, possible combinations of the total spin have different multiplicities. The dimensionality of the matrix that acts on this space is 2^n , because each spin \\frac{1}{2} gives a two-dimensional representation. This 2^n is written as a tensor product.\nWe use different notation that comes from \\frac{1}{2} \\otimes \\frac{1}{2} \\otimes ... . Last time we saw this can be decomposed into irreducible representations as different combinations of spins. For a large n , this is a huge number. But one of these numbers is the spin \\frac{n}{2} plus different spins. Constructing a specific state like |\\frac{n}{2}, \\frac{3}{2}\\rangle is more difficult.\nLet’s come back to reasonable numbers. I would like to continue with question number two: the dimensionality of the isospin matrix that acts on the space of three quarks. This is for the isospin group, the same as adding \\frac{1}{2} three times.\nEvery quark brings a doublet. When we talk about dimensionality, we count the basis vectors in the representation. For every product space, there are two basis vectors. To count how many basis vectors I have in the tensor product, I multiply the number of basis vectors. In the space of three quarks there are 2^3 = 8 basis functions. One of them is |u d u\\rangle . Another is |u u u\\rangle , a third is |d d u\\rangle , and so on.\nThe dimensionality of the isospin matrix that acts on this space is 8, so we have an 8 \\times 8 matrix. But we can arrange these combinations so they transform under isospin rotations together without talking to other combinations. That’s called splitting into irreducible representations by grouping the basis functions into multiplets.\nTo answer the last question, we do spin algebra: \\frac{1}{2} \\otimes \\frac{1}{2} \\otimes \\frac{1}{2} . We combine \\frac{1}{2} and \\frac{1}{2} , which gives 0 \\oplus 1 . Then we combine this result with another \\frac{1}{2} . We check the dimensionality: 2 \\times 2 \\times 2 = 8 . The decomposition is \\frac{3}{2} \\oplus \\frac{1}{2} \\oplus \\frac{1}{2} , with dimensions 4 + 2 + 2 = 8 . So our 8 \\times 8 matrix can be split into blocks of 2, 3, and 4 dimensions.\n\n\n\n\n\n\nThe tensor product of three I = \\frac{1}{2} representations decomposes into irreducible representations of SU(2) : \\frac{1}{2} \\otimes \\frac{1}{2} \\otimes \\frac{1}{2} = \\frac{3}{2} \\oplus \\frac{1}{2} \\oplus \\frac{1}{2}\nThe dimensions satisfy: 2 \\times 2 \\times 2 = 4 + 2 + 2 = 8 .\n\n\n\nIt’s super clear how to construct the basis for the highest isospin state. You start with |u u u\\rangle and act with lowering operators. But how to construct the others? I’ll follow this. The basis for I = \\frac{3}{2} has 4 states. For I = \\frac{1}{2} we’re going to have two states. The principle we use is simple: the vectors we build should be totally orthogonal to what we’ve built already.\nLooking at the available quark combinations with I_3 = \\frac{1}{2} , we can construct an orthogonal combination by putting different signs between them. For example, a combination like \\frac{1}{\\sqrt{2}}(|u u d\\rangle - |u d u\\rangle) . You ensure normalization by calculating the scalar product. To construct the basis function for I = \\frac{1}{2}, I_3 = -\\frac{1}{2} , take the upper one and act with a lowering operator.\nThat way you find the wave function is \\frac{1}{\\sqrt{6}}(|u d d\\rangle + |d u d\\rangle - 2|d d u\\rangle) . Now that we figured out that out of our eight states, the 8 \\times 8 matrix acting on them splits into a block of four, a block of two, and another block of two.\nI look at my representation. I have two basis vectors and I need to construct the third one that is orthogonal to both. Essentially, if I have vectors (1,1,1) and (1,-1,0) , the one orthogonal to both is something like (1,1,-2) . Therefore, the first one is |u d u\\rangle - |u u d\\rangle . The lower one I get by applying the lowering operator. It’s typical spin algebra.\nWith spins we have discussed, it works not only for half-integer spins but also for integer spins. When I combine two spins, I’m dealing with spin 1. Using spin algebra, what I can get ranges from lowest to highest. The lowest would be 0, the highest is 2. I check the dimensionality: 3 \\times 3 = 1 + 3 + 5 = 9 . I can start constructing the representation basis. I start with the easiest one, which is a vector.\nAgain, the lowering operator gives four combinations. For total spin S = 2 , the state is symmetric. For S = 1 , I need a vector orthogonal to that. I just put a minus sign. Be careful when you do this for realistic examples or homework; you have to use Clebsch-Gordan coefficients when you lower operators. Clebsch might appear different here and there.\nFor the basis, Clebsch are the same. It’s \\frac{1}{\\sqrt{2}} always. These are typical ladder operators. You can check in the SU(3) chapter. Let’s figure out this line. I want to construct two for my Y and write this as combinations. You can look at the Clebsch-Gordan table and find these coefficients; they appear to be \\frac{1}{\\sqrt{2}} .\nWe are not done with writing the flavor and spin wave functions, but I would consider this. It’s just a matter of practicing spin algebra. This comes in many courses: quantum mechanics, particle physics, and group theory. For SU(2) it’s simple spin algebra. You need to think about dimensionalities and how you add spin to each other, and know a few recipes to construct these coefficients.\nIn order to proceed and talk about structure functions, we need the proton wave function, because that’s where the understanding of the internal structure of hadrons comes from. In the homework there will be other questions related to the delta internal structure. It is easier to start with the delta wave function.\nWe start with the symmetries of the baryon wave function. We have to operate in four spaces: color, space, isospin, and spin. The baryon wave function has color indices and must be color neutral, as all hadrons are. We have a space wave function that describes distribution in x and t . We have to operate with isospin and spin.\nIt is important to realize they are not simply factorizable in the general case. The wave function lives in the product of the four spaces and can mix them. You need a sum of components. The color wave function is a singlet, meaning it’s a scalar. Therefore, the color wave function can be factored out. There is a good argument why the space wave function is a scalar and can be factored out as well. I am not convinced myself, but one should find the argument in the literature.\nWhat remains is spin and isospin, and these two do not factorize. That’s a large dimensional representation. We deal with baryons with three quarks, and every quark has a spin. Every quark is the product of flavor and spin. It’s a product of three quarks, so we deal with a basis in six dimensions. It’s the same thing as before.\nTo build the representation of particles in these six dimensions, we act with the lowering operator. Starting with something we know with no ambiguities: the delta, which has spin \\frac{3}{2} . When Delta has spin \\frac{3}{2} , the only combination is |u u u\\rangle . The \\Delta^{++} with J_z = +\\frac{3}{2} . \\Delta^+ with J_z = +\\frac{1}{2} is obtained by acting with a lowering operator in the spin space. If we act with the lowering operator in the flavor space, we reduce the charge and obtain a different particle.\nWe need to act twice with the lowering operator in flavor space and once in spin space to get \\Delta^0 and \\Delta^- . The proton appears to be a wave function that is orthogonal. The decomposition is \\frac{1}{2} \\otimes \\frac{1}{2} \\otimes \\frac{1}{2} = \\frac{3}{2} \\oplus \\frac{1}{2} \\oplus \\frac{1}{2} . This is 4 states plus 2 states plus 2 states. The proton is made of the same quarks as delta but has isospin \\frac{1}{2} and spin \\frac{1}{2} . Therefore, we need a wave function orthogonal in both spin and isospin spaces.\nWe are not going to do that because it’s technically complicated. What we will do is explore symmetry. The baryon wave function must be totally antisymmetric under quark exchange. This is a new symmetry not related to SU(2) directly. We now swap dimensions: take one particle with its spin and isospin and swap with another.\nWe have a basis function we constructed, and we can examine them to see if they have certain permutation symmetry. For most, there is no symmetry; they are not eigenstates of permutation. Let’s see what we demand from the function. The total \\Psi must be antisymmetric under permutation: \\Psi(1,2,3) = -\\Psi(2,1,3) .\nThe color wave function is antisymmetric. To see this, you need to see how it looks. Color is transformed under SU(3) . In three dimensions there are three colors. The representation of SU(3) is more complicated. There are decuplets and octets from combining three quarks: \\mathbf{3} \\otimes \\mathbf{3} \\otimes \\mathbf{3} = \\mathbf{1} \\oplus \\mathbf{8} \\oplus \\mathbf{8} \\oplus \\mathbf{10} . The dimensions match: 27 = 1 + 8 + 8 + 10 .\nThe singlet is \\mathbf{1} and its wave function can be constructed. It’s easiest to start with the highest weight state for the decuplet. For the components that have red, green, and blue, you need a totally antisymmetric combination: \\frac{1}{\\sqrt{6}}(|rgb\\rangle + |gbr\\rangle + |brg\\rangle - |rbg\\rangle - |grb\\rangle - |bgr\\rangle) . All even permutations have a plus sign, odd permutations a minus sign. The color wave function is antisymmetric; swapping two gives a minus sign.\nThe space wave function is symmetric for the ground state baryons. They are all in the simplest symmetric configuration. Therefore, the combined spin and isospin wave function must be symmetric.\nLet’s do an example. To construct a wave function for a proton, we combine isospin \\frac{1}{2} and spin \\frac{1}{2} . Let’s examine some basis functions. Is it symmetric under permutation? If I swap particles 1 and 2, the function changes; it doesn’t have a certain symmetry. However, it might be symmetric under permutation of quarks 2 and 3.\nWe construct a spin wave function that has symmetry only on the permutation of 2 and 3. The proton wave function can be guessed by combining symmetric flavor with symmetric spin. But the total wave function must be antisymmetric under any two-particle exchange. If we use just one term, that would be illegal. The wave function goes into another function.\nWhen we combine three quarks, we get the spin \\frac{3}{2} representation and two spin \\frac{1}{2} representations. If I apply the permutation operator to the \\frac{1}{2} multiplet, it mixes with the other \\frac{1}{2} multiplet. The permutation operator is external to the rotation group. Therefore, to construct the proton, we need both of the two-dimensional multiplets.\nThe delta lives in the \\frac{3}{2} multiplet. Applying a permutation stays within the same multiplet. But for the proton, it lives in a mixture of the two \\frac{1}{2} multiplets. One has to do the algebra to find the answer.\nThe proton wave function is a combination. I memorize these components. The proton spin-up wave function is a combination of terms like |u u d\\rangle , |u d u\\rangle , |d u u\\rangle with different spin orientations. The coefficients in the basis come from ensuring overall symmetry. The normalization comes by summing the squares of coefficients: 4 + 4 + 4 + 6 = 18 , so the normalization factor is \\frac{1}{\\sqrt{18}} .\n\n\n\n\n\n\nThe proton wave function (spin-up, isospin-up) is a combination of quark spin-flavor states, ensuring overall symmetry under exchange when combined with antisymmetric color and symmetric spatial parts. For example: |p \\uparrow\\rangle = \\frac{1}{\\sqrt{18}} \\left[ 2|u\\uparrow u\\uparrow d\\downarrow\\rangle + 2|u\\uparrow d\\downarrow u\\uparrow\\rangle + 2|d\\downarrow u\\uparrow u\\uparrow\\rangle - |u\\uparrow u\\downarrow d\\uparrow\\rangle - |u\\uparrow d\\uparrow u\\downarrow\\rangle - |d\\uparrow u\\uparrow u\\downarrow\\rangle - |u\\downarrow u\\uparrow d\\uparrow\\rangle - |u\\downarrow d\\uparrow u\\uparrow\\rangle - |d\\uparrow u\\downarrow u\\uparrow\\rangle \\right]\nThis reflects the mixed symmetry in spin and isospin spaces required by the Pauli exclusion principle.\n\n\n\nWe have the wave function of the proton. Now we can evaluate cool properties of the proton. That came as a surprise.\nNow, let’s discuss studies of structure. One way we experimentally probe structure is to use electron scattering. The simplest first question we can answer is: what is the charge distribution inside the hadron? That’s done with an electron probing the charge.\nWhen we scatter an electron off a hadron, almost all variables are fixed. The center-of-mass energy is fixed, and one variable remains: the scattering angle. Therefore, the experiment on structure functions is electron-proton scattering. We measure the angular distribution. From it, we get insights on the proton charge distribution and magnetic moment. That’s called a scattering experiment.\nIt’s important to realize we write many variables, like Q^2 (momentum transfer squared), but it’s all related to one angle. You need the probability for the electron to scatter. The kinematics in the lab frame: the electron collides with the proton, and the electron goes to some direction. This is simple two-body kinematics. The only variable is the angle.\nWhat’s the probability for the electron to scatter with almost no change in direction compared to going perpendicular? Rutherford scattering gives a term like 1/\\sin^4(\\theta/2) , a huge peak at zero angle. Most of the time, the electron prefers to go straight.\n\n\n\n\n\n\nFigure 1: This figure illustrates the difference between elastic and inelastic electron-proton scattering, key processes in probing the internal structure of hadrons discussed in the lecture. - The top two diagrams depict elastic scattering, where an incoming electron ( e ) scatters off a proton ( p ), and both emerge as the same particles ( e' , p' ) after the interaction. In elastic scattering, the proton remains intact, and the kinematics (like the scattering angle \\theta ) determine the momentum transfer Q^2 . The angular diagram shows the initial and final directions of electron and proton, emphasizing the one-variable (angle) dependence of such experiments. - The lower diagram shows inelastic scattering, where the electron scatters off the proton, but the proton breaks up, producing a set of hadrons denoted by X . This process allows the study of the proton’s internal structure by measuring how the energy and momentum are distributed among the outgoing particles. Inelastic electron-proton scattering leads to the extraction of structure functions F_1(x,Q^2) and F_2(x,Q^2) , which reveal information about the distribution and dynamics of quarks inside the proton. Together, these diagrams summarize how scattering experiments are used to access information about hadron structure: elastic scattering measures overall charge and magnetic form factors (related to the proton’s charge and magnetic moment distributions), while inelastic scattering provides evidence for point-like constituents (quarks) inside the proton through the observation of deep inelastic structure functions.\n\n\n\nThe deviation from that behavior tells us about structure. That process is elastic scattering, where initial and final particles are the same.\nIn contrast, inelastic scattering is where the proton is dissociated. In elastic scattering, the proton stays intact. In inelastic scattering, the final state is many particles X . The differential cross section for elastic scattering of point-like particles is d\\sigma/d\\Omega \\propto 1/\\sin^4(\\theta/2) . An example is electron-muon scattering.\nIn QED, you calculate diagrams. The matrix element is \\mathcal{M} = \\bar{u}_3 \\gamma^\\mu u_1 \\cdot (g_{\\mu\\nu}/Q^2) \\cdot \\bar{u}_4 \\gamma^\\nu u_2 . For this course, we analyze it generally. The matrix element is a scalar. It’s obtained by contracting different Lorentz structures. The spinor has four components, contracted by gamma matrices.\nThis is point-like scattering. When we deal with the proton, we extend the vertex function with form factors. The dimensionality of this object is a simple function of Q^2 . It is convenient to introduce a combination: the electric form factor G_E(Q^2) and magnetic form factor G_M(Q^2) . They both are functions of Q^2 .\nIn non-relativistic theory, there is a straightforward interpretation. Those factors show the charge distribution. Q is momentum. There is a transformation: Q^2 = -q^2 , so q is the three-momentum transfer. We can transform to coordinate space by Fourier transform. The charge density \\rho(r) is the Fourier transform of G_E(q^2) : \\rho(r) = \\int \\frac{d^3q}{(2\\pi)^3} e^{i \\vec{q} \\cdot \\vec{r}} G_E(q^2) .\n\n\n\n\n\n\nThe charge distribution \\rho(r) is obtained from the electric form factor via Fourier transform: \\rho(r) = \\int \\frac{d^3q}{(2\\pi)^3} e^{i \\vec{q} \\cdot \\vec{r}} G_E(q^2)\nThis relates the momentum-space form factor to the spatial charge density.\n\n\n\nWhen I put q = 0 , the Fourier transform gives the normalization. So the normalization of the form factors is fixed: G_E(0) = 1 (the proton charge), and G_M(0) = \\mu_p (the magnetic moment).\n\n\n\n\n\n\nFigure 2: This figure represents the basic Feynman diagram for elastic electron-proton scattering. An incoming electron ( e ) interacts with a proton ( p ) via the exchange of a virtual photon (the vertical line connecting the two). The diagram highlights one of the main experimental probes of proton internal structure discussed in the lecture. In this process, the electron scatters off the proton by exchanging a photon, allowing physicists to study the charge distribution and form factors ( G_E and G_M ) of the proton. The amplitude for this process is modified by the proton’s internal structure, which is encapsulated in the form factors. Measurement of the angular distribution of the outgoing electron in such experiments reveals information about the spatial distribution of charge and magnetization inside the proton, providing crucial evidence for the non-point-like, composite nature of hadrons as described by the quark model and confirmed by analyses of structure functions in deep inelastic scattering. The process depicted here is foundational for understanding the structure functions F_1 and F_2 , and their relationship to the proton’s internal constituents (quarks) and the necessity of introducing symmetry concepts like isospin and color.\n\n\n\nThe magnetic moment is a quantity that reacts in a magnetic field. It is proportional to the spin of the particle: \\vec{\\mu} = g \\frac{e}{2m} \\vec{S} . For a point-like Dirac fermion, g = 2 . For the electron, the magnetic moment is \\mu_e = \\frac{e}{2m_e} . The same for a muon.\nBut for the proton, it’s not. The proton has spin \\frac{1}{2} , charge +e , mass m_p . That relation is completely different. There is a correction due to internal structure. The magnetic moment can be measured by analyzing G_M at Q^2 = 0 . One finds it’s quite an amazing number: approximately 2.79, not 1. It’s a large correction.\nIt comes from the quark model and is easy to see if you analyze the proton wave function. What could have gone wrong in our naive consideration? We know the proton is made of quarks. How will the equation be modified? Instead of the proton charge, we should use the charges of quarks ( +\\frac{2}{3}e, -\\frac{1}{3}e ). Instead of the proton mass, we should use the masses of the quarks. The spin is the same.\nThe answer is a combination. When we analyze the magnetic moment, we see internal structure. Therefore, what we put as charge and mass in the naive model is not correct. This number can be obtained by looking at the wave function.\nLet’s act with the magnetic moment operator on the proton. The operator for a baryon is the sum of quark contributions: \\hat{\\mu} = \\sum_{i=1}^3 \\frac{q_i}{2m_i} \\vec{\\sigma}_i . Act on |u u d\\rangle . The u quark has charge +\\frac{2}{3}e and mass m_u , the d quark has charge -\\frac{1}{3}e and mass m_d .\nWhen you act with the \\mu_z operator, you get a number. Doing the algebra for the full proton wave function, you figure out that once you act this operator, you don’t get the proton wave function back. The proton is not an eigenstate of the individual quark magnetic moment operator. You have to take the expectation value.\nLet’s make it clear with the quark model. Assume m_u \\approx m_d \\approx 300 \\text{ MeV} , and m_p \\approx 1 \\text{ GeV} . The calculation yields \\mu_p = \\frac{e}{2m_u} \\cdot \\frac{3}{2} . Comparing to the naive expectation \\mu_p^{\\text{naive}} = \\frac{e}{2m_p} , we get a factor of \\frac{m_p}{m_u} \\approx 3 . So we’ve got a factor of about three.\nWe can compare this result: part of it is three. Cool. We managed to understand the anomalous magnetic moment of the proton. But basically, this number is the ratio equal to mass of proton over mass of quark? It just turns out to be like this because for the neutron, the answer is approximately -1.91. So the anomalous magnetic moment for neutron is -1.91, for proton it’s +2.79. It’s not simply a ratio of masses; it’s an algebra of the charges and masses together.\n\n\n\n\n\n\nThe magnetic moment operator for a baryon is the sum of the magnetic moments of its constituent quarks: \\hat{\\mu} = \\sum_{i=1}^3 \\frac{q_i}{2m_i} \\vec{\\sigma}_i\nFor the proton, using m_u \\approx m_d , the magnetic moment is: \\mu_p = \\frac{4}{3} \\mu_u - \\frac{1}{3} \\mu_d = \\frac{4}{3} \\cdot \\frac{2e}{3 \\cdot 2m_u} - \\frac{1}{3} \\cdot \\left(-\\frac{e}{3 \\cdot 2m_d}\\right) = \\frac{e}{2m_u} \\cdot \\frac{3}{2}\nThis yields \\mu_p \\approx 2.79 \\, \\mu_N , where \\mu_N = e/(2m_p) is the nuclear magneton.\n\n\n\nI found it amazing. Essentially, what we showed today, just knowing SU(2) and spin algebra, we can build the proton wave function. Using this function, we can figure out the magnetic moment—something that experimentally shows the proton is not a point-like particle. In the homework, we have an exercise for delta, which is relatively similar, as well as dealing with the magnetic moment operator for the delta particle."
  },
  {
    "objectID": "2024-Lecture-03.html#evidence-for-three-quarks-and-color",
    "href": "2024-Lecture-03.html#evidence-for-three-quarks-and-color",
    "title": "(2024) Lecture 3",
    "section": "2 Evidence for Three Quarks and Color",
    "text": "2 Evidence for Three Quarks and Color\nAnother interesting point is understanding that there are three parts inside a proton. This evidence comes from scattering experiments.\nFrom deep inelastic scattering, we observe the distribution of form factors. The cross section is described by structure functions F_1(x, Q^2) and F_2(x, Q^2) , which reveal the proton’s internal structure:\n\\frac{d^2\\sigma}{d\\Omega\\, dE'} = \\frac{\\alpha^2}{4E^2\\sin^4(\\theta/2)} \\left[ \\frac{F_2(x, Q^2)}{\\nu} \\cos^2(\\theta/2) + \\frac{2F_1(x, Q^2)}{M} \\sin^2(\\theta/2) \\right]\nHere, \\nu = E - E' is the energy transfer, \\theta is the scattering angle, M is the proton mass, and \\alpha is the fine-structure constant. The key observation was that F_2 scales with the Bjorken variable x = \\frac{Q^2}{2M\\nu} , which provided direct evidence for point-like constituents—quarks.\nSo, how do we arrive at three quarks in the proton? It’s not about three colors yet, but three quarks.\nThe quark model magnetic moment of the proton can be calculated from three constituent quarks (two up and one down):\n\\mu_p = \\frac{4}{3}\\mu_u - \\frac{1}{3}\\mu_d\nwhere \\mu_u and \\mu_d are the magnetic moments of the up and down quarks. Explicitly, this is approximately:\n\\mu_\\text{proton} \\approx \\frac{2}{3} \\frac{2}{3 m_u} + \\frac{1}{3} \\frac{1}{3 m_d} + \\frac{1}{3} \\frac{1}{3 m_u}\nThis magnetic moment calculation was an early piece of evidence for three quarks, though the exact historical observable might be debated.\n\n\n\n\n\n\nThe Gell-Mann–Okubo mass formula from the Eightfold Way provided further evidence for quark organization. It relates the masses of hadrons within an SU(3) flavor multiplet: M = M_0 + aY + b\\left[ I(I+1) - \\frac{1}{4}Y^2 \\right]\nwhere M_0 is a base mass, Y is the hypercharge, and I is the isospin. This successful classification of mesons and baryons into octets and decuplets suggested an underlying three-quark structure.\n\n\n\nWhy does the model require exactly three quarks? This connects to the concept of color charge. The requirement for a totally antisymmetric baryon wavefunction under quark exchange forces the introduction of a new quantum number: color.\nThe total wavefunction is a product:\n\\Psi_{\\text{total}} = \\psi_{\\text{space}} \\otimes \\psi_{\\text{spin}} \\otimes \\psi_{\\text{flavor}} \\otimes \\psi_{\\text{color}}\nThe color part \\psi_{\\text{color}} must be the antisymmetric singlet state:\n\\psi_{\\text{color}} = \\frac{1}{\\sqrt{6}} \\left( RGB - RBG + BRG - BGR + GBR - GRB \\right)\nThis ensures the total wavefunction obeys \\Psi_{123} = -\\Psi_{213} under particle permutation, satisfying the Pauli exclusion principle for identical quarks. So, the need for three colors arose from spectroscopy and symmetry, not directly from the early scattering experiments, which at the time were not precise enough to reveal color."
  },
  {
    "objectID": "2024-Lecture-04.html",
    "href": "2024-Lecture-04.html",
    "title": "(2024) Lecture 4",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-04.html#computing-the-omega-baryon-magnetic-moment",
    "href": "2024-Lecture-04.html#computing-the-omega-baryon-magnetic-moment",
    "title": "(2024) Lecture 4",
    "section": "1 Computing the Omega Baryon Magnetic Moment",
    "text": "1 Computing the Omega Baryon Magnetic Moment\nToday’s lecture is dedicated to the experiments in spectroscopy and the computations of the kinematics for the experiments. But before going there, I would like to have a short recap of the last lecture and to pose two questions.\n\nCompute the magnetic moment in the current model of the Omega baryon.\nCompute the lowest 1s multiplet excitation multiplet of the Sigma particle parameter. This is essentially asking about isospin fermions.\n\nLet’s address the first question quickly because it’s rather straightforward.\n\n1.1 Calculating the Magnetic Moment of the Omega Baryon\nWhat is the quark content of the Omega baryon (Ω⁻)? It consists of three strange quarks (sss).\nThe total wave function lives in the tensor product space of color, flavor (isospin), and spin coordinates. For this magnetic moment calculation, we focus on the spin part, as the flavor part is trivial for three identical strange quarks.\nThe Omega baryon has spin J = 3/2 and positive parity. To calculate its magnetic moment, we use the maximal spin projection state, |s↑ s↑ s↑ \\rangle , where all three quark spins are aligned up.\n\n\n\n\n\n\nYou don’t need to use complicated spin configurations. For calculating the magnetic moment, you can simply take the state with the highest value of spin projection ( m_s = +3/2 ). Acting on this state with the magnetic moment operator yields an eigenvalue directly.\n\n\n\nThe total magnetic moment operator for the baryon is the sum of the magnetic moment operators for its constituent quarks: \\hat{\\mu}_z = \\sum_{i=1}^{3} \\hat{\\mu}_{i,z} = \\sum_{i=1}^{3} \\frac{e q_i}{2 m_i} \\sigma_z^{(i)}\nwhere for a strange quark, the charge q_s = -\\frac{1}{3}e and its mass m_s \\approx 500 \\text{ MeV} .\nSince all three quarks are identical, the magnetic moment of the Omega baryon is simply three times the magnetic moment of a single strange quark in this fully aligned state: \\mu_{\\Omega^-} = 3 \\cdot \\mu_s = 3 \\cdot \\left( \\frac{e q_s}{2 m_s} \\right)\nSubstituting q_s gives: \\mu_{\\Omega^-} = \\frac{e}{2 m_s} \\cdot (3 \\cdot (-\\frac{1}{3})) = -\\frac{e}{2 m_s}\nIn absolute terms, |\\mu_{\\Omega^-}| = \\frac{e}{2 m_s} .\n\n\n1.2 Interpretation and Scale\nOur intuition is correct: the magnetic moment is negative because the Omega baryon has a net negative charge. However, the mass in the denominator is the constituent quark mass (roughly 500 MeV), not the mass of the Omega baryon itself (about 1672 MeV).\nHow does this compare to an electron? The electron’s magnetic moment is \\mu_e = \\frac{e}{2 m_e} , with m_e \\approx 0.5 \\text{ MeV} . The ratio is: \\frac{|\\mu_{\\Omega^-}|}{\\mu_e} = \\frac{m_e}{m_s} \\approx \\frac{0.5}{500} = 10^{-3}\nThis shows the Omega baryon’s magnetic moment is about one thousand times smaller than the electron’s, due to the much larger mass scale of the strange quark.\nKey Lesson: With a simple, symmetric wave function, the evaluation is straightforward. You take the maximal projection state, apply the magnetic moment operator, and collect the contributions."
  },
  {
    "objectID": "2024-Lecture-04.html#excitation-pattern-of-the-σ_b-baryon",
    "href": "2024-Lecture-04.html#excitation-pattern-of-the-σ_b-baryon",
    "title": "(2024) Lecture 4",
    "section": "2 Excitation Pattern of the Σ_b Baryon",
    "text": "2 Excitation Pattern of the Σ_b Baryon\nNow, question number two is the excitation pattern of the \\Sigma_b baryon.\nI gave you a hint that the ground state of the \\Sigma_b baryon has the light diquark in the configuration with isospin I=1 and spin 1/2^+ .\nA bonus question is the isospin pattern: the partners of this baryon that one gets simply from isospin. You see that isospin equals 1. It immediately tells you the multiplicity of the isospin multiplet.\nHow many charge partners am I going to get for this baryon? Since isospin is one, there are three different projections, three different quantizations: I_3 = +1 , 0 , and -1 .\nWhat are the charges? I’m going to get \\Sigma_b^+ (uub), \\Sigma_b^0 (udb), and \\Sigma_b^- (ddb). Two up quarks and one bottom quark is like a proton, it has a charge of +1 . Once I act with a spin lowering operator, I reduce the charge by one unit. So this number tells you immediately how many particles and what their charges are. It is super simple.\n\n\n\n\n\n\nThe charges for the \\Sigma_b isospin triplet ( I=1 ) can be determined from the quark content or the Gell-Mann–Nishijima formula, Q = I_3 + Y/2 , where the hypercharge Y=1 . This gives:\n\nI_3 = +1 → Q = +1 ( \\Sigma_b^+ , uub)\nI_3 = 0 → Q = 0 ( \\Sigma_b^0 , udb)\nI_3 = -1 → Q = -1 ( \\Sigma_b^- , ddb)\n\n\n\n\nIn order to find the excitation pattern you need to work with spin, not with isospin. All three families are related by isospin, therefore their properties are going to be almost the same. Isospin is broken by different quark masses, but this breaking is tiny. I can talk about any of these three, and for all of them, the ladder of excitations is going to be the same.\nLet’s now pick one of them, put it as the lowest state as usual. For the diagram of the excitation pattern, we draw on the x-axis different quantum numbers, often the orbital angular momentum L . On the y-axis we put the energy or the rest mass of the state, which is the same as the mass of the hadron.\nTo obtain that, I start by combining the spins of the light quarks and the heavy quark.\n\n\n\n\n\n\nFigure 1: This figure schematically illustrates the excitation pattern of the \\Sigma_b baryon in terms of its quantum numbers and mass splittings, as discussed in the lecture. On the vertical axis is the energy or mass of the hadron (labeled “mass of hadron”), while the horizontal axis represents the orbital angular momentum L  of the system. - The lowest block at L=0 (S-wave) corresponds to the ground state multiplet of the \\Sigma_b , specifically the J^P=1/2^+ and J^P=3/2^+ states, arising from combining the light diquark spin ( s_\\ell = 1 ) with the heavy quark spin ( s_Q = 1/2 ). - The “radial excitation” arrow, labeled as approximately \\Lambda_{\\text{QCD}} , represents the energy gap between different principal quantum numbers (radial excitations), reflecting the typical QCD scale for hadronic structure. - The higher-lying blocks at L=1 (P-wave) display the P-wave excitation multiplet, with five total states corresponding to the possible combinations of spins and orbital motions: specifically, J^P=1/2^-, 3/2^- (from S=1/2 ) and J^P=1/2^-, 3/2^-, 5/2^- (from S=3/2 ). - The vertical separations correspond to mass splittings between S-wave and P-wave states (dominated by orbital excitation energy, of order \\Lambda_{\\text{QCD}} ), while the smaller splittings within each block are due to hyperfine interactions (suppressed by 1/m_Q for the heavy quark). - This diagram captures the overall structure of the baryon spectrum, encoding both the quantum number assignments and the physical energy scales discussed in the lectures on spectroscopy and multiplet structure.\n\n\n\nFor most hadrons, except the light meson sector, the radial excitation from 1s to 2s orbitals is much higher than the hyperfine splitting. Once you deal with heavy quarks, this is always true.\nThe energy difference from combining the spin of the heavy quark and the spin of the light quark comes with a suppression factor, 1/m_Q . When you combine the light diquark, which has spin s_\\ell=1 , and the heavy quark of spin s_Q=1/2 , for the S-wave you get two total spin combinations: J=1/2 and J=3/2 .\nGround State (S-wave) Multiplicity:\n\nCoupling s_\\ell = 1 and s_Q = 1/2 gives: J = \\frac{1}{2}, \\frac{3}{2} .\nParity is positive for S-wave states.\nThis yields the ground-state doublet: \\Sigma_b (J^P = 1/2^+) and \\Sigma_b^* (J^P = 3/2^+) .\n\nIf I want to calculate the multiplicity of states after adding one unit of orbital angular momentum, I have to consider both possibilities separately and do the spin algebra. For the P-wave ( L=1 ), combining with S=1/2 gives J^P = 1/2^-, 3/2^- . Combining with S=3/2 gives J^P = 1/2^-, 3/2^-, 5/2^- .\nP-wave ( L=1 ) Multiplicity:\n\nFor S = 1/2 : J^P = \\frac{1}{2}^-, \\frac{3}{2}^-\nFor S = 3/2 : J^P = \\frac{1}{2}^-, \\frac{3}{2}^-, \\frac{5}{2}^-\nTotal: Five distinct P-wave states (negative parity).\n\nThe multiplicity for the P-wave block is five. The multiplicity for the S-wave orbital is two. The lowest state is 1/2^+ and 3/2^+ . Then there are five states in the P-wave. That is what we call the excitation pattern.\nAll of these lines are different particles you find in the PDG. I don’t think the 2004 PDG had even the next one, because it was discovered recently. The \\Sigma_b^* entered there roughly 10 years ago. This was a discovery of the colliders.\nNow one word about energy splitting. The energy splitting between the S-wave and P-wave states is caused by the orbital excitation, with a scale given by quark dynamics of order \\Lambda_{\\text{QCD}} , roughly a few hundred MeV. That gives the elevation of the different blocks.\nWithin a block, the splitting between levels comes from the dynamics of the heavy quark spin. This splitting is suppressed inversely proportional to its mass, \\Delta E_{\\text{hyperfine}} \\sim \\kappa/m_Q . In the Lagrangian of effective theories, the spin-orbit interaction enters as a term like (C/m_Q) \\vec{S}_Q \\cdot \\vec{S}_\\ell .\nThe mass of the b quark is about 4 GeV. \\Lambda_{\\text{QCD}} is a few hundred MeV. The ratio between them is roughly 1:10. That is the difference between the orbital excitation energies and the hyperfine splittings within a multiplet.\nI think that if I remember correctly, the energy difference between \\Sigma_b with spin 3/2 and \\Sigma_b with spin 1/2 is on the order of 10 MeV."
  },
  {
    "objectID": "2024-Lecture-04.html#the-puzzle-of-exotic-hadrons",
    "href": "2024-Lecture-04.html#the-puzzle-of-exotic-hadrons",
    "title": "(2024) Lecture 4",
    "section": "3 The Puzzle of Exotic Hadrons",
    "text": "3 The Puzzle of Exotic Hadrons\nToday’s lecture is dedicated to kinematics and experimental techniques.\nI would like to start by overviewing what we do in physics on the experimental side. The direction of hadron spectroscopy has been extremely vibrant and fruitful in the last 10 years. It started around 2004, where it became a prominent and trending topic with the first observations of exotic particles.\nSince then, every few months, there would be new observations of hadrons that do not fit the simple quark model of mesons and baryons. Many experiments have since dedicated part of their programs to study these exotic hadrons.\nAcross the world, several large labs study particle collisions. One of the central, puzzling questions is to understand the very fabric of matter: how hadrons form, which combinations are possible, and what rules determine their excitation patterns and properties.\nWe have a quantum theory of strong interactions—Quantum Chromodynamics (QCD)—which seems to describe these interactions well. However, there has been no success in classifying and predicting large multiplets of exotic hadrons from first principles. We observe something and would like to predict its properties, but we cannot. This is due to:\n\nLimitations in our computational methods (e.g., Lattice QCD works well for ground states but not yet for excited states).\nThe intrinsic complexity of the theory itself.\n\nThere are many emerging phenomena. You can look at the QCD Lagrangian and see quarks and gluons, but these are not the direct degrees of freedom for describing hadrons. We seem to be facing a transition in the description of matter: from configurations where quark degrees of freedom are important, to configurations where hadrons themselves become the important degrees of freedom, binding together to form hadronic atoms or molecules.\nIn hadron spectroscopy, you face this borderline. You have a mixture of:\n\nCompact hadrons made of elementary quarks.\nLarger, sparse objects where hadrons bind into bigger entities (e.g., \\text{Hadron}_1 + \\text{Hadron}_2 \\rightarrow \\text{Molecule} ).\n\nSome hadrons are complicated exactly for this reason—they are in a mixed state of different configurations. Some properties require it to be a compact hadron, while others require it to be a sparse hadronic molecule. This is the area where, at the current stage, lattice QCD cannot help very much.\nExperiments around the world provide new data and insight. The way we understand this is by measuring the properties of hadrons and their decays. We want to:\n\nObserve hadrons in new decay configurations.\nMeasure the same hadron from different production mechanisms.\n\nMany labs explore these different mechanisms:\n\nExperiments like Belle (Japan) and BESIII (China) collide leptons (electrons and positrons). They annihilate to produce an intermediate state that decays. A typical reaction is: e^+ + e^- \\rightarrow \\psi \\rightarrow \\text{hadrons}, \\quad \\sqrt{s} \\sim 2 - 4 \\, \\text{GeV}\nThe study happens by analyzing these decay products.\nColliders at CERN, like the LHC, explore different mechanisms by colliding protons (large energetic conglomerates of quarks and gluons). This produces many particles, including long-lived particles with heavy quarks like B and D mesons.\n\nThese heavy mesons live long enough to travel a measurable distance, providing a clean environment to study hadrons. A B or D meson is produced, flies a few millimeters, and we track this with our detectors. We can then distinguish the primary vertex from the secondary decay vertex.\n\n\n\n\n\n\nKey Experimental Formulas The analysis in these experiments relies on fundamental kinematic formulas:\n\nRelativistic Energy-Momentum: E^2 = p^2 c^2 + m^2 c^4\nInvariant Mass: Used to reconstruct particle masses from decay products. M_{\\text{inv}}^2 = \\left( \\sum_i E_i \\right)^2 - \\left( \\sum_i \\vec{p}_i \\right)^2 c^2\nDecay Width & Lifetime: \\Gamma = \\hbar / \\tau\nResonance Cross-Section: Described by a Breit-Wigner form, \\sigma(E) \\propto 1/[(E - M)^2 + \\Gamma^2/4] , crucial for identifying short-lived exotic states."
  },
  {
    "objectID": "2024-Lecture-04.html#hadron-production-and-spectroscopy-experiments",
    "href": "2024-Lecture-04.html#hadron-production-and-spectroscopy-experiments",
    "title": "(2024) Lecture 4",
    "section": "4 Hadron Production and Spectroscopy Experiments",
    "text": "4 Hadron Production and Spectroscopy Experiments\nAnother class of experiments uses hadronic production. Essentially, shooting a hadron at a hadron without aiming to describe the kinematics exclusively. Those are mostly fixed-target experiments.\nI will be talking about the GlueX experiment at Jefferson Lab that has a photon beam, and the COMPASS experiment at CERN that has a pion beam. They both use a hydrogen target. The proton in the target and whatever particle comes in gets excited or scatters off the target.\n\n\n\n\n\n\nFigure 2: This figure schematically represents a generic hadronic collision in which two incoming particles interact and produce a multiparticle final state. The arrows entering the central blob on the left signify two incoming particles (such as protons, pions, photons, or leptons) participating in the collision. The arrows exiting on the right denote the production of several outgoing hadrons (“h” stands for a generic hadron), which may include resonances or decay products. In the context of this lecture, this diagram illustrates the general ** 2 \\to n process** central to experiments in hadron spectroscopy. Such processes underpin both inclusive and exclusive production mechanisms discussed above—for example, proton-proton collisions at the LHC, photon-proton collisions at GlueX, or e^+e^- annihilation at Belle and BES experiments. The central region represents the strong interaction dynamics, where the initial particles interact via Quantum Chromodynamics (QCD) to create various possible hadronic final states. Physically, this encapsulates the need to analyze multi-particle final states using Lorentz invariant phase space, mass-shell constraints, and energy-momentum conservation, as described in the kinematics section of the lecture. The schematic is a universal representation of the kind of events for which one computes invariant masses, studies resonance production, and counts independent kinematic variables.\n\n\n\nThat’s another way to study hadrons, by using different production mechanisms.\nI would say the third major way to study hadrons is to compute their properties from lattice QCD. That’s where a large piece of information comes from.\nLet’s overview the production mechanism and experiments. We start with BES.\n\nThe BES experiment (Beijing Spectrometer) is located at the BEPC (Beijing Electron Positron Collider) accelerator complex.\nIt collides electrons and positrons and is dedicated to studying hadrons in the Charmonium and Tau energy regions.\nIt is a symmetric collider; the electron has the same energy as the positron.\n\n\n\n\n\n\n\nFigure 3: This diagram represents the process of electron-positron ( e^+e^- ) annihilation and the subsequent production of hadrons in a collider experiment such as BESIII or Belle II. In this physical context, an electron ( e^- ) and a positron ( e^+ ) collide head-on, annihilate at the interaction point, and produce a virtual intermediate state—typically a photon or a vector meson with quantum numbers J^{PC} = 1^{--} . This intermediate state then decays into multiple hadrons, shown here as several arrows radiating from the interaction point. The image encodes the experimental environment where all produced hadrons fly out from the collision vertex and are detected. This is central to studies in hadron spectroscopy, where the kinematics and invariant mass distributions of the outgoing hadrons are analyzed to identify hadron resonances, determine their properties, and scan for new or exotic states. This mechanism serves as the basis for resonance production, allowing experiments to reconstruct resonance peaks and study the strong interaction via the analysis of the final-state hadrons.\n\n\n\nWhen the two particles collide, one interaction possibility is annihilation. The electron and positron produce a virtual photon that then couples to a hadron.\n\n\n\n\n\n\nQuantum Number Selection Rule In relativistic e^+ e^- collisions, the initial state quantum numbers restrict the produced virtual photon.\n\n\n\n\n\n\n\n\n\nFigure 4: This diagram depicts the fundamental process of hadron production in an electron-positron ( e^+ e^- ) collider experiment as described in the lecture. An electron ( e^- ) and a positron ( e^+ ) annihilate, producing a virtual photon ( \\gamma ). This virtual photon then couples to a hadronic resonance, specifically the J/\\psi meson, which has quantum numbers J^{PC} = 1^{--} , consistent with the selection rules discussed. The J/\\psi resonance subsequently decays into three pions: a positive pion ( \\pi^+ ), a negative pion ( \\pi^- ), and a neutral pion ( \\pi^0 ). In the context of the lecture, this process illustrates how e^+ e^- annihilation at experiments like BES or Belle/Belle II can be used to study hadron spectroscopy, especially by observing exclusive decay final states of vector mesons (like J/\\psi ) into lighter mesons. The depicted reaction is a clear example of both the initial state quantum number selection (only 1^{--} states can be directly produced) and the analysis of exclusive decays in spectroscopy experiments. The decay products ( \\pi^+ , \\pi^- , and \\pi^0 ) can be reconstructed to study the properties and dynamics of the J/\\psi resonance via invariant mass techniques and Dalitz plot analysis as highlighted in the lecture.\n\n\n\nCombining the spins and parities of the electron ( 1/2^- ) and positron ( 1/2^+ ) in an S-wave results in quantum numbers J^{PC} = 1^{--} . This means only hadronic resonances with J^{PC} = 1^{--}  (like the J/\\psi or \\psi(2S) ) can be directly produced in e^+ e^- annihilation.\n\n\n\n\n\n\nFigure 5: This figure schematically represents the total cross section \\sigma_{e^+e^- \\to X} measured as a function of the center-of-mass energy \\sqrt{s} in electron-positron annihilation experiments, such as those conducted at BES or Belle II. The vertical axis shows the cross section for producing hadronic final states X in e^+e^- collisions, while the horizontal axis is the center-of-mass energy, marked at characteristic values (e.g., 2 GeV, 4 GeV). The sharp peaks and structures correspond to the production of intermediate resonances, such as the J/\\psi and its excitations ( \\psi(2S) , etc.), which have J^{PC}=1^{--} and couple directly to the virtual photon in e^+e^- annihilation. The decomposition \\sigma_\\text{full} = \\sigma_{3\\pi} + \\sigma_{2D} + \\dots at the top indicates that the total cross section is the sum over exclusive cross sections for different final states. This plot physically illustrates how the hadronic production rate varies with \\sqrt{s} , highlighting resonance peaks where particle production is enhanced due to the formation of specific quark-antiquark bound states (quarkonia), a central method in hadron spectroscopy.\n\n\n\nTherefore, the BES experiment explores hadrons with the quantum numbers 1^{--} .\nThe experiment operates in two main modes:\n\nResonance Peak Data Taking: They set the beam energy to sit directly on a resonance peak (e.g., the J/\\psi ) and collect enormous amounts of data on its production and decays.\nEnergy Scan: They vary the beam energy point-by-point to measure the cross section \\sigma_{\\text{total}} as a function of center-of-mass energy \\sqrt{s} .\n\n\\sigma(e^+ e^- \\to R \\to \\text{hadrons}) \\propto \\frac{\\Gamma_{e^+ e^-} \\Gamma_{\\text{total}}}{(s - M_R^2)^2 + M_R^2 \\Gamma_{\\text{total}}^2}\nThe cross section is not homogeneous; it shows peaking structures (resonances) where the probability of interaction is higher. Researchers then analyze specific final states (like \\pi^+\\pi^- or 3\\pi ) from these data sets to extract hadron properties.\nThe Belle II experiment in Japan also uses an electron-positron collider (the SuperKEKB accelerator). Its primary goal was to study B mesons and CP violation, but its data is extremely valuable for hadron spectroscopy.\nIn contrast to symmetric colliders like BES, Belle II is an asymmetric collider. The electron and positron beams have different energies.\n\n\n\n\n\n\nFigure 6: This figure illustrates the production mechanism at the Belle II experiment, an asymmetric electron-positron collider. An electron beam with an energy of approximately 7 GeV collides with a positron beam of about 4.6 GeV. The collision center-of-mass energy is tuned to \\sqrt{s} \\approx 10.58\\,\\text{GeV} , which matches the mass of the \\Upsilon(4S) resonance (a bottomonium state with quantum numbers J^{PC} = 1^{--} ). The \\Upsilon(4S) then decays predominantly into a pair of B mesons ( B\\bar{B} ). The asymmetric beam energies provide a net boost to the produced B mesons, causing them to travel a measurable distance before decaying—this is essential for identifying secondary decay vertices. This process is a central feature of experimental techniques in hadron spectroscopy described in the lecture, specifically highlighting how asymmetric colliders like Belle II facilitate the study of B mesons through precise vertex separation and kinematic reconstruction.\n\n\n\n\nFor symmetric colliders: \\sqrt{s} = 2E\nFor asymmetric colliders: \\sqrt{s} = 2\\sqrt{E_- E_+}\n\nBelle II operates at a center-of-mass energy tuned to the \\Upsilon(4S) resonance mass ( \\sqrt{s} = 10.58 \\text{ GeV} ), which primarily decays to a B\\bar{B} pair.\n\n\n\n\n\n\nPurpose of the Asymmetric Design The energy asymmetry ( E_- \\neq E_+ ) creates a boost of the entire center-of-mass frame along the beam axis. \\beta_{\\text{CM}} = \\frac{|E_- - E_+|}{E_- + E_+}, \\quad \\gamma_{\\text{CM}} = \\frac{E_- + E_+}{\\sqrt{s}}\nThis boost gives the produced B mesons significant longitudinal momentum. As a result, they travel a longer, measurable distance ( L_{\\text{lab}} = \\gamma_{\\text{CM}} \\beta_{\\text{CM}} c \\tau ) from the primary interaction vertex before decaying. This secondary vertex separation is crucial for identifying and studying the short-lived B mesons.\n\n\n\nLet’s return to the spectrum. The J/\\psi is the first charmonium state discovered and appears as a clear peak in the e^+ e^- cross section. It is a 1^{--} state.\nThe charmonium spectrum is organized into multiplets based on radial ( n ) and orbital ( L ) excitations:\n\nThe lowest 1^{--} state is the J/\\psi(1S) .\nIts radial excitation is the \\psi(2S) .\nThe lowest state in the 1S multiplet is the \\eta_c(1S) ( 0^{-+} ).\nThe P-wave multiplet ( L=1 ) consists of the \\chi_{cJ} states: \\chi_{c0} ( 0^{++} ), \\chi_{c1} ( 1^{++} ), and \\chi_{c2} ( 2^{++} ).\n\nThe mass splittings within these multiplets arise from the detailed interactions in the quark model, including spin-spin and spin-orbit terms."
  },
  {
    "objectID": "2024-Lecture-04.html#from-charmonium-to-bottomonium-and-lhc-multiplicities",
    "href": "2024-Lecture-04.html#from-charmonium-to-bottomonium-and-lhc-multiplicities",
    "title": "(2024) Lecture 4",
    "section": "5 From Charmonium to Bottomonium and LHC Multiplicities",
    "text": "5 From Charmonium to Bottomonium and LHC Multiplicities\nTo reconstruct the schematics before we move away from Belle II, let me relate to what we just said before.\nEssentially it’s the same process: e^+e^- annihilation. So it’s a total cross section \\sigma(e^+e^- \\to \\text{everything}) .\n\n5.1 Quarkonium Spectroscopy: Charmonium to Bottomonium\nThe Belle experiment operated at energies covering the J/\\psi and the \\tau production threshold. Belle II operates in the region of bottomonium—the family of hadrons made of b\\bar{b} quarks, analogous to charmonium ( c\\bar{c} ).\n\nThe energy scale moves from ~3 GeV (KEK) to the ~10 GeV region.\nThe bottomonium system is very similar to charmonium, but the b quark is heavier.\nThis leads to a smaller hyperfine splitting between states. The mass difference is given by: \\Delta M_{\\text{hfs}} = M(1^{--}) - M(0^{-+})\nWhile the scale between major energy levels is still roughly a few hundred MeV, the states within each level are much more condensed in energy.\n\nThe new symbol here is upsilon ( \\Upsilon ). This is the vector particle (spin 1, quantum numbers 1^{--} ), making it the cousin of the J/\\psi .\n\nThe J/\\psi is the easiest charmonium particle to produce in e^+e^- annihilation due to its 1^{--} quantum numbers.\nIts counterpart in the bottomonium spectrum is the \\Upsilon .\nWhen scanning the energy, the states appear sequentially: \\Upsilon(1S) , \\Upsilon(2S) , \\Upsilon(3S) , \\Upsilon(4S) .\nThe \\Upsilon(4S) is notable because all these states are above the production threshold for b quarks (~9.46 GeV for the \\Upsilon(1S) ). ### Contrast with Hadron Colliders: The LHC Environment\n\n\n\n\n\n\n\nFigure 7: This figure illustrates the physical process occurring during a high-energy proton-proton collision at a hadron collider like the LHC. Each proton (denoted by “P”) enters the collision point with an energy of 7 TeV. Upon collision, the energy released results in the production of a very large number of secondary particles—on the order of 10^3 (about a thousand) per event. This reflects the high multiplicity environment typical of LHC collisions, as described in the lecture. The resulting particles are distributed in various directions with a broad range of momenta, most commonly with energies of a few hundred MeV. This environment is crucial for hadron spectroscopy studies, as it enables the observation and identification of rare and exotic hadronic states among the many produced particles. The diagram underscores the difference between the complex, high-multiplicity environment of hadron colliders and the cleaner environment of e^+ e^- colliders.\n\n\n\nProton-proton colliders like the LHC present a far more complex environment compared to clean e^+e^- annihilation.\n\nEnergy & Process: At the LHC, protons collide at energies like 7.7 TeV per beam. This is not a simple annihilation process; the beam remnants—primarily quarks and gluons—carry TeV-scale energies.\nEvent Multiplicity: The collisions produce a very high number of particles. The average multiplicity \\langle N \\rangle scales with the collision energy \\sqrt{s} : \\langle N \\rangle \\propto \\ln(\\sqrt{s})\nAt the LHC, a typical event has a multiplicity of roughly a thousand particles.\nParticle Spectrum: The transverse momentum ( p_T ) distribution of these particles follows an approximate exponential fall-off: \\frac{dN}{dp_T} \\propto e^{-p_T / \\langle p_T \\rangle}\nThis means there are many low-energy particles and a long tail extending to high energies.\n\n\n\n\n\n\n\nKey Scale: The typical energy scale for most particles produced in an LHC collision is on the order of hundreds of MeV. Even with thousands of particles sharing the total collision energy, the bulk of them have low momentum, establishing this few-hundred-MeV scale as characteristic of the hadronic environment."
  },
  {
    "objectID": "2024-Lecture-04.html#hadron-production-and-spectroscopy-at-lhcb",
    "href": "2024-Lecture-04.html#hadron-production-and-spectroscopy-at-lhcb",
    "title": "(2024) Lecture 4",
    "section": "6 Hadron Production and Spectroscopy at LHCb",
    "text": "6 Hadron Production and Spectroscopy at LHCb\nLHCb has been the most productive experiment in discovering new hadrons because of the high cross section. The cross section for two protons interacting, \\sigma_{pp \\to \\text{hadrons}} , is much larger than the cross section for annihilating two electrons, \\sigma_{e^+e^- \\to \\text{hadrons}} . This enables the detailed study of hadron production.\nThe two main production mechanisms explored in proton-proton collisions are:\n\nPrompt production: The particle of interest originates directly from the primary collision vertex.\nDisplaced production: The particle originates from the decay of a longer-lived particle, creating a secondary vertex. ### Studying Hadrons via Prompt Production\n\n\n\n\n\n\n\nFigure 8: This figure illustrates two main types of hadron production observed in high-energy collider experiments, as discussed in the lecture: prompt production and production from b -hadron ( B/\\Lambda_b ) decays. - Prompt production: The top part shows the direct (prompt) creation of hadrons at the primary interaction point. It depicts the decay of an excited charmed baryon, \\Omega_c^0 , which promptly decays into a cascade baryon \\Xi_c and a K^- meson. The \\Xi_c is then reconstructed from its decay products (e.g., proton, K^- , and \\pi^+ ), and a characteristic secondary vertex is indicated (displaced by several millimeters from the primary vertex), signifying the weak decay of the \\Xi_c . - Production from b -decays: The bottom part shows the production of hadrons via the decay of a long-lived b -hadron ( B or \\Lambda_b ). The B/\\Lambda_b baryon travels a measurable distance (on the order of \\sim 2 cm) from the primary collision before decaying. Its decay produces particles such as J/\\psi , a proton ( p ), and a kaon ( K ). The diagram notes ** P_c resonances** (pentaquark candidates observed in the J/\\psi p invariant mass spectrum) and ** \\Lambda^* resonances** (seen in the pK spectrum), illustrating how secondary vertices allow the identification of new excited hadronic states. The physical meaning centers on the use of vertex displacement to distinguish production mechanisms, the reconstruction of invariant mass spectra to identify resonances, and the importance of tracking kinematics in hadron spectroscopy studies as explained in the lecture.\n\n\n\nA prime example from charm production is the observation of the \\Omega_c baryons and the \\Xi_c^* and \\Omega_c^* baryons in prompt production. This is done by reconstructing \\Xi_c K combinations.\nThe \\Xi_c is the ground state of the cascade multiplet. For all such multiplets containing a charm or bottom quark, the ground state decays weakly because the heavy quark is stable under the strong interaction. The decay proceeds via the weak interaction, with a proper lifetime \\tau on the order of 10^{-10} seconds.\nFor a boosted particle with a momentum around 100 GeV, this lifetime results in a measurable flight distance. The decay length in the lab frame is given by:\nL = \\gamma \\beta c \\tau\nwhere \\gamma is the Lorentz factor and \\beta = v/c . This is sufficient to resolve its decay vertex from the primary vertex. The ground states of charm baryons fly millimeters; we resolve their decays from the primary vertex. In this case, the \\Xi_c produces a separate secondary vertex, displaced by roughly 5 or 6 millimeters.\nYou reconstruct this \\Xi_c secondary vertex by looking at combinations of charged particles, such as a proton, kaon, and pion. From the thousands of other particles, you then loop over all kaons and combine each with an identified \\Xi_c .\nBy examining these combinations, you find resonances that are produced promptly at the primary vertex and then decay into this pair. In the spectrum of the \\Xi_c K invariant mass, defined as:\nM_{\\Xi_c K}^2 = (E_{\\Xi_c} + E_K)^2 - (\\vec{p}_{\\Xi_c} + \\vec{p}_K)^2\nyou see distinct peaks. These peaks, five of them, correspond to the highest probability for producing a system, meaning the system resonates at a frequency corresponding to excited states in the \\Omega_c spectrum.\n\n\n\n\n\n\nIdentifying the State via Strangeness: The \\Xi_c has quark content csu and contains one strange quark (s), giving it strangeness S = -1 . The K^- has quark content s\\bar{u} and strangeness S = -1 . Therefore, \\Xi_c K combinations have a total strangeness of S = -2 . The resonances appearing in this spectrum have quark content css , which is precisely the \\Omega_c baryon.\n\n\n\n\n6.1 Studying Hadrons via Displaced Production\nAnother method is to look at separate secondary vertices from B hadrons. The ground-state hadrons containing a b quark are the B mesons and the \\Lambda_b baryon. These are easiest to produce from the fragmentation of the initial b quark.\nSince they are ground states, they also decay weakly. Their proper lifetime is longer, on the order of 10^{-9} seconds. When boosted, they produce a secondary vertex a few centimeters away from the primary interaction point, for example, two centimeters.\nThis flight distance cleanly separates the decay we want to study from the primary interaction vertex, making the kinematics very clean. You reconstruct the final-state particles, determine the decay length and the momentum of the B hadron, and study its isolated decay. (see Figure 8)\nResonances in this case appear within the decay products of the B or \\Lambda_b . A prominent recent example, which led to the discovery of pentaquark states, is the decay:\n\\Lambda_b \\to J/\\psi \\, p \\, K^-\nThis is a three-body decay. You start with the \\Lambda_b and look at the exclusive combination of the final-state particles: J/\\psi , proton, and kaon. These particles can resonate at different masses.\n\nIf you look at the invariant mass spectrum of the proton and kaon, M_{pK}^2 = (p_p + p_K)^2 , you see bumps corresponding to known \\Lambda resonances.\nIf you look at the invariant mass spectrum of the proton and J/\\psi , M_{J/\\psi p}^2 = (p_{J/\\psi} + p_p)^2 , you do not expect any known resonances. However, resonant peaks are still observed.\n\nThese peaks in the J/\\psi\\, p spectrum correspond to pentaquark resonances, meaning they are combinations of five quarks: u, u, d, c, \\bar{c} ."
  },
  {
    "objectID": "2024-Lecture-04.html#fixed-target-experiments-and-light-hadron-spectroscopy",
    "href": "2024-Lecture-04.html#fixed-target-experiments-and-light-hadron-spectroscopy",
    "title": "(2024) Lecture 4",
    "section": "7 Fixed-Target Experiments and Light Hadron Spectroscopy",
    "text": "7 Fixed-Target Experiments and Light Hadron Spectroscopy\nNow let’s quickly overview fixed-target experiments and the techniques used there.\nI will have three examples.\n\nThe GlueX experiment at Jefferson Lab operates with a 9 GeV photon beam hitting a liquid hydrogen target, which is essentially a liquid way of preparing protons as a target.\nThe COMPASS experiment at CERN explores hadron structure with a beam of pions, also using a liquid hydrogen target.\nThe CB-ELSA/TAPS experiment at Bonn uses a 2 GeV photon beam.\n\nWith these energies, we are not talking about bottom or charm quark production. Most of these experiments are focused on light hadron spectroscopy.\n\nCOMPASS studies light hadrons like protons, kaons, and light mesons.\nGlueX does similar physics but with a different setup, beam, and energy.\nCB-ELSA/TAPS also studies light mesons in a fixed-target configuration.\n\n\n\n\n\n\n\nThe center-of-mass energy available in these fixed-target collisions is a key kinematic quantity, given by: \\sqrt{s} = \\sqrt{m_{\\text{beam}}^2 + m_{\\text{target}}^2 + 2 E_{\\text{beam}} m_{\\text{target}}}\nFor photoproduction experiments like GlueX and CB-ELSA/TAPS, the threshold photon energy to produce a particle of mass m_X from a proton target is: E_{\\gamma}^{\\text{th}} = \\frac{m_X^2 - m_p^2}{2 m_p}\n\n\n\nThe event rate in these experiments depends on the luminosity. For a fixed-target setup, the luminosity is \\mathcal{L} = \\Phi \\, n \\, L , where \\Phi is the beam flux, n is the target number density, and L is the target length."
  },
  {
    "objectID": "2024-Lecture-04.html#two-mechanisms-in-fixed-target-experiments",
    "href": "2024-Lecture-04.html#two-mechanisms-in-fixed-target-experiments",
    "title": "(2024) Lecture 4",
    "section": "8 Two Mechanisms in Fixed-Target Experiments",
    "text": "8 Two Mechanisms in Fixed-Target Experiments\nIt is important to realize that there are two different mechanisms involved when you deal with fixed-target experiments at intermediate energy. These are not the same.\nThe first process is diffraction and the second one is s-channel scattering. Which process happens when you collide two particles is determined by the energy. ### Diffraction vs. s-Channel Scattering\n\n\n\n\n\n\nFigure 9: This figure illustrates the two primary physical processes occurring in fixed-target hadron experiments at intermediate energies: diffraction and s-channel scattering. - On the left, the diagram represents diffraction, where an incoming photon ( \\gamma ) interacts with a stationary proton ( p ) via the exchange of a color-neutral gluonic field, phenomenologically described as a Pomeron. This process is characteristic at higher energies (around 20 GeV), where the proton acts as a source of strong interaction fields. The photon is excited through interaction with the gluonic field, producing a final hadronic state, with the proton typically remaining intact. - On the right, the diagram depicts s-channel scattering, which occurs predominantly at lower energies (2–3 GeV). Here, an incoming pion ( \\pi ) collides with a proton ( p ), and both particles can resonate together via an intermediate state (the “X” in the middle), forming a true resonance. The final state contains specific outgoing hadrons resulting from this short-lived intermediate state. These processes are distinguished by their production mechanisms: diffraction involves exchange of a Pomeron (gluonic field) and typically dominates at higher energies, while s-channel scattering proceeds through the formation of a resonant intermediate state and is more prevalent at lower energies. This distinction is crucial for understanding hadron production and excitation patterns in experiments like GlueX and COMPASS, as described in the lecture.\n\n\n\n\nDiffraction: This process uses the proton as the source of the strong interaction field. The proton sits and emits gluons. A pion or a photon comes and interacts with these gluonic fields and gets excited. The excited state X then flies for a bit and decays.\nWhen we say “for a bit,” it’s not a physical flight in the detector. We are talking about strong interactions and hadronic resonances. Light hadronic resonances live for about 10^{-25} seconds, which is not sufficient time at these energies to move away from the primary vertex. However, on diagrams we sketch them as separate particles.\ns-Channel Scattering: This process is more plausible at lower energies, typically around 2–3 GeV. Here, the proton and the incoming beam (pion or photon) can resonate at a specific frequency.\n\nFor fixed-target kinematics, experiments like COMPASS separate the regime of diffraction from the regime of s-channel production to study baryonic excitations.\n\n\n\n\n\n\nThe exchanged object in diffraction is not a single gluon (the proton must remain color neutral). It is a color-neutral gluonic field, described phenomenologically by the Pomeron. The Pomeron is not a fundamental particle found in the Particle Data Group (PDG) listings but is a useful way to model this interaction.\n\n\n\n\n8.1 Exclusive vs. Inclusive Processes & Kinematic Counting\nWe now move to discussing exclusive reactions, where all final-state particles are measured ( 2 \\to n ). This is in contrast to inclusive processes, where a system is produced alongside many other particles that are not measured.\nTo analyze an exclusive process, we need to count its independent kinematic variables. The method is:\n\nCount the independent components of all particle momenta.\nSubtract constraints from energy-momentum conservation.\nOptionally subtract degrees of freedom fixed by choosing a specific reference frame.\n\nExample: A 2 \\to 3 Process\n\nEach of the 5 particles has a four-momentum p_i^\\mu = (E_i, \\mathbf{p}_i) .\nThe mass-shell condition p_i^2 = E_i^2 - \\mathbf{p}_i^2 = m_i^2 reduces each four-vector to 3 independent components.\nEnergy-momentum conservation, \\delta^4(P_{\\text{initial}} - \\sum p_i) , imposes 4 constraints.\n\nThe count before fixing a frame is: N_{\\text{vars}} = (5 \\text{ particles}) \\times (3 \\text{ components}) - 4 \\text{ constraints} = 11\nBy choosing a specific frame (fixing 3 rotations and 3 boosts), we lose 6 more degrees of freedom, leaving 5 independent variables to describe the kinematics.\n\n\n8.2 Phase Space and its Element\nFor cross-section calculations, we need the Lorentz Invariant Phase Space (LIPS) element, which counts the number of accessible kinematic configurations. For an n -particle final state, it is:\nd\\Phi_n = \\left[ \\prod_{i=1}^n \\frac{d^3 \\mathbf{p}_i}{(2\\pi)^3 \\, 2E_i} \\right] (2\\pi)^4 \\delta^4\\!\\left(P_{\\text{initial}} - \\sum_{i=1}^n p_i\\right)\nKey points about this formula:\n\nThe factor \\frac{d^3 \\mathbf{p}_i}{(2\\pi)^3 2E_i} for each particle comes from integrating over its four-momentum and enforcing the mass-shell condition.\nThe (2\\pi)^4 \\delta^4(...) enforces total energy and momentum conservation.\nThis element is Lorentz invariant, meaning it has the same form in any inertial reference frame.\n\nPhase space for complex processes (e.g., a 1 \\to 4 decay) can often be evaluated recursively by factorizing it into successive two-body phase spaces, which is a kinematic simplification, not a dynamical one."
  },
  {
    "objectID": "2024-Lecture-04.html#recursive-phase-space-parameterization",
    "href": "2024-Lecture-04.html#recursive-phase-space-parameterization",
    "title": "(2024) Lecture 4",
    "section": "9 Recursive Phase Space Parameterization",
    "text": "9 Recursive Phase Space Parameterization\nWhen you calculate the phase space, you see that three integrals come for every particle. That’s why I have a factor of three here for every particle in the phase space.\nHere we have a final state and an initial state. For the phase space to count, you only count the final state. So you see the initial state doesn’t enter.\nThen the four energy-momentum conservation conditions come here explicitly. That’s the number of the integrals that remain. That gives you three times four: twelve, minus four remains eight.\nThis is the five kinematic variables. So five plus three overall rotations, which is five variables. The three rotations are the Euler angles. But which five I pick to parameterize my kinematics is up to me.\nOne has to choose these five in the most convenient way to calculate dynamics, because it’s not going to tell you what interactions you have in these vertices. It doesn’t even tell you that your reactions happen in this cascade way. It’s just purely kinematical parameterization. It’s your choice of the kinematic variables.\nOne particular choice is to say I’m going to introduce M_X here and M_Y there and write my phase space as the integral \\frac{dM_X^2}{2\\pi} \\frac{dM_Y^2}{2\\pi} \\, d\\Phi_2(P \\to p_X, p_Y) \\, d\\Phi_3(p_Y \\to p_1, p_2, p_3) . That’s what is referred to as the recursive expression.\nIt’s not only valid for two, but you can also do this for three. The important thing is that they introduce a variable that is the sort of intermediate mass of the combination and you integrate over this variable, and every integral comes with a 2\\pi in the denominator.\nJust another example: if I just introduce d\\Phi_2(P \\to p_Y, p_4) and then d\\Phi_3(p_Y \\to p_1, p_2, p_3) , that’s also legal. That’s fine.\n\n\n\n\n\n\nThe general formula for an n -body final state is: d\\Phi_n(P; p_1, \\dots, p_n) = (2\\pi)^4 \\delta^{(4)}\\left(P - \\sum_{i=1}^n p_i\\right) \\prod_{i=1}^n \\frac{d^3p_i}{(2\\pi)^3 2E_i}\nThe number of independent kinematic variables is 3n - 4 .\n\n\n\n\n\n\n\n\n\nFigure 10: This diagram represents a typical cascade decay chain in a multi-particle final state process, often encountered in hadron spectroscopy experiments. Here, an initial state produces an intermediate resonance X (after vertex 1), which subsequently decays into another intermediate state (at point 2), followed by further decays resulting in final state particles labeled 3 and 4. The particle denoted “i” appears to decay into a multi-particle final state, as indicated by the several lines emerging from it. Physically, this diagram illustrates how a complex decay topology is analyzed via exclusive processes (where all final state particles are measured), as discussed in the lecture. Each vertex represents a step in the decay where energy-momentum conservation applies, and the overall structure enables the use of recursive phase space factorization. For example, the total n -body phase space d\\Phi_n can be decomposed into products of two- and three-body phase spaces at each vertex, integrating over intermediate invariant masses (e.g., M_X ). This is foundational for reconstructing resonance signals, calculating invariant mass distributions (such as those used in Dalitz plots), and determining the kinematic variables required to describe multi-body decays in hadron spectroscopy experiments.\n\n\n\nFor a 4-body decay ( n=4 ), this gives 3 \\times 4 - 4 = 8 variables, as mentioned.\nOnce you learn this trick, this calculation of the phase space is super straightforward because every two-to-two phase space is \\frac{2p}{\\sqrt{s}} \\frac{d\\Omega}{4\\pi} \\times \\frac{1}{2\\pi} . So this does not have any simplification."
  },
  {
    "objectID": "2024-Lecture-04.html#two-body-phase-space-and-introduction-to-the-dalitz-plot",
    "href": "2024-Lecture-04.html#two-body-phase-space-and-introduction-to-the-dalitz-plot",
    "title": "(2024) Lecture 4",
    "section": "10 Two-Body Phase Space and Introduction to the Dalitz Plot",
    "text": "10 Two-Body Phase Space and Introduction to the Dalitz Plot\n\nWe have now completed a more general treatment for the two-body phase space.\nWith this expression and the general formula, you are equipped to calculate any n-body phase space. As a next step, there is an exercise for you to try at home: play with the three-body phase space.\nThe three-body phase space will have:\n\nThree particles × three coordinates = 9 initial degrees of freedom.\nMinus 4 constraints from energy-momentum conservation.\nMinus 3 from overall rotations.\n\nThis leaves only two independent variables. The resulting distribution is often represented using these two variables.\nA common choice for these two variables is to use invariant masses of particle pairs. When plotted, this representation is called the Dalitz plot.\n\n\n\n\n\n\nIn a three-body decay, the Dalitz plot is a two-dimensional distribution where each point corresponds to a specific pair of invariant masses squared. It visually encodes the entire dynamics of the decay, making it a powerful tool for analyzing resonances and interaction mechanisms."
  },
  {
    "objectID": "2024-Lecture-05.html",
    "href": "2024-Lecture-05.html",
    "title": "(2024) Lecture 5",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Anna Zimmer"
  },
  {
    "objectID": "2024-Lecture-05.html#kinematics-recap-22-scattering-processes",
    "href": "2024-Lecture-05.html#kinematics-recap-22-scattering-processes",
    "title": "(2024) Lecture 5",
    "section": "1 Kinematics Recap: 2→2 Scattering Processes",
    "text": "1 Kinematics Recap: 2→2 Scattering Processes\nWe start with a recap on kinematics. The first question: how many variables does one need to describe the two-to-two scattering process? We have two particles in the initial state and two particles in the final state.\n\nInitial state: two 0⁻ scalar particles\nFinal state: two 0⁻ scalar particles\nExample: 0⁻ + 0⁻ → 3⁻ + 1⁺ scattering\n\n\n\n\n\n\n\nThe “blob” in scattering diagrams represents the interaction region where strong, electromagnetic, or gravitational interactions occur. These are not Feynman diagrams but sometimes called unitarity diagrams.\n\n\n\nThe number of kinematic variables needed depends only on the external particles - whatever happens inside the interaction blob does not affect this count."
  },
  {
    "objectID": "2024-Lecture-05.html#counting-kinematic-variables",
    "href": "2024-Lecture-05.html#counting-kinematic-variables",
    "title": "(2024) Lecture 5",
    "section": "2 Counting Kinematic Variables",
    "text": "2 Counting Kinematic Variables\nLet’s calculate systematically:\nStep 1: Initial counting\n\n4 particles × 4 momentum components each = 16 variables\n\nStep 2: Apply conservation laws\n\n4-momentum conservation (E, pₓ, pᵧ, p₂) removes 4 constraints → 12 remaining variables\n\nStep 3: Remove redundant degrees of freedom\n\n3 rotations and 3 boosts can be eliminated → subtract 6 more variables\n\nFinal count: 2 independent variables\n\n\n\n\n\n\nBoth scalar and spinning particle cases require only 2 variables to fully describe 2→2 scattering kinematics. The difference is that spinning particles have more scattering amplitudes, but all amplitudes still depend on the same 2 kinematic variables."
  },
  {
    "objectID": "2024-Lecture-05.html#choosing-the-two-variables",
    "href": "2024-Lecture-05.html#choosing-the-two-variables",
    "title": "(2024) Lecture 5",
    "section": "3 Choosing the Two Variables",
    "text": "3 Choosing the Two Variables\nPrimary Mandelstam variables: s = (p_1 + p_2)^2 = (p_3 + p_4)^2 t = (p_1 - p_3)^2 u = (p_1 - p_4)^2\nThese variables are related by: s + t + u = \\sum m_i^2, so only two are independent.\nPhysics meaning:\n\ns: Total center-of-mass energy squared\nt: Momentum transfer squared between particles 1 and 3\nu: Alternative momentum transfer variable\n\nCenter of Mass Frame Variables:\n\n\\sqrt{s}: Center-of-mass energy\n\\cos\\theta_{CM}: Scattering angle between initial and final state particles\n\nOther possibilities:\n\nLab frame energies E_1 and E_3\nAny two independent variables that characterize the process\n\n\n\n\n\n\n\nMandelstam variables are preferred because they are Lorentz invariant and provide an undistorted representation of phase space density. The transformation to these variables has a constant Jacobian."
  },
  {
    "objectID": "2024-Lecture-05.html#scattering-amplitudes-and-spin-dependence",
    "href": "2024-Lecture-05.html#scattering-amplitudes-and-spin-dependence",
    "title": "(2024) Lecture 5",
    "section": "4 Scattering Amplitudes and Spin Dependence",
    "text": "4 Scattering Amplitudes and Spin Dependence\nFor scalar particles: The scattering amplitude is a single scalar function A(s,t)\nFor spinning particles: The scattering amplitude becomes a multi-component object:\n\nSpin-3 particle: 7 dimensions\nSpin-1 particle: 3 dimensions\nTotal amplitude dimension: 7 × 3 = 21 components\n\nHowever, all 21 amplitudes are still functions of the same 2 variables (s and t)."
  },
  {
    "objectID": "2024-Lecture-05.html#extension-to-three-body-decays",
    "href": "2024-Lecture-05.html#extension-to-three-body-decays",
    "title": "(2024) Lecture 5",
    "section": "5 Extension to Three-Body Decays",
    "text": "5 Extension to Three-Body Decays\nNow considering three-body decays (1 particle → 3 particles):\nKinematic variables: Still 2 variables needed, same as 2→2 scattering\nDalitz plot variables: Typically use two invariant mass squared variables: m_{34}^2 = (p_3 + p_4)^2 m_{24}^2 = (p_2 + p_4)^2\nThree-body phase space formula: d\\Phi_3 = d\\Phi_2(m_{12}^2) \\times d\\Phi_2(m_{34}^2) \\times \\frac{dm_{34}^2}{2\\pi}\nTwo-body phase space element: d\\Phi_2 = \\frac{1}{8\\pi} \\frac{2|\\vec{p}|}{\\sqrt{s}} \\frac{d\\Omega}{4\\pi}\n\n\n\n\n\n\nThe phase space for three-body decay is flat when plotted against Mandelstam variables. (see Figure~1) This means the differential width directly reveals the dynamics of the interaction without kinematic distortions. (see Figure~2) (see Figure~3) (see Figure~6)"
  },
  {
    "objectID": "2024-Lecture-05.html#applications-and-homework",
    "href": "2024-Lecture-05.html#applications-and-homework",
    "title": "(2024) Lecture 5",
    "section": "6 Applications and Homework",
    "text": "6 Applications and Homework\nWe will continue discussing angular distributions after the Dalitz plot. The homework exercise on Dalitz plots connects directly to hadron spectroscopy, which is the focus of upcoming lectures.\nKey realization: For any N-body process, once you specify the kinematic variables, you can completely reconstruct the “rigid body” configuration of all momentum vectors in the center-of-mass frame.\nThe recursive phase space formula demonstrates that the Jacobian for transformation to Mandelstam variables is constant, making these variables ideal for studying interaction dynamics through Dalitz plot analyses.\n\n\n\n\n\n\nFigure 1: A sketch illustrating the recursive relation when computing the phase-space expression. This is not a dynamic assumption but a mathematical trick that rewrites the full three-body phase-space through lower-dimensional phase-space elements and the two-body phase-space, for which the expression is simple.\n\n\n\n\n6.1 Decoding the Λc Dalitz Plot\nYou can see the example of the triple decay that I have here of the \\Lambda_c baryon going to the proton, kaon, and pion: \\Lambda_c^+ \\to p + K^- + \\pi^+\nWe measure \\Lambda_c produced in proton-proton collisions or any other collisions. In experiments, they observe \\Lambda_c abundantly. This is one of the particles that lives long enough and is produced copiously.\nParticles with charm ground states are produced abundantly and live sufficiently long to fly from the primary vertex. That’s why we have a good sample and a good understanding of their decay kinematics—not only kinematics, but dynamics as well. (see Figure~6)\nIn this decay, there is a charm quark in the initial state and no charm quark in the final state, indicating that this occurs via weak interaction. The charm quark disappears between initial and final states: the charm quark decays, transitioning into a strange quark that ends up in the kaon. This c \\to s transition happens within one generation and is not suppressed—it is an allowed process.\nThis decay is considered a golden channel for detection because:\n\nThe final state contains three charged particles—there are no neutrals.\nThe proton is charged, travels well, and is stable.\nThe kaon and pion are stable in our accelerator experiments.\n\nThese particles fly from the decay without distraction, and we see their tracks clearly through all detectors. They point away from the primary interaction vertex.\nThere is roughly a 1 cm shift between the primary vertex and the secondary vertex in \\Lambda_c decays. This displacement occurs due to the boost and the fact that \\Lambda_c lives longer in the laboratory frame than in its rest frame.\n\n\n\n\n\n\nThe decay length in the laboratory frame is given by: L = \\beta\\gamma c\\tau At the LHC, \\Lambda_c is produced with energies of a few hundred GeV, making this decay particularly clean and well-suited for study.\n\n\n\nWe have studied this decay extensively. Here is the result of an analysis that resembles experimental data. If I showed you actual experimental data, you wouldn’t distinguish it from this plot—the statistics are so high that the distribution appears very smooth.\n\nOn the x-axis: invariant mass of the proton and kaon, m_{12}^2\nOn the y-axis: invariant mass of the kaon and pion, m_{23}^2\n\nAll allowed kinematic values for the decay are shown in color. (see Figure~6) The white area corresponds to kinematics where no physical configuration exists—energy and momentum cannot be conserved there.\nIf you select a point inside the colored region, you can compute angles between particles and reproduce the configuration with a 3D-printed rigid body. But if you choose a point in the white region, you quickly find that energy conservation cannot be satisfied.\nThe range of possible values for the invariant masses is limited, and this surface is called the Dalitz plot. The kinematic boundaries are defined by:\nm_{12}^2 + m_{23}^2 + m_{13}^2 = m_{\\Lambda_c}^2 + m_p^2 + m_K^2 + m_{\\pi}^2\nDifferent colors in the plot indicate different probabilities for the decay to occur at that kinematic point. (see Figure~6) The differential decay rate in the Dalitz plot is:\n\\frac{d^2\\Gamma}{dm_{12}^2  dm_{23}^2} \\propto |\\mathcal{M}|^2\nWe measure the decay by reconstructing particle tracks and identifying from which kinematic point the decay originated. There is an unambiguous relation between four-vectors and kinematic points. (see Figure~3)\nIt turns out that certain kinematics are more probable than others—particles prefer specific directions. For example, one configuration may be more common, while another is rare. On the border of the Dalitz plot, particles are aligned in one line, whereas inside the surface they always have an angle between them.\nThink about how to maximize the invariant mass and where on the border such a point lies.\n\n\n6.2 Dalitz Plot Kinematics in Three-Body Decay\nLet’s consider the three-body decay \\Lambda_c^+ \\to pK^-\\pi^+ and its kinematics. (see Figure~1) We want to maximize the invariant mass of the proton–Kaon system. (see Figure~6)\nThere are three outgoing momenta. The idea is that if the three momenta are arranged in opposite directions, the total three-momentum sum should be as small as possible. (see Figure~6)\nIf we add both momentum vectors, the forward momentum—or more precisely, the magnitude of the sum of the momentum vectors—should be as large as possible. Therefore, we should be on the right side of the Dalitz plot diagram.\nNow, consider the mass on the y-axis: should it be as large or as small as possible? (see Figure~3) It should be as small as possible.\nWhy? Because when the three momenta are collinear and we subtract them appropriately, the invariant mass is minimized.\nOne way to think about this is to go to the rest frame of the Kaon and pion. If they are flying nearly together, their relative momentum is small. In their mutual rest frame, they could both be at rest, so their invariant mass would simply be the sum of their rest masses—this is the minimum possible.\n\n\n\n\n\n\nThe minimum invariant mass for any two-particle system is given by M_{ij}^{\\text{min}} = m_i + m_j This occurs when the two particles are at rest relative to each other.\n\n\n\nYou are correct: we are looking for the minimal invariant mass of the proton–Kaon system.\nLet’s identify what this point corresponds to kinematically. In certain configurations, two particles can be nearly at rest while the third carries away the momentum. (see Figure~6) That corresponds to the minimal invariant mass case.\nThis plot is likely from experimental data. How would we reconstruct such an event experimentally if we don’t detect the proton directly? Even though measurements occur in the lab frame (which is boosted), the analysis is often performed in the center-of-mass frame.\nThe point of maximum invariant mass occurs when the two particles move back-to-back with maximum momentum. The point we are discussing minimizes the invariant mass.\nFor three-body decays, there is a similar way to define angular variables. (see Figure~1) Let me briefly mention this.\nI will boost into the rest frame for each kinematic setup. To clarify, I am referring to the proton, Kaon, and pion. Suppose I fix the invariant mass of the proton–Kaon system.\nThe approach is to work in the center-of-momentum frame of the \\Lambda_c, where the three final-state particles have momenta summing to zero. Then, I boost to the rest frame of the Kaon and pion. (see Figure~6) In that frame, the Kaon and pion have equal and opposite momenta. (see Figure~7)\nIf I fix the invariant mass of the proton–Kaon system and explore phase space along a line where that mass is fixed, the magnitudes of the momenta are fixed—only the angle \\theta changes.\nAs \\theta varies from 0 to \\pi, one extreme (\\theta = 0) corresponds to the proton and Kaon moving in the same direction, yielding a small invariant mass. The other extreme (\\theta = \\pi) corresponds to them moving oppositely, giving the maximum invariant mass.\n\n\n\n\n\n\nThe invariant mass squared for two particles is M_{ij}^2 = (p_i + p_j)^2 = (E_i + E_j)^2 - (\\vec{p}_i + \\vec{p}_j)^2 This quantity is Lorentz invariant and is used to define Dalitz plot axes.\n\n\n\nFor angle \\theta = 0, the invariant mass is small. As the angle increases, the invariant mass grows. The same logic applies to the other pairings.\nA straightforward analysis method is to go to the rest frame of the proton–Kaon system, where all quantities are fixed, and scan by changing the angle between the proton and Kaon relative to the pion direction. (see Figure~6)\nThus, lines in the Dalitz plot represent configurations where the angle is varied in some rest frame.\nAnother variable in 2 \\to 2 scattering kinematics is the U variable, which offers a more symmetric treatment. For three-body decays, we also have the invariant mass of the pion–proton system.\nIf I fix the invariant mass of the proton–Kaon system and scan the angle, which line do I move along? This follows from the relation that the U variable is a linear combination of the invariant masses.\nIn fact, the coefficients are such that the motion corresponds to a diagonal in the Dalitz plot. This line represents a fixed pion–proton invariant mass, moving from one kinematic endpoint to the other.\nThe standard representation in experimental analyses uses Dalitz plots with the x-axis as the invariant mass squared of one pair and the y-axis as the invariant mass squared of another pair—exactly what is shown here.\nIn homework, you may encounter a more symmetric Dalitz plot where all variables enter symmetrically. This uses the geometry of an equilateral triangle, where every point inside satisfies a conservation relation.\n\n\n\n\n\n\nIn the symmetric representation, the coordinates are x = \\frac{\\sqrt{3}}{2}(M_{12}^2 - M_{23}^2), \\quad y = M_{13}^2 - \\frac{1}{2}(M_{12}^2 + M_{23}^2) The factor \\frac{\\sqrt{3}}{2} arises from the 60° angles in an equilateral triangle.\n\n\n\nIf you sum the perpendicular distances from any interior point to the three sides of an equilateral triangle, the total is constant. This allows us to define symmetric variables representing the sum of the invariant masses.\nThe variables are interpreted as distances to the sides. This gives a very symmetric and elegant representation.\nEssentially, this is equivalent to the standard plot—they are related by a linear transformation, not just a rotation but also a skew. To plot experimental data in this form, one must apply the correct coordinate transformation.\nYesterday, I worked through the algebra relating Cartesian coordinates to the heights in the triangle—it’s straightforward but interesting.\nThis symmetric representation is nice, while the standard one is more common and easier to plot directly. Both capture the same kinematics.\nIn the Dalitz plot, regions with higher event density indicate kinematic enhancements. The purpose of this kinematic representation is to identify the dynamics and underlying processes governing the decay.\n\n\n\n\n\n\nFigure 2: A kinematic representation of the transition from the initial state to the final state in the process where particle 0 decays into particle x and particle 3. The arrows indicate the three-momenta of particles 3 and x, and the fat dot marks particle 0, which is at rest in this frame.\n\n\n\nLooking ahead, we will see that \\Lambda_c decay to three particles often proceeds via intermediate resonances. Temporarily, two particles form a resonant state that then decays, increasing the decay rate in certain invariant mass regions.\nWhen the energy of two particles matches a resonance, their interaction is stronger, making the decay more probable. This is why we observe enhanced densities along certain bands in the Dalitz plot.\n\n\n6.3 Resonance Structures and Angular Distributions in Three-Body Decays\nYou might have seen cross sections for two-particle resonances. These exhibit a characteristic bump known as a hadronic resonance. The underlying physics is that when you have a system of two particles, and the quantum numbers of that system match those of an intermediate resonance, the interaction probability increases dramatically at specific energies.\n\n\n\n\n\n\nThe Breit-Wigner resonance cross section describes this enhancement: \n\\sigma(E) \\propto \\frac{\\Gamma^2/4}{(E - E_R)^2 + \\Gamma^2/4}\n where E_R is the resonance energy and \\Gamma is the resonance width.\n\n\n\nBy adjusting the system energy, you explore how likely two particles are to interact. When passing through the resonance region, the probability increases significantly. This creates bent structures in the Dalitz distribution—when projected onto one axis, you see the characteristic resonance shape.\nThis example is particularly interesting because it shows resonances in all three particle pairs:\n\nHorizontal lines correspond to fixed K\\pi mass → K^* resonances\nVertical lines correspond to fixed proton-K\\pi mass → K-nucleon resonances\nDiagonal lines correspond to pion-proton combinations → \\Delta resonances\n\n\n\n\n\n\n\nThe Dalitz plot density for three-body decays is: \n\\frac{d^2\\Gamma}{dm_{12}^2  dm_{23}^2} = \\text{constant} \\times |\\mathcal{M}|^2\n where m_{ij} are invariant masses and \\mathcal{M} is the decay amplitude. (see Figure~1)\n\n\n\nThe lines appear parallel to the sides of the Dalitz triangle:\n\nK^* resonances parallel to one side\n\\Lambda resonances parallel to another side\n\\Delta resonances parallel to the third side\n\n\n\n\n\n\n\nFigure 3: The Dalitz plot, a representation of the phase-space for the three-body decay. (see Figure~6) It appears as an ellipse-shaped area where the internal region corresponds to allowed kinematics and the outside region is forbidden. On the x-axis lies the squared mass of two final-state particles, while the y-axis corresponds to the other subsystem. A horizontal line represents a slice of the phase-space with one mass fixed. The borders of the area correspond to configurations where all three momenta are aligned in the rest frame of the decaying particle, or equivalently, where the scattering angle in the relevant rest frame is either 0 or π.\n\n\n\nNow let’s examine angular distributions within resonance bands. When traversing phase space while keeping the mass combination fixed, you’re effectively changing the decay angle. This angle dependence reveals important physics:\n\nWithin a resonance band, probability can be inhomogeneous\nParticles often prefer aligned vs. perpendicular configurations\nThese preferences occur because intermediate resonances have spin\n\n\n\n\n\n\n\nAngular distributions are powerful tools for measuring:\n\nSpin\nParity\nOther quantum numbers\n\n\n\n\nKey observations:\n\nHigher spin particles produce more structured angular distributions\nScalar particles produce no angular asymmetries\nThe number of nodes in angular distribution often equals the spin value\nFor spin-J particles: N_{\\text{states}} = 2J + 1 spin projections\n\nWhen dealing with particle spins, we need to understand how quantum states transform under rotations. For a particle with spin J, there are 2J+1 possible projections along a quantization axis.\n\n\n\n\n\n\nThe Wigner D-function describes rotations using Euler angles (\\phi, \\theta, \\gamma): \nD^J_{m'm}(\\phi, \\theta, \\gamma) = e^{-i m' \\phi}  d^J_{m'm}(\\theta)  e^{-i m \\gamma}\n where d^J_{m'm}(\\theta) is the Wigner small d-matrix.\n\n\n\nRotation conventions in particle physics: 1.\n\n\n\n\n\n\nFigure 4: A diagram showing the spin projection. The horizontal line arrow indicates the z-axis, which is chosen as the quantization axis. The arrow denotes the particle spin, and its projection onto the axis is represented by m in the equations.\n\n\n\nRotate by \\phi about Z-axis\n\nRotate by \\theta about Y-axis\nRotate by \\gamma about Z-axis again\n\n\n\n\n\n\n\nBe careful with conventions! Mathematica uses opposite sign conventions compared to standard particle physics. Wikipedia and Python’s sympy library are reliable references.\n\n\n\nLet’s construct a model for three-body decays via cascade processes: initial particle → intermediate resonance X → particles 1 + 2, plus particle 3.\n![A unitary diagram for the three-body decay.\n\n\n\n\n\n\nFigure 5: A dynamic diagram of a cascade decay, where particle 0 decays to a three-body final state through an intermediate state x that sequentially decays into particles 1 and 2. (see Figure~6) The intermediate particle carries spin j and serves as an expansion term of the full amplitude, known as the partial projection term. Lines represent initial and final state particles, while the double line denotes the intermediate particle.\n\n\n\nThe arrows show the initial and final state particles, and the blob stands for the interaction that transforms the initial state into the final state.](2024-Lecture-05-images/fig1.png)\nThe general cascade decay amplitude structure:\n\nA_{\\lambda_0, \\lambda_1, \\lambda_2, \\lambda_3}(s, \\theta) = \\sum_{\\lambda'_X} H^X_{\\lambda_0 \\lambda'_X} D^{j_X}_{\\lambda'_X \\lambda_X}(\\theta_X, \\phi_X) H^Y_{\\lambda_X \\lambda_Y} D^{j_Y}_{\\lambda_Y \\lambda_3}(\\theta_Y, \\phi_Y)\n\nComponent breakdown:\n\nH factors: Contain dynamics from strong/weak/EM interactions\nD functions: Handle rotational kinematics and angular distributions\n\\lambda_i: Helicity projections along particle directions of motion\n\n\n\n\n\n\n\nIn the helicity formalism, we quantize spins along the direction of motion, making \\lambda_i the helicity projections.\n\n\n\nSpecial case: aligned kinematics (\\Phi = \\theta = 0)\n\nRotation matrices simplify significantly\nMany summations collapse due to delta functions\nFinal expression becomes much cleaner:\n\nThe simplified amplitude becomes: \n\\mathcal{A} = H_0 D(\\theta)^{J_X}_{\\lambda_X, \\lambda_0 + \\lambda_3} D(\\theta)^{\\lambda_0 + \\lambda_3}_{\\lambda_1 - \\lambda_2}\n\nKey insight: Angular distributions are determined primarily by rotational group properties, with only the production preferences coming from specific interactions.\n\n\n\n\n\n\nFigure 6: A kinematic configuration for the introduction of the helicity matrix in the transition of particle x decaying into particles 1 and 2. The representation is drawn in the rest frame of particle x, shown as a dot at rest, with arrows representing the three-momenta of particles 1 and 2 in this frame.\n\n\n\nThis separation makes angular analysis a powerful model-independent tool for determining particle properties.\n\n\n6.4 Angular Distributions and Partial Wave Analysis\nHow many numbers do I need in order to compute electromagnetic interactions or gravity? Specifically, to predict the angular distribution, what input parameters are required? The current framework appears to miss some fundamental components.\nWhat is inside these interaction vertices or amplitude blocks? To predict all observable values, I need the transition amplitudes for different spin configurations.\nThe number of independent amplitudes is given by the spin degeneracy factor: (2j_1 + 1)(2j_2 + 1) where j_1 and j_2 are the spins of the particles involved. These amplitude values might also be functions of particle masses, particularly the masses of the intermediate states.\nA similar number of parameters is needed for the final state amplitudes, but there are reasonable approximation methods available.\n\n\n\n\n\n\nIn experimental analysis, we often make the initial assumption that these amplitude coefficients are constant, representing fundamental particle properties rather than dynamic functions. This simplification allows us to compute angular distributions without knowing the detailed internal dynamics.\n\n\n\nWith this constant amplitude assumption, I can compute the angular distribution while fixing the mass parameters and intensity normalization.\nThe differential decay rate with respect to \\cos\\theta is given by: \\frac{d\\Gamma}{d\\cos\\theta} \\propto |\\mathcal{M}|^2\nUsing \\cos\\theta rather than \\theta itself is preferable because it has a simpler Jacobian—we avoid the \\sin\\theta factor that appears in the \\theta distribution. The matrix element squared |\\mathcal{M}|^2 is typically treated as constant in this approximation.\nThe angular distribution spans from \\cos\\theta = -1 to \\cos\\theta = 1:\n\nA flat distribution indicates isotropic decay\nFor particles with spin, we often observe parabolic distributions (second-order polynomials in \\cos\\theta)\nOther characteristic patterns may appear depending on the spin structure\n\nIt’s crucial to recognize that A represents the quantum transition amplitude—a complex-valued quantity that gets squared to give the observed probability. In experiments, we only measure the squared magnitude of amplitudes.\nFor unpolarized decays, the distributions are averaged over initial spin projections and summed over final spin projections: \\frac{d\\sigma}{d\\Omega} \\propto \\frac{1}{(2s_1+1)(2s_2+1)} \\sum_{\\text{spins}} |\\mathcal{M}|^2\nWhen analyzing experimental data, we don’t initially guess the amplitude form directly. Instead, we project the angular distributions onto orthogonal polynomials, particularly Legendre polynomials: \\frac{d\\sigma}{d\\cos\\theta} = \\sum_{\\ell=0}^{L_{\\text{max}}} a_\\ell P_\\ell(\\cos\\theta)\nThis Legendre polynomial basis connects directly to the spins of the produced particles, forming the foundation of:\n\nPartial wave analysis: Modeling cross sections with amplitude parameters to learn about internal dynamics\nMoment analysis: Projecting differential cross sections onto polynomial moments\n\nThe initial projection onto polynomials doesn’t directly reveal the internal amplitude structure but provides combinations of these parameters that can be measured experimentally.\nThis approach isn’t straightforward, and we’ll have more opportunities to discuss it in detail. We’ve only briefly touched on the differences between canonical states (defined in the rest frame) and helicity states introduced later.\nFor comprehensive coverage of this subject, I recommend Martin Spearman’s Elementary Particle Theory, particularly Chapter 4, which covers:\n\nLorentz group fundamentals\nVector construction methods\nAccessible group theory applications\nParticle state definitions\n\nThe chapter provides substantial insights without overwhelming mathematical complexity.\nExercise Assignment: I will distribute Dalitz plots from CLEO and BaBar experiments with removed particle labels. You’ll receive:\n\nOne D meson decay dataset\nOne D_s meson decay dataset Using your kinematic knowledge, your task is to:\nDetermine particle masses from the kinematic boundaries\nIdentify the specific decay processes Each group will analyze one case initially, then examine additional examples.\n\n\n\n6.5 Office Hours Arrangement\n\nPeople, I have to leave now.\n\n\n\n\n\n\nThis portion of the lecture contains only administrative announcements about homework distribution and scheduling—no physics formulas or technical content are present in this segment.\n\n\n\nHomework Distribution:\n\nIf you don’t want to take the homework now, I’ll distribute it from my office.\nPlease come with me to collect it.\nThis applies to all of you.\n\nSchedule & Apologies:\n\nThank you for coming, and I apologize for being slightly late.\nWill you have time tomorrow at 8am?\nYou may leave now."
  },
  {
    "objectID": "2024-Lecture-06.html",
    "href": "2024-Lecture-06.html",
    "title": "(2024) Lecture 6",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-06.html#lambda-decay-kinematics-and-unpolarized-width",
    "href": "2024-Lecture-06.html#lambda-decay-kinematics-and-unpolarized-width",
    "title": "(2024) Lecture 6",
    "section": "1 Lambda Decay: Kinematics and Unpolarized Width",
    "text": "1 Lambda Decay: Kinematics and Unpolarized Width\nLet’s start with the recap. The physics reaction to consider is the lambda baryon decay into the proton and a pion.\nWe go through a standard list to understand any reaction:\n\nWhat type of interaction is responsible?\nWhat variables describe the process?\nWrite the matrix element.\nCalculate the unpolarized decay width. ### 1. Identifying the Interaction\n\n\n\n\n\n\n\nFigure 1: This figure presents a schematic representation of the decay process \\Lambda \\rightarrow p + \\pi^- in the context of particle physics. The initial state is a \\Lambda baryon, with spin-parity J^P = \\frac{1}{2}^+ and quark content uds , decaying into a proton ( p ) with quark content uud and the same spin-parity, and a negatively charged pion ( \\pi^- ) with quark content \\bar{u}d and spin-parity 0^- . The diagram includes notations identifying each particle’s quantum numbers and quark composition. Importantly, the vertex connecting the initial and final states is labeled as “weak,” highlighting that this process proceeds via the weak interaction rather than the strong force. This distinction is physically significant because the decay involves a change in strangeness ( \\Delta S = 1 ), which is only possible through weak interactions due to flavor conservation by the strong interaction. The figure visually reinforces key lecture themes: the necessity of the weak force for strangeness-changing decays, and the role of quantum numbers (spin, parity, strangeness) and quark content in determining allowed interactions. The physical meaning, as discussed in the text, is that the \\Lambda baryon’s comparatively long lifetime and the observation of flavor-changing decays are direct evidence for the weak interaction’s unique properties, including parity violation.\n\n\n\nWe have a \\Lambda , a proton, and a pion. This is a flavor-changing process:\n\nInitial state ( \\Lambda ): quark content uds , strangeness S = -1 .\nFinal state ( p + \\pi^- ): quark content uud + \\bar{u}d , strangeness S = 0 .\n\nStrangeness-changing transitions can only proceed via the weak interaction, as strong and electromagnetic interactions conserve flavor. Since the weak interaction violates parity, this decay will not conserve parity.\n\n\n\n\n\n\nThe key identifier is the strangeness change: \\Delta S = 1 . This uniquely specifies the interaction as weak.\n\n\n\n\n1.1 2. Kinematics and Variables\nThis is a one-to-two body decay: \\Lambda \\to p + \\pi^- . The simplest approach is to work in the center-of-mass frame, which is the rest frame of the decaying \\Lambda .\nIn this frame:\n\nThe \\Lambda is at rest.\nThe proton and pion are emitted back-to-back.\nThe magnitude of their momentum |\\mathbf{p}| is fixed entirely by the particle masses via energy-momentum conservation:\n\n|\\mathbf{p}| = \\frac{1}{2M_\\Lambda} \\sqrt{ [M_\\Lambda^2 - (m_p + m_\\pi)^2] [M_\\Lambda^2 - (m_p - m_\\pi)^2] }\nSince there is no preferred direction when the \\Lambda is at rest, there are no free angular variables. The only remaining degrees of freedom are the discrete spin projections of the particles involved.\nParticle Spins and Parity:\n\n\\Lambda : Spin J=\\frac{1}{2} , Parity P=+ ( J^P = \\frac{1}{2}^+ )\nProton: J^P = \\frac{1}{2}^+\nPion: J^P = 0^-\n\n\n\n1.2 3. The Matrix Element and Helicity Amplitude\nThe transition amplitude H describes the process. Given the kinematics, H cannot depend on angles, but it does depend on spin projections.\nLet the spin projection (helicity) of the \\Lambda be \\lambda_\\Lambda and of the proton be \\lambda_p . The pion is spinless. Angular momentum conservation along the decay axis requires: \\lambda_\\Lambda = \\lambda_p\nWe denote this common value simply as \\lambda = \\pm\\frac{1}{2} .\nTherefore, the helicity amplitude is: H_{\\lambda} = \\langle p(\\mathbf{p}, \\lambda), \\, \\pi^-(-\\mathbf{p}) \\, | \\, \\mathcal{T} \\, | \\, \\Lambda(\\mathbf{0}, \\lambda) \\rangle\nWe have two independent amplitudes: H_{+1/2} and H_{-1/2} .\n\n\n1.3 4. Unpolarized Decay Width\nThe decay width \\Gamma for a spin- \\frac{1}{2} particle is given by: \\Gamma = \\frac{1}{2M_\\Lambda} \\times (\\text{Spin-Averaged } |\\mathcal{M}|^2) \\times (\\text{Phase Space})\n\nSpin Average/Sum: We average over the 2 initial \\Lambda spin states and sum over the 2 final proton spin states. The condition \\lambda_\\Lambda = \\lambda_p means only two terms survive: |H_{+1/2}|^2 and |H_{-1/2}|^2 .\nPhase Space: For a two-body decay in the parent’s rest frame, the Lorentz-invariant phase space integrates to \\frac{|\\mathbf{p}|}{8\\pi^2 M_\\Lambda^2} \\int d\\Omega . With no angular dependence, \\int d\\Omega = 4\\pi .\n\nPutting it all together, the unpolarized width simplifies to: \\Gamma = \\frac{|\\mathbf{p}|}{8\\pi M_\\Lambda^2} \\left( |H_{+1/2}|^2 + |H_{-1/2}|^2 \\right)\nThis width, for the dominant decay \\Lambda \\to p \\pi^- , determines the \\Lambda baryon’s lifetime: \\tau_\\Lambda = \\frac{\\hbar}{\\Gamma} \\approx 10^{-9} \\, \\text{s}\nThis lifetime is long enough that the \\Lambda travels measurable distances (e.g., meters in a detector) before decaying, creating a displaced secondary vertex—a key experimental signature.\n\n\n1.4 5. Extension: The Helicity Frame for a Moving \\Lambda\nThe discussion so far assumed a \\Lambda at rest. If the \\Lambda is moving in the lab frame, its momentum defines a preferred axis (the helicity frame). By boosting to the \\Lambda ’s rest frame along this axis, we can now measure decay angles ( \\theta, \\phi ) relative to it.\nThis introduces angular dependencies into the decay distribution. For a polarized \\Lambda , the differential decay rate takes the form: \\frac{d\\Gamma}{d\\cos\\theta} \\propto 1 + \\alpha \\, P_\\Lambda \\cos\\theta\nwhere P_\\Lambda is the \\Lambda polarization and \\alpha is the decay asymmetry parameter, which encodes the parity violation in the weak decay and is related to the helicity amplitudes: \\alpha = \\frac{|H_{+1/2}|^2 - |H_{-1/2}|^2}{|H_{+1/2}|^2 + |H_{-1/2}|^2}\nThis angular analysis allows experiments to extract spin and parity-violation information."
  },
  {
    "objectID": "2024-Lecture-06.html#spin-states-and-helicity-transformations",
    "href": "2024-Lecture-06.html#spin-states-and-helicity-transformations",
    "title": "(2024) Lecture 6",
    "section": "2 Spin States and Helicity Transformations",
    "text": "2 Spin States and Helicity Transformations\nI would like to start giving a bit more detail on the topic from last time. ### Canonical Spin States and Rotations\n\n\n\n\n\n\nFigure 2: This figure illustrates the concept of rotating a particle’s state in the context of canonical spin states. The particle, initially at position M on the Z -axis, is subjected to an active rotation—meaning the particle itself is rotated, not the coordinate system. The curved arrow represents a rotation about the Y -axis, changing the direction of the particle’s momentum from the Z -axis towards the X -axis by an angle \\theta . This visualization directly connects to the discussion in the lecture about how canonical spin states |J, M\\rangle transform under rotations, and how Wigner D-functions describe the resulting mixture of spin projections after such a rotation. This process is fundamental for constructing helicity states and understanding how the spin quantization axis changes relative to the particle’s motion.\n\n\n\nThe state |J, M\\rangle is the base state of a particle with spin J and has a projection onto the Z-axis equal to M . If you act with the J_z operator, you find that this is an eigenstate of J_z with eigenvalue M .\nJ_z |J, M\\rangle = M |J, M\\rangle\nThis defines the canonical spin state, where the quantization axis is fixed as the Z-axis. The picture to have in mind is the 2J + 1 possible projections of the state, which could be in a mixed state.\nAll transformations we will apply are active transformations. It’s easier to think of them as transformations applied to the particles themselves, not to the coordinate system. The coordinate system remains fixed. If I boost or rotate and show you a direction, that operation is applied to the physical object.\n\nIf I boost a particle in the Z direction, the particle gets faster and moves along Z.\nIf I rotate my particle by an angle about the Y axis, I rotate the particle, not the coordinates. Rotations about the Y axis are often the most nontrivial and are what we will focus on.\n\nWhen we rotate a spin state with a definite projection M , we find it becomes a combination of states with different projections:\nR(\\theta) |J, M\\rangle = \\sum_{M'} D^J_{M'M}(\\theta) |J, M'\\rangle\nThe coefficients D^J_{M'M}(\\theta) are the Wigner D-functions. They are tabulated, often alongside Clebsch-Gordan coefficients.\n\n\n\n\n\n\nSince we discussed SU(2) extensively with Isospin, the group theory here is exactly the same. To compute these rotations, you can either look up the Wigner D-functions or perform a matrix exponentiation: R(\\theta) = e^{-i J_y \\theta} . The matrix form of J_y depends on the spin J .\n\n\n\n\n2.1 Explicit Rotation Matrices\nFor a spin-1/2 particle, the generator J_y is \\frac{1}{2}\\sigma_y , where \\sigma_y is the Pauli matrix. The rotation operator is:\nR_{1/2}(\\theta) = e^{-i \\frac{\\theta}{2} \\sigma_y}, \\quad \\text{where } \\sigma_y = \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix}\nExponentiating this gives the explicit 2x2 rotation matrix:\ne^{-i \\frac{\\theta}{2} \\sigma_y} = \\begin{pmatrix} \\cos\\left(\\frac{\\theta}{2}\\right) & -\\sin\\left(\\frac{\\theta}{2}\\right) \\\\ \\sin\\left(\\frac{\\theta}{2}\\right) & \\cos\\left(\\frac{\\theta}{2}\\right) \\end{pmatrix}\nNote the half-angle \\theta/2 , which is characteristic of spinor representations. For higher spins (e.g., spin-1), the matrix in the |J, M\\rangle basis is more complicated, involving terms like (1 - \\cos\\theta) instead of just \\cos\\theta .\n\n\n2.2 Constructing Helicity States for Moving Particles\nNow, let’s understand what happens to spin states when we boost them. The goal is to define spin quantization for a moving particle.\n\n\n\n\n\n\nFigure 3: This figure illustrates the concept of a moving particle and the definition of its spin state in the context of Lorentz transformations, as discussed in the provided lecture notes. - Top Panel: Shows a coordinate system with axes x and z , and a momentum vector \\vec{p} pointing in the xz -plane. This represents a particle moving with momentum \\vec{p} in a given direction, not aligned with the coordinate axes. - Bottom Panel: Depicts the same coordinate system, with the momentum vector \\vec{p} again in the xz -plane. Additionally, a vector labeled m appears, likely representing the spin projection direction (or magnetic quantum number orientation) with respect to the axes. Physical Meaning: The image demonstrates that for a moving particle, there are two important directions to consider: 1. Momentum direction ( \\vec{p} ) – the direction of the particle’s motion. 2. Spin quantization axis ( m ) – the direction along which the particle’s spin projection is specified. The key concept depicted is the difference between the canonical basis (spin projection along the fixed z -axis, regardless of the particle’s momentum) and the helicity basis (spin projection along the direction of motion, i.e., the momentum \\vec{p} ). This figure corresponds to the lecture’s discussion on constructing helicity and canonical states for moving particles: - Helicity State: Spin is quantized along the momentum direction ( \\vec{p} ). - Canonical State: Spin is quantized along a fixed axis (typically z ), irrespective of the actual momentum direction. The illustration sets up the need to relate these two descriptions (basis choices) using appropriate Lorentz transformations (boosts and rotations). This is foundational for understanding how spin states transform for moving particles and is essential for analyzing decays and scattering processes in relativistic (high-energy) physics.\n\n\n\nConsider a particle moving in the XZ plane. There are two common ways to define its spin state:\n\nHelicity Basis: Quantize the spin along the direction of motion.\nCanonical Basis: Define the state with non-zero momentum but quantize the spin along the fixed Z-axis.\n\nThese two bases are not equal, but they are related. A state with definite helicity (spin projection along momentum) will be a mixed state in the canonical basis, and vice versa.\nThe helicity state |p, \\lambda\\rangle is constructed systematically:\n\nStart with a particle at rest in a canonical state |0, \\lambda\\rangle , with spin projection \\lambda along the Z-axis.\nBoost it along the Z-axis with a boost B_z(\\beta) to give it momentum.\nRotate the entire system using a rotation R(\\phi, \\theta, 0) to point the momentum in the desired direction p .\n\nThis construction is summarized by the formula:\n|p, \\lambda\\rangle = R(\\phi, \\theta, 0) \\, B_z(\\beta) \\, |0, \\lambda\\rangle\n\n\n2.3 Key Properties and Lorentz Algebra\nHelicity states have an important property: helicity is invariant under rotations.\nR(\\alpha) |p, \\lambda\\rangle = |p', \\lambda\\rangle\nwhere p' = R(\\alpha) p . Rotating the state simply rotates the momentum vector, but since the spin quantization axis is tied to the momentum direction, the helicity eigenvalue \\lambda remains the same.\nThe most demanding part of working with these states is managing the algebra of boosts and rotations. A key relation in the Lorentz group is that any combination of a boost, a rotation, and another boost can be rewritten as a different combination of a rotation and a boost:\nB' R B \\Leftrightarrow R^{-1} B' R\nWhen you apply this to a canonical state, you get a linear combination of helicity states, \\sum C_{\\lambda'} |p, \\lambda'\\rangle .\nWe know how Lorentz transformations act on 4-vectors like momentum. For example, a boost along the Z-axis is represented by the matrix:\nB_z(\\beta) = \\begin{pmatrix}\n\\gamma & 0 & 0 & \\gamma\\beta \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n\\gamma\\beta & 0 & 0 & \\gamma\n\\end{pmatrix}, \\quad \\gamma = (1-\\beta^2)^{-1/2}\nThe remaining task is to track how the spin projection mixes with the directional motion under these transformations. The result is intuitive: a transformation generally produces a linear combination of different spin projections, not a single one. The exact coefficients are found by applying the boost-rotation composition rules."
  },
  {
    "objectID": "2024-Lecture-06.html#boost-rotation-relations-and-state-notation",
    "href": "2024-Lecture-06.html#boost-rotation-relations-and-state-notation",
    "title": "(2024) Lecture 6",
    "section": "3 Boost-Rotation Relations and State Notation",
    "text": "3 Boost-Rotation Relations and State Notation\nWhat will happen here is that we started with a vector. Instead of boosting this vector directly—which would make it a little more inclined forward—you could start from the particle’s rest frame.\nThe boost-rotation-boost sequence applied to the particle’s thrust is equivalent to this long vector expression. This is the same as rotating and then boosting. The boost I apply to the particle at rest directly produces my vector with the desired momentum magnitude. The only additional operation needed is a rotation to orient it. So, instead of boosting twice, I can boost only once to achieve a vector of a specific speed or length. That’s the essence of the relation shown.\nNow, let’s examine the second type of state: the canonical state, and how we obtain it.\nThe canonical state is defined by the following combination of operations. First, consider the recipe for achieving a state where the momentum \\mathbf{p} is rotated by an angle \\theta from the z-axis:\n\nBegin in the particle’s rest frame.\nApply a rotation R^{-1} so that the state has a specific projection onto the z-axis. After this rotation, you can visualize the spin arrow pointing slightly downward.\nThen, boost this state forward along the new direction.\n(see Figure 3) Finally, apply the rotation R .\n\nLet me visualize this: We have the initial state, we boost it to give it momentum, then we perform the final rotation, and voila, we arrive at the desired configuration.\n\n\n\n\n\n\nOn Notation: When I write |\\mathbf{p}, j, m \\rangle , you must ask: is this a canonical state or a helicity state? Strictly speaking, seeing \\mathbf{p} , j , and another number doesn’t tell you.\nIn general notation, m usually refers to the z-axis projection (canonical), while \\lambda refers to the helicity. It is much better to indicate this explicitly, for example, by adding a subscript like _{\\text{can}} or _{\\text{hel}} . I will sometimes be less precise when rushing, but clear notation is important to avoid confusion.\n\n\n\nIt is now clear how the two types of states are related. But before discussing that relation, let’s look at the transformation property of canonical states.\nTransformation of Canonical States\nI want to apply a rotation R to a canonical state |\\mathbf{p}, j, m \\rangle_{\\text{can}} . According to the definition, this state is constructed as R B R^{-1} acting on the rest state |0, j, m \\rangle .\nSo, we compute: R |\\mathbf{p}, j, m \\rangle_{\\text{can}} = R (R' B R'^{-1}) |0, j, m \\rangle\nwhere R' and B are the specific rotation and boost used to create |\\mathbf{p}, j, m \\rangle_{\\text{can}} from the rest state.\nTo proceed, I insert an identity ( R'^{-1} R' ) in a strategic spot: = (R R') B (R'^{-1} R) R^{-1} |0, j, m \\rangle\nBy grouping the operations, the combination (R R') B (R'^{-1} R) becomes a new boost-rotation sequence that generates a canonical state with a rotated momentum \\mathbf{p}' = R\\mathbf{p} . The remaining operation R^{-1} acts directly on the rest state.\nWe know how a rotation acts on a rest-state spin projection: it’s given by the Wigner D-matrix. Therefore, the result is a linear combination: R |\\mathbf{p}, j, m \\rangle_{\\text{can}} = \\sum_{m'} D^j_{m'm}(R) |\\mathbf{p}', j, m' \\rangle_{\\text{can}}\nwhere \\mathbf{p}' = R \\mathbf{p} .\nDoes the momentum change? Yes, it gets rotated to \\mathbf{p}' . In the construction, after the initial boost along the z-axis, the momentum is p\\hat{z} . The subsequent rotation R then rotates this momentum to its final direction \\mathbf{p}' ."
  },
  {
    "objectID": "2024-Lecture-06.html#helicity-states-and-parity-violation-in-lambda-decay",
    "href": "2024-Lecture-06.html#helicity-states-and-parity-violation-in-lambda-decay",
    "title": "(2024) Lecture 6",
    "section": "4 Helicity States and Parity Violation in Lambda Decay",
    "text": "4 Helicity States and Parity Violation in Lambda Decay\nI learned you to boost yourself in the exercises, and now let’s discuss their relation to boosted states.\nSo, have a look at them and tell me how you would relate them. If you need to relate one to another: this is a boosted state, and this is a canonical state.\nHere we have the sequence B, J, N, C, T, N, J, M, \\text{can} . What I want to write clearly is: they are not equal to each other, but one can express the boosted state |\\psi(p, j, \\lambda)\\rangle as a linear combination of canonical states. These coefficients are then—I would like you to have a clear understanding of how we find them.\n\n4.1 1. Relating Boosted and Canonical States\nThis state is defined according to a specific transformation. What that means: on the left side, we have R^{-1} , a rotation. In order to apply “rotation, boost, rotation minus one” to the state, I like to introduce R^{-1} R (the identity). Once I do that, I have something like this, but then R B R^{-1} will be my boost that makes the canonical state. What remains is to apply the R to this state, and you know how to apply R . This is simply it.\n\n\n\n\n\n\nPhysics meaning: A boosted state |\\psi(p, j, \\lambda)\\rangle with definite momentum p and helicity \\lambda is connected to a rest-frame canonical state |\\psi(0, j, m)\\rangle via Lorentz transformations: |\\psi(p, j, \\lambda)\\rangle = R(B) |\\psi(0, j, m)\\rangle , where R(B) is the rotation associated with the boost direction.\n\n\n\n\n\n4.2 2. Revisiting Lambda Decay and the Helicity Frame\nI wanted to quickly come back to the \\Lambda decay and tell a little more about how we derived the formula. The large peak formula involves many D -functions and H ’s from the last lecture.\nI’m going to consider now a \\Lambda that moves in the wave frame. It has a helicity, and then it decays. To define the z -axis, we need the direction of motion of the \\Lambda in the lab frame.\n\n\n\n\n\n\nFigure 4: This figure illustrates the decay of a polarized \\Lambda baryon, focusing on the transformation between different reference frames using the concept of the helicity frame. - Leftmost: A \\Lambda baryon is moving with its spin polarization (indicated by \\lambda_\\Lambda ) along the z -axis. This represents the initial state, where the \\Lambda is in motion (lab frame). - Center: Upon decay, the \\Lambda produces a proton ( p ) and a pion ( \\pi ). Their momenta ( \\vec{p}_p and \\vec{p}_\\pi ) and spin projection \\lambda_p for the proton are shown lying in a specific plane, which is crucial for defining the decay kinematics. This plane is set by the \\Lambda ‘s momentum and the outgoing proton/pion momenta. - Rightmost: The diagram is labeled by the operation B^{-1} , representing a Lorentz boost to the \\Lambda rest frame (i.e., the “helicity frame”). In this frame, the decay products’ momenta become back-to-back and lie in the same decay plane, with the definitions of the z -axis and the helicity angle \\theta  relative to the polarization direction preserved. Physical meaning: The sequence demonstrates how, for a polarized \\Lambda baryon decay, one defines the quantization axis (the z -axis) by the \\Lambda ’s motion. Then, by boosting into the \\Lambda rest frame (helicity frame), the angular distribution of the proton (or pion) can be analyzed relative to the polarization vector. This enables measurement of the decay asymmetry and parity violation in the process, as encoded in the \\cos\\theta dependence of the decay products in the helicity frame. The figure clarifies the importance of boosting to the correct frame and defining the correct angles for extracting physical information, such as the polarization and analyzing power \\alpha in weak decays.\n\n\n\nAfter the boost, that direction gives us the z -axis. This way of defining the z -axis is called the helicity frame for the \\Lambda .\n\nYou always have to describe from which frame you are boosting, because it depends. In different frames, the direction of the \\Lambda will be different, leading to differences when you arrive at the \\Lambda ’s rest frame.\nThe helicity frame is defined as the rest frame of a particle obtained by boosting from the frame where it was moving.\nThe angle of the decay particle, when you take one of the particles (e.g., particle number one) and use it to define the angle, is called the helicity angle. That’s common jargon in hadron physics.\n\nWhen we talk about the helicity angle, it implies that we:\n\nBoosted to the particle’s rest frame.\nTook one of the decay products as a reference.\nMeasured the angle from there.\n\nAll the motion is still in the same plane as before. The boost and the two particle momenta are now exactly opposite. So here, the boost inverse has happened.\nLet’s visualize the process:\n\nWe start with a \\Lambda flying in the z -direction with a certain velocity.\nIt decays into a proton and a pion in some plane.\nWe invert the boost (go to the \\Lambda rest frame).\nThe proton and pion are still in the same plane, with exactly opposite directions.\n\nIf I removed the original \\Lambda momentum from this picture, you would no longer have a defined plane. The plane is formed by three vectors: I need the original direction of motion of the \\Lambda to define the axis with respect to which I measure the angle, and then I have a plane.\n\n\n4.3 3. Calculating the Decay Amplitude\nThis was our recap exercise. We started without knowing that, so we only had one axis. But now we have a plane and one more variable on which the amplitude depends—the scattering or helicity angle \\theta —in addition to the discrete helicity variables.\nWe have to compute a final state, which will be a two-body decay. On the right side, we have configurations of the \\Lambda sitting in its rest frame with the proton and pion. On the left side, we have the configuration of the moving \\Lambda .\nThe way to proceed is to apply a rotation to this configuration to align it. The answer for the transition matrix element in the helicity basis is H_{\\lambda_p, \\lambda_\\Lambda} .\n\\mathcal{M}_{\\lambda_p, \\lambda_\\Lambda} = \\langle p, \\pi^-; \\lambda_p | T | \\Lambda; \\lambda_\\Lambda \\rangle\nThis is the equation we had last time, describing the matrix element for the decay sequence. The way we get there is by applying the transition operator T on the final state to simplify it. This T acts on the proton-pion state.\nWe want to evaluate the application of the transition operator that takes a pion-proton state and transforms it into a \\Lambda . This operator acts on the pion-proton state that has momentum \\vec{P}=0 . We notice this state is rotated about the y -axis by the angle \\theta . We want to align it because, on the left, the state has aligned combinations. So, we have a rotation.\nWe pull out the rotation, and then we have the same combination now along the z -axis: the proton goes forward, the pion goes backward, and the rotation is explicit. Since these operators commute (strong interactions conserve spin), we can compute the transition operator and rotation, acting first with the transition and then by the rotation.\nEssentially, this transition operator transforms a pion-proton state into a \\Lambda . We explicitly do this by inserting an identity (a sum over \\Lambda states) here. This matrix element we just evaluated is related to LS coupling. The inserted identity should have all possible combinations, giving a sum over \\lambda_\\Lambda , which results in delta functions. Therefore, we select only one state.\nThe last step is to apply the rotation. Once you get the idea, it’s easy to see that for every bit of the transition, you have the product of a helicity transition matrix element and a rotation matrix (a Wigner D -function).\n\n\n\n\n\n\nRotation of Helicity States: Under a rotation R(\\theta, \\phi) , a helicity state transforms as: R(\\theta, \\phi) |p, j, \\lambda\\rangle = \\sum_{m'} D_{m'\\lambda}^j(\\phi, \\theta, 0) |p', j, m'\\rangle\nwhere D_{m'\\lambda}^j are the Wigner D-matrices. For spin-1/2, this matrix is: D^{1/2}_{m'm}(\\phi, \\theta, 0) = \\begin{pmatrix} e^{-i\\phi/2}\\cos(\\theta/2) & -e^{-i\\phi/2}\\sin(\\theta/2) \\\\\\\\ e^{i\\phi/2}\\sin(\\theta/2) & e^{i\\phi/2}\\cos(\\theta/2) \\end{pmatrix}\n\n\n\n\n\n4.4 4. Differential Cross Section and Parity Violation\nNow, the differential cross section exists as a function of the angle \\theta . We know these are our cosine and sine matrices. For spin-1/2, we just had an explicit matrix, and we have two coupling constants measured in experiment. You can take them to compute the angular distribution.\nThe answer is the same as before because \\sin^2 + \\cos^2 = 1 . In front of one term, you have \\sin^2 + \\cos^2 ; in front of the other, you have -\\sin^2 + \\cos^2 .\nWhat we learned in this example is that if you have an unpolarized particle, you will not observe any interesting angular distribution. We summed over the final and initial states, and no non-trivial angular distribution remains for d\\Gamma/d\\Omega before integrating over \\cos\\theta .\nNow we have a differential cross section. Before, we just wrote that \\Gamma is equal to something, and the phase space has d\\Omega/(4\\pi) , an integral d\\cos\\theta/2 , d\\phi/(2\\pi) .\n\n\n\n\n\n\nFigure 5: This diagram represents the angular distribution of an unpolarized two-body decay in the particle’s rest frame, specifically showing the differential decay rate \\frac{d\\Gamma}{d\\cos\\theta} as a function of \\cos\\theta for a decay like \\Lambda \\to p \\pi^- when the initial particle is unpolarized. - The horizontal axis runs from -1 to +1 , which corresponds to the allowed range of \\cos\\theta , with \\theta being the decay angle between the decay product’s momentum and some fixed axis (normally, the direction of the parent particle’s spin or momentum). - The vertical axis represents the value of the differential decay rate, \\frac{d\\Gamma}{d\\cos\\theta} . - The height of the boxes (constant for all \\cos\\theta ) indicates that the decay distribution is isotropic, i.e., independent of angle, which occurs when there is no initial polarization and no parity-violating asymmetry ( \\alpha = 0 ) in the decay. Physically, this tells us that for an unpolarized initial state, the decay products are emitted equally likely in all directions, resulting in a flat angular distribution of \\frac{d\\Gamma}{d\\cos\\theta} versus \\cos\\theta . This matches the expectation from weak decays with no preferred direction due to polarization or parity violation.\n\n\n\nNow I just move this \\cos\\theta dependence to the other side.\nPolarized decay: You get non-trivial distributions if you polarize your particle. When the \\Lambda was flying, it had a spin projection \\lambda_\\Lambda . Now we have a formula that tells us how this looks.\nLet’s think about what we see in an experiment. The \\Lambda travels with a certain momentum, and the projection of its spin onto its direction of motion is \\pm 1/2 . When it decays, we will find that it’s more likely for the proton to travel forward than backward relative to the \\Lambda spin direction. This angle is the proton’s helicity angle.\nThis violates parity. If you apply parity to the initial and final states, you flip the momentum but not the spin. Parity implies there cannot be such a forward-backward asymmetry. This is consistent with the fact that we consider the decay amplitude inside the interaction to be from the weak force.\n\n\n\n\n\n\nFigure 6: This figure illustrates the angular distribution of the decay products in the weak decay of a polarized \\Lambda baryon, such as \\Lambda \\rightarrow p + \\pi^- . The vertical axis represents the differential decay rate \\frac{d\\Gamma}{d\\cos\\theta} as a function of the cosine of the decay angle \\theta (measured relative to the \\Lambda spin or polarization axis). The diagram shows a forward-backward asymmetry, where the decay rate is higher in the forward direction (along the spin or polarization) than in the backward direction. This kind of asymmetry is a hallmark of parity violation in weak decays. The strength of the asymmetry is governed by the decay asymmetry parameter \\alpha and the polarization P : \\frac{d\\Gamma}{d\\cos\\theta} \\propto 1 + \\alpha P \\cos\\theta A nonzero slope indicates \\alpha \\neq 0 , meaning that the angular distribution can be used to measure the polarization of the parent \\Lambda baryon. The regions labeled in the plot correspond to the fraction of events moving “forward” vs. “backward”, and the observable forward-backward asymmetry A_{FB} can be extracted by comparing these event counts. This asymmetry is a direct probe of parity violation and the polarization transfer in the decay.\n\n\n\nThe parity violation appears explicitly if the two helicity amplitudes H_{1/2} and H_{-1/2} are not equal. If they were equal, \\sin^2 + \\cos^2 gives 1, and there is no angle dependence.\n\\frac{d\\Gamma}{d\\cos\\theta} = \\frac{\\Gamma_0}{2} \\left(1 + \\alpha P_\\Lambda \\cos\\theta\\right)\nThe decay asymmetry parameter \\alpha quantifies this parity violation:\n\\alpha = \\frac{|H_{1/2}|^2 - |H_{-1/2}|^2}{|H_{1/2}|^2 + |H_{-1/2}|^2}\nIf \\alpha = 0 , the angular distribution is symmetric (parity conservation). If \\alpha \\neq 0 , it indicates parity violation, as in the weak decay of the \\Lambda ."
  },
  {
    "objectID": "2024-Lecture-06.html#polarization-analyzing-power-and-polarimetry-in-lambda-decay",
    "href": "2024-Lecture-06.html#polarization-analyzing-power-and-polarimetry-in-lambda-decay",
    "title": "(2024) Lecture 6",
    "section": "5 Polarization, Analyzing Power, and Polarimetry in Lambda Decay",
    "text": "5 Polarization, Analyzing Power, and Polarimetry in Lambda Decay\nThanks for the question. That’s really important to know, and in fact they are not.\nMoreover, we consider the polarized decay: if the 100% polarization P = 1 is a pure state, it is a spin projection 1/2 and it’s a fully polarized state. One can consider a mixed state where you don’t have that, where it’s not fully polarized.\nMost realistically, the degree of polarization for the lambda hyperon is not 100% but let’s say 60%. That’s what we have. In the BES experiment case, the lambda is produced with a polarization of about 60%, and in that case the asymmetry is smaller.\nSo one finds that the differential decay rate is given by: \\frac{d\\Gamma}{d\\cos\\theta} = \\Gamma_0 ( 1 + \\alpha P \\cos\\theta )\nPhysics Meaning:\n\n\\frac{d\\Gamma}{d\\cos\\theta} is the differential decay rate.\n\\Gamma_0 is the total decay rate or normalization constant.\n\\alpha is the analyzing power (or decay asymmetry parameter).\nP is the degree of polarization of the parent particle (e.g., Λ hyperon).\n\\cos\\theta is the cosine of the angle between the decay product’s momentum and the polarization axis.\n\nWe can rewrite these equations by contracting the matrix element with the polarization matrix and find out that the difference between the two hemispheres defines how well this particular decay reflects polarization.\nThe quantity \\alpha , the analyzing power, tells you how well this decay is suited to measure the initial polarization. If the scalar and pseudoscalar coupling constants g_S and g_P are equal to each other |g_S| = |g_P| , you don’t have sensitivity to the initial polarization. The decay is insensitive.\n\n\n\n\n\n\nThis condition \\alpha = 0 when |g_S| = |g_P| means parity violation may not be observable via the angular distribution, even if the decay intrinsically violates parity. For most decays, however, there is a non-zero analyzing power.\n\n\n\nIt can happen even for big decays that the couplings are equal. Parity can be violated, but it’s not measured. But for most of them there is a non-zero analyzing power. So this \\alpha is non-zero.\nAnd that’s why by looking at the angular distribution you see parity violation. But you can also measure the initial polarization. That’s called a polarimetry technique and that’s actively used.\nThe polarization P can be extracted from the measured forward-backward asymmetry: A_{FB} = \\frac{N(\\cos\\theta &gt; 0) - N(\\cos\\theta &lt; 0)}{N(\\cos\\theta &gt; 0) + N(\\cos\\theta &lt; 0)} = \\frac{\\alpha P}{2}\nwhere N denotes the number of decays in the forward or backward hemispheres.\nLook at the angular distributions. All particles have known spin, the couplings are known. But these parameters have to be measured in advance. And in that case you can measure polarization.\nThis initial polarization is a super powerful observable. So particles like lambda hyperons with a spin carry polarization out of the interaction point, which is part of the information.\n\nHow the lambda is produced\nWith what momentum\nWith what polarization\n\nThis tells us about the internals of the interaction. For example, imagine that a lambda hyperon is produced in the quark-gluon plasma. Its polarization can now be related to the properties of that plasma.\nThis is a kind of free carrier of information out of the mess of the quark-gluon interaction. So polarization plays an important role, if not more than other observables. And this particle is not only carrying it, but also by decaying gives us a way to measure that polarization."
  },
  {
    "objectID": "2024-Lecture-06.html#a-pedagogical-pause",
    "href": "2024-Lecture-06.html#a-pedagogical-pause",
    "title": "(2024) Lecture 6",
    "section": "6 A Pedagogical Pause",
    "text": "6 A Pedagogical Pause\nWe have time. Instead of beginning a new topic, I would like to pose a question I have in mind for this lecture. This is as if I were to explain the material to you already—you would know it, but I haven’t explained it yet. Therefore, I’ll just give you a question and see if you know it without my lecture. Please let me know if you have any questions about this approach.\n\n\n\n\n\n\nThe speaker is introducing a pedagogical exercise. While no specific physics formulas are presented here, if the lecture proceeds into topics like nuclear physics, common formulas you might encounter include:\n\nRadioactive Decay Law: N(t) = N_0 e^{-\\lambda t}\nBinding Energy per Nucleon: B = \\frac{\\Delta m c^2}{A}\nCross-Section for Nuclear Reactions: \\sigma = \\frac{\\text{Number of reactions per unit time}}{\\text{Incident flux} \\times \\text{Number of target nuclei}}"
  },
  {
    "objectID": "2024-Lecture-06.html#analytic-structure-and-contour-integration-in-the-complex-plane",
    "href": "2024-Lecture-06.html#analytic-structure-and-contour-integration-in-the-complex-plane",
    "title": "(2024) Lecture 6",
    "section": "7 Analytic Structure and Contour Integration in the Complex Plane",
    "text": "7 Analytic Structure and Contour Integration in the Complex Plane\nNext lecture, we will move on to discussing analytic functions and properties of amplitudes in the complex plane. This requires you to have a little bit of complex analysis. We’ll discuss this, and even the next problem sheet has a bit of discussion on the complex plane. So we need a little bit of complex algebra.\nLet me just say where it comes from. What is written here is obtained by doing a contour integral. I started with a little circle. My function is analytic and I’m going to extend and stretch the circle in all directions. This is my x-plane, the complex plane.\nConsider the Cauchy integral of F(x) . If no singularities occur inside my integration contour, for any analytic function, the contour integration is zero. Then there is Cauchy’s theorem that tells me I can insert explicitly a singularity inside the circle. If I integrate \\frac{F(x')}{x' - x} dx' around the contour, the integral was zero. But now let me put a pole explicitly inside like this. When I integrate, my integral is not zero any longer. It’s equal to the function evaluated at the pole, and that’s my F(x) .\n\n\n\n\n\n\nThis is the essence of Cauchy’s Integral Formula. For an analytic function f(z) and a point a inside a simple closed contour C , the formula is: f(a) = \\frac{1}{2\\pi i} \\oint_C \\frac{f(z)}{z - a} \\, dz\nThis represents inserting a pole at z = a inside the contour, leading to a non-zero integral equal to the function’s value at that point.\n\n\n\nNow I have this expression here. It’s something similar. I started from a little contour, stretched it to infinity. This part of the contour dropped and the one thing that remained is the integral from 1 to 7. I’m integrating the imaginary part of F(x) from 1 to 7 and asking: can this equation be satisfied? The second question is: what is the analytic structure? What do you mean by analytic?\n\nCut both branch points. This is super maybe unusual for math courses, but that’s what we use all the time in physics is this type of integral where the leftover of the contour is from 1 to 7.\nSince the integral comes from both sides of the cut, and they have opposite signs, what remains is the imaginary part. The real part is the same and cancels. So the thing that remains is the integral of the imaginary part.\n\nThis leads to a dispersion relation: F(x) = \\frac{1}{\\pi} \\int_{1}^{7} \\frac{\\operatorname{Im} F(x')}{x' - x} \\, dx' + \\text{(possible subtractions)}\nHere, the function F(x) is reconstructed from its imaginary part along the cut from 1 to 7.\nIt’s just guessing. Yes, three is a solution. You can just take the constant three because it has no imaginary part. So the real question is if you remove the constant, are there non-trivial solutions? Sometimes we use words like non-vanishing. If I just say F(x) = 3 , then the imaginary part is not present anywhere. The question is about solutions beyond this constant.\nI think you’re completely right. But I was actually thinking of non-trivial solutions. Do they exist or not? You can probably put power expansions in. It might work, it totally could work. Correct, it can be satisfied. The answer is: give me any function \\rho(x) you want. I put it here. Any function \\rho(x) , that integral actually converges for any value.\nLet’s do \\rho(x) = \\sqrt{x} . Put it here and it’s satisfied. Just anything put inside the imaginary part, it’s satisfied. The reason we’re satisfied is this. It’s a way to construct the function. Let me show you this: I put \\sqrt{x} here instead of the imaginary part expression. Then this way I compute my function F(x) . Now this is a super special function. Its imaginary part is equal to \\sqrt{x} in the region from 1 to 7. If I evaluate, the imaginary part is equal to that. In the rest of the complex plane the function is non-zero, but there are no singularities.\nThis insertion that I made is actually done by introducing some non-trivial analytic structures.\nSo let’s now we have three candidates. What kind of non-analytic structures have I introduced? Well, I’d say it’s like a continuous stretch of poles, a stretch of poles. What is meant by a cut? They just end somewhere. Exactly. So the cut is this non-analytic structure where the function on one side is different from the function on the other side.\nIt’s like \\sqrt{-1 + i\\epsilon} and \\sqrt{-1 - i\\epsilon} . We see that this one is equal to +i and this one is equal to -i . So on different sides I have different values. This is a cut. So it’s not really anything else than a spectrum of poles. Poles have a divergence, and this thing does not have a divergence.\nSo what will you say? You go for poles. Okay, so you say that here I introduce poles. Are you attracted by the concept of branch points or cuts? I was thinking about cuts, but now I’m convinced both solutions are not poles. In the integral, there are no poles. Oh, you mean the integrand? Yeah, the integrand has poles, but they are at zero and x . You have to analytically continue something. Something like I say, it’s like you probably have to take it above the complex line or the real line, and below, probably differently. And I think you probably get different branches.\nWe say this and this. I’m not sure what the branch point is, to be honest. Oh, the branch point is where the cut starts and where it ends. So you forget about, let’s say the branch work for the elements. And then you get… Okay, what if, say, poles. So the analytic structure of my function in the x-plane, if I… This is the x-plane. My function has a branch point at 1, a branch point at 7, and then they’re connected by a cut. There are no poles. The function doesn’t have any poles.\nThat’s the way how we, I mean, the way of constructing the function here in this way, you introduce on the castle, you don’t do your space. It’s really funny to think, I mean, where this didn’t come from, go where. And then it appears that what you can do, you can look at this plane and then take a walk here. So here you walk, you never experience any poles, any singularities.\nWhat we can do, we can dive under. I mean, there. And you end up in a different world that has a gate. So it goes through the gate to the other world. And then you find that here there are poles, this is zero, it has poles. And then it has \\sqrt{x} , so it has another cut. The function has an interesting and complicated structure.\nThe complex plane on the regular complex plane where we call the function doesn’t have any singularities except one gate. Through the gate you can go to the other so-called sheet and there you have a lot of stuff going on. That’s it. I mean you just get used to it. And it’s really fun to think of this. We will discuss a little bit more of the complex chart structure and how scattering, what is actually the complex structure of the scattering amplitudes."
  },
  {
    "objectID": "2024-Lecture-06.html#complex-analysis-and-multivalued-functions",
    "href": "2024-Lecture-06.html#complex-analysis-and-multivalued-functions",
    "title": "(2024) Lecture 6",
    "section": "8 Complex Analysis and Multivalued Functions",
    "text": "8 Complex Analysis and Multivalued Functions\nWe have a two-week break next week, so we don’t have class. Have a nice holiday, everyone.\nLet’s make it simpler. The integral will always converge from 1 to 7. So this is what we have, and this is a logarithm. The logarithm itself can have a pole.\nLet’s evaluate the function at 8: \\log(1 - 8) - \\log(17 - 8) . So I’m going to say 8^+ and 8^- , and then \\log(1) = 0 . \\log(-1 - i0) is equal to \\log(-1) - i\\pi .\nWe arrived at the result that they equal each other. So dy is at -i0 and +i0 , but in the equation there is no… I mean, this is continuous. Here is the jump.\nFrom the difference here, the real part of x cannot be between 1 and 7 because we want to have a structure around it. We cannot have an x from 1 to 7 because we have the structures looping around it. Exactly. So the structure is looking around.\nYou introduced the branch point at the edges and then a cut connecting these points. It’s explicitly clear on the Riemann surface by doing a simple integral. You see this expression has this structure: a cut, a branch point at one, a branch point at seven, and then a cut.\nBut the branch point is it. Is it anything else but a pole? No. A branch point can have a divergence; the function could be infinity there. But this function doesn’t have one. So this function’s branch point is at zero and there is… Okay, but the function is zero. Here the function is infinity.\n\nA pole is something like 1/x^3 , which is a pole of third order.\n1/(x - c) \\log(x - c) is not a pole. The pole is something you can get rid of by adding an infinitesimal value in the denominator in the unique complex plane, but it would stay infinity. A pole is an isolated singularity. It means it’s just one point.\nAnd the branch point is a… Where did you hear these words? Of course, I only heard of poles for like your residue theorem and stuff like that. Probably some mathematics course, mathematics for physicists, I suppose, and I guess theoretical minimum, but quite a while ago. I’ve never heard of branch points. Well, you know this by other means, like for square root or \\log(x) . I guess I knew it existed, but I didn’t know like I… Now I fear that I scared people.\n\n\n\n\n\n\n\nOn Branch Cuts and Discontinuities The discussion of evaluating \\log(-1 - i0) relates to the discontinuity across a branch cut. For a logarithm, this is formally: \\text{Disc} \\, \\log(z) = \\log(z + i0) - \\log(z - i0) = 2\\pi i \\, \\Theta(-\\text{Re}(z))\nThis formula describes the jump of the logarithm across its branch cut along the negative real axis, which is essential for analyzing singularities in scattering amplitudes.\n\n\n\nI think for us your lectures are a bit unstructured and you’re like a bit all over the place. But it also makes it a bit more fun because your sketches of boosts, beasts, and rotations are just sketches. You don’t really prove anything in other courses; it’s like a strict or rigorous proof of everything, which is just not fun for a while.\nI wouldn’t be afraid regarding this course. I would rather be afraid regarding first semester courses. But you might confuse them obviously. So for teaching advanced people I’m fine, but you have to be more structured for younger students.\nWe go through the gate, but outside the gate. You said that function is fine, it’s continuous. But here you said it’s another gate. This is the first world, second world enter. Here we can walk around the gate, it’s fine. But then it goes through the gate and ends up another. This is another gate. This is because of how we choose; this is our first road.\nSo you can go through the gate and then appear on that world. And it has many more gates. You can go actually around this and enter on the other side; that’s where you come out here. It would somewhat make huge sense. At least you know what happens when you just return and go and then you appear here.\nBut if you do this, you are not in the end. It’s a third world. And then it’s an infinite number of worlds because it’s a logarithm. This gives an infinite number of worlds, but this one is a bit simpler. So we come here, you go to the first world. This is another world, and this guy has a gate still. You appear here and you can go around and then you appear here. So for this one, yes, it works because this one is a square root and this is logarithmic.\nBut imagine really taking the VR glasses and walking. That would be quite fun. You can suggest this to the Matrix Netflix. Make it an escape room: you only get out if you find the first gate. Escape room quest to this.\nAnd where does this function appear? All scattering amplitudes are like this. All of the scattering amplitudes as functions of Mandelstam variables have energies in the ** s -channel**.\n\n\n\n\n\n\nConnection to Physics This “multi-world” analogy describes the Riemann sheets of a complex function. In physics, scattering amplitudes \\mathcal{A}(s, t) are analytic functions of Mandelstam variables like s . They have:\n\nBranch points at physical thresholds (e.g., s_{\\text{th}} ).\nBranch cuts along the real axis, corresponding to where particle production can occur. The integral structure discussed, similar to a dispersion relation F(s) = \\int_{s_{\\text{th}}}^{\\infty} \\frac{\\rho(s')}{s' - s - i0}  ds' , gives rise to this exact analytic structure."
  },
  {
    "objectID": "2024-Lecture-07.html",
    "href": "2024-Lecture-07.html",
    "title": "(2024) Lecture 7",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-07.html#pentaquark-mass-and-quantum-numbers",
    "href": "2024-Lecture-07.html#pentaquark-mass-and-quantum-numbers",
    "title": "(2024) Lecture 7",
    "section": "1 Pentaquark Mass and Quantum Numbers",
    "text": "1 Pentaquark Mass and Quantum Numbers\nAll right, two minutes. So all of the problems are one-liners. You solved them online, but you have to know what to do. It’s okay.\n\n1.1 Question 1: The Pentaquark State\nLet’s discuss quickly question number one. First, the mass of the states. This appears as the particle. In this condition, neglecting inelastic channels, this particle is formed by the cascade \\Sigma_c and \\bar{D} .\n\n\n\n\n\n\nFigure 1: This image represents the internal structure of a hadronic molecule, specifically illustrating a bound state of two hadrons. In the context of the lecture, it shows two color-singlet clusters (hadronic “bags”), each containing three quarks—one on the left with quark content cud (likely a \\Sigma_c baryon) and one on the right with u\\bar{c} (likely a \\bar{D} meson). The connection between them indicates they are held together by residual strong forces, similar to the nuclear force binding nucleons in the deuteron. This depicts the concept of hadronic molecules discussed in the “Pentaquark State” section, where such states are interpreted as loosely bound systems of two hadrons (rather than five-quark bags), with their total mass close to the sum of the constituent hadron masses, and small binding energy.\n\n\n\nThis particle can travel, can leave. This is a regular particle, but its internal structure is a hadronic molecule.\n\n\n\n\n\n\nA hadronic molecule is a bound state of two or more hadrons, held together by residual strong forces, similar to how nucleons form a deuteron.\n\n\n\nWhat is the mass of this particle? Indeed, what is roughly the mass of this P_c particle—that’s how we call them—is the mass of the constituents. Let me put an equal sign: M_{P_c} \\approx M_{\\Sigma_c} + M_{\\bar{D}}\nThat’s the way how we define the binding energy. Binding energy is the mass difference between the mass of the constituents and the mass of the particle: B = (M_{\\Sigma_c} + M_{\\bar{D}}) - M_{P_c}\nIt used to be called P_c , and last year we updated notations. Now it’s a P_c , because with the C , you indicate that it contains charm. I think this is better. So that’s really clear. As an index, you list heavy quarks because they kind of conserve quantities with the decay; light quarks are… we don’t miss them. You can always recover them from the capital letter. If I say \\Sigma , you know, that’s a capital. The two light quarks, depending on the charge, are either u u , or d d , or u d . An SAP means pentaquark—5 quarks. An SACC , you know, the content is c \\bar{c} plus other 3. For the P_c^+ , this is u d . Likely the P_c candidates that we see in this particular channel are of this type.\nMass of the… okay, this was easy. Neglecting binding energy, you really get the mass of two particles that are called the threshold. The language that we use is saying that the state is… since the binding energy is small, the state sits at the threshold. So the hadronic threshold is there.\nHow much is the binding energy? Approximately like 10 MeV? 100 MeV? What’s the scale? 10. Less than 10. More than 1. Yes. The mass of the \\Sigma_c is 2.5 or so, the mass of the D is around 2 GeV. So the sum is 4.5 GeV. That’s roughly where one would search for such formations.\nNow, quantum numbers, spin algebra—my favorite exercise in this course. We have 1/2 and 3/2 constituents. Parity should be minus minus because we have s-wave. Exactly. Very good. So then it tells you that you expect two states. One of them with spin-parity one-half minus, another one with spin-parity three-halves minus.\nThey have a lower bound on lifetime. Where does the lower bound really come from? It is the binding of the two constituents. Any idea why this state would ever decay and how it would decay? When we talk about lifetime, the particle then decays. That’s what happens with all the particles.\nHow does this particle decay? The energy of the system is conserved. Once you split it into two, the minimal energy that is in a system of two is their mass, like mass one plus mass two. This is already high energy. If they fly apart, its energy is even higher. So this is not allowed. Energy must be conserved. We sit in the rest frame of this particle, and all the energy you have is the mass of this particle. That’s it.\nBecause the c and the \\bar{c} charm quark travel via the electromagnetic process? So annihilation of these two quarks is possible. But this is a slow process. Since it’s an electromagnetic interaction, the probability of this process is much smaller than the process that I would like you to come up with.\nWhy have c \\bar{c} ? It will. Why do they have to annihilate electromagnetically? Can they annihilate via the strong interaction? I mean, like when he says that we take c \\bar{c} and then, even if they have different color, they can produce… then you can create some other quarks. This is… it’s actually suppressed for heavy particles. The heavier the particles, the smaller the chance for them to annihilate. So this is also strongly suppressed.\nNo, no. The three gluons appear only for the color neutral objects. The three gluons we need to construct the color neutral object here are living in the color octet. It’s not singular, so they don’t. The strict vertex is a different suppression. No. So you just make the strange. Yeah. Right.\nSo the big decay, that’s what happens with this object. If we neglect inelastic channels, the decay of this particle that is going to happen is one of the c quarks transitions to s emitting the W . This is a big decay. Actually if the structure of the object is like that, we can even understand the probability of this decay to happen. Because what happens is… Oh, sorry. Big decay is one thing, but there is another transition.\nOkay, big decay is what we discussed. So then one of these two objects decays since it decays weakly. This object will decay or this object would decay quickly. So we can compute the lifetime due to that. But there is another process. You see that this guy is not the lower, it’s not the ground state.\nAs I said, in the spectrum of the D , we combine quarks. So we have 1 and 0 . The lower one is called D and the upper one is called D^* . The T is D^* here is the D , here is energy. This transition is possible by emitting \\pi^0 or \\pi . Actually the most likely decay channel of this is the radiative decay of the D . That’s what happens lower bound of the lifetime. The width is smaller than the width of the D^* . So the time is bigger than the time of the D^* . That’s a bound.\nNever mind. You combine two objects and the object lives as long. It would live an infinite amount if these two particles are stable. Like deuteron is made of proton and neutron, both proton and neutron. Proton is stable, neutron is not stable, but lives long. But deuteron is a stable particle. It happens because the neutron is so bound inside that it cannot decay.\nWhat happens is that the binding mechanism suppresses the phase space of the decay and suppresses the lifetime of the particle. The D meson here would live longer than the D meson. D^* meson isolated. The width of the state is smaller than the width of the D^* . The lifetime \\tau is one over the width. So the lifetime of this object is bigger than the lifetime of the D^* .\nWill the \\Sigma_c^* also survive or also be an atomic molecule? It just goes down an energy step instead of really falling apart. Let’s try to understand what you ask. You say there is a cascade: \\Sigma_c^* and now the \\Sigma_c plus \\pi^0 this molecule. Does this exist? It does.\nMy question was just: so this molecule just makes steps down one energy step? Can it do this? Yes. But it can also dissociate into \\Sigma_c D \\pi or \\Sigma_c D \\gamma , because the energy for this is a lot. In my project, I have a fixed binding energy because my toy model is fixed for the U turn. So it’s actually this binding energy and the situation of the decays is actively discussed in the field, and at every conference you come, you see five talks roughly. That’s a really hot subject.\n\n\n1.2 Question 2: Kinematics and Mandelstam Variables\nLet’s move to other questions. Let’s move to item number two. Understand? Plane is plane of invariants. For any reaction that has a blob, an open direction center on four legs going out, X , A , B , C , you can define invariant variables that characterize the kinematics.\nThe first variable is the mass of the A and B squared. So mass of the A and B computed as the square root of P_A + P_B . So s is the mass squared and square root of s will be the mass of the system of particle A and B . Then t is mass of the system where it has B and C particles. Then the u is the mass of the system that has A and C . Oh, mass squared. Sorry: s = (p_A + p_B)^2, \\quad t = (p_A - p_C)^2, \\quad u = (p_A - p_D)^2\n\n\n\n\n\n\nFigure 2: This figure schematically represents a generic 2 → 2 scattering process in particle physics, as discussed in the context of Mandelstam variables and kinematics. The central blob denotes an unspecified interaction (“something happens”) between four particles, labeled X , A , B , and C , each with arrows indicating their directions. All arrows are pointing outward from the interaction, which is a standard convention indicating final states (except for X if it is considered an initial state). In the context of the lecture, this setup is used to define the Lorentz-invariant Mandelstam variables ( s, t, u ): - s = (p_A + p_B)^2 , the invariant mass squared of particles A and B - t = (p_A - p_C)^2 , the squared momentum transfer between A and C - u = (p_A - p_D)^2 , the squared momentum transfer between A and D This diagram is crucial for understanding how these invariants are assigned based on the flow of momenta, to analyze particle reactions and kinematic domains for scattering and decay processes. It forms the basis for further analysis of the physical kinematics, such as the allowed regions in Dalitz plots, and is central to the discussion of unitarity and analytic properties of the scattering amplitude.\n\n\n\n\n\n\n\n\n\nFigure 3: This figure represents the Dalitz plot or plane of Mandelstam invariants for a 2 → 2 scattering process as discussed in the lecture. The triangle in the center illustrates the kinematically allowed region for the Mandelstam variables s , t , and u . Each vertex and side of the triangle corresponds to one of the channels (s, t, u). The labeled arrows indicate the directions and relationships between the Mandelstam variables: - s : total energy squared for the incoming system, - t : squared momentum transfer between certain legs, - u : squared momentum transfer for the cross-channel. The shaded areas outside the triangle represent physically forbidden regions, while the interior triangle (Dalitz plot) is the physically allowed region for the process, where the transitions and resonance formations happen. The letters b , c , and d correspond respectively to the external particles, aligning with the notation A, B, C, D from the text. The points where the boundaries are marked indicate kinematic thresholds determined by the masses of the particles, and the triangle’s edges are defined by the zeros of the Källén function \\lambda . This diagram visualizes how scattering amplitudes span different kinematic domains and how all physical observable processes for the 2 → 2 system are confined within the Dalitz plot.\n\n\n\n\n\n\n\n\n\nFigure 4: This figure illustrates the kinematics of a 2 \\to 2 scattering process in particle physics, as described in the lecture. The top part of the figure shows a generic Feynman diagram with two incoming particles (labeled p_1 , p_2 ) and two outgoing particles ( p_1' , p_2' ), all connected via a central blob which represents an unspecified interaction. This visual encapsulates the general scenario discussed when introducing Mandelstam variables and the scattering amplitude. The bottom part of the figure provides a depiction of the momenta in the center-of-momentum frame. Here, the incoming momenta p_1 and p_2 are directed towards each other, while the outgoing momenta p_1' and p_2' are shown with the angle \\theta between p_1 and p_1' . The angle \\theta represents the scattering angle, the primary observable that characterizes the final state in elastic 2 \\to 2 scattering. This geometric arrangement is essential for defining variables such as the Mandelstam s , t , and u , and for expanding the scattering amplitude in terms of partial waves, where the amplitude depends on the collision energy and the scattering angle. The figure thus directly links the abstract formalism of scattering theory to concrete physical kinematics and observables.\n\n\n\n\n\n\n\n\n\nThese are the Mandelstam variables. They are Lorentz-invariant quantities that fully describe the kinematics of a 2 → 2 scattering process A + B \\to C + D .\n\n\n\nIt appears that what we figured out before is that two variables are enough to characterize kinematics of the four-legged process. It just comes from counting degrees of freedom. These two variables we have to pick could be either s and t or could be s and u , or it could be all three. But then on the plane they are connected since the sum of the three invariants is related to the masses: s + t + u = m_A^2 + m_B^2 + m_C^2 + m_D^2\nThe matrix element or the scattering amplitude or transition amplitude depends on two variables only, s and t or s and u or any. This amplitude is defined as a function on the plane of invariants and the different domains on this plane describe different processes.\nBefore making this step, let’s only focus on kinematics of the process and try to see where A , B , C , D are located. Any ideas? Number one and the way how I want to solve this is to check just the signs. I want to ask for every process: is s more or less than 0, t more or less than 0, u more or less than 0. By identifying what is the correct answer here, I should be able to place the kinematics.\nLet’s do A . The question is, is the mass of these two particles physical? If it’s physical, then it’s more than zero. If it’s unphysical, then it doesn’t, you know, like most of the dynamics. You have to see exact masses of particles to see exactly where the range of the variables for these kinematics lies. But for the exercise right now, this should be sufficient.\nOkay, A is variable s positive. Why? Because we just simply sum masses of this? Not simply sum the masses. No, that’s not what we do. It’s sum of four-vectors. It’s not equivalent of summing masses. True. But they are like real particles. So the mass of the system for these two real particles is well defined. This mass is at least the sum of masses. Since they have a momentum in the rest frame, the energy of the system is bigger than the sum of masses if they have. For the A , the answer is s more than zero. That’s actually more than (m_A + m_B)^2 .\nWhat about t ? Same logic. If you write drawing the momenta on the right side on this one. I had to say in which direction arrows are pointing out of the blob or inside of the blob. In this definition all of the particles A , B , C are pointing out of the blob and X points inside the blob and that defines the sign.\nThe t is a regular variable, the same as s . It’s a physical mass of two particles. It’s also more than zero and more than even particle threshold, m_B + m_C , and then u more than zero. So the domain. s is bigger than the threshold. This is threshold, this is threshold (m_B + m_C)^2 . u is also bigger than the threshold. The only domain that we have here is the allowed domain for the first kinematics.\nFor B , t is the physical mass of two particles, is again more than zero, more than threshold again. To discuss, to avoid redefining these variables I then discuss A and D particles. I swap p to r , p to minus. I mean if you don’t like that object and we can do it different, but I don’t know is it.\nThe point is to discuss kinematics of part of the reactions, so-called cross-channel reactions, using the same variables. For this scattering, one has to modify definition of the invariants by swapping momenta to minus momenta for particles that move to the other side.\nTwo different directions and then the sum minuses would appear in the first place there. We could start with this direction. The place for this is when t is more than zero because t is the physical mass of two particles. Then s is under A and B . This is kind of an impossible combination. They are on different sides and the variable s is going to be less than zero and then u is less than zero.\nIt’s another impossible combination and the domain, roughly speaking, is where u is below zero. Then s is above, t is above zero. So t prime, t , t . Here’s t . t is this direction. s is above zero. This and u is above zero. This color has so here this is the minimum. This one is B and same on the C . Another one D where is D ? A plus C , X plus B . A and C give us u channel. This is the positive. u is positive.\nNow to see real physical contours for the kinematics. One has to calculate what are the physical ranges of the scattering variables. Like if you work in the cosine of the scattering angle, by placing the restriction that cosine should be from minus one to one, you identify that the border—that not all points here are allowed, but only a certain region.\nThe true border for the scattering is often given by this sixth-order polynomial. In the center is this canvas. This is our Dalitz plot. This is here. Another direction could be here. So 1, 2, 3, 4. Four regions for physical reactions that are happening. It’s important to realize that connection because there’s just a single amplitude, a matrix element, that describes all four.\nIf you get this function and if you constrain it, I mean if you get precisely this function, it describes all four. Just define it on this domain and for every point you can compute, it gives you the complex number one plus three i . This is the value of the quantum transition amplitude. The amplitude itself you can compute at a different place. Now we have a complex transition amplitude for the decay. I think that’s super cool.\nIt works very well in QED. When you consider Compton scattering, photon electron going to photon electron. This is a Compton process. It’s exactly the same matrix element that describes the electron positron annihilation to two photons. It’s exactly the same process that describes two-photon production of an electron positron pair in quantum electrodynamics.\nIn hadron physics it’s a little bit more complicated. Since we don’t have perturbation theory, we always model. What we are going to do when we describe the Dalitz plot, we model it as a sum of the resonances. Then you find that once you want to compute this function right here, the scattering amplitude, it blows up. It has infinities, so it has unphysical behavior.\nThe reason is because we employ a finite range or a finite number of resonances and the physics is more complicated analytically. The fact that this amplitude is related to that domain tells you already that you have to put an infinite number of resonances. Like we saw the lines on the dispersion, these are all resonances. In order to relate this to that domain, you have to operate with infinite sums and then the infinite terms would compensate each other and then you have a reasonable amplitude.\nThere has been an effort for now, 30 years, 50 years, to find such a set of functions that works everywhere nicely and is analytic and reasonable. What’s most difficult is to come up with something that describes the data, because the data is described by Regge theory. You might have heard of Regge theory and this is one of the approaches. So you come up with a complex function that has all the nice properties; it works reasonably in the scattering domain and it works in the decay domain.\nHowever, of course, it lacks an exact understanding of the resonance properties. Like, it would put in resonances there that have zero width in Regge theory. One of the interesting developments is to implement resonances with widths.\nOkay, questions on Monday’s timeline. One more thing. If you like playing with functions, there is a very simple expression that describes the contours of the physical domain. This is called the Källén function. I think it’s worth giving. There is just one function. If you solve \\Phi(s, t, u) = 0 , you find this line, that line, that line and that line.\nJust one function, put it into a solver and for any given value of s . Let’s fix s —where is our s ? Let’s fix s to be minus, you know, 50. We’re going to get two solutions. One of them, let’s put s equal to plus 20. Then you have two solutions using this. So this function is really easy to type into code. This is the Källén function or Klein function. It’s almost a complete polynomial but it misses more terms of this table.\nSo it’s x^2 + y^2 + z^2 - 2xy - 2yz - 2zx . This is called the Källén or challenge function. I think it’s—correct me if it should be going a different direction. So challenge function or Källén function and that’s it. Then the Kibble function is the challenge of three challenge functions where every \\lambda_1 , \\lambda_2 and \\lambda_3 corresponds to a different channel.\nSo \\lambda_2 is then for B it’s \\lambda(t, m_X^2, m_A^2) . Here is the—what’s missing? Mass and t . \\lambda_3 is \\lambda(u, m_X^2, m_B^2) . Yeah, that’s it: \\Phi(s, t, u) = \\lambda(\\lambda_1, \\lambda_2, \\lambda_3) .\n\n\n\n\n\n\nThe Källén (or triangle) function is defined as \\lambda(x, y, z) = x^2 + y^2 + z^2 - 2xy - 2yz - 2zx . The Kibble function, \\Phi(s, t, u) = \\lambda(\\lambda_1, \\lambda_2, \\lambda_3) , where each \\lambda_i is a Källén function of different Mandelstam variables and masses, defines the physical boundaries of the Dalitz plot.\n\n\n\nSo then you come home, you go to Wolfram Alpha and say give me a contour plot. Then you form them and you find all this function and discussion on that in the Pikin and Calani book. Have we discussed this book? The best book on particle kinematics is written by two authors. This is the, if I got it right, see Byckling and Kajantie. The book is excellent. If you get a chance, get yourself this. You know everything about particle kinematics, particularly very peculiar properties of the Kibble function and the Chandrasekhar function, right?\n\n\n1.3 Unitarity and the Scattering Amplitude\nSo we are good to move to the topic of today and it’s unitarity. Unitarity is a constraint on the scattering amplitude. In particle physics we don’t compute from first principles the scattering amplitude, this amplitude, but rather we model it and our guiding principles are on what this amplitude can be and what it cannot be.\nYou cannot just write up an arbitrary expression for this amplitude that fits the data. There are some principles and one of them is probability conservation. Probability conservation transforms into the mathematical statement on the amplitude that is known as unitarity. You might have seen earlier in the particle scattering course, of course, the optical theorem that relates the imaginary part to the total cross section, essentially telling that the imaginary part is equal to the total cross section.\nThat’s a consequence of unitarity, a consequence of the probability conservation. It’s so important that this is a very powerful statement that we are going to derive hopefully today, that just this principle alone allows you already to get a decent low-energy scattering amplitude that describes all of the resonance phenomena. You see the bump in the spectrum due to the resonance. You know what expression you should take in order to describe this phenomenon.\nMoreover, since unitarity is about analytic properties of the amplitude, it tells you what the analytic structure of the amplitude is. In the last lecture we shortly discussed analytic functions and what singularities they might have like cuts, branch points. Unitarity also tells you what is the location of the singularities in the complex plane. That comes from the fact that we are going to deal with unitary functions. Our scattering amplitudes are real unitary functions, functions for which the imaginary part determines the locations of the cuts.\nLet’s start discussing the scattering amplitude and partial waves. For the sake of time, let me state where we arrive. We’ll arrive there first, and then the emphasis is on the derivation. We will derive the following three equations. The first, and all three are dealing with scattering amplitudes.\nThe first one tells how unitarity acts on the full amplitude. So A is the scattering amplitude that describes a certain process. Unitarity tells you that A - A^* is equal to i times A^* A integrated over the phase space of the intermediate state: T - T^\\dagger = i \\int d\\Phi \\, T^\\dagger T\n\n\n\n\n\n\nThis is the general unitarity condition. It is derived from the requirement that the S-matrix is unitary ( \\hat{S}\\hat{S}^\\dagger = \\hat{I} ), where \\hat{S} = \\hat{I} + i \\hat{T} .\n\n\n\nWhat is this diagrammatically? We are going to simplify this process for writing this. For the partial waves, and for the partial waves the variable A is a function of. So the amplitude A is a function of one variable. We’re going to find that A - A^* is equal to this expression, where A^* is very similar to that. For the partial waves you can simplify the phase space and find the expression for that.\nEssentially it tells you that amplitude minus its complex conjugate gives you the imaginary part, and the imaginary part of the amplitude is now equal to. Okay, let’s now try to get these expressions and start with the scattering amplitude and the process, and we are going to deal with the 2-to-2 scattering elastic process.\nOn the board, I draw the first diagram where the blob just indicates some interaction—something happens with two particles. Below is the kinematic representation of the reactions in the center of mass frame—the center of momentum frame. In the center of momentum, lengths of the vectors are the same, so the center of momentum means total momentum is zero.\nEven if particles have different masses, their momenta are the same and they equal to the function of square root of the \\lambda function of masses. So the p_1 is equal to p_2 is equal to \\lambda^{1/2} / (2\\sqrt{s}) , and \\lambda has s and the masses. After interactions, particles are the same, the masses are the same, breakup momentum is the same. The only thing that happens is the angle is changing.\nYou might wonder where this whole beautiful physics is sitting. Where in my variables would I see different interactions that they put in? It appears the observable for these interactions is the distribution over this angle. We have discussed this already. Whatever happens inside has only one way to manifest itself in the way how the distribution over the angle looks like. Because for two-to-two everything is fixed, energy is fixed. Once you fix the energy, the only way to manifest itself will be the angle.\nThere are two variables on it: the energy of the system and the scattering angle, right? So p_1 , p_2 is the state, is the two-particle state vector, and I’m, I also have mass, and I’m going to use the variable \\theta . The only variable that I need is the scattering angle. The one here I’m going to drop, it indicates that the angle is for particle one.\nI would like to define the amplitude. I would like to consider the contraction of the final state. I make that first: p_1' , p_2' ; p_1 , p_2 is that scattering amplitude is defined as the expectation value of two-particle states: initial state on the right and then the final state on the left. Conservation of energy and momentum comes with these four delta functions.\nNow in order to proceed, which is integrated, so this is the identity operator, or the projection operator. This phase space for 2-body is nothing but 1 / (2\\pi)^5 \\cdot (\\sqrt{s}/2) \\, d\\cos\\theta \\, d\\phi / 2 . What my state here is is the two particles back to back. I define the coordinate system as xyz . In that coordinate system I have a two-particle state with the angles \\theta and \\phi which are going back to back. The momentum of particle 1 I characterize by the angles \\theta and \\phi .\nThat’s why it actually makes sense to keep \\theta and \\phi here. I have the same state on the right and on the left. I integrate over all possible angles. The two-body phase space here just gives me all possible directions on the sphere. On the sphere for all possible combinations of angles for the 4\\pi solid angle.\nNow it’s obvious. It’s important to make sure that identity acts as an identity. You come, you act as an identity. You should get something like something similar from that you have normalization condition. What is that? I mean, you see this already. So I put it in. I have to. This is certainly not a function of the p_1 , p_2 , p_1' , p_2' . 1 / . The first phase space integral d^4 , so probably d^3 / (2\\pi)^3 . That’s the expression for this paper. 2\\pi over cube, 2\\pi over 2 and 2\\pi over 4 over here. So this should be identical.\nLet’s see if it works. We put it in. Now I have everything right. If I put this identity here, I get to integrate over p_1 , p_2 and 2\\pi .\n\n\n\n\n\n\nFigure 5: This figure represents the unitarity condition for the scattering amplitude in diagrammatic form. On the left side, there is a difference between the full amplitude and its complex conjugate (depicted as two blobs), illustrating the left-hand side of the unitarity equation. On the right side, the diagram shows the “cut” through the intermediate state, representing the sum over all possible intermediate on-shell states in the phase space. The equality reflects the mathematical expression T - T^\\dagger = i \\int d\\Phi \\, T^\\dagger T , where the imaginary part of the full amplitude is generated by the sum over amplitudes involving all possible intermediate configurations. This is a pictorial way to represent probability conservation (unitarity) at the level of Feynman diagrams.\n\n\n\nOf course, if you have one, we have a density. Now we can proceed with unitarity.\nThis two-particle scattering amplitude is defined. Now unitarity comes. Shouldn’t there also be from the unitarity the option that p_1' is p_2 ? They are distinguishable particles for me, scalar particles distinguishable, different type to avoid cross terms. The probability is a statement on the full scattering operator that it’s unitary, and part of the operator is the identity—the transition without interaction—and another one that.\nWell, by subtracting identity from the full scattering operator, we introduce our interaction operator, this T , and that’s the operator that stands here that defines our scattering amplitude. When we deal with these amplitudes in field theory we always talk about the nontrivial part, something addition to this one. The easiest way to proceed with this. This is our unitary constraint.\nThat’s a critical statement that will constrain our partial waves, will constrain our scattering amplitude. But in order to see that we need to come from this condition to the condition for T , and then the condition for A . The way goes is that by putting T , so 1 - 1 + i T , 1 - i T^\\dagger . Let’s see if i is on the right side. So minus plus here, plus minus here, i times i gives me plus. That’s why plus here T T^\\dagger , right? Then here is the i T multiplied to one and then minus i T^\\dagger here.\nOnce we multiply both parts by i , the minus appears here, this i disappears and we move to the other side. That’s correct. The only thing that remains is to put the final state and we put now the T operator here to split it into A A^* . Let me first fill this part. For the sake of time.\nRight, so the way to proceed from here is to use this expression for the amplitude here and here. That’s the product here. What to do with this is a bit more involved. We have to insert identity here and split it into intermediate states. Insert intermediate state, which is in our case just all possible orientations of the intermediate particles, and energy is fixed. Then we have to integrate over the momentum.\nWhat now happens here is that this gives us T and then (2\\pi)^4 delta function. This gives another T^\\dagger , T^* , (2\\pi)^4 delta function. It’s equal to i . This together is the delta function to the power 4 even in the phase space d\\Phi_{\\text{intermediate}} . Delta function for the energy momentum conservation is going to tell you that p_1' + p_2' should be equal to the p_{1,\\text{int}} + p_{2,\\text{int}} . That’s the first.\nThe second one is going to tell me that the p_1 + p_2 is going to equal p_{1,\\text{int}} + p_{2,\\text{int}} . This, the first one connects initial state to final state. Second connects initial state to intermediate, intermediate to final. We can just pull out the one that connects intermediate, which one connects the initial to final. Then keep the one that just constrains the sum of the momentum for the two particles and get our phase space equal to the 2\\pi equals \\delta(p_1 + p_2 - p_{1,\\text{int}}) , and then integral of the T^\\dagger T d^4 .\nNow we arrive to the first equation: T - T^\\dagger = i \\int T^\\dagger T \\, d\\Phi . The most general form of this equation that does not have none of these constraints is going to be very similar to that. It’s just you have to sum over all intermediate states and then integrate not over two-body phase space, but rather n-body phase space if there are n-body allowed.\nDiagrammatically, it says amplitude minus amplitude conjugated has to be sum over all intermediate states. Every time you have it, the means that you have to integrate over all possible configurations. That’s what now. Instead of working, we simplify variables in terms of the momentum and the transferred energy squared and transferred momentum. We can change. We can use angle and this.\nNow a function of angle can be approximated by the partial waves. That’s a very convenient series because it converges well, especially when for hadron physics. These amplitudes are. There are constraints on this amplitude that they cannot be present for the high J , so they cannot be large for high J . There is a natural suppression related to the size of hadrons. There are no, the contributions of the high values of the J are small.\nThat’s why often in experiment, in order to describe the data, you just need a few partial waves, two, three, sometimes six, but not more than ten. That’s a very convenient approximation. It’s not an approximation once you keep this sum to infinity. Once you. If you keep the sum to infinity, like in Regge theory, that’s an exact relation between left and right.\n\n\n\n\n\n\nThe scattering amplitude is often expanded in partial waves: A(s, \\theta) = \\sum_{\\ell=0}^\\infty (2\\ell + 1) a_\\ell(s) P_\\ell(\\cos\\theta) . This expansion simplifies the unitarity condition for each angular momentum component \\ell ."
  },
  {
    "objectID": "2024-Lecture-07.html#partial-wave-amplitudes-and-unitarity-constraints",
    "href": "2024-Lecture-07.html#partial-wave-amplitudes-and-unitarity-constraints",
    "title": "(2024) Lecture 7",
    "section": "2 Partial Wave Amplitudes and Unitarity Constraints",
    "text": "2 Partial Wave Amplitudes and Unitarity Constraints\nAnother thing that appears here is the partial wave amplitude. This amplitude is a function of a single variable. For every partial wave there is one function of one variable, and every partial wave has fixed quantum numbers.\nA large advantage of partial waves is that they do not talk to each other. They don’t influence each other. Every partial wave is independent. Since quantum numbers in scattering are conserved, partial waves in the initial state are only related to partial waves in the final state with the same quantum numbers.\nIn the unitarity constraint, you will see that it’s actually a single partial wave that relates to its output. There is no mixing of partial waves.\nThe way we can proceed is to insert the partial wave expansion here and then simplify the phase space. For this, you will need one magic formula, and I don’t have time to derive it. It’s present in many references, which I will send you.\nBut there is a really cool relation I would like you to see. When we insert the expansion, the initial state has an angle of zero. The final state depends on the scattering angle \\theta .\nFor the final state, the Legendre polynomial P_J(\\cos\\theta) is a function of \\theta . This is the same as the big Wigner d function d^J_{0,0}(\\cos\\theta) . We can write it differently. We know d^J_{0,0} is important, and it can be decomposed using the relation: d^J_{0,0}(\\cos\\theta) = \\sum_\\lambda d^J_{0,\\lambda} \\, d^J_{\\lambda,0}\nThis is a very powerful expression.\nHere, the capital G function is defined such that when the indices are zero, it relates to d^J_{0,0} . What happens next is that you have to integrate over all possible intermediate states, and both amplitudes are expanded in partial waves. The way to do this is to expand the cosine between the first, second, and last states into a composition of intermediate states. These are exactly the functions we need to relate the full amplitude to the partial wave amplitude.\nThe expression we arrive at for the partial wave amplitude has expected numerical coefficients because it’s essentially a base case. The next step is to divide the right part by… or multiply both parts by 1 / a_J , so that term vanishes. Then we have 1 / a_J^* , and a minus sign appears.\nFrom this, we find the imaginary part of the partial wave amplitude is simply i \\rho(s) .\n\n\n\n\n\n\nFigure 6: This figure represents the behavior of the imaginary part of the inverse partial wave amplitude, as constrained by unitarity in two-body scattering. The key relation shown in the lecture is \\operatorname{Im} a_J^{-1} = -i \\rho , which leads to a prediction for how the imaginary part of the amplitude, \\operatorname{Im} a_j , depends on the kinematic variable s (the square of the total energy in the center-of-mass frame). Physically, the plot shows that as the invariant mass \\sqrt{s} increases from the two-particle threshold (where \\sqrt{s} = m_1 + m_2 ), the phase space factor \\rho(s) also increases. This function \\rho(s) is proportional to the breakup momentum of the two outgoing particles and characterizes the available phase space for the reaction. The curve in the diagram starts from zero at the threshold (where the particles just begin to be produced), rises sharply with a square-root behavior, and then gradually saturates to a constant value 1/(16\\pi) at high energies, as described by the expression [ (s) = ] where the Källén function \\lambda encodes kinematic constraints. This plot highlights how unitarity fixes the imaginary part of the partial wave amplitude as a function of energy: it is determined entirely by kinematics and phase space, not model-dependent details. This is crucial for constructing amplitudes that respect probability conservation in scattering theory.\n\n\n\nThis is amazing because it tells us exactly how the imaginary part of the inverse amplitude looks.\n\n\n\n\n\n\nThe unitarity condition for a partial wave amplitude a_J(s) is: \\operatorname{Im} a_J(s) = \\rho(s) \\, |a_J(s)|^2\nThis leads directly to the inverse amplitude relation: \\frac{1}{a_J(s)} = \\operatorname{Re} \\left[ \\frac{1}{a_J(s)} \\right] - i \\rho(s)\nThe imaginary part of the inverse amplitude is fixed by unitarity to be -\\rho(s) .\n\n\n\nLet’s visualize this. Plot s on the horizontal axis and the imaginary part of a_J on the vertical axis. The phase space function \\rho(s) starts from threshold with a square-root behavior, \\sqrt{s - (M_1 + M_2)^2} , and approaches a constant 1/(16\\pi) at high s .\nMore precisely, the two-body phase space factor is: \\rho(s) = \\frac{1}{16\\pi} \\frac{\\lambda^{1/2}(s, m_1^2, m_2^2)}{s}\nwhere \\lambda(x, y, z) = x^2 + y^2 + z^2 - 2xy - 2xz - 2yz . This function goes to one at high s .\nNow for the last point: modeling. We know the imaginary part from unitarity, but we do not know the real part. The real part of the amplitude is genuine to the specific interaction—whether electromagnetic, strong, or gravitational. Any unitary interaction must have an imaginary part related to phase space, but the real part must be computed or modeled.\n\nTheorists extract the real part by analyzing LHC data.\nExperimentalists extract it by analyzing hadronic data.\n\nThe simplest model writes the inverse amplitude as some real function plus the unitary imaginary part. One option for this real function is a simple pole. The amplitude computed assuming the real part is a single pole is called a relativistic Breit-Wigner amplitude: a_J(s) = \\frac{g}{M^2 - s - i g \\rho(s)}\nModeling the amplitude in terms of such pole terms is often called the ** K -matrix approach, where: a_J(s) = \\frac{K(s)}{1 - i \\rho(s) K(s)}\nand K(s) is a real function, like K(s) = g / (M^2 - s) . Let me plot this unperturbed amplitude. On the vertical axis is the absolute value of A , and on the horizontal axis is s . The parameter M is the bare mass** where the peak appears, and the coupling g determines how broad the peak is. This is the simplest resonance amplitude.\n\n\n\n\n\n\nFigure 7: This figure shows the typical shape of the absolute value of the resonance scattering amplitude, |A| , as a function of the center-of-mass energy squared, s . The peak occurs near the “bare mass,” marked as m^2 , and the height of the peak is related to the coupling squared, g^2 . This diagram represents a resonant phenomenon described by the relativistic Breit-Wigner amplitude, which is commonly used in particle physics to model resonance behavior. When two particles scatter, if the energy matches the resonance mass, the scattering probability rises sharply—this is visible as the large peak in the amplitude. Away from this energy, the amplitude is small, resulting in a characteristic bump. This behavior is a direct manifestation of creating an intermediate unstable particle (a resonance), and the width of the peak encodes the lifetime (inverse of the decay width) of that resonance. The plot thus visualizes how the unitarity constraint and resonance modeling describe experimental observations in particle collision experiments.\n\n\n\nThis describes a resonant phenomenon: particles collide, form an intermediate resonance for a short time, and then decay. In an experiment, you smash particles and count how often they scatter, tuning their collision energy. You would observe:\n\nA small interaction probability at most energies.\nA huge peak in the cross-section when the energy matches the resonance mass M .\nThe probability dies out again at higher energies.\n\nThis resonance phenomenon indicates something interesting inside the interaction: an intermediate particle that can be formed."
  },
  {
    "objectID": "2024-Lecture-07.html#two-pole-structure-and-unitarity-in-scattering-amplitudes",
    "href": "2024-Lecture-07.html#two-pole-structure-and-unitarity-in-scattering-amplitudes",
    "title": "(2024) Lecture 7",
    "section": "3 Two-Pole Structure and Unitarity in Scattering Amplitudes",
    "text": "3 Two-Pole Structure and Unitarity in Scattering Amplitudes\nNow, from the two-particle K-matrix, we get two poles. The cross section has two peaks: the first corresponds to the first pole, and the second corresponds to the second pole, with a zero in between.\nThis zero comes from the fact that the K-matrix vanishes. There is a typo to correct: it should be K^{-1} in the initial expression. The correct scattering amplitude is: A = (K^{-1} - i)^{-1}\nWhen K multiplies this expression, the entire amplitude is managed, producing two poles. The K-matrix itself has one singularity, which generates another set. To reach the second singular asymptotic behavior, the function must cross zero. Therefore, K vanishes between the poles, and this zero propagates into the squared amplitude, resulting in an exact zero on the real axis.\nAnother key point is that the energy values of the peaks are not exactly the bare masses. They enter a complicated expression, so the peak occurs very close to, but not exactly at, the bare mass value. This is why the mass is called the bare mass; the process of inserting it into the amplitude dresses the bare particle mass via propagator screening. Let’s examine the amplitude expression more closely: A = (K^{-1} - i \\rho)^{-1}\nExpanding this in a Taylor series gives: A = K + K(i\\rho)K + K(i\\rho)K(i\\rho)K + \\cdots\nThis infinite series provides a diagrammatic meaning:\n\n\\rho represents the two-particle phase space (the propagator).\nK represents the point-like elementary interaction.\n\n\n\n\n\n\n\nFigure 8: This figure illustrates the decomposition and diagrammatic expansion of the two-body scattering amplitude in the K-matrix formalism. The equation a = (K^{-1} - i\\rho)^{-1} expresses the amplitude a as the sum of iterated elementary interactions (K), each connected by insertions of the two-particle phase space factor ( i\\rho ). The expansion K + K(i\\rho)K + K(i\\rho)K(i\\rho)K + \\ldots represents the resummation of all possible repeated scatterings between two particles, where each term corresponds to an additional loop (propagator) in the intermediate state. The diagrams underneath the terms show the corresponding Feynman-like representations: - The first term (K) is a single point-like interaction (no intermediate states). - The second term (K i\\rho K) describes two consecutive point-like interactions separated by a loop, indicating propagation through an intermediate two-particle state. - The third term (K i\\rho K$iK) corresponds to three such interactions connected by two intermediate propagations, and so on.  Physically, this expansion encapsulates the unitarity constraint discussed in the lecture, showing that the imaginary part (and analytic structure) of the amplitude arises from the possibility of these intermediate on-shell two-particle states, as enforced by the phase space factor $. This formalism guarantees probability conservation in the scattering process and models resonant phenomena, such as the formation of intermediate bound or quasi-bound states (resonances). The approach is foundational in constructing amplitudes that respect the analytic properties and unitarity required by quantum field theory.\n\n\n\nThe scattering amplitude is a complex function. We have discussed the magnitude (length) of this complex vector, but not its angle—the scattering phase. The argument of the scattering amplitude is this phase, and it has interesting behavior.\nIn the complex plane, the amplitude traces a circle. Starting from threshold, it increases, reaches a maximum, then decreases back to zero before making a second, similar shape. The variable here is the imaginary part of$ A$ as a function of s . The maximum is approached around m_{1,0}^2 . This plot is called an Argand diagram. A more convenient quantity to plot is often: F = A \\cdot \\rho\n\n\n\n\n\n\nThe unitarity constraint, from probability conservation, is a crucial tool for modeling amplitudes. It fixes the imaginary part of the amplitude, so we only need to model the real part. This real part represents the point-like interaction, which must be resummed to all orders.\n\n\n\nTo summarize, unitarity provides a powerful constraint for modeling. The real part of the interaction can be modeled in several ways; one common technique is the effective range expansion.\nYou can parametrize the inverse K-matrix at low energy as: K^{-1}(k) = a^{-1} + \\frac{1}{2} r_s k^2 + \\mathcal{O}(k^4)\nThis is called the effective range approximation, where:\n\na is the scattering length.\nr_s is the effective range."
  },
  {
    "objectID": "2024-Lecture-08.html",
    "href": "2024-Lecture-08.html",
    "title": "(2024) Lecture 8",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-08.html#analytic-and-holomorphic-functions",
    "href": "2024-Lecture-08.html#analytic-and-holomorphic-functions",
    "title": "(2024) Lecture 8",
    "section": "1 Analytic and Holomorphic Functions",
    "text": "1 Analytic and Holomorphic Functions\nIn today’s lecture, I would like to discuss unitarity and complex numbers and move towards discussing complex functions. We had a little too little time in the previous lecture to cover these aspects, but this is important to understand and I think it also links to what you already know from mathematics.\nI would like to introduce you to two mathematical concepts: analytic functions and holomorphic functions, which are two words for the same idea.\n\nA function is called analytic at a point x_0  if it can be represented by a Taylor series that equals the function in the vicinity of that point. This means there exist coefficients such that: f(x) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(x_0)}{n!} (x - x_0)^n\nA function is called holomorphic if its complex derivative exists, meaning you can approach the point from any direction in the complex plane and the derivative is the same. This is the same property as being analytic. Don’t be afraid of the word “holomorphic”—it’s just mathematicians inventing a cool word to say a function is analytic.\n\n\n\n\n\n\n\nKey Definitions:\n\nAnalytic/Holomorphic Function: A function that can be locally represented by a convergent power series (Taylor series) and has a well-defined complex derivative.\nTaylor Series Representation: f(x) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(x_0)}{n!} (x - x_0)^n expresses that the function’s value near x_0 is determined by its derivatives at x_0 .\n\n\n\n\n\n1.1 Examples and Properties of Analytic Functions\nAs examples, consider functions that are analytic:\n\nAll polynomials are analytic everywhere.\nA rational function (a polynomial divided by another polynomial) is analytic except at a finite number of points—the zeros of the denominator.\nWhen we say a function is analytic on a domain, it means every point in that domain is a point of analyticity.\n\nThe function \\sqrt{x} is analytic everywhere except at x = 0 . Zero is called a branch point, a point where there is no derivative and no valid Taylor series.\nReal analytic functions are another interesting class—functions that are real-valued and analytic. An example is the real function \\sqrt{x} for x \\geq 0 .\nA key property of a real analytic function extended to the complex plane is the Schwarz reflection principle. It states that for such a function f , the value at the complex conjugate of a point is the complex conjugate of the function’s value: \\overline{f(z)} = f(\\overline{z})\n\n\n1.2 Visualizing and Applying the Concepts\nWhen discussing analytic functions of a single complex argument, it’s convenient to draw the domain—the complex plane. On the x-axis is the real part of the argument ( \\Re(z) ), and on the y-axis is the imaginary part ( \\Im(z) ). We can indicate regions of analyticity on this diagram.\nThe Schwarz reflection principle implies a symmetry: the function’s values in the lower half-plane are related to those in the upper half-plane. You can compute a value in the lower half-plane by computing it at the conjugate point in the upper half-plane and then taking the complex conjugate.\nLet’s test this with an example using f(z) = \\sqrt{z} , which is real analytic for real z . We’ll compute \\sqrt{1 + i} and \\sqrt{1 - i} .\nFirst, express the numbers in polar form z = r e^{i\\theta} , where r = |z| and \\theta = \\arg(z) :\n\nFor 1 + i : r = \\sqrt{2} and \\theta = \\pi/4 . So, 1 + i = \\sqrt{2} e^{i\\pi/4} .\nFor 1 - i : r = \\sqrt{2} and \\theta = -\\pi/4 . So, 1 - i = \\sqrt{2} e^{-i\\pi/4} .\n\nNow, apply the square root using the rule \\sqrt{z} = \\sqrt{r} e^{i\\theta/2} :\n\n\\sqrt{1 + i} = \\sqrt{\\sqrt{2} e^{i\\pi/4}} = 2^{1/4} e^{i\\pi/8}\n\\sqrt{1 - i} = \\sqrt{\\sqrt{2} e^{-i\\pi/4}} = 2^{1/4} e^{-i\\pi/8}\n\nNotice that \\sqrt{1 - i} is indeed the complex conjugate of \\sqrt{1 + i} , which confirms the Schwarz reflection principle: \\overline{\\sqrt{1 + i}} = \\sqrt{\\overline{1 + i}} = \\sqrt{1 - i} ."
  },
  {
    "objectID": "2024-Lecture-08.html#cauchys-theorem-and-discontinuous-integrals",
    "href": "2024-Lecture-08.html#cauchys-theorem-and-discontinuous-integrals",
    "title": "(2024) Lecture 8",
    "section": "2 Cauchy’s Theorem and Discontinuous Integrals",
    "text": "2 Cauchy’s Theorem and Discontinuous Integrals\nCauchy’s theorem states that the integral over a closed contour of a function in the complex plane is equal to all non-analytic contributions inside this contour. If the singularity is a pole, it’s given by residues. If it’s a branch point, one must contour around it, and so on. The theorem systematically accounts for all non-analytic behavior.\nWhat is notable is that this provides a numerically well-defined procedure to integrate a function that is discontinuous. For example, we can compute the integral of the function \\sqrt{z} on the circle of radius 1, and the integral converges despite the function being discontinuous at the branch point.\n\n2.1 Contour Integral of \\sqrt{z} on the Unit Circle\nOn the circle |z|=1 , the function is parameterized as z = e^{i \\phi} . However, \\sqrt{z} jumps across the branch cut: above the cut it is +1 , and below it is -1 . The contour integral is:\n\\oint_{|z|=1} \\sqrt{z} \\, dz = \\int_{0}^{2\\pi} \\sqrt{e^{i \\phi}} \\cdot i e^{i \\phi} \\, d\\phi\nTaking the principal branch where \\sqrt{e^{i \\phi}} = e^{i \\phi/2} , this simplifies to:\n\\oint_{|z|=1} \\sqrt{z} \\, dz = i \\int_{0}^{2\\pi} e^{i (3/2) \\phi} \\, d\\phi\nCare must be taken because the function is discontinuous on the interval [0, 2\\pi] ; one cannot simply evaluate at the endpoints. To handle this properly, one can shift the integration range to [-\\pi, \\pi] , where the function is continuous on that segment:\ni \\int_{-\\pi}^{\\pi} e^{i (3/2) \\phi} \\, d\\phi\nThis yields a finite, well-defined result.\n\n\n2.2 Deforming the Contour and the Branch Cut Discontinuity\nThe key point is that this contour integral equals the integral of the discontinuity across the branch cut. By shrinking the contour around the branch cut (typically placed along the negative real axis), the integral transforms.\nFor \\sqrt{z} with a branch cut along the negative real axis, the values on either side of the cut are:\n\nAbove the cut: \\sqrt{z}_{\\text{above}} = i\\sqrt{|x|}\nBelow the cut: \\sqrt{z}_{\\text{below}} = -i\\sqrt{|x|} , for z = x &lt; 0\n\nThe discontinuity across the cut is therefore:\n\\sqrt{z}_{\\text{above}} - \\sqrt{z}_{\\text{below}} = 2i\\sqrt{|x|}\nThus, deforming the original circular contour gives an equivalent representation:\n\\oint \\sqrt{z} \\, dz = \\int_{\\text{branch cut}} \\left[ \\sqrt{z}_{\\text{above}} - \\sqrt{z}_{\\text{below}} \\right] dz = \\int_{-\\infty}^{0} 2i\\sqrt{|x|} \\, dx\nThis illustrates a core property of analytic functions and Cauchy’s theorem: the contour of integration can be deformed freely as long as no non-analytic regions are crossed. For this example, it is instructive to verify that the circular integral and the branch-cut discontinuity integral give the same result.\n\n\n\n\n\n\nThe residue theorem, \\oint_{\\mathcal{C}} f(z) \\, dz = 2\\pi i \\sum_{k} \\text{Res}(f, z_k) , is the foundation. For integrals with branch points, we extend the logic by deforming the contour around branch cuts, which reduces the problem to integrating the function’s discontinuity across that cut. This technique is powerful for evaluating real integrals and appears in physics contexts like dispersion relations and spectral representations.\n\n\n\nThe remaining step is the final evaluation, which involves the imaginary part of \\sqrt{x} times i , leading to a simple integration on the real axis. The two methods—direct parameterization and branch-cut deformation—provide a consistent answer, demonstrating the robustness of the complex analysis approach."
  },
  {
    "objectID": "2024-Lecture-08.html#analyticity-and-branch-points-in-the-scattering-amplitude",
    "href": "2024-Lecture-08.html#analyticity-and-branch-points-in-the-scattering-amplitude",
    "title": "(2024) Lecture 8",
    "section": "3 Analyticity and Branch Points in the Scattering Amplitude",
    "text": "3 Analyticity and Branch Points in the Scattering Amplitude\nThe scattering amplitude is the real magic function.\n\n\n\n\n\n\nFigure 1: This figure illustrates the derivation of the optical theorem using the principle of unitarity in scattering theory. On the left, the sum over all possible intermediate states ( \\sum_n ) is shown, representing the process where the initial state can scatter into any set of possible intermediate particles (labeled by n ). The diagram in the center shows the forward scattering amplitude, while the terms on the right represent the subtraction of the amplitude from its complex conjugate. This corresponds to taking the difference between the amplitude and its Hermitian conjugate, which isolates the imaginary part of the forward scattering amplitude. This imaginary part is related (via unitarity) to the total cross section for the process, connecting the squared modulus of the amplitude summed over all intermediate states to the discontinuity (imaginary part) of the amplitude itself. This graphical equation expresses the optical theorem in terms of analyticity and unitarity of the scattering amplitude as described in the lecture.\n\n\n\nLet’s return to our two sketches of the amplitude, for which we derived the optical theorem and discussed the analytic structure. The claim is that the amplitude is a real magic function, so part of it.\nLet’s clarify the assumptions and the physical principle. The amplitude is not accessed directly in experiment; we cannot validate its properties exactly. What we measure is the amplitude squared. Access to the amplitude itself is only available via our observables.\nHowever, scattering theory and probability conservation imply that certain properties of the amplitude, particularly constraints on its imaginary part, tell us where the imaginary part is present. The fact that it’s analytic is a postulate. This is something we have to assume.\nIt’s stronger than an assumption. We don’t assume its analytic properties; this is the building principle of our series. All series we have seen so far have unitarity built in. Therefore, not only unitarity, but also causality, which is related to analyticity.\nThe amplitude being an analytic function is a principle that is postulated in our theory. It is related to the causality of the theory—that the past does not influence the future. Events separated outside the causality cone don’t influence each other. We are not deriving this, but you can find the causality connection to analyticity in several books; we take it as a postulate.\nThe amplitude is analytic, and then unitarity tells you more. Moreover, the amplitude is real analytic below the threshold, because the imaginary part is connected to the particle’s appearance in intermediate states. This is only present once you are above threshold, because the interaction tells you that the amplitude has an imaginary part above the threshold. Below threshold it doesn’t have any imaginary part; it’s real.\nSo here I have a diagram on the x-axis. Again, it’s the complex plane of the energy. The variable s is E^2 , where E is the center-of-mass energy, and the amplitude \\mathcal{A}(s) as a function of this s is an analytic function.\nWhat we get to deal with is only the values of this amplitude above the threshold. However, the postulates of our theory tell you that using analyticity we can extend the domain of definition into the full complex plane. I hope you wrap your mind around the idea that now we can extend this analytic domain and think of our amplitude as a complex function.\nInstead of the energy of the interactions being like 5 GeV, you can put a complex number there and then you probe the function away from the real axis. This function has a certain range of singularities. The fact that the imaginary part is not present below threshold and then suddenly appears above threshold tells you that a certain singular disk pops up. These singularities are the branch points.\nEvery threshold has nice derivations of the threshold singularities for different numbers of particles. However, something to see easily is the two-body threshold. I want to show you that it introduces square root singularities. It simply follows from the fact that the imaginary part has a square root.\nLet me show you that the imaginary part of the amplitude from unitarity that we derived last time is related to the amplitude squared itself. There is a prefactor here. This prefactor is the phase space, simply the two-body phase space. The one half comes from \\mathcal{A} - \\mathcal{A}^* .\nI place the imaginary part on here, here I replace it and \\frac{1}{2} over here. The two-body phase space has the factor \\frac{2p_{\\text{cm}}}{\\sqrt{s}} . This 2p_{\\text{cm}} is the breakup momentum. This is something that actually makes a singularity, something that vanishes at the threshold.\nThe breakup momentum is the momentum particles have. Clearly if you are at the threshold, you have the minimal energy of the system. It’s simply two masses of the particles. They don’t have free energy, they don’t have momentum. That’s something that vanishes.\nMathematically you see that if you compute this two-body breakup momentum, you find that it’s equal to the Källén function.\n\n\n\n\n\n\nFigure 2: This figure represents the analytic structure of the scattering amplitude \\mathcal{A}(s) as a function of the Mandelstam variable s = E^2 , where E is the center-of-mass energy. The horizontal axis is the real axis of s , while the vertical axis would represent the imaginary part if drawn fully. The portion of the real axis labeled “real analytic” depicts the region below the two-particle threshold at s = (m_1 + m_2)^2 . In this region, the amplitude is real analytic, meaning it is a real-valued, analytic (holomorphic) function—there is no imaginary part, and the function can be represented by a convergent Taylor series. At the point s = (m_1 + m_2)^2 , the threshold for producing two particles of masses m_1 and m_2 , a branch point occurs. This marks the beginning of a branch cut along the real axis for s &gt; (m_1 + m_2)^2 , which is where the imaginary part of the amplitude appears due to physical particle production. The branch cut is related to the square root behavior of the two-body phase space, as discussed in the lecture. Thus, the figure illustrates how the analytic properties of the amplitude change at the physical threshold, emphasizing the importance of branch points and cuts in the analytic structure of scattering amplitudes.\n\n\n\nRemember \\lambda(x, y, z) = x^2 + y^2 + z^2 - 2xy - 2yz - 2zx . You can arrange this as the product, and to be precise, the product of the two terms where you have x - y + z . This is the masses of two particles and the difference between them and under the square root.\nThe first term gives you a singularity at the threshold and the second one gives you a singularity at the pseudothreshold. The integral relation as we wrote it, as we derived, is valid only above the threshold. The imaginary part is non-zero and present only once you go above the threshold.\nThis imaginary part appears to have a square root behavior. That indicates, that tells you that the function itself has a square root branch point. Essentially above that point the function has this branch cut.\nWe would like to connect this to the Schwarz reflection principle. Since our function was real and analytic on a segment of the real axis, the Schwarz reflection principle works above. It connects the amplitude in the upper half-plane with the amplitude in the lower half-plane.\nIf your function is \\mathcal{A}(s + i\\epsilon) , it simply tells you that the imaginary part flips if you go from above the real axis to below the real axis. That’s a relation where \\epsilon is small enough.\nThis is now in the pop, in the rock. People like the word. Maybe next time I bring you something. I was impressed recently. Listen to the song “Infinitesimal,” and that’s a word I like. It just means very, very small, infinitesimal.\nI’m going to use this i\\epsilon , and you’ve seen it before. This is just the little number that indicates that you are like a very, very small amount above the real axis or below the real axis. Cool.\nIt happens due to the phase space. We realized that if the function, if there were no phase space configuration summations on the right, you could relate the imaginary part to the amplitude itself and there would not be branch points. But it’s unavoidable. You have to sum over phase configurations.\nThat gives you the square root branch point. It also tells you that the amplitude has a branch point starting at the threshold and going in the positive direction.\nI wanted to quickly give an example of such a function, an example of a real analytic function, a function with a cut to the right. An example of a real analytic function like our scattering amplitude, but something very simple with a square root function that has a cut to the right.\nThe square root of x doesn’t work. Test. Cut on the left? On the left. Let’s cut to the left. How do I see where it has the cut? Simply because amplitude of 1 + \\epsilon is equal to amplitude of 1 - \\epsilon , there is no cut.\nThen \\sqrt{-1 + i\\epsilon} is equal to i , and \\sqrt{-1 - i\\epsilon} is equal to -i . On this side the function evaluated from above and the function evaluated from below have different values. That tells me in which direction I put my cut.\nThis is a branch point and this is a non-analytic point. For every branch point there is a cut attached and then it splits my manifold and analyticity into the functions, into the sort of surfaces, different sheets. All of the functions elsewhere except this point are analytic.\nBut you have to work to see this analyticity. Essentially you have to analytically continue functions. If you see the pattern, you want to make this function analytic. It’s always possible, but you have to work a little bit by extending the analyticity domain.\n\n\n\n\n\n\nKey Formulas for This Section\n\nTwo-Body Unitarity: \\operatorname{Im} \\mathcal{A}(s) = \\frac{1}{2} \\int d\\Phi_2 \\, |\\mathcal{A}(s)|^2\nBreakup Momentum & Phase Space: \\rho(s) = \\frac{2p_{\\text{cm}}}{\\sqrt{s}} , where p_{\\text{cm}} = \\frac{\\sqrt{\\lambda(s, m_1^2, m_2^2)}}{2\\sqrt{s}}\nKällén Function: \\lambda(x, y, z) = x^2 + y^2 + z^2 - 2xy - 2yz - 2zx . For two-body kinematics, this becomes \\lambda(s, m_1^2, m_2^2) = [s - (m_1 + m_2)^2][s - (m_1 - m_2)^2] , showing the square-root branch points at the threshold (m_1+m_2)^2 and pseudothreshold (m_1-m_2)^2 .\nSchwarz Reflection Principle: \\mathcal{A}(s + i\\epsilon)^* = \\mathcal{A}(s - i\\epsilon) for real s below the first threshold."
  },
  {
    "objectID": "2024-Lecture-08.html#analytic-structure-and-branch-cuts-of-a-square-root-function",
    "href": "2024-Lecture-08.html#analytic-structure-and-branch-cuts-of-a-square-root-function",
    "title": "(2024) Lecture 8",
    "section": "4 Analytic Structure and Branch Cuts of a Square Root Function",
    "text": "4 Analytic Structure and Branch Cuts of a Square Root Function\nComing back to the example, you’ll understand it better once I finish it.\nSo, if I put the minus x and evaluate the function somewhere in the complex plane, I find it’s now fully analytic here, and it has a cut to the right.\nNow, let’s evaluate this function at s = -1. What is it equal to? I want my function here, and it gives me one minus, minus. This is an example of a real analytic function.\nOr, let’s put the amplitude—the simplest amplitude. A valid amplitude would be: \\sqrt{-s + m_1^2 m_2^2}\nwhich has similar properties.\n\n\n\n\n\n\nFigure 3: This figure illustrates the analytic structure of the function \\sqrt{x} in the complex plane. The image shows a complex plane with a vertical (imaginary axis) and horizontal (real axis) line, with a thickened or darkened segment along the negative real axis. This dark segment represents the branch cut of the function \\sqrt{x} , which is a line (chosen conventionally along the negative real axis) where the function is discontinuous. The point at the origin ( x=0 ) is the branch point where the non-analytic behavior begins. Physically, this means that as you move around the origin in the complex plane, the value of \\sqrt{x} can jump discontinuously when crossing the cut, which is essential for defining the function’s analytic properties. In the context of scattering amplitudes and complex analysis, identifying such branch points and cuts is crucial for understanding where the amplitude is analytic (holomorphic) and where it develops discontinuities due to physical thresholds.\n\n\n\n\n\n\n\n\n\nThis function f(s) = \\sqrt{-s + m_1^2 m_2^2} is analytic in the complex s -plane except along a branch cut. This cut is typically placed where the expression under the square root, -s + m_1^2 m_2^2 , is real and negative, leading to a discontinuity.\n\n\n\nQuickly, while I’m cleaning the board: what is the analyticity structure of this? We are in the x-plane.\nLet’s finish here. I put -9 in the first one to make it more interesting. Anyway, this first function has the cut on the right, and the second one has a cut. They are very similar, but shifted by one.\nSo essentially, the structure is: one cut, then a second cut. When you have this situation, there is no jump here. You can jump twice and the cuts overlap, so there is no discontinuity of the function. It’s analytic right here.\nThe right answer is just the cuts connecting two points. This one is tricky. The first time I saw it in a mathematical context, I was really shocked because the locations of the branch points are the same. There are two points, x and x, where the function is non-analytic.\nBut the locations of the cut are driven by the places where the imaginary expression under the square root has an argument of \\pi or -\\pi . For a regular square root function, the cut appears where the argument is either \\pi or -\\pi .\nTo understand where your Mathematica, C, or Python library would draw a cut, you need to understand where the expression under the square root has an argument touching \\pi or -\\pi . And then, apparently, this is indeed between the points, but also along this line.\n\nThis is the first cut going to infinity.\nThis is the second cut going to infinity.\n\nIt’s crazy, and this is actually different from the previous case.\nIf you just split the product into two square roots: \\sqrt{(-s + a)(-s + b)} = \\sqrt{-s + a} \\cdot \\sqrt{-s + b}\nthen you remove these two connections. I don’t want to confuse you, but to warn you: one has to be careful how you write the expression, exactly how you split the square root, because that makes the function different on the real axis.\nI think they will be the same on the real axis, but on the complex plane the functions are different. They might even be different elsewhere…\nTo prove that \\sqrt{(-s + a)(-s + b)} is not equal to \\sqrt{-s + a} \\cdot \\sqrt{-s + b} , we can simply evaluate the function at s = -1. That’s an easy exercise.\nThe way I see that they are different is because I know the analytic structure of the first expression is one cut connecting two branch points. In order to arrive from this structure to the other, I can take this cut, rotate it over here, take this one, rotate it over there, and cancel two cuts. Making these two cuts cancel each other tells me that the function in the original configuration has a different value at s = -1.\nIf I evaluate, I should see this immediately:\n\nEvaluating the top one: \\sqrt{(-(-1) + 2)(-(-1) + 2)} = \\sqrt{(1+2)(1+2)} = \\sqrt{9} = 3\nEvaluating the product of square roots: from the first factor \\sqrt{1+2} = \\sqrt{3} and from the second \\sqrt{1+2} = \\sqrt{3} . Their product is (\\sqrt{3})^2 = 3 .\n\nHowever, with careful sign consideration from the branch choices (as hinted in my notes), the values can differ. For instance, \\sqrt{2i} \\cdot \\sqrt{2i} could be evaluated as 2i , while \\sqrt{(2i)^2} = \\sqrt{-4} could be 2i with an appropriate branch, illustrating the subtlety. The key point is their analytic structures—their branch cuts—are fundamentally different."
  },
  {
    "objectID": "2024-Lecture-08.html#complex-plane-analogy-for-scattering-amplitudes-and-resonances",
    "href": "2024-Lecture-08.html#complex-plane-analogy-for-scattering-amplitudes-and-resonances",
    "title": "(2024) Lecture 8",
    "section": "5 Complex Plane Analogy for Scattering Amplitudes and Resonances",
    "text": "5 Complex Plane Analogy for Scattering Amplitudes and Resonances\nIts resonances are poles of the scattering amplitude. You will hear that many times in the future.\nThink of the intensity flow. The function in the complex plane is like the complex structure of a house. In this house there are just a few routers. You desperately want your Internet; the farther you are from the router, the weaker signal you get. If you sit at a point and you have a really good Internet, you are probably sitting not far from the router. Similar to that, this is our couch in the house where people usually sit and they experience different strengths of the Internet. The routers are the resonances.\nHere I have combined two modes on the Y axis. I have a complex s plane, with real s on the axis. This indicates minus imaginary s . This is the same as I would have for the complex plane. I draw a square. The square is the strength of your Internet when you sit on this couch. In the middle you have the closest distance to the router, to the resonance pole, and therefore your strength is the highest. If you go far away, your Internet weakens.\nNow let’s make the house a little bit more complicated. We have several floors. In that case the cuts… Here is my map of the room. As usual, I am the couch where people sit on the real axis. But in that case I have the house a little bit complex. There is a room with different electronics, a different floor, so I can go to another room. I experience all the routers that are in another room. Essentially, if in another room I have a router sitting here, I want to see the influence of it from my couch. Let me put it here. This is floor one and the next is two. I am going to draw the sheet too. Sheet one is our floor one and then sheet two is floor two. Here is the gate. You can think of this now as the sort of stairs from one to another, and this continues. If I have my router here, I am going to see I have a really good strength here and then here as well. But if I go around the corner, I start losing the signal. Here the distance becomes high. The way to get Internet is around the wall. This is the gate to another floor and I can only enter on that side.\nIs it clear? I feel like this picture of the floors and the routers is really helpful, but might be still overwhelming. The routers are the resonances. I see the routers on each floor. If they are above the threshold, it is too complicated. Essentially, when you hear about the complex plane and the poles, just think of the intensity floor somewhere in the complex domain. There are gates to other floors. Do not think about them as changing the level, but it is simply the way to connect one to another. Somewhere on this surface that has different levels, you place the routers. These routers influence your intensity, which you see on the real axis.\nWhat is the difference between a bigger room and multiple floors? No difference. The rooms are infinitely big either way. But since at every point I can be at different sorts of floors that are connected smoothly to each other, I have to draw several maps, several sheets. In the shopping malls you also have multiple floors with shops indicated because it is really hard to show it on a single one.\nFor simplicity, unitarity tells us the cut should be to the right. But I would never do it practically like that. I know unitarity tells me that. Nothing happens if I just place the cut to the left. I will demonstrate what I want to do with the square root function, \\sqrt{x} . It has a branch cut and I am carrying my function value right here. There is nothing going to happen if I just draw the cut in different directions. I would like to say that this function is the same function. But now in that case I have a branch cut. Is it the same? Let us evaluate this function. At x = -1 you have an i . At -1 + \\epsilon you have an i . This function at -1 gives you an i again. This function and that function are exactly the same in this region. The difference between them is that I took my branch cut and rotated it to the right such that I opened the space underneath. I just made the renovation and changed the rooms how they are located in the house. It changes nothing in the strength of the amplitude essentially because the walls, I mean there are no walls. Essentially everything is continuous. The cut, the way how I draw the cut, is just a way to separate different branches. There is no wall that prevents the signal strength. That is why for this I would never do this practically like that. This is what unitarity tells us about imaginary part and real analyticity. For practical reasons it is always convenient to open up the closest branch to us to see. Therefore it is more natural to place the cut in a convenient location. The cut goes to the right, I turn it to the left and now actually my function is not real, but I now expose a bigger range of the complex plane to analyze.\nEssentially, if I sit here, this point on the real axis is influenced by all singularities in the complex plane that are nearby. If I have a pole right here, I do not have to care about the branches any longer. I just immediately see the effect in the strength of my amplitude if my pole is nearby. That is the most convenient, in my opinion, way to think of the complex plane and the scattering amplitude.\n\n\n\n\n\n\nFigure 4: This figure illustrates the physical meaning of resonances as poles in the scattering amplitude and the analytic structure of complex functions in the context of scattering theory. - Branch cuts and analyticity: The sketches at the top show the analytic structure of functions like \\sqrt{x(x-1)} versus \\sqrt{x}\\sqrt{x-1} , emphasizing that while individual square roots have branch cuts on the real axis, their product (if not written with care) might not match the full analytic structure, demonstrating the importance of how a function is defined with respect to branch points and cuts. The analytic continuation and placement of branch cuts affect the behavior and discontinuities of the function. - Poles and “intensity flow”: The middle section introduces the concept that physical resonances correspond to poles of the scattering amplitude in the complex s -plane (where s is the Mandelstam variable, often s=E^2 ), and how these influence observable data. The schematic “complex s plane” with a marked resonance pole shows that the observable intensity |A|^2 (the square of the amplitude) on the real axis is enhanced in the vicinity of such a pole—this is the resonance “peak” seen in experiment. The sketch shows this as “strength of signal” near the pole. - Sheets and analytic continuation: The two panels labeled “Sheet I” and “Sheet II” display different Riemann sheets in the complex s -plane associated with the function’s branch points and cuts. This reflects the fact that multivalued functions like those with square roots naturally extend to multiple sheets, and poles associated with resonances may appear on different sheets depending on the analytic continuation—a key concept in understanding physical resonances and thresholds. - Cuts can be rotated: The panel illustrating how branch cuts can be “rotated” or placed differently without changing the analytic nature of the function emphasizes that the mathematical convenience of cut placement aids analysis, but the physical consequences (like the influence of poles) are unchanged. - Amplitude pole formula and physical interpretation: The expression \\mathcal{A} = 1/(m_R^2 - s) and the boxed formula m_R^2 = (M_R - i \\Gamma_R/2)^2 indicate that the complex pole position encodes both the mass M_R and width \\Gamma_R of the resonance, and the concept of “Full Width at Half Maximum” (FWHM) shown on the intensity plot at bottom right links these mathematical quantities directly to physical observables. - Influence of singularities: It is noted that “data points are influenced by singularities”—meaning that the experimental measurements on the real axis “feel” the presence of nearby analytic structures (branch cuts and poles) in the complex plane. Physically, this figure captures: - How the analytic structure (branch points, cuts, and poles) of the scattering amplitude function in the complex plane directly governs the observable phenomena in scattering experiments (resonance peaks, thresholds, and cusps). - That resonances (unstable particles) are defined as poles of the amplitude in the complex s -plane, while branch cuts stem from multi-particle thresholds. - The importance of Riemann sheets and analytic continuation for understanding the full behavior of these complex amplitudes. - The freedom to draw branch cuts where convenient, reflecting the purely mathematical aspect of cuts in representing multi-valuedness, rather than physical discontinuities. - Ultimately, the physical resonances in scattering data are manifestations of the analytic structure of complex functions associated with the amplitude—particularly the positions and nature of poles and branch points in the complex plane.\n\n\n\n\n\n\n\n\n\nKey Analytic Structure The scattering amplitude \\mathcal{A}(s) has a pole at a complex value s = s_p where the denominator vanishes: \\mathcal{A}(s) \\propto \\frac{1}{s - s_p}\nThis pole defines the resonance. Its location is complex: s_p = (M_p - i\\Gamma_p/2)^2 , where M_p is the pole mass and \\Gamma_p is the pole width.\n\n\n\nI measure my amplitude above threshold. Here is (M_1 + M_2)^2 . That is where I measure my amplitude. What I measure is influenced by structures near threshold. If there is a resonance that I see in the data, it means down below there is a pole that makes this resonance. A resonance is always a pole. That is actually how we define the particles. Particles are always poles in the amplitude.\nWe have conventions for how to define the width and mass of the resonance. They come from the location of the pole. A single pole amplitude has this form: \\mathcal{A}(s) \\propto \\frac{1}{s - s_p} . When I say pole I literally mean a zero of the denominator. The location of this pole where the denominator vanishes is s_p or \\bar{m}^2 . This is a complex number. The real and imaginary part of this number are called mass parameters of the pole. This is literally the definition.\nWe call the mass of the pole the real part of the square of the pole location and the width of the pole twice the square root of the pole, twice imaginary part minus twice imaginary part of the pole location. More precisely, s_p = (M_p - i\\Gamma_p/2)^2 . They are related to the observed mass and width, because this is something you can define experimentally. If you see the signal, it has a peak location and a full width at half maximum. For narrow resonances, \\Gamma_p is approximately equal to the full width at half maximum and M_p is approximately equal to the peak location. That is not the case for broad resonances, but for narrow ones this is the case.\nWhat is the analytic structure of this function? The analytic structure is simply a pole. There are no branch points, there is nothing else. It is simply one pole.\nA little bit more complex example that we have on an exercise sheet is the relativistic case. Wigner had everything built in. It had a pole in the K-matrix and it had a square root branch point from the phase space. The K-matrix that we discussed last time is the way to incorporate poles and correct analytic structure together. It works for multiple loops. The scattering amplitude is \\mathcal{A} = K (1 - i \\rho K)^{-1} .\n\n\n\n\n\n\nParameterizing Resonances In practice, we often use specific parameterizations to fit data:\n\nThe Breit-Wigner amplitude is a common limit: \\mathcal{A}_{\\text{BW}}(s) = \\frac{g}{s - M^2 + i M \\Gamma(s)}\nThe more general K-matrix formalism ensures unitarity and can handle multiple channels: \\mathcal{A} = K (1 - i \\rho K)^{-1}\nHere, K is a real symmetric matrix, and \\rho is the phase-space factor.\n\n\n\n\nThe last comment on this subject is what we do when we analyze the data. The ultimate goal is to characterize resonances by their mass and width, or the pole location. We come up with the parameterization using a K-matrix or P-vector. Often you can use a simple Breit-Wigner, \\mathcal{A}_{\\text{BW}}(s) = \\frac{g}{s - M^2 + i M \\Gamma(s)} , which is the limit case of the K-matrix, unless you constrain your amplitude. The amplitude then has an expression that is rather complicated, has many terms, but it is an analytic function.\nYou have three parameters that you are just looking at in the data. By fitting this, you fix these parameters by analyzing data and then you explore the analytic expression. You know that it probably has a branch point. You decide either you draw it to the right or to the left. It is up to you. What is important is that everything that you see, all spikes, all peaks, everything that you see in your functions has some origin, and the origin is in the complex plane. If it has a peak, likely there is a pole there."
  },
  {
    "objectID": "2024-Lecture-08.html#thresholds-branch-points-and-poles",
    "href": "2024-Lecture-08.html#thresholds-branch-points-and-poles",
    "title": "(2024) Lecture 8",
    "section": "6 Thresholds, Branch Points, and Poles",
    "text": "6 Thresholds, Branch Points, and Poles\nAnother important phenomenon you see in the data is the cusp. This is the amplitude squared, |A|^2 , plotted against the Mandelstam variable s . You see a cusp, and that type of singularity is also known as a branch point.\nSo, do we have our branch points? The first threshold introduces a branch point; every threshold introduces a singularity. For two particles, it’s a branch point. We have already discussed this branch point. If there are more than two particles, combinations like \\pi\\pi , KK , or \\bar{K}K would give a branch point at 1 GeV. Then the amplitude might have a spike. This is an indication that in the complex plane all is fine, but there is a branch point.\nFor every branch point, we have to attach a sheet. This is the location of the cut; it’s up to us how to draw it, but it introduces more surfaces. So this is a direction.\nThe last thing to realize is about the triangle. We know that at threshold the function has a square root singularity, but thresholds are only opening new surfaces for you. The thresholds are only determining the map of your complex plane. The real singularities, or the strong singularities that make intensity peak, are poles.\nA situation where |A|^2 has this threshold behavior, but then rises very quickly and goes down, indicates that there are some poles nearby. If the poles were underneath, that kind of function would of course peak at that place. In that case, what likely happens is that there is a bound state; there is a pole here. If there is a pole on the real axis, it would not show up as a nice resonance-like peaking structure.\nIf you think again about the map of routers and the internet: if you have a router here and you sit on the couch, the signal strength will be highest here and then lower farther away. That’s simply how to understand threshold enhancements.\n\nThreshold enhancements are often indications of poles below threshold. These are bound states.\nThere is another phenomenon of poles at the same locations, but underneath another sheet, which is called a virtual state. They are not that different from each other.\nA bound state can live forever; it is a real state that can travel. It is a particle that does not decay.\nA virtual state is one that does not travel and does not decay. This is simply an enhancement.\n\nThis distinction is one of the objectives and discussion points in the field. When you observe a new structure, what kind of structure is it?\n\nIs it related to a threshold?\nIs it a pole?\nIs it a pole sitting below a certain threshold?\nOr is it a resonance that sits in the complex plane and is not related to a threshold?\n\nA relation to a threshold indicates a molecular nature. Remember, every threshold has two masses that are summed: s = (m_1 + m_2)^2 . It implies that there is a continuum; there is one particle and a second particle that interact with each other. This is our threshold. If there is a pole that is related to a threshold, likely part of the wave function for this state is of this two-particle type. This is the molecular type. That’s why identifying all thresholds and the complex structure, and where the resonance pole sits, is so important.\nNow, a quick question. What about the other threshold, s = (m_1 - m_2)^2 ? Yes, it’s a pseudo-threshold. It appears artificially in our expressions because of the breakup momentum formula: p = \\frac{\\sqrt{[s - (m_1 + m_2)^2][s - (m_1 - m_2)^2]}}{2\\sqrt{s}}\nIf you look at that place, the amplitude is not supposed to have a physical singularity. This tells you that you cannot literally take this expression and continue analytically at the place of this pseudo-threshold. This is a sort of false threshold. We don’t see it in the amplitude.\nThis is one indication that you should not take this expression literally and build it into your model. Instead of using just the phase space factor, \\rho(s) = \\frac{1}{8\\pi} \\frac{2p}{\\sqrt{s}} , note that this is actually the imaginary part of the bubble diagram. You see this simply from unitarity, because once you cut this diagram, the imaginary part would be equal to the product of the matrix elements (both equal to one) and the two-body phase space, because you cut two lines. Here is the two-body phase space.\nThe pseudo-threshold is present here because you are using only the imaginary part in your amplitude. If you were to take the full bubble diagram, you don’t have a pseudo-threshold there.\n\n\n\n\n\n\nKey Formulas Recap\n\nPhysical Threshold: s = (m_1 + m_2)^2 defines where a new two-particle channel opens, creating a branch point.\nTwo-Body Phase Space: \\rho(s) = \\frac{1}{8\\pi} \\frac{2p}{\\sqrt{s}} is the phase space factor and appears as the imaginary part of the bubble diagram from unitarity.\nUnitarity Relation: A simplified form is \\operatorname{Im} \\mathcal{M}(s) \\propto \\rho(s) |\\mathcal{M}(s)|^2 , linking the amplitude’s imaginary part to the phase space.\n\n\n\n\nI was thinking we could do the exercise in the lecture today of computing this bubble diagram literally, because it’s really closely related to unitarity."
  },
  {
    "objectID": "2025-Lecture-01.html",
    "href": "2025-Lecture-01.html",
    "title": "(2025) Lecture 1",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Anna Zimmer"
  },
  {
    "objectID": "2025-Lecture-01.html#starting-with-qed",
    "href": "2025-Lecture-01.html#starting-with-qed",
    "title": "(2025) Lecture 1",
    "section": "1 Starting with QED",
    "text": "1 Starting with QED\nI start with QED — quantum electrodynamics — which describes how light interacts with anything that has a charge.\nIt’s relevant for us for only two reasons:\n\nOur quarks have charge, so they interact with photons.\nThe Lagrangian for QED is much simpler than for QCD. (see Figure~4)\n\nLet’s use this chance to understand all symbols, and we’ll proceed to QCD later.\nThe equation is complicated, but once you understand the general structure, you don’t need to look it up to write it down.\nThe Lagrangian is a function of two fundamental fields:\n\n\\psi — the field of an electron, muon, or quark (something with charge)\nA — the photon field\n\nSo, \\psi is a fermion field, and A is the photon field."
  },
  {
    "objectID": "2025-Lecture-01.html#lagrangian-structure-and-notation",
    "href": "2025-Lecture-01.html#lagrangian-structure-and-notation",
    "title": "(2025) Lecture 1",
    "section": "2 Lagrangian Structure and Notation",
    "text": "2 Lagrangian Structure and Notation\nThe Lagrangian is a scalar quantity — not a vector or matrix, but a number once evaluated at any point.\nScalar quantities are achieved by contracting indices: every index introduces a dimension, and you only get a scalar when all indices match.\nWe use Einstein notation: when you see the same index twice, it means we sum over it — same as in quantum mechanics.\nHere, \\mu and \\nu are Lorentz indices living in 4 dimensions: 3 spatial (x, y, z) and 1 time dimension.\nThe \\mu here and \\mu there must be contracted. I’m skipping the explicit summation over \\mu from 1 to 4, and also over \\nu, which also appears twice.\nNow, F_{\\mu\\nu} is actually a matrix: \\mu is 4-dimensional and \\nu is 4-dimensional, so F_{\\mu\\nu} is a 4 \\times 4 matrix.\nYou don’t multiply matrices as usual; you multiply them component-wise. Every component is multiplied by itself, and then you take the trace or sum all elements.\nEach coordinate in this matrix is computed as:\nF_{\\mu\\nu} = \\partial_\\mu A_\\nu - \\partial_\\nu A_\\mu\nwhere \\partial_\\nu is the derivative in time and space — essentially \\frac{\\partial}{\\partial x^\\nu}."
  },
  {
    "objectID": "2025-Lecture-01.html#indices-and-spinor-structure",
    "href": "2025-Lecture-01.html#indices-and-spinor-structure",
    "title": "(2025) Lecture 1",
    "section": "3 Indices and Spinor Structure",
    "text": "3 Indices and Spinor Structure\nIf it were just \\mu contracted with \\mu, it would be simple. But here, we also have spinor indices.\nThere is another set of indices that I suppressed — \\tau and \\rho — which come from the spin of the particles.\nParticles are not scalar; they have spin. That’s why the fermion field \\psi has four components.\n\\tau and \\rho are spin indices, not Lorentz indices. For Lorentz indices, we distinguish covariant and contravariant, but for spin indices, we just sum.\nSomething is still fishy in this Lagrangian because I’m adding a map.\nWe agree that these are four matrices, and this is a vector, so we can contract them. We get a matrix here, and then somehow from a matrix I’m subtracting a scalar — that’s not good.\nWhat’s missing is the diagonal matrix.\n\\psi is a four-component spinor, and \\bar{\\psi} is not a four-component spinor in the same way — it’s a row vector.\nWhat we do is take the conjugate transpose (dagger), then multiply by the \\gamma matrix from the left so it remains a row of numbers. Then you’re ready to contract with whatever matrix is here.\n\n\n\n\n\n\nThe full QED Lagrangian is: \\mathcal{L}_{\\text{QED}} = -\\frac{1}{4}F_{\\mu\\nu}F^{\\mu\\nu} + \\bar{\\psi}(i\\gamma^\\mu D_\\mu - m)\\psi This describes interactions between charged fermions and photons, with the first term representing electromagnetic field energy and the second describing fermions with mass and interactions.\n\n\n\n\n\n\n\n\n\nFigure 5: Feynman diagram representing an interaction term in the Lagrangian: two fermion fields coupled to the electromagnetic current with vertex strength g. The diagram directly corresponds to the interaction term of the Lagrangian."
  },
  {
    "objectID": "2025-Lecture-01.html#moving-to-qcd",
    "href": "2025-Lecture-01.html#moving-to-qcd",
    "title": "(2025) Lecture 1",
    "section": "4 Moving to QCD",
    "text": "4 Moving to QCD\nOne exercise is to see the same structure for the QCD Lagrangian, which I’ll write next. Once you do it once, it becomes super clear.\nLet’s do QCD now — it’s not too bad.\nThe exercise says: recover the indices, the range, the number of terms. You introduce the blue one because every index is N.\nSo: F_{G\\mu\\nu}, then U_{G\\nu} minus D_G, A is contracted besides gluon. That’s a really good exercise to write down — it’s super logical.\nIt’s actually the same equation as here with more indices because there are more dimensions.\nLet me check if I forgot G in front of the term g_s — exactly, here there is another G."
  },
  {
    "objectID": "2025-Lecture-01.html#dimensionality-in-qcd",
    "href": "2025-Lecture-01.html#dimensionality-in-qcd",
    "title": "(2025) Lecture 1",
    "section": "5 Dimensionality in QCD",
    "text": "5 Dimensionality in QCD\nNow let’s figure out the dimensionality of the objects quickly.\nThere’s a new object \\lambda here. These are three-dimensional — that’s a good starting point.\nSo IJ is here. These are 2 \\times 2 matrices. IJ must be here, must be here this one. Then they come, you contract over A.\nThis has a \\mu and also ij. These are still…\nNow we go here: IJ stays I, J, I, J. Here is the trace in these IJ dimensions.\nWhen you commute two matrices, you get a matrix — it’s multiplication minus subtitled multiplication.\nOverall, this is a matrix in \\mu and \\nu (2 \\times 2), but also in ij where I is an index of 3 and j is an index of 3.\nI’ll try to make more sense of this equation in a moment. As soon as I think all indices have to be introduced.\nI really care that you understand what equations are right, at least in terms of mathematical structure. Definitely everyone is capable of tracing this."
  },
  {
    "objectID": "2025-Lecture-01.html#flavor-and-color-indices",
    "href": "2025-Lecture-01.html#flavor-and-color-indices",
    "title": "(2025) Lecture 1",
    "section": "6 Flavor and Color Indices",
    "text": "6 Flavor and Color Indices\nThe F traces the flavors — F numbers: quarks U, D, S, C, T, B. We have six flavors, so the index F goes over all six possibilities.\nWhat else? Spinors in that case had four dimensions, and now there’s an extra three for color.\nThe index I here traces the color charge.\nThe only thing I don’t track is the spinor indices. For the QED Lagrangian, we agreed there’s something related to the spin projection of the particle — that’s another \\tau\\rho indices. We don’t put it here; otherwise it’s too complicated.\nIf you think of this field, it has:\n\nA flavor (let’s fix to up quark)\nA color (let’s fix to red)\nAnother four which are spinors (spin projections)\n\n\n\n\n\n\n\nThe QCD Lagrangian is: \\mathcal{L}_{\\text{QCD}} = -\\frac{1}{2}\\mathrm{Tr}(G_{\\mu\\nu}G^{\\mu\\nu}) + \\sum_f \\bar{\\psi}_f(i\\gamma^\\mu D_\\mu - m_f)\\psi_f where f runs over the 6 quark flavors, and the field strength tensor includes non-Abelian terms due to gluons carrying color charge."
  },
  {
    "objectID": "2025-Lecture-01.html#equations-of-motion",
    "href": "2025-Lecture-01.html#equations-of-motion",
    "title": "(2025) Lecture 1",
    "section": "7 Equations of Motion",
    "text": "7 Equations of Motion\nLast thing about this expression: once you know the Lagrangian, you can get the equations of motion by applying \\frac{\\partial\\mathcal{L}}{\\partial(\\partial_\\mu \\text{field})}.\nI think it’s easier to look at this expression where such a partial derivative would be nonzero.\nFor \\psi, we can do the same for A_\\mu (the gauge field). \\psi is only sitting in this term.\nThe first derivative for the first term actually equals zero. The only place where this is nonzero is when you have \\partial_\\mu \\psi.\nThe D has the inside of it — that’s the derivative. If you expand this, you’ll have \\bar{\\psi}\\gamma^\\mu D_\\mu\\psi.\nWhen you differentiate, \\bar{\\psi} will remain, and then \\frac{\\partial\\mathcal{L}}{\\partial\\psi} would be nonzero from the other term here.\nThe mass term will also produce something for the second term.\nThat way, you get equations of motion — differential equations describing how the field evolves in time and space.\nIf we apply this to QED, do you know what the equation is called that describes the motion of a fermion?\nPerfect. Remember, what’s the equation? It says it changes, but it doesn’t have a \\bar{\\psi} side; it just has \\psi.\nNote: G plus or minus is the same term as here. I think the D_\\mu here instead of the short — yes.\nThat would be for the next portion."
  },
  {
    "objectID": "2025-Lecture-01.html#gauge-transformations",
    "href": "2025-Lecture-01.html#gauge-transformations",
    "title": "(2025) Lecture 1",
    "section": "8 Gauge Transformations",
    "text": "8 Gauge Transformations\nGo to the next portion — the Rancho Kinemic picture.\nWhile I’m cleaning the board, let me ask questions about this point.\nWe discussed the Lagrangian and equations of motion. Let’s discuss gauge transformation and gauge symmetry — an extremely important concept in field theory.\nWe’ll only touch on this briefly since we’re not doing field theory, but it’s really important you know where legs grow from it.\nSomething very familiar from quantum mechanics is the phase ambiguity of the wave function. We can update the phase, and the absolute square of the wave function won’t change because you multiply \\psi to \\psi^* and the phase drops out.\nThis is fine. First is to acknowledge that this should be a symmetry of our theory — we should be allowed to make this phase transformation.\nIt’s kind of by definition, so this overall phase you don’t even have to think about.\nThe problem appears when you demand your theory to be invariant under changes of phase at all possible space-time points simultaneously with different phases.\nWhat if I want to adjust my wave function at every space point?\nWhy is this a problem? Because in our equation of motion, in our Lagrangian — let me just write the Dirac part: \\bar{\\psi}D_\\mu\\gamma^\\mu\\psi.\nHere I have a term \\partial_\\mu\\psi, and this term becomes \\partial_\\mu\\psi' which is \\partial_\\mu(e^{i\\alpha(x)}\\psi).\nLet me take the derivative. This equals applying the derivative to the first term and then to the second term.\nWhen I apply it to the second term, I just have \\partial_\\mu\\psi. When I apply it to the first term, I get \\partial_\\mu acting on this — the exponent stays, but I have to take the derivative of the exponent.\nSo there’s an extra term. Indeed, the same equation won’t hold for \\psi'. It doesn’t transform to the same equation because the derivative yields another term with \\partial_\\mu\\alpha.\nThis means that local gauge transformation is not a symmetry of the free Lagrangian of the free moving Dirac particle.\nYou cannot adjust phase independently at different points for a free particle.\nIn simple words, this means the theory is incomplete. It only becomes complete if you consider radiation, photons, and charged particles together.\nOnce you look at the full Lagrangian (I think I get a minus here — that’s an exercise in field theory), you update simultaneously the phase of the field \\psi and the electromagnetic field A.\nThen you see that the additional term appearing in the covariant derivative D_\\mu will cancel exactly the one you get from the phase.\nThen the Lagrangian stays the same with the updated fields \\psi and A.\nThis fact led us to the D_\\mu term. Actually, writing D_\\mu minus or plus — was it plus before or minus? That’s correct.\n\n\n\n\n\n\nThe covariant derivative in QED is: D_\\mu = \\partial_\\mu - ieA_\\mu This ensures local U(1) gauge invariance by canceling the extra terms from phase transformations, with e being the electromagnetic coupling constant."
  },
  {
    "objectID": "2025-Lecture-01.html#physical-implications",
    "href": "2025-Lecture-01.html#physical-implications",
    "title": "(2025) Lecture 1",
    "section": "9 Physical Implications",
    "text": "9 Physical Implications\nFrom equations of motion, you can see how different fields are coupled to each other.\nIn our pendulum example, we would see how the pendulum affects the movement of the upper marble.\nSimilarly, from equations of motion, we can see that motion of fermion fields is affected by motion of photons, and photons are affected by fermions.\nThe way we introduce gauge symmetry tells us exactly how they affect each other — how they interact.\nGauge symmetry enforces a certain way photons and fermions interact with each other. They have to interact with strength g.\nThe structure is very simple. Again, this is a scalar quantity.\nYou can figure out and convince yourself that the same integral is a scalar quantity. I guess it comes from this G matrix — \\gamma being 4 \\times 4 and then contracting the stuff.\nThese are contracted. We’ll find — that’s important.\nI think it’s worth writing down: gauge symmetry tells us how objects interact with each other. That’s very important."
  },
  {
    "objectID": "2025-Lecture-01.html#extending-to-other-theories",
    "href": "2025-Lecture-01.html#extending-to-other-theories",
    "title": "(2025) Lecture 1",
    "section": "10 Extending to Other Theories",
    "text": "10 Extending to Other Theories\nNow we’ll take this idea and move from QED to QCD.\nBefore jumping to QCD, where we deal with wave functions in three dimensions, let’s consider wave functions in the space of two coordinates — the case for weak interaction.\nFor weak interaction, you have up components and down components. Remember how the weak charge for quarks was +1/2 or -1/2 — the same range.\nHere you have an up field and down field. Remember, it’s still a fermion, so they have hidden four spinor components (we don’t talk about that).\nIn that case, the transformation that updates the phase is more general.\nWhat we want is that the update happening here doesn’t change the observable. Our observable will be \\psi^\\dagger\\psi.\nG or the matrix that updates the field — \\psi is the 2 \\times 2 matrix, and it’s unitary because observables should not change.\nIn this case, we’re dealing with transformations that are unitary, described by unitary matrices spanning the class called the U(2) group.\nWe’ll also fix the determinant of this matrix to be 1, and then this S comes from — for all matrices with determinant equal to 1 and unitary, they can be represented as an exponent.\nWho has seen the exponent of a matrix before? If you saw, what is this? Can you tell me what I should write here and then V?\nThis is more complicated. As soon as I put here one, it gets a little bit…\nWe solved it last year, right? I think it’s either 1 or 1 - e something. So e to 1, 1, 10 gets more complicated.\n\n10.1 Matrix Exponentiation and Generators in SU(N) Groups\nExactly right. So the approach is to take the expansion and perform multiple matrix multiplications.\nI recall it’s either e^{1} or 1 - e, but here, this is certainly not zero — and in fact, I’m not entirely sure about that anyway — so you understand what I’m referring to.\nThis is matrix exponentiation, and you can represent any element of the SU(2) group using matrix exponentiation. Here, we have a 2 \\times 2 matrix with zero trace. That condition comes from the determinant: \n\\det(U) = e^{\\mathrm{Tr}(\\alpha)} = 1\n which implies the trace of \\alpha must be zero.\nIn fact, there are only three matrices that span the entire basis of such traceless matrices: the Pauli matrices. These are called the generators of the group because they generate any group element.\nOnce we identify these three generators, we can take any three real numbers \\alpha_1, \\alpha_2, \\alpha_3, compute the combination -i\\alpha_j \\sigma_j, exponentiate it, and obtain an element of SU(2) — and in fact, this spans the entire group. You need to know the generator matrices — they’re fixed — then provide three numbers, and I can plug them into a Python routine.\n\n\n\n\n\n\nAny element of SU(2) can be written as: \nU = e^{-i \\alpha_j \\sigma_j}\n where \\sigma_j are the Pauli matrices and \\alpha_j are real parameters.\n\n\n\nIs there a reason we fix the determinant to 1? Yes — because we’re working with SU(2). In general, \nU(N) = U(1) \\times SU(N)\n So U(2) is U(1) × SU(2). The U(1) part is just a simple scalar phase, while SU(2) contains the non-trivial matrix structure. The scalar phase behaves exactly as in the 2D case, but the SU(2) matrix gives something interesting.\nSo I see the relationship, but why do we fix the determinant? Because SU(2) is one of the standard groups — we know a lot about it. If we considered U(2) instead, we’d have more generators and greater complexity. SU(2) is one of the primary elementary groups — that’s the main reason. We know everything about SU(2): how many generators it has, its matrix structure — it’s a nice object to work with.\nThis factorization helps us proceed similarly for higher groups: \nU(3) = U(1) \\times SU(3)\n We factor out the phase, and what remains is the standard group SU(3), which we use to describe the global update of the wave function with the same components. This is exactly what we deal with in quantum chromodynamics (QCD).\nWhen dealing with color charge, we don’t have two components — we have three: red, blue, and green. The transformation is then a 3 \\times 3 matrix with an overall phase — that’s not too complicated. We’ve discussed this before.\nBut then there’s a non-trivial contribution where you update your fields significantly. These are 3 \\times 3 matrices with determinant equal to 1. Again, you can relate this to the matrix exponential, and the exponent must be traceless.\nThe basis of traceless matrices in three dimensions that satisfy the anti-commutation properties — should I say the output must be anti-Hermitian? Does it hold for our condition? We insert it, multiply by two, and get -i\\alpha, then move to the other part.\nIf you look at the basis in two dimensions for traceless matrices, you get three generators; in three dimensions, you get eight. The number of generators is related to the number of charge carriers in the field.\nIn fact, we identify each generator matrix with the action of the field because they appear in the interaction term. The interaction term includes this matrix: every time you attach the field \\psi and the interaction field A, it comes together with this generator matrix.\nTo connect this back: remember where this chunk came from? We were computing derivatives and found an extra derivative for the phase. This extra derivative led us to introduce an extended derivative of the field — an interaction term that appears in Feynman diagrams.\nAs soon as we deal with higher dimensions, the same derivative we compute will come together with the appropriate matrix. So \\alpha is now 2 \\times 2, and it will appear here as another matrix. These generator matrices — \\sigma for SU(2), or \\lambda for SU(3) — will appear in the interaction vertex.\nWe find that:\n\nFor SU(2): 3 generators → 3 charge carriers: Z, W^+, W^-\nFor SU(3): 8 generators → 8 gluons\n\nUnfortunately, we lack the imagination to name all eight gluons properly, but they are identified by their matrices.\nIn the case of weak interaction, one matrix is diagonal in the space — roughly corresponding to the Z boson. The W and Z are charged similarly to the gluon field; some will be diagonal, and we identify certain extra hypercharges for the states. Some will behave like W_2, W^+, depending on the matrix.\nYou’ll see the same matrices in homework exercises. Think of them as the eight different gluons — you can name them, and they act differently on the field. They appear in the interaction vertex depending on the flavor of the gluon interacting with the quark. Each vertex behaves differently, driven by the structure of the Pauli matrices or their generalizations.\nThat’s why it’s a good exercise to think about this interaction term: How does this become a skewer? How do we contract the color charge? It’s a big, old puzzle.\nNow, the last part: I have two more topics. Confinement is important to discuss, so let me say a few words about it, and then we’ll go through the basic equations quickly.\nConfinement is the property of the theory where the strong interaction grows with distance. Unlike electromagnetic interactions, which decrease with distance, the strong interaction governing color charge increases when you pull quarks apart. This confines quarks to small scales.\nThe only way to feel the strong interaction is to zoom in to the smallest objects: mesons and baryons. Let’s draw them again:\n\nThis is a meson\nThis is a baryon\n\nThe word “confined” means that the strong interaction exists only inside the bubble of the meson or baryon. There is no strong interaction outside. If you try to pull them apart with huge force, at some point they divide — but then the resulting objects are again color-neutral, confined, and travel as stable particles.\nColor neutral means having zero charge with respect to the strong interaction. Remember: as soon as a particle has color charge, gluons can interact with it — meaning it’s not confined. Therefore, matter forms into these little bubbles where strong interactions are active inside, but outside they don’t feel the strong field — they are color neutral.\nI’m not deriving this — I’m stating it as a fact of the theory, proven by the existence of life as we know it. Confinement plays a vital role in binding and making life possible.\nHowever, if you look at the Lagrangian — where did our Lagrangian go? — you can’t directly see that it’s a confined theory. There are indications of confinement in the Lagrangian, and one of them is the gluon self-interaction.\n\n\n\n\n\n\nFigure 6: Diagrams of gluon self-interactions arising from the gauge part of the Lagrangian. These illustrate the non-Abelian nature of QCD and provide the basis for color confinement.\n\n\n\nIn QED, we had photon terms; in QCD, we have G_\\mu terms like: \nG_\\mu G_\\nu - G_\\nu G_\\mu + f^{abc} G_\\nu G_\\nu\n and then G_\\mu G_\\mu with 3-gluon and 4-gluon terms. These manifest in interaction vertices like this and this — called gluon self-interactions.\nGluon self-interaction is one indication of confinement — not a proof, but a clue. People study all possible field theories; some have confinement, some don’t. Confinement remains one of the great unsolved problems — there’s even a prize waiting for whoever can explain it.\n\n\n\n\n\n\nThe running coupling \\alpha_s(Q) depends on the momentum transfer Q:\n\nAsymptotic freedom: \\alpha_s(Q) \\to 0 as Q \\to \\infty\nConfinement: \\alpha_s(Q) grows large at low Q (around 1 GeV)\n\n\n\n\n\n\n\n\n\n\nFigure 7: Running of the strong coupling \\alpha_s(Q) with momentum transfer Q. At high Q, the coupling decreases, showing asymptotic freedom; at low Q \\lesssim 1 GeV, the coupling grows large, marking the confinement region.\n\n\n\nWe define Q as the momentum with which we probe the hadron. What we experience is the effective strong coupling \\alpha_s^{\\text{eff}}. You can think of a gluon coming in, interacting with a quark, and a lot happening — effectively, one quantum bubble with an effective interaction strength that depends on the gluon’s momentum.\nThis gluon, depending on its energy, will experience different interaction strengths. In electromagnetic interactions, we discuss screening effects; here, the effective interaction depends on Q as follows:\n\nIf Q is very high, we’re in the regime of asymptotic freedom\nIf Q is low, we’re in the regime of confinement\n\nThe transition happens around 1 GeV. Hadrons live in the low-Q region.\nIf you think about it: these particles talk to each other, exchange gluons, and the gluon couples to the fermion. When they’re close together, the gluon momentum is small — below 1 GeV — and that’s where the interaction is super strong. Meanwhile, at very high momentum transfer, the coupling becomes small — that’s asymptotic freedom, which we’ll discuss more later.\n\n\n10.2 Nuclear Binding and Decay Fundamentals\nI notice you’ve provided detailed instructions and examples for editing lecture transcripts, but you haven’t included the actual nuclear physics lecture transcription that needs to be polished.\nThe helping material contains several relevant nuclear physics formulas that could be integrated if they appear in your transcript:\nKey Nuclear Physics Formulas:\n\nNuclear Binding Energy: Calculates the energy equivalent of the mass defect: B(Z,A) = [Zm_p + (A-Z)m_n - m_{\\text{nucleus}}]c^2\nSemi-Empirical Mass Formula: Approximates binding energy based on the liquid drop model: B(Z,A) = a_V A - a_S A^{2/3} - a_C \\frac{Z(Z-1)}{A^{1/3}} - a_A \\frac{(A-2Z)^2}{A} + \\delta(A,Z)\nRadioactive Decay Law: Follows exponential decay: N(t) = N_0e^{-\\lambda t}\nRutherford Scattering: Describes angular distribution: \\frac{d\\sigma}{d\\Omega} = \\left(\\frac{Z_1Z_2e^2}{8\\pi\\epsilon_0E}\\right)^2 \\frac{1}{\\sin^4(\\theta/2)}\nUniverse Evolution Timeline: Includes key phases:\nt \\sim 10^{-12} seconds: Quark-Gluon Plasma\nt \\sim 1 second: Big Bang nucleosynthesis begins\nQuark Charge Properties:\nUp-type quarks (u, c, t): Electric charge +\\frac{2}{3}\nDown-type quarks (d, s, b): Electric charge -\\frac{1}{3}\n\n\n\n\n\n\n\nThese formulas represent fundamental concepts in nuclear and particle physics that might appear in your lecture transcript. The binding energy formulas explain nuclear stability, the decay law describes radioactive processes, Rutherford scattering reveals nuclear structure, and the quark properties form the basis of particle physics.\n\n\n\nCould you please provide the actual lecture transcription you’d like me to edit? Once you share the text, I’ll apply your requested corrections while preserving all technical content, explanations, and analogies."
  },
  {
    "objectID": "2025-Lecture-02.html",
    "href": "2025-Lecture-02.html",
    "title": "(2025) Lecture 2",
    "section": "",
    "text": "Presenter: Farah Afzal\nNote Taker: Anna Zimmer"
  },
  {
    "objectID": "2025-Lecture-02.html#isospin-and-hadron-classification",
    "href": "2025-Lecture-02.html#isospin-and-hadron-classification",
    "title": "(2025) Lecture 2",
    "section": "1 Isospin and Hadron Classification",
    "text": "1 Isospin and Hadron Classification\nWelcome everyone to today’s lecture. It will be mostly about classification of hadrons. I will walk you a little bit through the history of how important discoveries were made and what we learned from there about the hadrons and how we can group them together.\nIn the 1950s and 1960s, there were a lot of new big accelerators built, like for example the Bevatron. It came into operation in 1954. It was a proton accelerator with energies of up to 13 GeV. These high energy protons were then shot at a fixed target, and a lot of different particles were produced and detected. They found over 100 new particles, which was then called the particle zoo. Physicists of the time had to think about how to organize these particles: is there some pattern? Are these all fundamental particles? This is what we will be talking about today.\nIf you think about the periodic table, for example, we had all these atoms and we were able to group them together according to their proton and neutron numbers. We knew how many electrons were in the outermost shells, which helped us to group them together in the periodic table. This is kind of what we want to do now with hadrons. In the context of particle physics or hadron physics, the characteristics that we choose to group them together are according to their quantum numbers. We will now discuss different quantum numbers and why they were introduced and how they helped us to group together certain particles.\n\n1.1 Isospin Introduction\nLet’s start with isospin. In 1932 the neutron was discovered, and different experiments showed that when we look into proton-proton interactions, proton-neutron interactions, or neutron-neutron interactions, they had a very similar interaction strength. If you look at the rate at which these interactions were taking place, then they were basically the same. Experiments showed that all of these had similar interaction strength. If you also look at the mass of the proton and neutron, it’s almost the same at 939 MeV. This led to the suggestion that we can consider proton and neutron to be the same particle, but to have two different states that it can occur in, described by the isospin.\nThis means that the strong interaction does not distinguish between proton and neutron. The only time when we know that there are different particles is in an electromagnetic field. We can describe them as the same particle, the nucleon, and put them into an isospin doublet:\nN = \\begin{pmatrix} p \\\\ n \\end{pmatrix}\nThis is an analog property like the spin: if you look at the electron, we can have either spin up or spin down. This is similar here. At the level of quarks, since protons and neutrons are composed of up and down quarks, this means that the strong interaction does not distinguish between up and down.\nThe strong interaction is not capable of distinguishing between the different flavors of down and up. We can write that the up quark has an isospin of I = \\frac{1}{2} with the third component I_3(u) = +\\frac{1}{2}, and the down quark with I_3(d) = -\\frac{1}{2}.\n\n\n\n\n\n\nThe isospin quantum numbers for quarks are:\n\nUp quark: I_3(u) = +\\frac{1}{2}\nDown quark: I_3(d) = -\\frac{1}{2} For antiquarks, the signs are reversed: I_3(\\bar{u}) = -\\frac{1}{2} and I_3(\\bar{d}) = +\\frac{1}{2} to maintain consistent SU(2) transformation properties.\n\n\n\n\n\n\n1.2 Mathematical Framework of Isospin\nIsospin is not exactly a property like the spin, but mathematically we can treat the isospin like the spin. It follows the SU(2) algebra. In the last lecture, you already heard a little bit about the SU(2) algebras. Let me remind you a couple of things. It holds for the matrices, and we can describe this as a rotation matrix. Here, these sigma matrices are just the Pauli matrices. For the isospin operator, it was the same as for the spin where you had J instead of an I.\nGenerally we write these states always with the isospin and then the third component: |I, I_3 \\rangle. If we apply, for example, the I_3 operator to up, then we just get the eigenvalue +\\frac{1}{2}. We have here the lowering operators. If you have the isospin I, then we can have different projections I_3 from I down to -I, so you have 2I + 1 projections. With these lowering operators, you can go from one projection to the next. If you apply this to a state, you get out the Clebsch-Gordan coefficients.\nThis is just to remind you how this SU(2) algebra works.\n\n\n\n\n\n\nThe SU(2) isospin algebra follows these key relations:\n\nCommutation relations: [I_i, I_j] = i\\epsilon_{ijk}I_k\nLadder operators: I_\\pm = I_1 \\pm iI_2\nCasimir operator: I^2|I,I_3\\rangle = I(I+1)|I,I_3\\rangle\n\n\n\n\n\n\n1.3 Meson Isospin Combinations\nNow let’s look at a couple of examples. For example, if you want to think about the up and down quarks: last time you heard that we can form mesons taking a quark and an antiquark. Let’s think about what kind of particles we can get if you combine up and down quarks with antiquarks for the mesons.\nIf you look here at the isospin, we have for both up and down quarks isospin \\frac{1}{2}. We combine \\frac{1}{2} with another \\frac{1}{2}. What can we get if we have two \\frac{1}{2} isospin particles? We can have isospin of 0 or 1, just like you’re used to in the spin. If you think about the dimensions here, we always have two projections for one half: +\\frac{1}{2} or -\\frac{1}{2}. This is the dimensions here: 2 \\times 2. To indicate that we have here an antiquark, I place this bar here on top.\nIf you have an isospin of 1, how many projections can we have for I_3? You can have 2I + 1 projections. For I = 1, you get three: +1, 0, -1. For I = 0, just zero. If you take these as dimensions, then you would get 3 + 1. This is how you would write it down according to group theory:\n\\mathbf{2} \\otimes \\mathbf{\\bar{2}} = \\mathbf{3} \\oplus \\mathbf{1}\nI will also discuss a little bit later how we can understand this in terms of matrices. Here basically you have a 4 \\times 4 matrix and then you can decompose it into two components: into a 3 \\times 3 and a 1 \\times 1 matrix.\n\n\n\n\n\n\nFigure 1: Excerpt of a Clebsch–Gordan coefficient table for the spin combination of 1/2 and 1/2. The table lists the coefficients used to couple two spin-1/2 particles into total spin states, showing how individual spin components combine to form singlet and triplet configurations.\n\n\n\nThis is a triplet isospin state and this is an isospin singlet. This is how these different states would look like written down in terms of up and down quarks and form mesons.\nNow I want to briefly discuss with you where these factors come from. Like in the case of spins, you can use Clebsch-Gordan coefficients if you combine two spins or two isospins to figure out what kind of signs and coefficients you have in front of them. I will just write down a small fraction of the Clebsch-Gordan coefficients. We are combining here either spin \\frac{1}{2} with \\frac{1}{2}. These are the isospins of the two particles that we want to combine, and these are then the projections, the I_3 components.\nI will write the one now on top. Here you can see the outcome: the new particles that you get out and below it you see the projection I_3 of this combination. We said we can have an isospin triplet with isospin 1, so we get here this one three times with the projection +1, 0, -1. We have here the singlet with zero and the projection zero. Then here we can see the Clebsch-Gordan coefficients, and you also have to always take the square root. If you now look here, you can then see why these states look the way they do.\n\n\n\n\n\n\nThe explicit wavefunctions for the pion triplet members are:\n\n|\\pi^+\\rangle = -|u\\bar{d}\\rangle\n|\\pi^0\\rangle = \\frac{1}{\\sqrt{2}}(|u\\bar{u}\\rangle - |d\\bar{d}\\rangle)\n|\\pi^-\\rangle = |d\\bar{u}\\rangle These come from Clebsch-Gordan coefficients for combining isospin-1/2 states.\n\n\n\n\nJust one more thing that I need to mention is that for the antiquarks we get I_3(\\bar{u}) = -\\frac{1}{2} and I_3(\\bar{d}) = +\\frac{1}{2}. This minus sign is chosen so the quarks and antiquarks behave in the same way when you apply SU(2) transformations. If you look here at the singlet, we get then from the up and anti-up we get this vector: we have these projections +\\frac{1}{2}, -\\frac{1}{2}, so we get this vector with the square root. You do the same for down anti-down: you have -\\frac{1}{2}, +\\frac{1}{2}, you get here this minus sign, but because there’s also here this minus sign, it ends up being a plus. Then you do the same with the triplet one states. I just wanted to show you how it’s done, because we also practice this a lot more in the exercises.\nNow let’s take a step forward. I also wanted to mention what kind of particles we have here. This triplet typically pions: this would be a \\pi^+, this would be a \\pi^0, and here \\pi^-. We can also have rho particles: they’re basically the same, but there’s one thing that distinguishes these two, and that’s their spin. Here we have antiparallel spin, spin zero, and here they have parallel spin, but otherwise they’re the same. For the singlets we can have here an omega and here eta prime. Choosing this isospin quantum number, we can already group together some particles.\n\n\n1.4 Meson-Nucleon Systems and Baryons\nLet’s now go one step further and think about if you take for example a pion beam and shoot it on a proton target. We have a pion with isospin 1 and a nucleon target with isospin \\frac{1}{2}. What kind of isospin states can you get out of this? If you combine isospin 1 and isospin \\frac{1}{2}, you add this up. What do you guess? It’s either \\frac{3}{2} or \\frac{1}{2}.\nLet me write this properly. What are the dimensions here? For I = 1, we know it’s three: we have three different projections that are possible. For I = \\frac{1}{2}, we have two projections. Here we get four because we have \\pm\\frac{3}{2} and \\pm\\frac{1}{2}, and we get two again for \\frac{1}{2}. This is how you write this theory:\n\\mathbf{3} \\otimes \\mathbf{2} = \\mathbf{4} \\oplus \\mathbf{2}\nI also wanted to mention what this actually means, what we’re writing down. Basically we have here a 6 \\times 6 matrix and we can decompose it into matrices of the subspaces here: we have here a 2 \\times 2 matrix and here a 4 \\times 4 matrix. These are then called irreducible representations. This is basically what we do. For small numbers it’s kind of easy to know and write it down, but if you have larger numbers, there are some methods how you can figure this out. We will not discuss it in more depth, but I just wanted to mention what this actually means.\nIf you have isospin in SU(2), you get these four projections. This can be actually assigned to particles that were found at the time: these are called delta particles. We have \\Delta^{++}, \\Delta^+, \\Delta^0, \\Delta^-. They also give you the mass m_\\Delta = 1232\\text{ MeV}.\nI want to do one last example. Right now we have looked into meson systems and combining a meson and a nucleon system. What about if you just combine three quarks to get baryons? Then you would have basically 2 \\times 2 \\times 2: three quarks, and there are always two projections possible for \\pm\\frac{1}{2}. We can now use what we have already seen here: 2 \\times 2 gives us 3 + 1. This is what we had before: \\mathbf{2} \\otimes \\mathbf{2} \\otimes \\mathbf{2} = \\mathbf{4} \\oplus \\mathbf{2} \\oplus \\mathbf{2}. This gives us four, eight: \\frac{3}{2} and we have here two out of spin doublets with isospin \\frac{1}{2}.\n\n\n1.5 Experimental Significance and Historical Context\nWhat is this good for in isospin? You will later also see in the exercises that we can actually use this quantum number to see why certain cross sections that were measured are of different sizes.\n\n\n\n\n\n\nFigure 2: Diagram showing the cross section on the y-axis and the mass on the x-axis, with two curves representing pπ⁺ and pπ⁻ interactions. A clear resonance peak appears at the Δ mass, indicating the formation of the Δ resonance during scattering.\n\n\n\nIf we take for example the cross section for \\pi^+ p and for \\pi^- p, if you look here in the delta mass region, you see that there is a factor of three difference: \\frac{\\sigma_{\\pi^+p}}{\\sigma_{\\pi^-p}} \\approx 3:1. You can figure out in the exercises and classwork why there are differences in the cross sections between the different reactions.\nI introduced this isospin concept for protons and neutrons. How was that in experiment? They also write like up and down quarks—that wasn’t there. This concept in the 1950s: how should you imagine this? They saw like, oh, well, you produce pions and rho—was it also there? Yes, they also found rho later on. They introduced this concept to find symmetries or something. They were first just looking for patterns that they could find between different particles. This was like purely mathematical looking: just how can we group these together?\nIf you take the isospin, then we can already group some of these particles together. Like I said, we can group the pions or the rhos into triplets. We can have the delta in an isospin quadruplet and things like this. Then later bigger patterns were also seen. That’s where this lecture is headed towards: we will look later next into the strangeness and then hypercharge and so on.\nThe reason why I’m asking is because if you look just at protons and neutrons, you might initially think, oh, you have spin and charge and that’s all they do. Why would you introduce isospin? But it’s only when you do these kinds of reactions: proton-proton, proton-neutron, and neutron-neutron, and if you see that the reaction rates are pretty much the same, then you can come to the conclusion: okay, maybe the strong interaction doesn’t care about whether it’s a proton or a neutron. That’s where the isospin idea came from.\nIt comes down to once you start to look at cross sections, you start to see that certain reactions are stronger and you need to introduce new concepts in the theory. Here it was actually that they are pretty much similar. If you look at these different experiments and you see that the strong interaction does not seem to care about whether it’s a proton or a neutron, on quark level it means then it doesn’t care about up or down quark. That’s why we also placed not just the proton and neutron into an isospin doublet, but also the up and down quarks."
  },
  {
    "objectID": "2025-Lecture-02.html#the-eightfold-way-and-quark-model",
    "href": "2025-Lecture-02.html#the-eightfold-way-and-quark-model",
    "title": "(2025) Lecture 2",
    "section": "2 The Eightfold Way and Quark Model",
    "text": "2 The Eightfold Way and Quark Model\nSo first, physicists had this kind of an isospin doublet. They found all these other particles like the pions and kaons and grouped them together, then looked for bigger patterns with also the strangeness included as the next quantum number.\nAround the 1960s, with the Bevatron experiment and large accelerators accessible, they found over 100 particles and didn’t know what to do with them. They later found out we can actually decompose them into smaller particles to understand how, and we are still trying to understand.\nSome particles detected behaved in a strange manner. For example, in cosmic rays with pions going to a carbon target, they could see in a cloud chamber four tracks which look like a V: \\pi^+, \\pi^-, proton, and \\pi^-.\n\n\n\n\n\n\nFigure 3: A π⁻ from cosmic rays collides with a proton, initiating decay chains involving several intermediate particles. The π⁻ decays into a K⁰ and a Λ⁰, which subsequently decay into π⁻π⁺ and pπ⁻ respectively, illustrating hadronic decay processes.\n\n\n\nThese particles always appeared in pairs and had a fairly long lifetime.\nThey concluded by introducing a new quantum number strangeness and said that it needs to be conserved. Isospin is also a quantum number conserved in strong interactions.\nHow do we assign this quantum number? Particles consisting of up and down quarks have strangeness S = 0, for example pion, neutron, proton. Particles with strangeness S = +1 include lambda, and in general these are called hyperons. There are different types of hyperons like lambda, sigmas, cascades, and kaons.\nWith this we can form two isospin doublets with K^+ and K^0, and similarly K^- and \\bar{K^0} in an isospin doublet with strangeness S = -1. They figured since these two come always in pairs that this quantum number needs to be conserved in strong interaction, but it is not conserved in weak interaction.\nLooking at the lambda decay \\Lambda \\to p + \\pi^-, both products don’t have strangeness but this decay can happen. From the long lifetime this means weak decay. They are produced in strong interaction because we have \\pi + p \\to p + K^+ and n \\to hypercharge.\nHypercharge Y is given by baryon number B and strangeness number S: Y = B + S. For baryon number, if it’s a baryon then it gets B = +1, if it’s an antibaryon then B = -1, and if it’s a meson then B = 0.\nWe can’t have certain reactions. For example, if here we didn’t have a lambda but a proton, then this would not happen. Same way here, if you have lambda then we can’t have a \\pi in here. This always comes in pairs, so the strangeness number is conserved.\nAlso if you have \\pi^- in a proton beam, then you can’t have suddenly in the end two mesons only. There needs to be a baryon as well, so the baryon number is conserved.\nFrom isospin, we had the isospin triplet with projections +1, 0, and -1 correlating to charge: -1 for \\pi^-, 0 for \\pi^0, and +1 for \\pi^+. There seems to be a relationship between isospin and charge.\nThis is what Gell-Mann and Nishijima calculation tells us: the charge can be expressed as the third component of the isospin plus the hypercharge divided by two: Q = I_3 + \\frac{Y}{2}.\nLet’s check this formula:\n\nFor proton, I = \\frac{1}{2} and I_3 = +\\frac{1}{2}. Hypercharge: strangeness S = 0 for proton, but it’s a baryon so B = 1, giving Y = 1. Using the relation, charge Q = \\frac{1}{2} + \\frac{1}{2} = +1, as expected.\nFor neutron, I_3 = -\\frac{1}{2}, Y = 1, giving Q = -\\frac{1}{2} + \\frac{1}{2} = 0.\n\n\n\n\n\n\n\nKey Formulas:\n\nGell-Mann–Nishijima Formula: Q = I_3 + \\frac{Y}{2} relates electric charge to isospin and hypercharge\nHypercharge Definition: Y = B + S combines baryon number and strangeness\nConservation Laws: \\sum B_{\\text{initial}} = \\sum B_{\\text{final}} and \\sum S_{\\text{initial}} = \\sum S_{\\text{final}} (strong interactions only)\n\n\n\n\nUsing strangeness and/or hypercharge in combination with isospin, Gell-Mann and Ne’eman found a much larger pattern for these particles. They can be arranged in bigger multiplets, called the eightfold way.\nFor these larger patterns they looked not just at the up and down quark, but also included the strange quark. Now we are in the SU(3) flavor symmetry. At the time they didn’t know these different quarks existed, but we are just going to look at it in this way.\n\n\n\n\n\n\nFigure 4: Diagram plotting the z-component of isospin on the x-axis and strangeness (S) on the y-axis. An inverted triangle connects the up, down, and strange quarks, with each vertex labeled by its corresponding quantum numbers, visualizing the quark model’s flavor structure.\n\n\n\n\n\n\n\n\n\nFigure 5: Diagram with strangeness on the y-axis and the third component of isospin on the x-axis, showing the baryon octet. Each vertex of the hexagonal arrangement represents a baryon with its quark composition, demonstrating SU(3) flavor symmetry.\n\n\n\nPlotting the third component of isospin against strangeness for the up, down, and strange quarks, let’s write down the quantum numbers:\n\nFor baryon number each gets \\frac{1}{3} because up, up, down gives total 1\nCharge for up is +\\frac{2}{3}, for down is -\\frac{1}{3}\nThey’re all fermions with spin \\frac{1}{2}\nStrangeness for strange quark is -1\n\n\n\n\n\n\n\nFigure 6: Depiction of a baryon decuplet multiplet including Ω⁻, Ξ⁻, Ξ⁰, Σ⁻, Σ⁰, Σ*⁺, and the four Δ states (Δ⁻, Δ⁰, Δ⁺, Δ⁺⁺). Diagonals denote electric charge (Q) and horizontal lines indicate strangeness, with mass differences of roughly 150 MeV between each level.\n\n\n\nNow looking at bigger patterns for baryons. Baryons are composed of three quarks from up, down, or strange: \\mathbf{3} \\otimes \\mathbf{3} \\otimes \\mathbf{3} = \\mathbf{10} \\oplus \\mathbf{8} \\oplus \\mathbf{8} \\oplus \\mathbf{1}. This gives a decuplet and octets. We look at ground state variants arranged into an octet and decuplet.\nPlotting third component of isospin against strangeness (or hypercharge), we have S = 0, -1, -2.\n\n\n\n\n\n\nFigure 7: Meson octet diagram showing K⁰, K⁺, π⁻, η, π⁰, π⁺, K⁻, and K̄⁰. The y-axis represents strangeness, the x-axis represents the third component of isospin, and diagonal lines indicate electric charge (Q), highlighting SU(3) meson symmetry.\n\n\n\nOn the horizontal axis are isospin multiplets: isospin doublet for neutron and proton, triplet for sigmas, doublet for cascades.\nPointing out positions: here is I_3 = +\\frac{1}{2}, -\\frac{1}{2}, here I_3 = 0, here S = -1. You can see quark content: here all with one strange quark, here with two strange quarks.\n\n\n\n\n\n\nFigure 8: Table listing the u, d, and s quarks along with their fundamental quantum numbers. Entries include baryon number (B), electric charge (Q), spin, strangeness (S), isospin (I), z-component of isospin (I₃), and hypercharge (Y).\n\n\n\nLooking at masses:\n\nProton and neutron masses are almost the same, difference about 1 MeV\nSimilar for isospin partners\nBut in vertical direction, mass difference is much larger: sigma mass difference about 250 MeV, here to here about 130 MeV\n\nThis tells us that isospin symmetry in SU(2) is a good symmetry, but including strange quark it’s pretty much broken. It’s only an approximate symmetry because otherwise we would have same masses for all.\nWorking out the pattern: upper row has data, down here only minus. On this axis highest third component, along this axis strangeness 0, -1, -2.\nAll these particles have spin in common. Baryons in octet have spin \\frac{1}{2} and parity +. For decuplet, spin \\frac{3}{2} and parity +. Here spins can be aligned or permutations giving \\frac{1}{2}, here all aligned.\nWhen this pattern was found, the \\Omega^- was not yet discovered. This was a big success to predict its existence, found two years later in bubble chamber experiments with K^- + p \\to \\Omega^- + K^+ + K^0. For strangeness conservation, we need two more kaons.\n\\Omega^- decays into cascade \\Xi^-, then further to \\Lambda^0 + \\pi^0, \\pi^0 \\to 2\\gamma, and \\Lambda \\to p + \\pi^-. Not only predicted existence but roughly predicted mass: looking at masses between horizontal lines, \\Delta mass 1232 MeV, sigmas, then \\Omega^- mass around 1680 MeV, with mass spacing roughly 150 MeV.\nAll these considerations come from group theory, mathematical descriptions of particles with symmetry considerations. Difference between masses in octet and decuplet is that spin is different, so mass difference accounted to spin-spin or spin-orbit interactions from dynamics. For mesons, with up, down, strange quarks, \\mathbf{3} \\otimes \\bar{\\mathbf{3}} = \\mathbf{8} \\oplus \\mathbf{1}. On diagonal you have charge: here all charge -1, middle charge 0, +1, +2. This octet or nonet including \\eta' has quantum numbers 0^-+.\n\n\n\n\n\n\nFigure 9: Vector meson octet including ρ⁻, ω, ρ⁰, ρ⁺, and the K* mesons with charges 0, +, −, and anti-0. The diagram mirrors the pseudoscalar meson octet structure, illustrating similar flavor symmetry among vector mesons.\n\n\n\nThis means quark-antiquark pair have anti-parallel spins, parity -. For spins aligned parallel, spin 1, parity -1, charge conjugation C. Parity inverts spatial coordinates, charge conjugation converts particle to antiparticle.\nFor baryons, if you know orbital angular momentum L, parity P = (-1)^L. For octet ground states L = 0, parity + for \\frac{1}{2}^+ and \\frac{3}{2}^+. For mesons, P = (-1)^{L+1}, giving - for both. Charge conjugation well-defined for neutral mesons, e.g., \\pi^0 has C = +1.\nFor decays, parity and C parity are multiplicative. Combining spins of different particles to get total spin. Example: can \\omega meson decay into two pions? For \\pi^0, C = +1, multiplied gives +1, but for \\omega, C = -1, so cannot happen.\nLastly, consider quark content for \\Omega^- or \\Delta^{++}. All spins aligned, flavor content same. With Pauli exclusion principle for fermions, they should be distinguishable by one quantum number. Looking at total wave function: spatial, spin, and flavor.\nFor L = 0, spatial wave function symmetric. Spins all aligned up, symmetric. Flavor all same, symmetric. Physicists introduced new quantum number: color charge. This part of wave function must be antisymmetric to get total antisymmetric wave function.\n\n\n\n\n\n\nFigure 10: A step-like diagram with energy ω (in GeV) on the x-axis, showing three discrete levels corresponding to accessible quark flavors. The steps mark quark sets (u,d,s), (u,d,s,c), and (u,d,s,c,b,t), each annotated with example hadrons, providing evidence for the existence of color charge.\n\n\n\nAssign each quark different color: red, green, blue.\n\n\n\n\n\n\nParity Formulas:\n\nBaryons: P = (-1)^L (ground states have L = 0, P = +)\nMesons: P = (-1)^{L+1} (ground states have L = 0, P = -)\nMultiplet Decompositions:\n\nBaryons: \\mathbf{3} \\otimes \\mathbf{3} \\otimes \\mathbf{3} = \\mathbf{10} \\oplus \\mathbf{8} \\oplus \\mathbf{8} \\oplus \\mathbf{1}\nMesons: \\mathbf{3} \\otimes \\bar{\\mathbf{3}} = \\mathbf{8} \\oplus \\mathbf{1}\n\n\n\n\n\n\n\n\n\n\n\nFigure 11: Feynman diagram illustrating electron–positron annihilation producing a virtual photon. The photon subsequently decays into either a quark–antiquark pair or a lepton pair, with an example of a μ⁺μ⁻ final state shown.\n\n\n\nBriefly discuss experiment showing three colors. Looked into e^+ e^- annihilation with virtual photon exchanged, producing different particles: quark-antiquark pairs or leptons like \\mu^+ \\mu^-.\nMeasured ratio R = \\frac{\\sigma(e^+ e^- \\to \\text{hadrons})}{\\sigma(e^+ e^- \\to \\mu^+ \\mu^-)}. For leptons no color, so dividing gives proportionality to number of colors. Photon vertex proportional to charge squared, different quark types.\nInitially up, down, strange quarks measured as peaks in spectrum (rho, omega, pi mesons). When energy high enough, produce charm-anticharm bound states (J/ψ), then B bar states. Calculated steps show number of colors should be three.\nThis was historical background on how from detected particles, patterns were seen using eightfold way strangeness, later forming quark model where particles consist of smaller quarks with six flavors and three colors."
  },
  {
    "objectID": "2025-Lecture-02.html#unraveling-strange-particles-and-quantum-numbers",
    "href": "2025-Lecture-02.html#unraveling-strange-particles-and-quantum-numbers",
    "title": "(2025) Lecture 2",
    "section": "3 Unraveling Strange Particles and Quantum Numbers",
    "text": "3 Unraveling Strange Particles and Quantum Numbers\nGenerally, what I always find difficult with histories like what is known versus what’s not known relates back to my previous question about particle identification methods.\nI should have perhaps asked this earlier when you introduced strangeness in the context of cosmic rays.\n\n3.1 Particle Identification Through Invariant Mass\nThe fundamental practical question is: how do you distinguish kaons from other particles using just invariant masses? (see Figure 3)\n\n\n\n\n\n\nInvariant Mass Formula: M^2 = \\left(\\sum E_i\\right)^2 - \\left(\\sum \\vec{p}_i\\right)^2 This relativistic invariant allows identification of particle resonances from decay products. When analyzing cosmic ray events with protons and pions, peaks in the invariant mass spectrum reveal new particles like kaons.\n\n\n\nYou can only look at the invariant mass in these cases. You detect the proton and the pions, then examine the spectra to identify what’s known versus unknown.\n\n\n3.2 Historical Discovery Timeline and Strange Particles\nThese particles were called “strange” because researchers were confused about why they only appeared in pairs and had longer lifetimes than other particles.\n\n\n\n\n\n\nStrangeness Conservation: \\Delta S = 0 This quantum number explains why strange particles (like kaons) are always produced in pairs and have unexpectedly long lifetimes. Violation occurs only through weak interactions.\n\n\n\nThe pions were discovered relatively quickly after fundamental particles:\n\nProtons were known early\nNeutrons discovered in 1932\nLater in the 1950s: antiprotons and many other particles emerged\n\nSince many are charged, you can measure them directly.\n\n\n3.3 Conservation Laws and Quantum Numbers\nYou mentioned C-parity - how was that introduced? Was it used to say certain decays aren’t allowed? (see Figure 11)\nActually, I think it worked the other way around: researchers observed that certain decays weren’t measured, suggesting some quantum number must be violated.\n\n\n\n\n\n\nCharge Conjugation (C-parity): C|\\psi\\rangle = \\eta_C|\\psi\\rangle C-parity describes how particles transform into their antiparticles under charge conjugation, providing selection rules for decays.\n\n\n\nI don’t know exactly when charge conjugation was introduced, but it emerged when people started thinking systematically about particles and antiparticles - directly with the positron in the 1930s, before the antiproton discovery.\nThis highlights the difficulty: sometimes concepts come from theory, sometimes from experiments. It’s interesting how the omega baryon was predicted, but also how quantum numbers were introduced based on cross-section measurements.\n\n\n3.4 Quark Model Development and Mass Patterns\nHistorically, the multiplets were mostly correct - I only added the quark content for clarity. When multiplets were assembled, researchers postulated there might be smaller substructure, initially called “partons” before becoming “quarks.”\n\n\n\n\n\n\nQuark Model Mass Relations: M(\\Omega^-) - M(\\Xi^*) \\approx M(\\Xi^*) - M(\\Sigma^*) \\approx M(\\Sigma^*) - M(\\Delta) \\approx 150\\text{ MeV} The regular mass spacing in baryon multiplets provided crucial evidence for the quark model, suggesting these particles differ by replacing one quark with a heavier strange quark.\n\n\n\nThe mass differences already indicated there should be different quark content in these particles - for the deltas, sigmas, cascades, and so on. Researchers observed these mass differences and reasoned that the last undetected particle would also have approximately 150 MeV more mass than the others, which turned out to be correct.\nThe original quark paper is remarkably brief - just two pages - so you can easily look up how they introduced the concept.\nIt was an exciting time: they predicted the omega-minus in the quark model, and it was experimentally detected and discovered in 1964.\n\n\n\n\n\n\nOmega-Minus Discovery: K^- + p \\to \\Omega^- + K^+ + K^0 This was the experimental reaction that discovered the \\Omega^- particle, confirming quark model predictions."
  }
]