[
  {
    "objectID": "2024-Lecture-01.html",
    "href": "2024-Lecture-01.html",
    "title": "(2024) Lecture 1",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-01.html#lecture-logistics-and-upload-plans",
    "href": "2024-Lecture-01.html#lecture-logistics-and-upload-plans",
    "title": "(2024) Lecture 1",
    "section": "1 Lecture Logistics and Upload Plans",
    "text": "1 Lecture Logistics and Upload Plans\nYes. I will upload the lecture as well. If anything reasonable comes out of it, I will be happy to upload it.\nCertainly, what will be uploaded is the lecture content with items that I already have. There will also be references to material.\n\n\n\n\n\n\nThis initial segment is purely logistical and administrative. No specific physics concepts, variables, or mathematical relationships are being discussed here.\n\n\n\nBut let’s go to logistics in the last 15 minutes."
  },
  {
    "objectID": "2024-Lecture-01.html#the-early-universe-from-symmetry-breaking-to-hadronization",
    "href": "2024-Lecture-01.html#the-early-universe-from-symmetry-breaking-to-hadronization",
    "title": "(2024) Lecture 1",
    "section": "2 The Early Universe: From Symmetry Breaking to Hadronization",
    "text": "2 The Early Universe: From Symmetry Breaking to Hadronization\nSo we are living in a universe made of hadronic physics, but it was not always the case.\nI like thinking of the evolution of the universe on a time scale, with the origin of the universe where everything started. There was a Big Bang first, and then several epochs followed. It started with the Planck epoch, then there was the electroweak epoch, and then the quark epoch.\n\n2.0.1 The Electroweak Epoch and Symmetry Breaking\nWhat has been happening during these epochs is the part of the physics that we go through in the courses.\nLet me start with the electroweak epoch. This is where the Higgs potential V(\\phi) = \\mu^2 |\\phi|^2 + \\lambda |\\phi|^4\n—that is the field giving masses to particles and making sure that our proton doesn’t decay and our life can exist—gets a condensate.\nThe electroweak phase is where the transition happens. The entire space is filled now with a condensate, a fixed, non-moving condensate of the Higgs field, through which particles are slowed down; they get inertia and they obtain mass. That’s something known as the Higgs mechanism.\nThis process of the potential evolving is called spontaneous symmetry breaking, when one of the minima is picked. That’s how I like thinking about the electroweak stage.\nSo what happens then? Particles have masses. The universe starts evolving, and at some point we arrive at the quark epoch.\n\n\n2.0.2 The Quark Epoch and Quark-Gluon Plasma\nAt this stage, the universe is filled with a quark-gluon plasma. Essentially, quarks and gluons are making an unstructured soup of objects. There is nothing about structure formation yet. This is rather quarks disturbing—there is no yet scale that we are going to talk about.\nQuarks and gluons are together, and the universe is extremely hot. From that moment it starts cooling down. At some point the temperature is low enough that this medium starts separating, and we arrive at the quantum chromodynamics (QCD) epoch.\n\n\n\n\n\n\nThe transition to a quark-gluon plasma occurs when the temperature exceeds the QCD scale: T_{\\text{QGP}} \\sim \\Lambda_{\\text{QCD}} \\approx 150 \\text{–} 200 \\text{ MeV} . In the early universe, the age during this epoch can be estimated as t \\sim M_{\\text{Pl}} / T^2 , which for T \\sim 150 \\text{ MeV} gives t \\sim 10^{-6} \\text{ s} .\n\n\n\nThis hot medium starts forming small volumes where the interactions of quarks and gluons are confined to a small scale. You need two years to learn this in detail. This comes in particle physics, introductory nuclear physics, and a specialized course on QCD at finite temperature, since it’s a heated medium and there are different laws applied.\n\n\n2.0.3 The Hadronic Universe and Confinement\nHadrons are what we are going to focus on now. But if you think of how quickly this all happened, you’re going to be slightly surprised.\nThe timeline is incredibly brief:\n\n10^{-36} seconds for the Planck epoch\n10^{-12} seconds for the electroweak epoch\n10^{-6} seconds for the QCD transition\nThen 1 second.\n\nJust imagine there was nothing, and then the sound reached you on the back. When I clap, if you look at my palms, the time span between when I close them and you hear the sound is roughly 10 milliseconds. By that time we had already passed through all the stages and everything hadronized. That’s how quickly the universe evolved.\nIn that scale, the rest of the interval to the 13 billion years—the age of our universe—has been other interesting physics, but not as intense as this from the perspective of our hadron physics.\nWe can be talking about hadrons in the sense that we will be talking about the strong interaction. The hadrons are objects where the strong interactions are confined to the small scale of a few fermi: R_{\\text{hadron}} \\sim 1 / \\Lambda_{\\text{QCD}} \\approx 1 \\text{ fm} = 10^{-15} \\text{ m}.\nThere is essentially nothing around. There is a small chunk of volume where the quarks and gluons live. They interact with each other. There are large fractions of empty space.\nOne fermi is 10^{-15} meters. It’s difficult to imagine this scale, but this number can help you. It is a smaller scale we have, and the smallest scale where we actually can separate things.\nThe strong interaction is confined in this small scale and it stays there. By colliding hadrons we learned how to study internal structure and how to separate the subject. But there is no natural scale smaller than that."
  },
  {
    "objectID": "2024-Lecture-01.html#the-emptiness-of-matter-and-the-color-charge",
    "href": "2024-Lecture-01.html#the-emptiness-of-matter-and-the-color-charge",
    "title": "(2024) Lecture 1",
    "section": "3 The Emptiness of Matter and the Color Charge",
    "text": "3 The Emptiness of Matter and the Color Charge\nSo concerning the empty space in an atom, I wanted to sketch one of the most common elements on Earth. From the periodic table, what is the most common element? I think it’s oxygen.\nA neutral oxygen atom has eight protons and eight neutrons. Oxygen has many isotopes; one common one is oxygen-16, while oxygen-18 has eight protons and ten neutrons. The atom is neutral, so there must be electrons compensating the charge of the protons. The protons give a charge of +8e , and there are eight electrons in the configuration 1s^2 2s^2 2p^4 .\n\n\n\n\n\n\nThis notation, 1s^2 2s^2 2p^4 , is the ground-state electron configuration for a neutral oxygen atom (atomic number Z = 8 ). It describes how its 8 electrons are distributed: 2 in the 1s orbital, 2 in the 2s orbital, and 4 in the 2p orbitals.\n\n\n\nThe atom’s electrical neutrality is expressed by the condition q_{\\text{atom}} = Z e + (-e) \\sum_{i=1}^{Z} 1 = 0 . For oxygen ( Z=8 ), this is +8e - 8e = 0 .\nTo understand the scale of emptiness, let’s look at the nucleus. There is a center where protons and neutrons are packed closely together. Knowing the scale of a hadron, you can guess the core’s scale. The size of the nucleus scales as:\nR = R_0 A^{1/3}\nHere, R_0 \\approx 1.2 \\, \\text{fm} (femtometers) is a constant, and A is the mass number (protons + neutrons). This nuclear radius formula arises because nuclear volume is proportional to A , assuming nucleons are closely packed with nearly constant density. For oxygen-16 ( A = 16 ), the nuclear radius is roughly R \\approx 1.2 \\times 16^{1/3} \\, \\text{fm} \\approx 3 \\, \\text{fm} .\nBut electrons are completely different. Their wave function has a size about 3 orders of magnitude bigger. The atomic radius is roughly 50 picometers ( 5 \\times 10^{-11} \\, \\text{m} ).\nNow consider this scale difference:\n\\frac{R_{\\text{atom}}}{R_{\\text{nucleus}}} \\approx \\frac{50 \\times 10^{-12} \\, \\text{m}}{3 \\times 10^{-15} \\, \\text{m}} \\sim 10^4\nThis atomic vs. nuclear scale ratio—about 10,000—shows how empty an atom is. There is a very small core, and around it is a vast space where the electrons exist. In that space, there is no strong interaction.\nThe second item is what we know as the fundamental hardware: the Standard Model. This is the theory in particle physics that describes most known interactions. Setting aside neutrinos—where there are open questions—it describes everything well.\nThe part responsible for strong interactions is Quantum Chromodynamics (QCD). The participants are quarks and gluons. These are the only particles in the Standard Model that carry color charge, which is the charge needed to interact via the strong force.\nThis is similar to electrodynamics: only objects that are not neutral can interact. However, in strong interactions, the relevant charge is a different type—it’s not electric charge, it’s color charge. We could have invented a different word, but “color charge” is the term.\nThink of this charge as analogous to the electric charge of an electron or muon. But it’s a different quantum number; they are independent. This is the charge independence principle in the Standard Model:\nQ_{\\text{em}} \\neq Q_{\\text{color}}\n\nA particle with electric charge does not have to have color charge (e.g., an electron).\nA particle with color charge does not have to have electric charge (e.g., a gluon).\n\nWe usually measure electric charge in elementary units: the electron is -1 , the positron is +1 . For color charge, we don’t use simple units. Instead, we describe quarks and gluons by introducing their color wave function. Once they have a non-trivial color wave function, they are color-charged."
  },
  {
    "objectID": "2024-Lecture-01.html#the-origin-of-mass-and-the-constituent-quark-model",
    "href": "2024-Lecture-01.html#the-origin-of-mass-and-the-constituent-quark-model",
    "title": "(2024) Lecture 1",
    "section": "4 The Origin of Mass and the Constituent Quark Model",
    "text": "4 The Origin of Mass and the Constituent Quark Model\nTo finish with the Standard Model, I want to mention that these are the only particles that have color charge.\nLet me list other particles of the Standard Model: the electron and muon. The electron, muon, and tau lepton are kind of the same, but they have different masses. The electron is the one that is orbiting or living and compensating the charge of protons and neutrons in the nuclei. The muon is the heavier brother of the electron. The tau is a much heavier sister of the electron. All of them can be in both configurations.\nBut let’s complete the list. What else is in the Standard Model? Photons and neutrinos. That’s all. I just draw them all here to say that they don’t have color charge. They don’t have color charge, so they don’t interact with the quarks and are not influenced by the strong force. We will see them all the time, but they don’t participate in the strong interaction.\nAs I mentioned, if you don’t have a color charge, you don’t interact strongly. But if you have a color charge, you must interact strongly, though it doesn’t mean you don’t interact in other ways. All of these particles have different quantum numbers. Essentially, they are electrically charged. The electric charge of protons and neutrons is not zero for quarks.\nThere are six quarks in the Standard Model. That’s what we see: six quarks exist. They are different, but they have common properties. They are separated into groups by their electric charge.\n\nThose in the upper row have a positive charge of Q = +\\frac{2}{3}e .\nThe lower row has an electric charge of Q = -\\frac{1}{3}e .\n\nThey also split on the horizontal axis into three groups. These are generations: the first generation, second generation, and third generation. The higher the generation you go, the more difficult the particles are to produce, as the objects become heavier. This is why most of the matter we see around us is made of the first generation.\nWe produce strangeness rather easily once we collide particles. Cosmic rays have a lot of strange particle production, and less of the charm quark. The ‘C’ stands for charm. However, it also appears in cosmic rays. There is actually a hot discussion these days on whether the strange quark and the interaction of strange quarks is relevant for the equation of state when stars evolve.\nWe want to describe the maximal size of a neutron star. This maximal size is driven by the equation of state. Essentially, it depends on how the atoms are packed inside the neutron star. If there are clusters where strange particles appear, it changes the equation of state. This then changes the observable characteristics. Over the last five years, more discussion has evolved on the equation of state and the relevance of the strange quark there.\nThe charm quark is mostly studied in collisions at high energy, because you need a lot of energy to produce charm and bottom quarks. The top quark is relevant for Higgs physics. That’s the domain where these two are studied. The up and down quarks are called light quarks. The strange quark, charm quark, and bottom quark are studied a lot in colliders to see CP violation and in the search for precision physics.\nThe top quark measures very well the Standard Model quantities related to Higgs physics and electroweak interactions. We’ll be focusing on the five lighter flavors and will not talk much about the top quark because its lifetime is so short that it decays before it can form hadrons. You won’t find any hadrons that contain a top quark. But all of these other quarks can form hadrons.\nMost of the matter we know and that is abundantly present is of two types. We are going to talk about pions.\nWelcome to a lecture dedicated to the constituent quark model. Here is a sketch of the simple pictures that classify hadrons. As you see, there are two types: mesons and baryons. This model describes hadrons as compositions of a quark-antiquark pair or three quarks.\nYou may ask about gluons. I would like to come back to this picture. There is something very beautiful happening around the chiral symmetry breaking scale. Essentially, another condensation process occurs. When hadronization happens, as quarks and gluons from the soup start to confine themselves, the gluon field condenses as well.\nWhat happens is that the gluon field, similar to the Higgs field, forms a medium in which the quarks are moving. This medium is colored, and the quarks, by interacting with it, acquire energy. Effectively, gluons are now dressing the quarks, making them massive. The quarks we draw in the constituent picture are different from the Standard Model quarks; they are quarks dressed by gluons.\n\n\n\n\n\n\nIn the constituent quark model, quarks are dressed by gluons and acquire effective masses much larger than their bare masses. For light quarks: m_u^{\\text{const}} \\approx m_d^{\\text{const}} \\approx \\frac{m_p}{3} \\approx 313 \\text{ MeV}\nThis is compared to their bare masses from the Higgs mechanism, which are m_u^{\\text{bare}} \\approx m_d^{\\text{bare}} \\sim 3 \\text{ MeV} .\n\n\n\nThere is a nice way of thinking about this. Look at the masses of the light quarks. The mass of the u quark and d quark is on the order of 3 \\text{ MeV} . We will be using natural units throughout the course, where the speed of light c = 1 and \\hbar = 1 .\nIf you look at the other way of expressing \\hbar , it is a quantity with units: \\hbar = 6.6 \\times 10^{-34} \\text{ J} \\cdot \\text{s} , which is also equal to 6.6 \\times 10^{-22} \\text{ MeV} \\cdot \\text{s} . In natural units, we set \\hbar = 1 . This immediately tells you that to achieve that, you need to be able to translate meters to seconds.\nFrom that, you can take this second and move it to the other side: 1 \\text{ s} = 3 \\times 10^8 \\text{ m} . Meters are the same as seconds. Also from that, you can realize that in these units, 1 \\text{ s}^{-1} = 6.6 \\times 10^{-22} \\text{ MeV} . You can also relate joule and second. It’s important to realize these are not just relations between numbers, but also units.\nThis is the way you translate any meters to seconds and any second to mega electron volts. That’s the way to translate electron volts to seconds, and also the way to translate kilograms, because a joule can be expressed in kilograms. In these natural units, \\text{MeV} is the unit of mass, energy, and inverse distance. We will be using eV, MeV, and GeV for everything.\nJust to have a scale, in kilograms it’s 10^{-30} , which is a huge number. But what is the mass of the proton? The proton, which in the constituent model is made of u and d quarks, has a mass of roughly 1 \\text{ GeV} . To be accurate, the proton mass is around 1.67 \\times 10^{-27} \\text{ kg} .\n\n\n\n\n\n\nFigure 1: The diagram shows the contribution of different components to the visible mass of matter. Only about one percent comes from the Higgs field, which provides intrinsic fermion masses through Yukawa couplings, while the remaining ninety-nine percent arises from gluon interactions inside nucleons, where the QCD binding energy and quantum fluctuations generate the bulk of the nucleon mass.\n\n\n\nLet’s do a comparison. The Higgs mechanism involves making the condensate that gives all particles their masses. The mass that quarks get from the Higgs is a few MeV. Then another phenomenon happens. Essentially, energy gets stored in the strong quark interaction.\nAt the place where the strong interaction is happening, there is a large energy density of the gluon condensate. This large energy accounts for about 99% of the proton mass. If you think of the origin of mass, which was discussed a lot when the Higgs was discovered, the Higgs explains only a small part. It is less than 1% of the proton mass.\nI calculated the total mass. I summed the three quark masses and divided by three as well. It’s about 1%. If you think like I am around 70 kilos, what are these 70 kilos? Is it me moving through the Higgs field? It is actually gluons and quarks held together by the strong interaction. So, 69 point something kilos of me is due to strong gluon interactions."
  },
  {
    "objectID": "2024-Lecture-01.html#foundations-of-quantum-field-theory",
    "href": "2024-Lecture-01.html#foundations-of-quantum-field-theory",
    "title": "(2024) Lecture 1",
    "section": "5 Foundations of Quantum Field Theory",
    "text": "5 Foundations of Quantum Field Theory\nNow let’s move to a bit more of the equations and discuss quantum dynamics. Quantum chromodynamics is the theory of strong interactions. Quantum electrodynamics is the theory of electromagnetic interactions. I will put both of them because there is a lot in common between these two.\nI think I wrote this already. The framework that we use, starting from classical mechanics, and it turned out to be the most successful, is the Lagrangian approach. Similar to a mechanical system, in order to describe the quantum system, we will be using the Lagrangian and Lagrange equations.\nLet me start with QED. So what is QED? QED essentially is the electromagnetic field. If someone asks you about equations in QED, the first thing that comes to mind is the Maxwell equations. This is the equation of motion for the electric field.\nThe index \\mu here indicates that it’s a vector field. It means under boosts and rotations, it transforms as a vector. As the vector that we are used to, like the particle is moving in certain directions, its momentum is also a vector. The same thing is for this field.\nOnce you see the \\mu index, you know how to boost and rotate this object because it belongs to the vector representation of the Lorentz group. If someone asks you, “I give you the vector,” the zero component is the time component of the four-vector, and then the vector component. It’s the same as the regular four-vectors for momentum: the zero component is the energy and then the spatial components are the momentum. The same for the vector field.\nAgain, you see the index \\mu and then you know what it is. If I give you a four-vector for the vector field and ask you how it looks if I rotate it by 90 degrees, you know what to do. You remember the rotation matrix: 1, 0, cosine, sine. You just apply this to the vector and that’s it. You know how to boost this field as well, because it’s a vector field. There is a gamma, beta, gamma matrix that you apply and then you have it.\nThis might sound familiar already. This was in quantum mechanics and many other courses. They will be extremely useful in other field theory courses. But in our course we’ll be mostly operating with a different way. We barely will be using the four-vector. We barely will be using this, essentially four-vectors and tensor contractions.\nAnother thing to note is that here I am explicitly using Einstein notation and explicitly summing over repeated indices. \\mu here, \\mu there. They are repeated. That means if I were accurate, I should have written here a sum, and then have A_\\mu from 0 to 3, and sum all of the components. The \\nu is a repeated index again, sum.\nIf I look at this, how many terms should I sum? If I put a sum here, how many terms component-wise? If I expand this, how long will it be? It’s a 4 times 4, right? It’s 16 terms. If I also put F_{\\mu\\nu} here, and then have these two fields, for both of them there will be an extra four because it’s a two here, two there. If you multiply them, they will be 16 times 4, which is 64 terms.\nThe equation of motion for this Lagrangian is obtained using the Lagrange equation. You might remember this from classical mechanics where we had dots and the first one was the time derivative, the second one was the derivative of the field. We treat our Lagrangian as a function of the fields and their derivatives.\nWe feel the derivatives and the fields as the different objects and we first differentiate by the derivatives and second we differentiate by the field variables. In that case X is a \\mu . There should be a sum over \\mu . And then the X is the A_\\rho . It’s another Lorentz index.\nIf I take this Lagrangian and I use the Lagrange equation, I get the equation of motion, how the field is moving through space. We know that it’s Maxwell equations. So the equation of motion gives Maxwell and that is important.\nNow let me introduce the second part of the topic. This was the gauge field. It’s called A_\\mu . This is a little bit less intuitive concept that you might have seen before. But we will need it as well so that there are degrees of freedom that are not fixed for the photons, for the electromagnetic field.\nThere is an arbitrary gauge that we fix, that we can explore. This gauge is manifested in the fact that we can take A_\\mu and move it to other A'_\\mu which is A_\\mu - \\partial_\\mu \\chi . So \\chi is a scalar field. Essentially I’m taking all of my fields and I shift them by a derivative.\nUnder this transformation, F_{\\mu\\nu} goes to F'_{\\mu\\nu} . In order to find what it goes to, we have to put it here. This A becomes A' and then you have derivatives. Since this is a function of the space coordinate, you have to differentiate this term as well. You have to do this for the second term.\nIt turns out, and it’s easy to see, that the minus sign kills the extra term. So F'_{\\mu\\nu} = F_{\\mu\\nu} . Then our Lagrangian is invariant. This is the symmetry of the Lagrangian under gauge transformation.\nIf you do the exercise of the variation of the Lagrangian equations and the Maxwell Lagrangian trying to get the Maxwell equations, you won’t get immediately the known Maxwell equations, you will get them up to a gauge. So we see what this derivative does. It picks one of the terms.\nIf you differentiate F_{\\mu\\nu} by the derivative, you will get \\partial_\\rho A_\\nu - \\partial_\\nu A_\\rho and then it will be left over. Maxwell equation, as we know, is \\partial_\\mu \\partial^\\mu A_\\nu = 0 . But you will get an extra term that is easy to kill.\nIf you know that gauge invariance is present and in order to argue that this extra term vanishes, you can say that I can choose in all of my space such a function \\chi that kills the extra term. By fixing the gauge this way you get the common Maxwell equations that we have in electromagnetics.\nFine, we now introduce the fermion fields. As we do in electrodynamics, we have our leptons and the \\psi , where the \\bar{\\psi} is \\psi^\\dagger \\gamma^0 . Actually the \\psi is the four-component spinor which is built by steering degrees.\nEvery Lagrangian is a scalar quantity. It means there are no indices. It’s not a vector, not a matrix. Every Lagrangian is sort of a function, a number, and it’s made of objects of different dimensionality. The fermion field, a fermion is a particle that has spin one half.\nSince we have to deal with the particle and antiparticle components in the same vector, we have four components in the bispinor here. These are these four components. Don’t mix them up with a four-vector. It’s not legal to say \\mu because \\mu would indicate that this is an object that transforms under boosts and rotations the same way as the four-momentum. But that’s not true.\nThis field transforms differently. It still has four components, but it’s a different object. It’s called a bispinor, it’s not a four-vector.\nIn order to make a scalar quantity out of this vector, we do this transformation. We take it, we transpose it so it becomes a row. We multiply by the first matrix on the left. This is the gamma matrix. We look at this; it is a matrix as well, because the gamma is a four-by-four matrix. The mass is a scalar. But here there is a four-dimensional identity matrix in order to have the correct dimensions.\nEssentially, that way you form the Lagrangian. Then you take the Lagrange equations and you find out that the equation of motion is the Dirac equation. We like very much condensed notation. Often this contraction, these gamma matrices, is noted with a slashed symbol, a slash through the matrices.\nSo this is actually often written as: the equation of motion is (i \\not{\\partial} - m) \\psi = 0 , the Dirac equation.\n\n\n\n\n\n\nKey formulas from this section:\n\nMaxwell Lagrangian Density: \\mathcal{L}_{\\text{EM}} = -\\frac{1}{4} F_{\\mu\\nu} F^{\\mu\\nu} , where F_{\\mu\\nu} = \\partial_\\mu A_\\nu - \\partial_\\nu A_\\mu .\nGauge Transformation: A_\\mu \\rightarrow A'_\\mu = A_\\mu - \\partial_\\mu \\chi , leaving F_{\\mu\\nu} invariant.\nQED Lagrangian with Fermions: \\mathcal{L}_{\\text{QED}} = \\bar{\\psi} (i \\gamma^\\mu \\partial_\\mu - m) \\psi - e \\bar{\\psi} \\gamma^\\mu \\psi A_\\mu - \\frac{1}{4} F_{\\mu\\nu} F^{\\mu\\nu} .\nDirac Equation: (i \\gamma^\\mu \\partial_\\mu - m) \\psi = 0 or, in slash notation, (i \\not{\\partial} - m) \\psi = 0 ."
  },
  {
    "objectID": "2024-Lecture-01.html#gauge-invariance-and-the-structure-of-interactions",
    "href": "2024-Lecture-01.html#gauge-invariance-and-the-structure-of-interactions",
    "title": "(2024) Lecture 1",
    "section": "6 Gauge Invariance and the Structure of Interactions",
    "text": "6 Gauge Invariance and the Structure of Interactions\nAnd finally we arrive at an important aspect of field theory: introducing interactions. So far, we have dealt with a theory that has no interactions. Photons have been moving by themselves without interacting with charge or anything else. The fermions here are also free-moving particles. Essentially, a particle starts moving, doesn’t see anything, and just propagates. It is a free particle with no interaction.\n\n\n\n\n\n\nFigure 2: This figure represents a Feynman diagram illustrating the coupling of a fermionic field  \\psi(x)\\$  to a gauge field \\ A_$ . The interaction occurs via the electromagnetic current j^\\mu(x) = \\bar{\\psi}(x)\\,\\gamma^\\mu\\,\\psi(x), which couples to the gauge field, showing how fermions interact with gauge bosons in the Standard Model.\n\n\n\nWe now want to introduce interaction. The way to do this is guided by the gauge principle.\n\nFor the gauge invariance of the electromagnetic field, it was the shift of the field A_\\mu .\nFor fermions, gauge invariance implies changing the phase of the wave function.\n\nThe wave function \\psi for the fermion has an observable absolute value squared, but its phase is not fixed. We should be able to update this phase, which is called a phase transformation.\nThe check for gauge invariance is to perform this phase transformation and see if your Lagrangian remains invariant. It’s intuitive that you should be able to update the phase.\nWhat is tricky is that the phase can be updated differently at every point in spacetime. We are not doing a global phase rotation for all fields. Instead, we decide for every point what the phase update is.\nThis local transformation is much different because we must now account for the derivative. When we see how the Lagrangian changes under this transformation, the derivative acts not only on \\psi but also on the spacetime-dependent phase, which generates an extra term.\nSo, the Lagrangian changes to itself plus an extra term. Let’s reason through it: The derivative acting on the transformed field \\psi' = e^{i Q \\alpha(x)} \\psi will bring down a factor like -iQ \\partial_\\mu \\alpha . This extra term breaks the invariance of the free theory.\nThe solution is to replace the ordinary derivative with the covariant derivative: D_\\mu = \\partial_\\mu - i Q A_\\mu\nThe total Lagrangian for quantum electrodynamics (QED) becomes: \\mathcal{L}_{\\text{QED}} = \\bar{\\psi} (i \\gamma^\\mu D_\\mu - m) \\psi - \\frac{1}{4} F_{\\mu\\nu} F^{\\mu\\nu}\nWhat we find is that for the free Dirac theory, the Lagrangian is not gauge invariant because it changes under the phase transformation. However, if we incorporate the gauge field A_\\mu and perform the gauge transformation for both fields simultaneously, the extra term gets compensated.\n\nThe fermion field transforms as: \\psi \\rightarrow \\psi' = e^{i Q \\alpha(x)} \\psi\nThe gauge field transforms as: A_\\mu \\rightarrow A_\\mu + \\partial_\\mu \\alpha\n\nThe change in the interaction term \\bar{\\psi} i \\gamma^\\mu Q A_\\mu \\psi , due to the shift in A_\\mu , exactly cancels the unwanted term from the phase transformation of \\psi .\n\n\n\n\n\n\nThis is a super important concept: the way fields and fermions interact is driven by gauge invariance. We demand the freedom to change the phase locally at every point in spacetime, and this requirement determines how the interaction must work. The resulting interaction term in the Lagrangian is A_\\mu J^\\mu , where J^\\mu = \\bar{\\psi} \\gamma^\\mu \\psi is the fermion current.\n\n\n\nFrom this Lagrangian, if you derive the equations of motion, you won’t get just the free Dirac equation. You will have a source term, showing it’s not a free-moving field—it interacts with photons. This gives us a consistent framework for interactions.\nThe gauge principle does more than just dictate how particles interact; it determines the entire structure of the interactions. Depending on the mathematical nature of the “phase” transformation, we get different fundamental forces.\n\nIf the phase is a scalar (a simple number), you get electrodynamics (QED). There is only one type of gauge boson: the photon.\nIf the phase is a 2x2 matrix (like the Pauli matrices), you get Yang-Mills theory, which describes the weak interactions with the W ^+ , W ^- , and Z bosons.\nIf the phase is a 3x3 matrix (like the Gell-Mann matrices), you get quantum chromodynamics (QCD).\n\nThe mathematical object for the phase transformation is connected to a Lie group (U(1), SU(2), SU(3)). The dimensionality of this transformation determines the “charge space” in which the fermion field \\psi can live. For example, in electroweak theory, the left-handed quarks (up and down) form a doublet under the SU(2) transformation.\nThe general form of a non-Abelian gauge transformation is: \\psi(x) \\rightarrow \\psi'(x) = e^{i g \\alpha^a(x) T^a} \\psi(x)\nHere, T^a are the generators of the group (e.g., Pauli matrices \\sigma^a/2 for SU(2)), and \\alpha^a(x) are the spacetime-dependent parameters.\nThe corresponding covariant derivative becomes: D_\\mu = \\partial_\\mu - i g T^a A_\\mu^a\nThis ensures invariance under these more complex local transformations and leads to theories where the gauge bosons themselves carry charge and can interact with each other."
  },
  {
    "objectID": "2024-Lecture-01.html#exponential-form-and-group-closure",
    "href": "2024-Lecture-01.html#exponential-form-and-group-closure",
    "title": "(2024) Lecture 1",
    "section": "7 Exponential Form and Group Closure",
    "text": "7 Exponential Form and Group Closure\nNow, the important point when working with two exponents is to ensure we are operating within a group. If I were to write the transformations without an exponential form, I could not guarantee that combining them would yield the same type of object.\nIt is a proven result in group theory that writing a group element in exponential form ensures the result remains within the group. Therefore, if you multiply one such object by another of the same type, the product corresponds to a third object of the same exponential form.\nFor those familiar with matrix exponentials, what is e^{i \\theta_a \\lambda_a} ? To find it, you must perform a Taylor expansion: \\exp(M) = \\sum_{n=0}^{\\infty} \\frac{M^n}{n!}\nand then multiply the matrix by itself repeatedly.\nThis specific matrix follows a simple pattern. I believe once you square it, the result becomes diagonal. Consequently, you can often truncate the infinite series after a certain number of terms.\nThis leads us to an even more intricate object. Here, \\lambda represents a Gell-Mann matrix, and there are eight such matrices in the SU(3) formalism.\nLet us write \\lambda_1 : \\lambda_1 = \\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}\nSo, what is e^{i \\theta \\lambda_1} ? It should be straightforward to compute using the series expansion, noting that \\lambda_1^2 is diagonal.\n\n\n\n\n\n\nThe exponential form U = \\exp(i \\theta_a \\lambda_a) is central to group theory in quantum chromodynamics (QCD). It guarantees closure under multiplication—the product of two SU(3) group elements remains an SU(3) element. For matrices like the Gell-Mann matrices, the Taylor series for the exponential often simplifies dramatically.\n\n\n\nI am tempted to take a shortcut. You could ask either ChatGPT or Wolfram Alpha for the answer, and it would provide it quickly. However, I am confident it is easy to derive if you think about it for a moment.\nYou may not have much time now, but I encourage you to familiarize yourself with these matrices. It is both enjoyable and crucial for this course."
  },
  {
    "objectID": "2024-Lecture-01.html#qcd-lagrangian-and-confinement",
    "href": "2024-Lecture-01.html#qcd-lagrangian-and-confinement",
    "title": "(2024) Lecture 1",
    "section": "8 QCD Lagrangian and Confinement",
    "text": "8 QCD Lagrangian and Confinement\nThe last concept in this subject is that the Lagrangian for Quantum Chromodynamics (QCD) is constructed to be invariant under the SU(3) gauge transformation.\nIts structure is not entirely different from previous gauge theories, but it has a very important distinction: the proliferation of indices. The dimensionality of objects is super important.\nOnce we have a generator T^a , where T^a = \\lambda^a/2 , it is a 3 \\times 3 matrix. Contracting it with a field yields another 3 \\times 3 matrix, which is diagonal in the color dimension. We must keep track of multiple dimensions: color, Lorentz, and the gluon field A^a_\\mu .\nAn instructive exercise is to recover the familiar terms from Quantum Electrodynamics (QED) from this framework; you will see they are essentially the color-stripped versions.\nOne crucial aspect of QCD is that it is fundamentally different because it contains a term that allows gluons to interact with themselves. Even in a theory without quarks, gluons and their self-interaction terms would remain.\nThis self-interaction term in the equations of motion means gluons behave profoundly differently from photons. These gluon self-interactions lead to the phenomenon known as confinement. The screening of color forces works in the opposite way to the screening of electric forces in QED.\nIn a proper field theory course, you learn that the strength of interactions depends on the energy scale at which you probe the system, a concept related to renormalization. Depending on the energy scale of your experiment, you effectively experience a different charge.\n\n\n\n\n\n\nThe QCD Lagrangian contains the strong coupling constant g_s , which is “bare” in the Lagrangian. However, the coupling you observe in interactions is not this bare constant—it changes with the energy scale. This running is described by the QCD beta function: \\beta(\\alpha_s) = \\frac{d\\alpha_s}{d\\ln Q} = -\\frac{\\alpha_s^2}{2\\pi} \\left( 11 - \\frac{2}{3} n_f \\right) + \\mathcal{O}(\\alpha_s^3)\nwhere \\alpha_s = g_s^2/(4\\pi) and n_f is the number of quark flavors. The negative sign is key: it means \\alpha_s decreases at high energies (asymptotic freedom) and increases at low energies (confinement).\n\n\n\nFor QED, the coupling constant becomes smaller as you probe shorter distances (higher energy). For the strong interaction, the coupling constant g_s becomes stronger as you reduce the energy scale.\nThis increasing strength at low energies is the reason hadrons can form. Gluons and quarks bind into hadrons at these small energy scales.\n\n\n\n\n\n\nFigure 3: The diagram shows the dependence of the strong coupling  \\alpha\\_s(Q)\\$  on the transferred momentum \\ Q$ . At high  Q\\$ , the coupling decreases, illustrating the property of asymptotic freedom. At low \\ Q$ , the coupling grows, leading to the non-perturbative regime of QCD and the phenomenon of confinement. The transition scale is set by  \\Lambda\\_{\\text{QCD}} \\sim 300\\ \\text{MeV}\\$ , and for \\ Q  $ perturbative methods fail, marking the domain of confinement and hadronization.\n\n\n\nThe strong interaction is such that it does not allow colored objects (like individual quarks) to escape; it confines them. The high-energy regime where the coupling is small is called asymptotic freedom.\nThe root cause of both confinement and asymptotic freedom is the gluon self-interaction. There is essentially no “free” theory for QCD; even without quarks, gluons interact. This self-interaction leads to confinement at low energy and asymptotic freedom at high energy. The latter regime is where we perform calculations for processes like Higgs physics, where large momentum transfers occur.\nAn aspect not discussed in detail today is what Quantum Field Theory (QFT) tells us about performing computations in perturbation theory. In QED, or in the asymptotic freedom regime of QCD where the coupling is small, you can expand your equations of motion and iterate using the fact that the coupling is small.\nThis leads to the perturbative approach, with its diagrammatic representation known as Feynman diagrams. Using these, you compute matrix elements.\nIn this course, we will often refer to the matrix element squared |\\mathcal{M}|^2 , which is related to the cross section \\sigma of a process. The general formula for a 2 \\to N scattering cross section is: \\sigma = \\frac{1}{2E_A 2E_B |v_A - v_B|} \\int \\left( \\prod_{f=1}^N \\frac{d^3p_f}{(2\\pi)^3 2E_f} \\right) |\\mathcal{M}|^2 (2\\pi)^4 \\delta^{(4)} \\left( p_A + p_B - \\sum p_f \\right)\nHere, \\Phi represents the flux factor, and D\\Phi stands for the integration over the final-state particle phase space.\nThe matrix element in QFT is the key object that relates theory to observables. It tells you how to compute quantities you can measure in an experiment.\nIntuitively, you can understand it this way:\n\nThe matrix element \\mathcal{M} gives the quantum mechanical amplitude for a transition from an initial state to a specific final state.\n|\\mathcal{M}|^2 is proportional to the probability for that specific configuration.\nTo get the total probability, you must sum over all possible final-state configurations (integrate over phase space D\\Phi ).\n\nYou will see an example next week of how, for a two-body decay, you explicitly count the number of configurations in the final state. The total probability (or decay rate) will be this matrix element squared, summed over all possible configurations.\nIn these calculations, you must also account for particle spins:\n\nSum over the spin states of the final particles.\nAverage over the spin states of the initial particles.\n\nThis is why for a process like A + B \\to N , we include averaging factors. If you are given a correctly spin-averaged matrix element, along with the 1/(2E) factors for incoming particles, you can immediately calculate the corresponding cross section.\nThe cross section \\sigma  has units of area (e.g., cm ^2 ). It represents the effective “target area” presented by one particle to another. If the colliding particles pass within this area, the reaction is likely to occur; outside of it, the reaction does not happen.\nThe decay width \\Gamma  is related to the lifetime \\tau of an unstable particle ( \\tau = 1/\\Gamma ). For a particle of mass M decaying to N final particles, the partial width is: \\Gamma = \\frac{1}{2M} \\int \\left( \\prod_{f=1}^N \\frac{d^3p_f}{(2\\pi)^3 2E_f} \\right) |\\mathcal{M}|^2 (2\\pi)^4 \\delta^{(4)}\\left( p - \\sum p_f \\right)\nWe will discuss this formula in more detail next time."
  },
  {
    "objectID": "2024-Lecture-01.html#course-logistics-and-introduction",
    "href": "2024-Lecture-01.html#course-logistics-and-introduction",
    "title": "(2024) Lecture 1",
    "section": "9 Course Logistics and Introduction",
    "text": "9 Course Logistics and Introduction\nIt’s really nice to have you all today. We are three minutes out, but let me quickly go over the logistics for the course.\n\nI have prepared notes for 11 lectures and 11 exercises (though there will be fewer exercises due to some breaks).\nA calendar is available on Moodle listing the anticipated dates for lectures and exercises. Closer to those dates, we can discuss shifting exercise sessions, but for now, we will keep the schedule as is.\nFor the exam, we will track the points you gain through the exercise sheets during the semester. Achieving 50% of these points will admit you to the examination.\nThe exam itself is designed to be straightforward: you will receive the problem one or two weeks in advance to think about it.\nDuring the exam, you will bring your solutions, and we will have a discussion about the material.\n\nI think the most important thing is to work on the exercise sheets during the semester. Let me show them to you.\n\nThere is a barcode to scan on the sheets.\nThere will be one or two problems per homework that you must solve.\nProcess: You write your solutions down, bring the solved sheets to the lecture, and place them in a designated box. We will check them, and the teaching assistants will return the marked sheets during the Thursday exercise sessions, where they will also discuss the problems.\nSchedule: Lectures are on Tuesday, and exercise sessions are on Thursday.\n\nWe will have a certain excursion during the semester. Although it’s fully booked, we may still find one or two places if you haven’t signed up.\n\nOffice Hours: I will hold office hours on Thursdays from 9:00 to 10:00 in my office, 1 3B and B. You can come to discuss anything related to the course. This will be written down officially.\n\nThere are several summer schools happening in our field this summer. These are exciting events if you’re considering going to a different country.\n\nOne is in Zurich, Switzerland, for eight weeks.\nAnother is in Krakow, Poland, for four weeks.\nApplications for these are still open for another couple of weeks.\nWe are also organizing one in Bochum in July for two weeks, aimed at people more advanced in the field.\n\nIf you are interested, just write me an email, and I can forward you the official announcement.\nRegarding the exercise sheets, I encourage collaboration. You can solve the sheets together and feel free to use any resources—ChatGPT, books, etc. The problems are standard and are meant for learning, not for checking you. How you learn is up to you.\nHere are some of the key textbooks I will be following:\n\nHalzen and Martin\nMartin Schmaltz (dedicated to Higgs physics)\nThomson’s Particle Physics\n\nThe exercise sessions start this week. Before leaving, please take the sheets. We printed 15 copies; there are two sheets, each with two pages. Take one for yourself.\n\n\n\n\n\n\nOn Today’s Problem: The first problem involves a coupled spring-pendulum system. The pivot point from which the pendulum hangs can slide. You will start from the Lagrangian, which is the kinetic energy minus the potential energy, and work towards finding relevant equations of motion.\nA typical Lagrangian for such a coupled system is: L = \\frac{1}{2} m \\dot{x}^2 + \\frac{1}{2} m l^2 \\dot{\\theta}^2 + m l \\dot{x} \\dot{\\theta} \\cos\\theta - \\frac{1}{2} k x^2 - m g l (1 - \\cos\\theta)\nHere, \\dot{x} is the time derivative of the sliding coordinate, and the terms represent kinetic energy from sliding and rotation, a coupling term, and potential energy from the spring and gravity.\n\n\n\nThis is a fun problem. You can put the derived equations into a differential equation solver. It’s not that easy in quantum field theory, but people still do it in their research.\nI rushed a bit at the beginning and end, so let me clarify the plan. I will reintroduce the QED Lagrangian and the QCD Lagrangian. We will calculate something for QED as well, time permitting.\n\n\n\n\n\n\nKey Lagrangian for QED: The Quantum Electrodynamics (QED) Lagrangian describes the interaction between fermions (like electrons) and the electromagnetic field. It is given by: \\mathcal{L}_{\\text{QED}} = \\bar{\\psi}(i\\gamma^\\mu D_\\mu - m)\\psi - \\frac{1}{4} F_{\\mu\\nu} F^{\\mu\\nu}\nIn this formula, D_\\mu = \\partial_\\mu + i e A_\\mu is the covariant derivative, and F_{\\mu\\nu} is the electromagnetic field tensor.\n\n\n\nI think starting with a simpler case and explaining how you calculate the terms is a good approach. I’ve prepared an exercise on gauge transformations for QED. This will provide a useful comparison to understand the added complexity that QCD brings. While QED explains most electromagnetic interactions, QCD introduces further complexity.\nI think we should proceed. Let’s get started."
  },
  {
    "objectID": "2024-Lecture-02.html",
    "href": "2024-Lecture-02.html",
    "title": "(2024) Lecture 2",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-02.html#estimating-hadronic-cross-sections",
    "href": "2024-Lecture-02.html#estimating-hadronic-cross-sections",
    "title": "(2024) Lecture 2",
    "section": "1 Estimating Hadronic Cross Sections",
    "text": "1 Estimating Hadronic Cross Sections\nSo how were the problems from the homework? I think when you study particle physics, you have several courses and some problems you do a few times because they appear first in nuclear physics and then maybe in particle physics or quantum field theory. You do Clebsch-Gordan coefficients four times because that’s how it is; it’s so important. So it will be homework for this week. There will be some Clebsch-Gordan coefficients and I hope you won’t have troubles with that.\nToday’s lecture we will discuss more about the symmetries in hadron physics. We will start with QCD as we discussed before with the SU(3) group and then move to the phenomenology of the SU(3) flavor group. We will discuss isospin and then discuss SU(3) flavor by interchanging up and down quarks. We will connect this to the Lorentz group which has SU(2) as a subgroup responsible for rotations. You will see how the addition of spin has something to do with the addition of the quarks inside hadrons.\nI will remind you of a lot of material from quantum mechanics that you’ve seen already and I hope it will be easy to follow. I particularly enjoy this part because this is something you can derive once you isolate yourself from books and the Internet. You can just sit and work through this really nice spin algebra.\nLet me start by reminding you of the last lecture with a few questions. The first one I would like to ask is to remind you of the previous lecture. How would you estimate the typical cross section of hadronic reactions? Just an order of magnitude.\nIf I want just an order of magnitude, what would I do? You would take the integral over all possible configurations of the matrix element squared. If you know the matrix element, then you can calculate the cross section by summing over all final states:\n\\sigma = \\frac{1}{4\\sqrt{(p_1\\cdot p_2)^2-m_1^2m_2^2}} \\frac{1}{N_i} \\sum_{f} |\\mathcal{M}_{if}|^2 d\\Phi_n\nThis will give you an exact value for the cross section in units of inverse GeV, which you can convert to centimeters squared. That’s a good approach, and this is what we will do once we know the matrix element.\nThis is for a particular process. Here I assume that I know the initial state and the final state. This matrix element gives me the transition from the initial state to the final state. This is the particular cross section for the initial state scattering to that specific final state. If I want the total cross section, I sum over all possible final states. Since different final states are orthogonal to each other, there is no quantum coherence or interference between them, so I can just sum them up. This is the precise method.\nBut I want a number. What is the scale we are dealing with? What should we expect for the size of a cross section? The units of cross section is the barn. One barn is equal to 10^{-24} \\, \\text{cm}^2 .\nSo how do we get the order of barns? What is the cross section? Imagine that you fix your target particle, say a proton, at a certain point and you hit it with another proton. The cross section gives you the effective area in space. Once you hit this little area, the reaction happens. If you go outside, the reaction does not happen. So you can think of it literally as an area in space.\nWhat would this area be? It is the effective area of the interaction. How do I estimate this? By the scale of the strong interaction, by the size of the proton. Think of it as a solid ball. The strong interaction range is about one fermi, which is 10^{-15} meters or 10^{-13} centimeters.\nThe cross section is on the order of \\pi R^2 . That’s the area. For a radius R \\approx 1 \\, \\text{fm} , we get \\sigma \\approx \\pi \\times (10^{-13} \\, \\text{cm})^2 . This is on the order of 10^{-26} \\, \\text{cm}^2 , or about 10 millibarns. If you calculate the total cross section for hadrons, you’re going to get values around that scale because the way they interact is by essentially overlapping their densities. If they are far away from each other, they never talk to each other. The strong interaction is really strong, but it’s short-range.\n\n\n\n\n\n\nKey Estimation: The geometric cross section provides a quick order-of-magnitude estimate for hadronic reactions: \\sigma \\approx \\pi R^2 . For a proton radius R \\approx 1 \\, \\text{fm} = 10^{-13} \\, \\text{cm} , this yields \\sigma \\approx 3 \\times 10^{-26} \\, \\text{cm}^2 , or about 30 millibarns. This scale is typical because the interaction probability is essentially unity within the effective area defined by the particle’s size."
  },
  {
    "objectID": "2024-Lecture-02.html#defining-charge-via-conserved-currents",
    "href": "2024-Lecture-02.html#defining-charge-via-conserved-currents",
    "title": "(2024) Lecture 2",
    "section": "2 Defining Charge via Conserved Currents",
    "text": "2 Defining Charge via Conserved Currents\nThe second question I thought of is: how do I define charge in QED and QCD?\nFirst, what is the charge in QED? We can pick the electric charge as the prime example.\n\n2.1 Defining Charge via Noether’s Theorem\nDo you remember how I defined the charge? If I’m given a field, say a spinor \\psi , how do I figure out its charge?\nThe charge is a conserved quantity for the particles. For a free moving field, its charge isn’t changing. This conservation arises from a symmetry, and Noether’s theorem tells us there is a corresponding conserved current.\nThe charge is defined as the integral of the zero component (the time component) of this conserved current: Q = \\int d^3x \\, j^0\nFor a Dirac field \\psi in QED, this conserved current from the global U(1) symmetry is: j^\\mu = \\bar{\\psi} \\gamma^\\mu \\psi\nwhere \\bar{\\psi} = \\psi^\\dagger \\gamma^0 is the Dirac adjoint.\nIf we look specifically at the charge density j^0 : j^0 = \\bar{\\psi} \\gamma^0 \\psi = \\psi^\\dagger \\gamma^0 \\gamma^0 \\psi\nSince \\gamma^0 \\gamma^0 = I (the identity matrix), this simplifies to: j^0 = \\psi^\\dagger \\psi\nThis is a positive quantity for Dirac field solutions.\n\n\n2.2 Reconciling Theory with Convention\nThis leads to an implication: if my \\psi field represents an electron, the Noether charge Q would be positive. At first, this seems like a contradiction because we know the electron has negative electric charge.\nThe resolution is that the conserved quantity Q from field theory is what’s fundamentally conserved. How we match it to our physical observations—like the electron having charge -e —is a matter of convention.\nWe define the observed charge to match our conventions: Q_{\\text{observed}} = -e \\int d^3x \\, \\psi^\\dagger \\psi\nSo, it doesn’t matter what constant you put in front; the crucial point from field theory is that this quantity Q is conserved. Scaling it by a factor (like -e ) to match experiment is our choice.\n\n\n\n\n\n\nThis discussion focuses on electric charge in QED, arising from a U(1) symmetry. A similar logic applies to color charge in QCD, but it originates from a more complex SU(3) gauge symmetry. The conserved currents in QCD involve color indices and matrices (like the Gell-Mann matrices T^a ), leading to eight conserved color charges."
  },
  {
    "objectID": "2024-Lecture-02.html#currents-and-charges-in-qed-and-qcd",
    "href": "2024-Lecture-02.html#currents-and-charges-in-qed-and-qcd",
    "title": "(2024) Lecture 2",
    "section": "3 Currents and Charges in QED and QCD",
    "text": "3 Currents and Charges in QED and QCD\nThe electromagnetic current in QED is often denoted as J^\\mu or j^\\mu , where: j^\\mu = -e \\, \\bar{\\psi} \\gamma^\\mu \\psi\nThis is the conserved Noether current associated with the U(1) gauge symmetry of QED.\n\n\n\n\n\n\nFigure 1: This figure represents the process of probing (measuring or interacting with) electric charge using a photon. In the context of the lecture, this illustrates how, in Quantum Electrodynamics (QED), a photon couples to a charged particle (such as an electron) via an interaction vertex, allowing experimental or theoretical access to the particle’s electric charge. The wavy line corresponds to the photon, and the adjoining straight line represents the charged particle (like an electron or quark). This is a fundamental concept because the photon is the mediator of electromagnetic interactions, and its coupling directly measures the conserved electric charge associated with the U(1) symmetry of QED, as discussed when introducing conserved currents and Noether’s theorem.\n\n\n\nThe factor -e is a convention to match our common definition of electric charge (electrons have negative charge). We could have defined electrons as positively charged, but that is not our standard convention.So, how do we define the analogous charge in Quantum Chromodynamics (QCD)? We follow a similar logic. In QED, a photon couples to a fermion via a vertex with \\gamma^\\mu , probing its electric charge through the current. (see Figure 1) For QCD, we want a vertex that probes color charge.\n\n\n\n\n\n\nThe color current in QCD is the conserved non-Abelian current associated with the SU(3) gauge symmetry. It couples to the gluon fields and describes the flow of color charge, which has eight components corresponding to the eight gluons: j^{\\mu,\\,a} = g_s \\, \\bar{\\psi}_i \\gamma^\\mu (T^a)_{ij} \\psi_j\nHere, g_s is the strong coupling constant, \\psi_i is the Dirac spinor field for a quark with a color index i = 1,2,3 (representing red, green, blue), and (T^a)_{ij} are the Gell-Mann matrices (the generators of SU(3) ) with a = 1, \\dots, 8 .\n\n\n\nThe construction is very similar:\n\nThe quarks are still fermions, so we use the Dirac spinor \\psi , but now it carries a color index.\nAt the vertex, we still have a \\gamma^\\mu , but we must also include a Gell-Mann matrix T^A to account for the non-Abelian SU(3) structure.\n\nTherefore, the QCD vertex factor becomes \\gamma^\\mu T^A . Given a specific quark field \\psi , we can insert it into the current j^{\\mu,\\,a} to compute its color charge.\nA key result is that the color charge of a quark is not a single number like “red,” “green,” or “blue.” Instead, for a given quark state, you compute a vector of eight numbers, one for each gluon type (each generator T^a ).\n\nHow many color charges does QCD have? Eight, corresponding to the index a on the current j^{\\mu,\\,a} .\n\nFor example, consider a quark with a specific color state in the fundamental representation: \\psi_{\\text{color}} = \\begin{pmatrix} 1 \\\\ 2 \\\\ i\\sqrt{3} \\end{pmatrix}\nTo find its color charge, you compute the eight numbers given by the expectation value of the color charge operator Q^a_{\\text{QCD}} = g_s \\int d^3x \\, \\psi_i^\\dagger \\gamma^0 (T^a)_{ij} \\psi_j for this state. Depending on which gluon (labeled by index a ) you use to probe the quark, you will get a different component of this charge vector. All eight components are computed using the same fundamental equation for the color current."
  },
  {
    "objectID": "2024-Lecture-02.html#su2-group-representations-generators-and-physical-charges",
    "href": "2024-Lecture-02.html#su2-group-representations-generators-and-physical-charges",
    "title": "(2024) Lecture 2",
    "section": "4 SU(2) Group: Representations, Generators, and Physical Charges",
    "text": "4 SU(2) Group: Representations, Generators, and Physical Charges\nSo then this comes from group theory. Here we deal with U(1), U(2), SU(2), and SU(3). Today we will be discussing SU(2). We are finishing here with a recap and moving to the discussion of today’s SU(2) group.\nThe SU(2) group is a super important symmetry in particle physics. First, it’s a group. Let’s start by discussing a few words on what a group is.\nA group is defined by a set of elements with a composition rule. For any element G in the group, there exists an inverse G^{-1} that is also in the group. For any two elements G_1 and G_2 , their composition G_1 \\circ G_2 also belongs to the group. Finally, there is an identity element.\nSU(2) is a special unitary group. It is the group of 2 \\times 2 unitary matrices with determinant one. An element U \\in SU(2) satisfies: U^\\dagger U = U U^\\dagger = I, \\quad \\det(U) = 1\nThe letter S stands for “special,” meaning the determinant is exactly one.\n\n\n\n\n\n\nThis is the fundamental representation of SU(2). A representation is a way of realizing the group’s elements as matrices acting on a vector space. The fundamental representation acts on a 2-dimensional (complex) vector space.\n\n\n\nWe could imagine listing all matrices in the group, but it’s not possible because the group is continuous and infinite. However, if we could list them, we would know how they compose—multiplying two group elements gives another group element. To construct other representations, we find a correspondence where each group element is mapped to a matrix in a different dimension (e.g., 3 \\times 3 or 4 \\times 4 ) while preserving the group multiplication rules. SU(2) is a nice group because it has a straightforward way of constructing representations of any dimension.\nAnother key concept from group theory is the Lie algebra. All group elements near the identity can be generated from the algebra. For SU(2), the generators are the Pauli matrices, \\sigma_1, \\sigma_2, \\sigma_3 . Any group element can be written in exponential form: U = \\exp\\left(i \\sum_{i=1}^{3} \\theta_i \\sigma_i\\right)\nwhere \\theta_i are real parameters.\nThe matrix exponential is defined via its Taylor expansion: \\exp(M) = I + M + \\frac{M^2}{2!} + \\frac{M^3}{3!} + \\cdots\nFor certain matrices where M^2 = 0 , the series terminates at I + M . In general, you compute it by summing the series.\nThe generators obey the defining commutation relations of the \\mathfrak{su}(2) algebra: [\\sigma_i, \\sigma_j] = 2i \\epsilon_{ijk} \\sigma_k\nThese relations hold for the generators in any representation of SU(2). For the fundamental representation, the Pauli matrices satisfy this exactly.\nThis group is important in two major physical applications:\n\nSpin: Spin is a quantity that arises from the SU(2) symmetry related to rotations in space. For a three-vector, rotations are given by 3 \\times 3 rotation matrices. For a spinor (like an electron’s wavefunction), rotations are represented by the Pauli matrices.\nFlavor Symmetry: We can apply SU(2) to quark flavor, specifically mixing up and down quarks. Continuous transformations between up and down quark states are characterized similarly to rotating a spinor, but in flavor space.\n\nThe first application (spin) you’ve likely seen in quantum mechanics. Before moving on, let’s connect these groups to a physical concept: charge.\n\nIn QED (U(1) symmetry), the conserved charge is electric charge.\nIn QCD (SU(3) symmetry), the conserved charge is color charge.\n\nWhat is the charge for our SU(2) symmetries? We can compute it using Noether’s theorem. For a symmetry with generators T^a , the conserved charge is: Q^a = \\int d^3x \\, \\psi^\\dagger T^a \\psi\n\nFor the rotation (spin) group: We replace T^a with the Pauli matrices. The resulting charges S_1, S_2, S_3 correspond to the projections of the spin along the x, y, and z axes. They are related to the particle’s helicity, which is the projection of spin along the direction of motion: h = \\frac{\\mathbf{S} \\cdot \\mathbf{p}}{|\\mathbf{p}|} .\nFor the flavor group: We again use Pauli matrices, but now the wavefunction \\psi describes quark flavor (up and down). The resulting conserved charge is a new quantity called isospin.\n\nIn summary, the SU(2) algebra, with its commutation relations [\\sigma_i, \\sigma_j] = 2i \\epsilon_{ijk} \\sigma_k , underlies the physics of both spin and isospin."
  },
  {
    "objectID": "2024-Lecture-02.html#su2-representations-and-the-construction-of-generators",
    "href": "2024-Lecture-02.html#su2-representations-and-the-construction-of-generators",
    "title": "(2024) Lecture 2",
    "section": "5 SU(2) Representations and the Construction of Generators",
    "text": "5 SU(2) Representations and the Construction of Generators\nI am given the commutation relation [J_i, J_j] = i \\varepsilon_{ijk} J_k . This defines the Lie algebra of the SU(2) group, where \\varepsilon_{ijk} is the Levi-Civita symbol.\nLet me write it more quickly. Essentially, this means the generators J_1 , J_2 , and J_3 satisfy three fundamental relations. From this algebra, you get the three generators.\nSo \\sigma_3 is the one that will give you the Pauli matrices as well. Just to remind you, the Pauli matrices in the fundamental ( j=1/2 ) representation are: \\sigma_1 = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}, \\quad\n\\sigma_2 = \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix}, \\quad\n\\sigma_3 = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}.\nFortunately, there is no different convention for these; we all use the same.\nIt’s extremely important to ask: how many of the generators of the group have a diagonal form? This is a fundamental group theory question. All generators must be traceless because the condition for a matrix to have determinant one implies a relation between the determinant and the trace. Essentially, for these group elements, the determinant is equal to the exponential of the trace.\nBut it’s important to know how many are diagonal, because this tells you what the eigenvalues and eigenvectors are that you are going to deal with. For SU(2), there is just one matrix that is diagonal in the standard basis. That’s why the group is called rank one. If you go to a group theory class, you will see fascinating classifications of all possible groups that heavily rely on the rank of the group. For SU(2) the rank is equal to 1.\nThis diagonal matrix will be used to construct and determine physical quantities from the states.\nWe are now going to act with these matrices on the states. We will use the ket notation |J M\\rangle for the states, which implies a unit vector with only one non-zero component at the position corresponding to M .\nWe will use a lot of this notation. The label J gives you the dimension of the representation. We will discuss the spin applications of this group first, where J determines the dimension in the sense that every component corresponds to a certain possible value of the projection of the spin. There are 2J + 1 possible projections.\nThe physical picture is that we have a spin vector \\mathbf{J} and a quantization axis. Along this axis, there are several possible projections: -J, -J+1, ..., +J . The number of them is 2J+1 .\n\nJ = 1/2 corresponds to the two-dimensional representation. That’s fundamental. The basis states are |1/2, 1/2\\rangle and |1/2, -1/2\\rangle .\nThose Pauli matrices (divided by 2) are the generators for this fundamental representation, where the matrix acts on the vector space spanned by these two states.\nAny other state, like |3/2, -1/2\\rangle , lives in a larger vector space. This is just notation for the vector space. We construct any group element acting on that space using our generators. Okay, let’s look quickly at the lowering and raising operators. We define: J_+ = J_1 + i J_2, \\quad J_- = J_1 - i J_2.\nThese are the raising and lowering operators.\n\n\n\n\n\n\n\nFigure 2: This figure represents the mathematical expression for the construction of ladder operators, which are essential tools in the spin algebra of the SU(2) group discussed in the lecture. Specifically, it shows the definition of the raising and lowering operators: [ J_+ = J_1 + i J_2 ] and [ J_- = J_1 - i J_2 ] These operators act on quantum states labeled by total spin J and projection M , raising or lowering the value of M by one unit. They are fundamental for building the algebraic structure of angular momentum in quantum mechanics and are directly related to the manipulation of spin and isospin quantum numbers, as well as understanding how multiplets (like baryons and mesons) are constructed and how their quantum numbers combine. The ability to use these operators enables the calculation of Clebsch-Gordan coefficients and the systematic construction of higher spin and isospin representations, which are recurring themes of the lecture.\n\n\n\nTheir action on a state will lower or increase the projection quantum number M .\n\n\n\n\n\n\nFigure 3: This diagram represents the action of the SU(2) spin algebra operators on angular momentum eigenstates labeled by the quantum number M (the projection of total angular momentum or isospin along the quantization axis). Along the horizontal axis, different M states are shown as points. - J_3 is the operator corresponding to the projection of the angular momentum; it leaves the state unchanged except for multiplying by M . - The upward arrow labeled J_+ indicates the raising operator, which acts on a state |J, M\\rangle to increase M by one unit ( J_+ |J, M\\rangle \\propto |J, M+1\\rangle ). - The downward arrow labeled J_- indicates the lowering operator, which decreases M by one unit ( J_- |J, M\\rangle \\propto |J, M-1\\rangle ). This figure demonstrates the ladder structure of spin or isospin multiplets as dictated by the SU(2) Lie algebra: raising and lowering operators connect the different states within the same multiplet, illustrating how the total space of representations is constructed. This is crucial for understanding how quantum numbers change under these operators—an essential part of both spin and isospin algebra in particle physics.\n\n\n\nThe J_+ operator acting on a lower state will move the vector to the upper one.\nTo demonstrate their properties, consider the product: J_+ J_- = (J_1 + i J_2)(J_1 - i J_2) = J_1^2 + J_2^2 - i[J_1, J_2].\nUsing the commutation relation [J_1, J_2] = i J_3 , this becomes: J_+ J_- = J_1^2 + J_2^2 + J_3 = \\mathbf{J}^2 - J_3^2 + J_3.\n\n\n\n\n\n\nThe action of the operators on an eigenstate |J M\\rangle is defined by: J_3 |J M\\rangle = M |J M\\rangle, \\quad \\mathbf{J}^2 |J M\\rangle = J(J+1) |J M\\rangle.\nThese operators commute with each other and, in quantum mechanics, with a rotationally invariant Hamiltonian, making them conserved quantities.\n\n\n\nTherefore, J_+ J_- acting on |J M\\rangle gives [J(J+1) - M(M-1)] |J M\\rangle . From this, we find the action of the ladder operators themselves:\nJ_+ |J M\\rangle = \\sqrt{J(J+1) - M(M+1)} \\, |J, M+1\\rangle,\nJ_- |J M\\rangle = \\sqrt{J(J+1) - M(M-1)} \\, |J, M-1\\rangle.\nThe square root factors ensure the states remain normalized. This structure is very closely related to what we will see later with Clebsch-Gordan coefficients.\nSo, let’s give the method to construct an arbitrary representation. Imagine you want an analog of the Pauli matrices for, say, a four-dimensional representation.\nFirst, construct J_+ . For a dimension d=4 representation, the corresponding spin is j , where 2j+1 = 4 , so j = 3/2 . The operator J_+ acts on a state and moves the projection up by one. Therefore, its matrix will have non-zero elements only on the first off-diagonal. For example, one element would be J_+ |3/2, 1/2\\rangle = \\sqrt{3} |3/2, 3/2\\rangle .\nIt’s often easier to construct J_- first. For instance: J_- |3/2, 1/2\\rangle = \\sqrt{3} \\, |3/2, -1/2\\rangle.\nThis tells you one specific matrix element. You fill the J_- matrix with the appropriate square-root factors on the first sub-diagonal, and then J_+ is its Hermitian conjugate.\nOnce you have J_+ and J_- , you recover the original generators: J_1 = \\frac{J_+ + J_-}{2}, \\quad J_2 = \\frac{J_+ - J_-}{2i},\nand J_3 is the diagonal matrix with eigenvalues m = -j, -j+1, ..., j on the diagonal.\n\n\n\n\n\n\nGeneral Algorithm: For a representation of dimension d = 2j+1 , the diagonal entries of J_3 are m from -j to j in integer steps. Use the formula J_\\pm |j, m\\rangle = \\sqrt{j(j+1) - m(m \\pm 1)} \\, |j, m \\pm 1\\rangle to populate the J_+ and J_- matrices, then construct J_1 and J_2 .\n\n\n\nNow the fun part: to get finite rotations, you exponentiate these generators. A general SU(2) group element is given by: U(\\boldsymbol{\\alpha}) = \\exp(-i \\boldsymbol{\\alpha} \\cdot \\mathbf{J}).\nYou don’t do this manually for large representations; you use a computer. What we have discussed so far is how to construct an arbitrary matrix representation of the SU(2) group."
  },
  {
    "objectID": "2024-Lecture-02.html#the-ξ-baryons-and-isospin-symmetry",
    "href": "2024-Lecture-02.html#the-ξ-baryons-and-isospin-symmetry",
    "title": "(2024) Lecture 2",
    "section": "6 The Ξ Baryons and Isospin Symmetry",
    "text": "6 The Ξ Baryons and Isospin Symmetry\nThe Ξ baryons (the Greek letter xi) are found in the Review of Particle Physics (PDG). Their quark content consists of two strange quarks and one light quark (either up or down).\n\nThe charged state is the Ξ⁻, with quark content (s s d) .\nThe neutral state is the Ξ⁰, with quark content (s s u) .\n\nIf you look at the PDG, these two particles have very similar properties—their masses are very close, and they are essentially the same particle, just with different electric charge.\nAnother example is the Ξ_c baryons.\n\nThe upper one in the isospin doublet is the Ξ_c⁺, with quark content (c s u) .\nThe lower one is the Ξ_c⁰, with quark content (c s d) .\n\nThese are all well-known, discovered particles. They have very similar masses and very similar lifetimes; essentially, they look like the same particle.\nThe third member of this family is the Ξ_cc baryon, a doubly-charmed state.\n\nThe upper state would be the Ξ_cc^{++}, with quark content (c c u) .\nThe lower state is the Ξ_cc^{+}, with quark content (c c d) .\n\nThe Ξ_cc^{++} ** has been discovered. However, the **Ξ_cc^{+}  is frequently discussed at conferences. One experiment reported a signal-like bump, but another experiment, LHCb, did not find it at the expected mass. Moreover, LHCb found a candidate for the Ξ_cc^{+} $ with a mass that was in conflict—about 40 MeV different from the mass of the state seen previously.\n\n\n\n\n\n\nWhy is this discrepancy scandalous? Because, so far, whenever you replace an up quark with a down quark (or vice versa), the particle’s mass almost does not change and its properties remain the same. This is due to strong isospin symmetry, which arises because the strong interaction is essentially blind to the difference between up and down quarks, given their very similar masses:$ m_u m_d .\nFor the _{cc} $states, it would be impossible for them to have significantly different masses under this symmetry. They must have nearly identical properties.\n\n\n\nIf you were to do a PhD on data analysis and discover the Ξ_cc^{+}$ , you would become a superstar in particle physics. There have been several PhD projects dedicated to searching for it. The search often involves a blind analysis: researchers define the reactions and a mass window to study, but they do not look at the data in that window until all selection criteria and procedures are optimized and fixed. Only then do they “unblind” the mass range.\nFour PhD students completed this rigorous process, pressed the button to unblind their data, and unfortunately found nothing there. The challenge is likely in picking the right decay channel. The Ξ_cc^{+} $ decays through many modes, and current statistics may be insufficient to see it in some of the rarer ones. The right decay mode probably exists—we just haven’t found it yet."
  },
  {
    "objectID": "2024-Lecture-02.html#symmetry-isospin-and-combining-representations",
    "href": "2024-Lecture-02.html#symmetry-isospin-and-combining-representations",
    "title": "(2024) Lecture 2",
    "section": "7 Symmetry, Isospin, and Combining Representations",
    "text": "7 Symmetry, Isospin, and Combining Representations\n\n7.1 Symmetry of QCD\nWhen we speak about the symmetries of the Lagrangian of QCD, we have in mind the Lagrangian itself. It has a term for the gluons and a term for the quarks. This term for the quarks—the Dirac term—contains a mass parameter. If the quark masses are not the same, this mass term will break the flavor symmetry.\nFor the u and d quarks, since they have almost the same masses, this symmetry is not broken by the mass terms, and it remains a good symmetry. In contrast, the mass of the strange quark is about 100 MeV. Therefore, the symmetry between the u, d, and s quarks—the SU(3) flavor symmetry—is only approximate.\n\n\n7.2 Isospin SU(2) Symmetry\nLet’s focus on the u and d quarks. Their near-equal mass means rotations in this two-dimensional flavor space are a good symmetry. This is the SU(2) isospin symmetry.\nThe transformation under this SU(2) group for a doublet like$ (u, d) $is given by: U(\\boldsymbol{\\alpha}) = e^{-i \\boldsymbol{\\alpha} \\cdot \\boldsymbol{\\tau} / 2}\nwhere \\boldsymbol{\\alpha} are the rotation parameters and \\boldsymbol{\\tau} are the Pauli matrices. This is mathematically identical to how we describe spin rotations in quantum mechanics.\n\n\n\n\n\n\nThe particle historically named cascade is denoted by the Greek letter Ξ (Xi). Because its decay chain resembled a cascade of particles, and the Greek name can be challenging to pronounce, it’s commonly just called “cascade” in particle physics.\n\n\n\nIn this framework, treating the u and d quarks as an isospin doublet (like spin-1/2), a particle like the cascade (Ξ) can be assigned an isospin wave function.\n\nThe dimension of the representation tells us the isospin quantum number. For a representation of dimension d , the isospin I is given by d = 2I + 1 .\nA doublet ( d=2 ) corresponds to isospin I = 1/2 .\nA quartet ( d=4 ) corresponds to isospin I = 3/2 .\n\n\n\n7.3 Combining Representations: Higher Multiplets\nA natural question arises: if we only have two quarks (u and d) in an I=1/2 doublet, how do we get particles with higher isospin, like I=1 or I=3/2 ?\nThe answer is by combining quarks. When we build composite particles (like baryons and mesons) from multiple quarks, we must combine their individual isospins (and spins) to find the total isospin of the composite system. The rules for combining isospin are identical to the rules for combining angular momentum (spin).\nAngular Momentum Addition Rule: When combining two systems with spins j_1 and j_2 , the total spin j can take values: j = |j_1 - j_2|, \\, |j_1 - j_2| + 1, \\, \\dots, \\, j_1 + j_2\nThis is written as j_1 \\otimes j_2 = |j_1-j_2| \\oplus \\cdots \\oplus (j_1+j_2) .\nKey Examples:\n\nCombining two spin-1/2 particles (e.g., two quarks in an isospin doublet): \\frac{1}{2} \\otimes \\frac{1}{2} = 1 \\oplus 0\nThis yields a triplet ( I=1 , dimension 3) and a singlet ( I=0 , dimension 1).\nCombining spin-3 and spin-2: 3 \\otimes 2 = 1 \\oplus 2 \\oplus 3 \\oplus 4 \\oplus 5\n\nA powerful consistency check is that the total dimension must be conserved: \\text{Dim}(j_1) \\times \\text{Dim}(j_2) = \\sum_{j=|j_1-j_2|}^{j_1+j_2} \\text{Dim}(j)\nFor example, with j_1=3 (dimension 7) and j_2=2 (dimension 5): 7 \\times 5 = 35 , and 1+3+5+7+9+11 = 35 .\n\n\n\n\n\n\nGroup theory tells us that when we combine representations, the resulting higher-dimensional space breaks into blocks that do not mix under symmetry transformations (rotations in isospin or spin space). Each block corresponds to a distinct total spin/isospin value. This is why, for instance, a system with total spin 3 can never rotate into a state with total spin 4. ### Practical Application & Final Notes\n\n\n\n\n\n\n\n\n\nFigure 4: This figure illustrates the concept of angular momentum projection in quantum mechanics, specifically in the context of SU(2) symmetry, as used for both spin and isospin in particle physics. The arrow labeled “spin” represents the angular momentum vector \\vec{J} (or “spin”), while the slanted line labeled “projection axis” represents the quantization axis—customarily chosen as the z -axis for calculations. The diagram emphasizes how, for a system with total angular momentum J , only certain discrete projections M along the chosen axis are allowed ( M = -J, -J+1, ..., J ). This is a direct visualization of the concept behind the eigenstates |J\\, M\\rangle , with M being the quantum number corresponding to the component of \\vec{J} along the projection axis. This foundational idea underlies much of the spin algebra, angular momentum addition, and isospin formalism discussed throughout the lecture.\n\n\n\nBefore moving to practical combinations, let’s briefly introduce the concepts of parity and charge conjugation.\nCrucial Distinction: It is vital not to mix up isospin and spin.\n\nWe use isospin SU(2) when constructing the flavor wave function of quarks inside a hadron.\nWe use the rotational SU(2) (from the Lorentz group) when combining the intrinsic spin of particles to understand angular momentum and related dependencies.\n\nThe mathematical algebra and combination rules are identical for both; the only difference is the physical context in which they are applied."
  },
  {
    "objectID": "2024-Lecture-02.html#parity-charge-conjugation-and-excitations-of-the-λc-baryon",
    "href": "2024-Lecture-02.html#parity-charge-conjugation-and-excitations-of-the-λc-baryon",
    "title": "(2024) Lecture 2",
    "section": "8 Parity, Charge Conjugation, and Excitations of the Λc Baryon",
    "text": "8 Parity, Charge Conjugation, and Excitations of the Λc Baryon\nSo parity and charge conjugation quickly number 3, 4, 5. The parity operator is doing inversion. Both parity and charge conjugation are operators that act on a state and produce another state.\nThe parity operator \\hat{P} is space inversion with respect to the origin. Charge conjugation \\hat{C} is the operator flipping all charges, turning a particle into its antiparticle.\nAnswer the question: how do wave functions of the particle change when you flip the wave functions through the origin? It’s rather intuitive. You have a vector, you flip through the origin all of the spatial components, and you get the vector pointing in the opposite direction.\nFor any particle you can find out what its parity is. The parity acting on the state gives the eigenvalue. Since you act twice and get the same state—you do flip twice you get the initial configuration—the eigenvalue of this operator is modulus 1. By convention we say it’s real and then we say it’s plus or minus one, either +1 or -1 : \\hat{P} | \\psi \\rangle = \\pm | \\psi \\rangle .\nConnecting to the charge conjugation operator, acting on this state you get the same state if the particle or the wave function that you consider here is neutral, and for the charged one you get a different one. That’s what prime here stands for.\nFor any particle you can look up what its charge conjugation is, but not for every particle you find it. For every particle you can find parity. Let me give you the convention. Essentially, if the particle is the neutral one in the multiplet, the charge conjugation is the one that’s C is a member of the multiplet.\nSo the charge conjugation C of \\pi^+ or \\pi^0 is equal to—the Particle Data Group is the book that has a lot of information on all particles—would tell you these quantum numbers. For any particle you find the J^{PC} , which is the spin, total spin of the particle, parity, and charge conjugation.\nThink for all of them, for baryons, for the charged ones, for the neutral ones, you’ll find that J^{PC} is—spin is equal to 0, minus, plus 1—and for the \\pi^+ , \\pi^- you also find that charge conjugation is positive, but it’s not an eigenstate of the charge because acting with charge conjugation on \\pi^+ you get \\pi^- . Still we assign the charge conjugation. It’s convenient for many applications according to the charge conjugation of the neutral particle multiplet.\nIn order to find what are the charge conjugation, parity, and the spin, total spin for the combination of particles, you do the following:\n\nFirst you find the total J by doing the spin algebra.\nSecond, parity is multiplicative.\nThird, charge conjugation is multiplicative.\n\nFor L equals one, (-1)^L is the orbital angular momentum contribution to the parity that one has to add. The total parity for a composite system is P_{\\text{total}} = P_1 P_2 (-1)^L .\n\n\n\n\n\n\nKey Formulas for Composite Systems\n\nTotal Parity: P_{\\text{total}} = P_1 P_2 (-1)^L , where P_1 and P_2 are the intrinsic parities of the constituent particles and L is their orbital angular momentum.\nTotal Angular Momentum: \\mathbf{J} = \\mathbf{L} + \\mathbf{S}_1 + \\mathbf{S}_2 , obtained via vector addition of spins and orbital angular momentum.\nCharge Conjugation for Neutral Mesons: C = (-1)^{L+S} , where S is the total spin of the quark-antiquark pair.\n\n\n\n\nI would like to give an example before you stop because it’s one of the most important skills I would like you to have: to be able to determine what are possible combinations of the spin and parity when you combine two particles. I’m going to draw the table that would list J^{PC} , J^P .\nFor the uncharged fermions, there is no charge conjugation, so I won’t have charge conjugation here. So J^P , for the combination of particles I start following out with the orbital angular momentum equals zero. I just combine spin and charge. In that case I have 1/2 , I add a 0, I get only 1/2 . The charge is multiplicative. Parity is multiplicative.\nI go to the first row adding 1 unit of angular momentum L = 1 . Then I go to the second row by adding 2 and the parity follows from the rule of (-1)^L .\n\n\n\n\n\n\nFigure 5: This figure schematically represents the excitation spectrum of a quantum system—such as the hydrogen atom or a hadron—organized by total angular momentum quantum number J and energy E . The horizontal axis shows J , the total angular momentum, while the vertical axis represents energy levels E . Each box indicates a particular quantum state characterized by its principal and orbital quantum numbers (such as 1S, 2S, 1P, 1D ) along with superscripts labeling the total spin/parity combinations (e.g., 1/2^+ , 1^+ , 3/2^- , 5/2^+ ). The figure illustrates how states with different total angular momentum (arising from combinations of orbital angular momentum L , spin S , and their Clebsch-Gordan addition) appear at distinct energy levels. For instance, the 1S state ( J=1/2^+ ) lies at the lowest energy, the 2S state ( J=1/2^+ ) at a higher energy, and the 1P multiplet splits into J=1/2^- and J=3/2^- , with the 1D state further splitting into J=3/2^+ and J=5/2^+ . Physically, this diagram encodes the spin algebra and angular momentum addition rules discussed in the lecture. The vertical structure reflects how energy depends on the excitation (principal quantum number and angular momentum), and the splitting along the J -axis exemplifies how spin and orbital angular momentum combine according to SU(2) symmetry and group theoretical rules. This is crucial for understanding the spectrum of composite systems (like hadrons or atoms) and for deducing possible quantum numbers for excited states in experimental spectroscopy.\n\n\n\nI start with 0, I run the angular momentum, it will be minus, minus, plus. That’s pretty much the excitation spectrum for Lambda baryons. I look at the Lambda baryon in the quark model. In the quark model means that now I consider my heavy quarks. There are no gluons any longer; they all condensate. Then quarks are heavy. Among these quarks there is a charm quark that’s heavy and it’s not part of our symmetry. There is u and d from the flavor consideration of the group can be in isospin 1, or it could be in isospin 0. That’s how we combine the isospin. This is a flavor part of the group.\nThere is a symmetry that holds for baryons. Since they are the same particle, u and d , as we agreed, they have to be in symmetric combination. If they are in isospin zero, they are entered antisymmetrically. So isospin zero is minus sign here. That’s why the spin combination must from the spin. They also have to be in the spin zero to have overall antisymmetry.\nI’m mixing up overall wave function for the baryon. Since the fermions have to be antisymmetrical, there is a color wave function that we might discuss at one point; it gives a minus sign. There is the spin wave functions. As we found out for the eta and for the… So S wave is symmetric. I’m missing a minus sign somewhere. This is the right answer. I’m missing a minus sign somewhere.\nThe isospin wave function is there. Then spin wave functions would be good corresponds to that spin, spin zero of the u and d . And that’s what.\nNow we can consider how this baryon is excited. We discussed already that one way of making different particles out of this guy is to interchange U and D. But since the \\Lambda_c is isospin zero, there are no other particles in this multiplet. It’s only one \\Lambda_c .\nThe other way to make different particles out of the \\Lambda_c is to excite the system. You can excite it radially, like the hydrogen atom, to make the object bigger. You probably remember the hydrogen atom. There is an n quantum number, the principal quantum number that tells you how big the system is. Essentially, what are the orbitals of the electron. You can do the same for \\Lambda_c . You can have 1s, 2s, and so on.\nThis one will be the ground state \\Lambda_c . This next one will be an excited, bigger \\Lambda_c . You would call it \\Lambda_c^{**} . I think we found this one. It’s pretty broad.\nYou can excite the system orbitally, putting orbital angular momentum between, let’s say, the ud pair and the heavy center of this sigma. That would correspond to the orbital excitations. Then it gives these one P \\Lambda_c states. We have found what the quantum numbers of these are.\nLooking at this, this would be the ground state of \\Lambda_c . These two are orbital excitations. It’s important to realize that when we do excitation of the system, we obtain different particles.\nIf you look at the PDG, you will see the names that we know of. We have discovered in experiments around seven different \\Lambda_c ’s. So the ground one, these two guys, these two guys, and this one, I think six. Then there is one high-end spectrum that we don’t know which multiplet it belongs to. These are, although listed as different particles, sort of excitations of the ground state \\Lambda_c ."
  },
  {
    "objectID": "2024-Lecture-02.html#spin-algebra-and-decay-partial-waves",
    "href": "2024-Lecture-02.html#spin-algebra-and-decay-partial-waves",
    "title": "(2024) Lecture 2",
    "section": "9 Spin Algebra and Decay Partial Waves",
    "text": "9 Spin Algebra and Decay Partial Waves\nSuper important. Learn how to construct this table—essentially, how to do spin algebra.\n\n9.1 Constructing the S Wave and Angular Momentum Addition\nWe start by constructing the S wave, where the orbital angular momentum L = 0 . Using Clebsch-Gordan coefficients is straightforward here. Adding one unit of angular momentum is also straightforward, but you must be careful not to mix up the procedure.\n\n\n\n\n\n\nWhen combining two systems with angular momenta j_1 and j_2 , the total angular momentum j can take values: j = |j_1 - j_2|, |j_1 - j_2| + 1, \\dots, j_1 + j_2\nThis is the Clebsch-Gordan series, fundamental for constructing spin wavefunctions and determining allowed states.\n\n\n\nIf you are already in an orbital angular momentum zero combination—and there are only a few of them—you must consider them separately. One combination spans several states, and another will span several different states.\nThe same procedure applies when you want to combine angular momenta in a decay.\n\n\n9.2 Applying This to a Particle Decay\nConsider the decay of a particle A : A \\to B + C\nWe know the quantum numbers:\n\nParticle A is 0^+\nParticle B is a vector, 1^-\nParticle C is 2^-\n\nWe can ask: What is the orbital angular momentum L in this decay? The decay is analyzed in the rest frame of particle A . Particle B goes in one direction, particle C goes in the opposite direction, defining a relative angle.\n\n\n\n\n\n\nIn a decay A \\to B + C , parity is conserved: P_A = P_B \\, P_C \\, (-1)^L\nwhere (-1)^L is the parity of the orbital state.\n\n\n\nIf you combine the two final-state particles in an S wave ( L = 0 ), the possible total spin-parity J^P is only 1^- . In a P wave ( L = 1 ), the parity would be positive. To reach the 2^- state, you need a D wave ( L = 2 ).\nTherefore, the partial wave for this decay is a D wave. I hope we get to practice this calculation—it’s very important.\n\n\n9.3 A Practice Problem: Hydrogen Atom in a Magnetic Field\nLet’s work on a problem. We have a hydrogen atom placed in a strong magnetic field. The task is to determine the excitation spectrum.\nConsider the following energy levels: 1s , 2s , 2p , 3s , 3p , 3d .\n\n\n\n\n\n\nIn the hydrogen atom, the orbital angular momentum quantum number l is restricted by the principal quantum number n : l &lt; n\nThis is why, for n=3 , we have l = 0 (s), 1 (p), and 2 (d), but no f-wave ( l=3 ).\n\n\n\nWe will restrict ourselves to s, p, and d waves only, excluding the f-wave. This is a beautiful puzzle—you may have seen it before. It’s the same problem.\n\n\n\n\n\n\nIn a strong magnetic field (Paschen-Back regime), the energy shift for a state with quantum numbers n, l, m_l, m_s is approximately: \\Delta E = \\mu_B B \\, (m_l + 2m_s)\nwhere \\mu_B is the Bohr magneton, B is the field strength, m_l is the orbital magnetic quantum number, and m_s = \\pm 1/2 is the spin projection.\n\n\n\nThe skill of constructing and using the spin-algebra table is something we want to practice more. I think we’re done, except for this problem."
  },
  {
    "objectID": "2024-Lecture-03.html",
    "href": "2024-Lecture-03.html",
    "title": "(2024) Lecture 3",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-03.html#lecture-recording-and-isospin-review",
    "href": "2024-Lecture-03.html#lecture-recording-and-isospin-review",
    "title": "(2024) Lecture 3",
    "section": "1 Lecture Recording and Isospin Review",
    "text": "1 Lecture Recording and Isospin Review\nSo my experiment with recording lectures has been relatively successful, so I could recover what I was saying. There is an open large language model from OpenAI that can translate audio to text called Whisper. Since the architecture is known, there is a C implementation that even runs parallel on Mac. You just download and execute it, and then you have a transcript of your speech.\n\n\n\n\n\n\nI record the lecture for myself, but it might be converted to a document. If someone would volunteer to type the questions and the equations there and check them, that would be helpful. But I don’t know what to do with that. Just for fun and for exploring the technologies, I will keep the recordings. It records only me in the sense that it’s mostly me who speaks, so don’t hesitate to talk back because this will not appear in the recordings anyway.\n\n\n\nWe will talk today about structure functions, the structure of hadrons, their internal composition, and how we know about them. But before going there I would like to start with a recap and have a few questions.\nQuestion 1: Without looking at the PDG, just from the quark content, tell me the isospin of these particles. The quark content here is: c \\bar{s} , b \\bar{q} , b \\bar{s} , q \\bar{q} .\nQuestion 2: What is the dimensionality of the isospin matrix that acts in a space of three quarks? If I treat the quarks as a wave function in two dimensions where spin up corresponds to the u quark and spin down corresponds to the d quark, what is the dimensionality of the matrix that acts in this space?\nQuestion 3: What are the irreducible representations of this matrix acting on these quarks? Essentially, how does my matrix from the previous point split into independent blocks that don’t talk to each other?\nWhen we talk about isospin we talk about light quarks.\n\nThe first meson, c \\bar{s} , doesn’t have light quarks, so it has isospin I = 0 .\nThe B meson, b \\bar{q} , has one light quark and therefore we deal with I = \\frac{1}{2} . (Here, q means a light quark. Often people use notations: capital Q is a heavy quark, little q or l is a light quark.)\nThe b \\bar{s} meson: if you talk about SU(3) , it belongs to the light quarks. If you talk about isospin, s is not included. So again, one light quark means isospin is \\frac{1}{2} .\nNext, P_c , which is the pentaquark observed in J/\\psi p . If you speak generally about pentaquarks that have three light quarks, what is the isospin? That means it can have the same as the delta group. The three quarks are the same as the delta group. What is the isospin of \\Delta ? It is \\frac{3}{2} . It’s the length of the vector, not the projection.\n\nWhen we assign isospin to a particle, we don’t yet speak about the charge. Different charge versions of the particle form a multiplet. When we say the B meson has isospin \\frac{1}{2} , it implies there are two B mesons: B^+ ( b \\bar{u} ) and B^0 ( b \\bar{d} ). For the antiparticle doublet, you fully conjugate: \\bar{b} u is B^- and \\bar{b} d is \\bar{B^0} .\nNow, the cascade b has isospin \\frac{1}{2} . The dimensionality is 2I + 1 = 2 , so there are two particles of this type. The charges: u quark has charge +\\frac{2}{3} , d quark has charge -\\frac{1}{3} . When I combine three of the lower row like ddd , I get charge -1 . If I combine three of the upper one like uuu , I get charge +2 . For b \\bar{s} , the combination gives charge zero.\nNow we come to the last one which has three quarks, so there are several combinations. For isospin \\frac{1}{2} , the possibilities are P_c^+ and P_c^0 . For isospin \\frac{3}{2} , there are four particles in the multiplet, like for \\Delta^{++} .\n\n\n\n\n\n\nFor a particle with isospin I , the number of charge states is given by: \\text{Number of states} = 2I + 1 . This arises from the quantization of isospin in analogy with angular momentum.\n\n\n\nAn interesting question: what is the antiparticle for the P_c^+ ? For baryons especially, it’s important to distinguish baryon to anti-baryon. They have a different quark component. You put a bar under the quarks.\nLet’s go to the irreducible representation of the three quarks. We already have essentially the dimensionality of the isospin matrix acting on three quarks. How do you get to the P_c^+ and P_c^0 with isospin? We only talk about SU(2) . For SU(2) there are no decuplets; decuplets and octets are for SU(3) .\nIf you’re mixing uud , you can’t get I = \\frac{3}{2} because of the third component. There is the total isospin. The state uuu has I_3 = +\\frac{3}{2} . We also get I_3 = -\\frac{3}{2} , I_3 = +\\frac{1}{2} , and I_3 = -\\frac{1}{2} . We also have uud and ddu . In order to construct these, we are going to act with a lowering operator on the combination.\nWe expand. What we would like to do now is ask: what is the quark flavor wave function? To do that we need to construct the basis of the irreducible representations. The easiest way is to start with the state you know for sure, which is the maximum spin. For isospin, this is the I = \\frac{3}{2} state. I can talk about spin or flavor; the notation is equivalent.\nI would like to act with the isospin lowering operator I_- . What comes here is \\sqrt{j(j+1) - m(m-1)} . Since j = m here, it simplifies to \\sqrt{2j} . So, acting with I_- on |u u u\\rangle gives a combination. This operator is a sum where these operators act only in the space indicated by the index. So I write I_- = I_-^{(1)} + I_-^{(2)} + I_-^{(3)} .\n\n\n\n\n\n\nFor a state with total angular momentum j and projection m , the action of the lowering operator J_- is: J_- |j, m\\rangle = \\sqrt{j(j+1) - m(m-1)} \\, |j, m-1\\rangle\nThis is used to construct states with lower isospin or spin projections from the highest-weight state.\n\n\n\nTo ensure we are dealing with a normalized state |\\frac{3}{2}, \\frac{1}{2}\\rangle , we calculate the product with itself. You use the fact that \\langle u|d \\rangle = 0 and \\langle u|u \\rangle = \\langle d|d \\rangle = 1 . Same flavor is normalized and different flavors are orthogonal.\nWe’ve got that combination and we can follow by acting with more lowering operators. Essentially, that way you find the wave function. It is \\frac{1}{\\sqrt{6}}(2|uud\\rangle + 2|udu\\rangle + 2|duu\\rangle - |uud\\rangle' - ...) . It’s super easy with the highest spin.\nRemember we discussed last time the spin of \\frac{4}{2} . That gave us the dimensionality 2S + 1 = 5 . Imagine I want to build this from spin \\frac{1}{2} particles. How many spin \\frac{1}{2} particles do I need? Essentially, I have many legs. If I ask you to give me S = \\frac{3}{2} , you use the creation and apply the lowering operator many times. One can automate the process.\nIt gets trickier when I ask for \\frac{9}{2} . Out of this combination I can have different spins. We agreed that simple spin algebra works. Essentially, when I combine many spin \\frac{1}{2} particles, possible combinations of the total spin have different multiplicities. The dimensionality of the matrix that acts on this space is 2^n , because each spin \\frac{1}{2} gives a two-dimensional representation. This 2^n is written as a tensor product.\nWe use different notation that comes from \\frac{1}{2} \\otimes \\frac{1}{2} \\otimes ... . Last time we saw this can be decomposed into irreducible representations as different combinations of spins. For a large n , this is a huge number. But one of these numbers is the spin \\frac{n}{2} plus different spins. Constructing a specific state like |\\frac{n}{2}, \\frac{3}{2}\\rangle is more difficult.\nLet’s come back to reasonable numbers. I would like to continue with question number two: the dimensionality of the isospin matrix that acts on the space of three quarks. This is for the isospin group, the same as adding \\frac{1}{2} three times.\nEvery quark brings a doublet. When we talk about dimensionality, we count the basis vectors in the representation. For every product space, there are two basis vectors. To count how many basis vectors I have in the tensor product, I multiply the number of basis vectors. In the space of three quarks there are 2^3 = 8 basis functions. One of them is |u d u\\rangle . Another is |u u u\\rangle , a third is |d d u\\rangle , and so on.\nThe dimensionality of the isospin matrix that acts on this space is 8, so we have an 8 \\times 8 matrix. But we can arrange these combinations so they transform under isospin rotations together without talking to other combinations. That’s called splitting into irreducible representations by grouping the basis functions into multiplets.\nTo answer the last question, we do spin algebra: \\frac{1}{2} \\otimes \\frac{1}{2} \\otimes \\frac{1}{2} . We combine \\frac{1}{2} and \\frac{1}{2} , which gives 0 \\oplus 1 . Then we combine this result with another \\frac{1}{2} . We check the dimensionality: 2 \\times 2 \\times 2 = 8 . The decomposition is \\frac{3}{2} \\oplus \\frac{1}{2} \\oplus \\frac{1}{2} , with dimensions 4 + 2 + 2 = 8 . So our 8 \\times 8 matrix can be split into blocks of 2, 3, and 4 dimensions.\n\n\n\n\n\n\nThe tensor product of three I = \\frac{1}{2} representations decomposes into irreducible representations of SU(2) : \\frac{1}{2} \\otimes \\frac{1}{2} \\otimes \\frac{1}{2} = \\frac{3}{2} \\oplus \\frac{1}{2} \\oplus \\frac{1}{2}\nThe dimensions satisfy: 2 \\times 2 \\times 2 = 4 + 2 + 2 = 8 .\n\n\n\nIt’s super clear how to construct the basis for the highest isospin state. You start with |u u u\\rangle and act with lowering operators. But how to construct the others? I’ll follow this. The basis for I = \\frac{3}{2} has 4 states. For I = \\frac{1}{2} we’re going to have two states. The principle we use is simple: the vectors we build should be totally orthogonal to what we’ve built already.\nLooking at the available quark combinations with I_3 = \\frac{1}{2} , we can construct an orthogonal combination by putting different signs between them. For example, a combination like \\frac{1}{\\sqrt{2}}(|u u d\\rangle - |u d u\\rangle) . You ensure normalization by calculating the scalar product. To construct the basis function for I = \\frac{1}{2}, I_3 = -\\frac{1}{2} , take the upper one and act with a lowering operator.\nThat way you find the wave function is \\frac{1}{\\sqrt{6}}(|u d d\\rangle + |d u d\\rangle - 2|d d u\\rangle) . Now that we figured out that out of our eight states, the 8 \\times 8 matrix acting on them splits into a block of four, a block of two, and another block of two.\nI look at my representation. I have two basis vectors and I need to construct the third one that is orthogonal to both. Essentially, if I have vectors (1,1,1) and (1,-1,0) , the one orthogonal to both is something like (1,1,-2) . Therefore, the first one is |u d u\\rangle - |u u d\\rangle . The lower one I get by applying the lowering operator. It’s typical spin algebra.\nWith spins we have discussed, it works not only for half-integer spins but also for integer spins. When I combine two spins, I’m dealing with spin 1. Using spin algebra, what I can get ranges from lowest to highest. The lowest would be 0, the highest is 2. I check the dimensionality: 3 \\times 3 = 1 + 3 + 5 = 9 . I can start constructing the representation basis. I start with the easiest one, which is a vector.\nAgain, the lowering operator gives four combinations. For total spin S = 2 , the state is symmetric. For S = 1 , I need a vector orthogonal to that. I just put a minus sign. Be careful when you do this for realistic examples or homework; you have to use Clebsch-Gordan coefficients when you lower operators. Clebsch might appear different here and there.\nFor the basis, Clebsch are the same. It’s \\frac{1}{\\sqrt{2}} always. These are typical ladder operators. You can check in the SU(3) chapter. Let’s figure out this line. I want to construct two for my Y and write this as combinations. You can look at the Clebsch-Gordan table and find these coefficients; they appear to be \\frac{1}{\\sqrt{2}} .\nWe are not done with writing the flavor and spin wave functions, but I would consider this. It’s just a matter of practicing spin algebra. This comes in many courses: quantum mechanics, particle physics, and group theory. For SU(2) it’s simple spin algebra. You need to think about dimensionalities and how you add spin to each other, and know a few recipes to construct these coefficients.\nIn order to proceed and talk about structure functions, we need the proton wave function, because that’s where the understanding of the internal structure of hadrons comes from. In the homework there will be other questions related to the delta internal structure. It is easier to start with the delta wave function.\nWe start with the symmetries of the baryon wave function. We have to operate in four spaces: color, space, isospin, and spin. The baryon wave function has color indices and must be color neutral, as all hadrons are. We have a space wave function that describes distribution in x and t . We have to operate with isospin and spin.\nIt is important to realize they are not simply factorizable in the general case. The wave function lives in the product of the four spaces and can mix them. You need a sum of components. The color wave function is a singlet, meaning it’s a scalar. Therefore, the color wave function can be factored out. There is a good argument why the space wave function is a scalar and can be factored out as well. I am not convinced myself, but one should find the argument in the literature.\nWhat remains is spin and isospin, and these two do not factorize. That’s a large dimensional representation. We deal with baryons with three quarks, and every quark has a spin. Every quark is the product of flavor and spin. It’s a product of three quarks, so we deal with a basis in six dimensions. It’s the same thing as before.\nTo build the representation of particles in these six dimensions, we act with the lowering operator. Starting with something we know with no ambiguities: the delta, which has spin \\frac{3}{2} . When Delta has spin \\frac{3}{2} , the only combination is |u u u\\rangle . The \\Delta^{++} with J_z = +\\frac{3}{2} . \\Delta^+ with J_z = +\\frac{1}{2} is obtained by acting with a lowering operator in the spin space. If we act with the lowering operator in the flavor space, we reduce the charge and obtain a different particle.\nWe need to act twice with the lowering operator in flavor space and once in spin space to get \\Delta^0 and \\Delta^- . The proton appears to be a wave function that is orthogonal. The decomposition is \\frac{1}{2} \\otimes \\frac{1}{2} \\otimes \\frac{1}{2} = \\frac{3}{2} \\oplus \\frac{1}{2} \\oplus \\frac{1}{2} . This is 4 states plus 2 states plus 2 states. The proton is made of the same quarks as delta but has isospin \\frac{1}{2} and spin \\frac{1}{2} . Therefore, we need a wave function orthogonal in both spin and isospin spaces.\nWe are not going to do that because it’s technically complicated. What we will do is explore symmetry. The baryon wave function must be totally antisymmetric under quark exchange. This is a new symmetry not related to SU(2) directly. We now swap dimensions: take one particle with its spin and isospin and swap with another.\nWe have a basis function we constructed, and we can examine them to see if they have certain permutation symmetry. For most, there is no symmetry; they are not eigenstates of permutation. Let’s see what we demand from the function. The total \\Psi must be antisymmetric under permutation: \\Psi(1,2,3) = -\\Psi(2,1,3) .\nThe color wave function is antisymmetric. To see this, you need to see how it looks. Color is transformed under SU(3) . In three dimensions there are three colors. The representation of SU(3) is more complicated. There are decuplets and octets from combining three quarks: \\mathbf{3} \\otimes \\mathbf{3} \\otimes \\mathbf{3} = \\mathbf{1} \\oplus \\mathbf{8} \\oplus \\mathbf{8} \\oplus \\mathbf{10} . The dimensions match: 27 = 1 + 8 + 8 + 10 .\nThe singlet is \\mathbf{1} and its wave function can be constructed. It’s easiest to start with the highest weight state for the decuplet. For the components that have red, green, and blue, you need a totally antisymmetric combination: \\frac{1}{\\sqrt{6}}(|rgb\\rangle + |gbr\\rangle + |brg\\rangle - |rbg\\rangle - |grb\\rangle - |bgr\\rangle) . All even permutations have a plus sign, odd permutations a minus sign. The color wave function is antisymmetric; swapping two gives a minus sign.\nThe space wave function is symmetric for the ground state baryons. They are all in the simplest symmetric configuration. Therefore, the combined spin and isospin wave function must be symmetric.\nLet’s do an example. To construct a wave function for a proton, we combine isospin \\frac{1}{2} and spin \\frac{1}{2} . Let’s examine some basis functions. Is it symmetric under permutation? If I swap particles 1 and 2, the function changes; it doesn’t have a certain symmetry. However, it might be symmetric under permutation of quarks 2 and 3.\nWe construct a spin wave function that has symmetry only on the permutation of 2 and 3. The proton wave function can be guessed by combining symmetric flavor with symmetric spin. But the total wave function must be antisymmetric under any two-particle exchange. If we use just one term, that would be illegal. The wave function goes into another function.\nWhen we combine three quarks, we get the spin \\frac{3}{2} representation and two spin \\frac{1}{2} representations. If I apply the permutation operator to the \\frac{1}{2} multiplet, it mixes with the other \\frac{1}{2} multiplet. The permutation operator is external to the rotation group. Therefore, to construct the proton, we need both of the two-dimensional multiplets.\nThe delta lives in the \\frac{3}{2} multiplet. Applying a permutation stays within the same multiplet. But for the proton, it lives in a mixture of the two \\frac{1}{2} multiplets. One has to do the algebra to find the answer.\nThe proton wave function is a combination. I memorize these components. The proton spin-up wave function is a combination of terms like |u u d\\rangle , |u d u\\rangle , |d u u\\rangle with different spin orientations. The coefficients in the basis come from ensuring overall symmetry. The normalization comes by summing the squares of coefficients: 4 + 4 + 4 + 6 = 18 , so the normalization factor is \\frac{1}{\\sqrt{18}} .\n\n\n\n\n\n\nThe proton wave function (spin-up, isospin-up) is a combination of quark spin-flavor states, ensuring overall symmetry under exchange when combined with antisymmetric color and symmetric spatial parts. For example: |p \\uparrow\\rangle = \\frac{1}{\\sqrt{18}} \\left[ 2|u\\uparrow u\\uparrow d\\downarrow\\rangle + 2|u\\uparrow d\\downarrow u\\uparrow\\rangle + 2|d\\downarrow u\\uparrow u\\uparrow\\rangle - |u\\uparrow u\\downarrow d\\uparrow\\rangle - |u\\uparrow d\\uparrow u\\downarrow\\rangle - |d\\uparrow u\\uparrow u\\downarrow\\rangle - |u\\downarrow u\\uparrow d\\uparrow\\rangle - |u\\downarrow d\\uparrow u\\uparrow\\rangle - |d\\uparrow u\\downarrow u\\uparrow\\rangle \\right]\nThis reflects the mixed symmetry in spin and isospin spaces required by the Pauli exclusion principle.\n\n\n\nWe have the wave function of the proton. Now we can evaluate cool properties of the proton. That came as a surprise.\nNow, let’s discuss studies of structure. One way we experimentally probe structure is to use electron scattering. The simplest first question we can answer is: what is the charge distribution inside the hadron? That’s done with an electron probing the charge.\nWhen we scatter an electron off a hadron, almost all variables are fixed. The center-of-mass energy is fixed, and one variable remains: the scattering angle. Therefore, the experiment on structure functions is electron-proton scattering. We measure the angular distribution. From it, we get insights on the proton charge distribution and magnetic moment. That’s called a scattering experiment.\nIt’s important to realize we write many variables, like Q^2 (momentum transfer squared), but it’s all related to one angle. You need the probability for the electron to scatter. The kinematics in the lab frame: the electron collides with the proton, and the electron goes to some direction. This is simple two-body kinematics. The only variable is the angle.\nWhat’s the probability for the electron to scatter with almost no change in direction compared to going perpendicular? Rutherford scattering gives a term like 1/\\sin^4(\\theta/2) , a huge peak at zero angle. Most of the time, the electron prefers to go straight.\n\n\n\n\n\n\nFigure 1: This figure illustrates the difference between elastic and inelastic electron-proton scattering, key processes in probing the internal structure of hadrons discussed in the lecture. - The top two diagrams depict elastic scattering, where an incoming electron ( e ) scatters off a proton ( p ), and both emerge as the same particles ( e' , p' ) after the interaction. In elastic scattering, the proton remains intact, and the kinematics (like the scattering angle \\theta ) determine the momentum transfer Q^2 . The angular diagram shows the initial and final directions of electron and proton, emphasizing the one-variable (angle) dependence of such experiments. - The lower diagram shows inelastic scattering, where the electron scatters off the proton, but the proton breaks up, producing a set of hadrons denoted by X . This process allows the study of the proton’s internal structure by measuring how the energy and momentum are distributed among the outgoing particles. Inelastic electron-proton scattering leads to the extraction of structure functions F_1(x,Q^2) and F_2(x,Q^2) , which reveal information about the distribution and dynamics of quarks inside the proton. Together, these diagrams summarize how scattering experiments are used to access information about hadron structure: elastic scattering measures overall charge and magnetic form factors (related to the proton’s charge and magnetic moment distributions), while inelastic scattering provides evidence for point-like constituents (quarks) inside the proton through the observation of deep inelastic structure functions.\n\n\n\nThe deviation from that behavior tells us about structure. That process is elastic scattering, where initial and final particles are the same.\nIn contrast, inelastic scattering is where the proton is dissociated. In elastic scattering, the proton stays intact. In inelastic scattering, the final state is many particles X . The differential cross section for elastic scattering of point-like particles is d\\sigma/d\\Omega \\propto 1/\\sin^4(\\theta/2) . An example is electron-muon scattering.\nIn QED, you calculate diagrams. The matrix element is \\mathcal{M} = \\bar{u}_3 \\gamma^\\mu u_1 \\cdot (g_{\\mu\\nu}/Q^2) \\cdot \\bar{u}_4 \\gamma^\\nu u_2 . For this course, we analyze it generally. The matrix element is a scalar. It’s obtained by contracting different Lorentz structures. The spinor has four components, contracted by gamma matrices.\nThis is point-like scattering. When we deal with the proton, we extend the vertex function with form factors. The dimensionality of this object is a simple function of Q^2 . It is convenient to introduce a combination: the electric form factor G_E(Q^2) and magnetic form factor G_M(Q^2) . They both are functions of Q^2 .\nIn non-relativistic theory, there is a straightforward interpretation. Those factors show the charge distribution. Q is momentum. There is a transformation: Q^2 = -q^2 , so q is the three-momentum transfer. We can transform to coordinate space by Fourier transform. The charge density \\rho(r) is the Fourier transform of G_E(q^2) : \\rho(r) = \\int \\frac{d^3q}{(2\\pi)^3} e^{i \\vec{q} \\cdot \\vec{r}} G_E(q^2) .\n\n\n\n\n\n\nThe charge distribution \\rho(r) is obtained from the electric form factor via Fourier transform: \\rho(r) = \\int \\frac{d^3q}{(2\\pi)^3} e^{i \\vec{q} \\cdot \\vec{r}} G_E(q^2)\nThis relates the momentum-space form factor to the spatial charge density.\n\n\n\nWhen I put q = 0 , the Fourier transform gives the normalization. So the normalization of the form factors is fixed: G_E(0) = 1 (the proton charge), and G_M(0) = \\mu_p (the magnetic moment).\n\n\n\n\n\n\nFigure 2: This figure represents the basic Feynman diagram for elastic electron-proton scattering. An incoming electron ( e ) interacts with a proton ( p ) via the exchange of a virtual photon (the vertical line connecting the two). The diagram highlights one of the main experimental probes of proton internal structure discussed in the lecture. In this process, the electron scatters off the proton by exchanging a photon, allowing physicists to study the charge distribution and form factors ( G_E and G_M ) of the proton. The amplitude for this process is modified by the proton’s internal structure, which is encapsulated in the form factors. Measurement of the angular distribution of the outgoing electron in such experiments reveals information about the spatial distribution of charge and magnetization inside the proton, providing crucial evidence for the non-point-like, composite nature of hadrons as described by the quark model and confirmed by analyses of structure functions in deep inelastic scattering. The process depicted here is foundational for understanding the structure functions F_1 and F_2 , and their relationship to the proton’s internal constituents (quarks) and the necessity of introducing symmetry concepts like isospin and color.\n\n\n\nThe magnetic moment is a quantity that reacts in a magnetic field. It is proportional to the spin of the particle: \\vec{\\mu} = g \\frac{e}{2m} \\vec{S} . For a point-like Dirac fermion, g = 2 . For the electron, the magnetic moment is \\mu_e = \\frac{e}{2m_e} . The same for a muon.\nBut for the proton, it’s not. The proton has spin \\frac{1}{2} , charge +e , mass m_p . That relation is completely different. There is a correction due to internal structure. The magnetic moment can be measured by analyzing G_M at Q^2 = 0 . One finds it’s quite an amazing number: approximately 2.79, not 1. It’s a large correction.\nIt comes from the quark model and is easy to see if you analyze the proton wave function. What could have gone wrong in our naive consideration? We know the proton is made of quarks. How will the equation be modified? Instead of the proton charge, we should use the charges of quarks ( +\\frac{2}{3}e, -\\frac{1}{3}e ). Instead of the proton mass, we should use the masses of the quarks. The spin is the same.\nThe answer is a combination. When we analyze the magnetic moment, we see internal structure. Therefore, what we put as charge and mass in the naive model is not correct. This number can be obtained by looking at the wave function.\nLet’s act with the magnetic moment operator on the proton. The operator for a baryon is the sum of quark contributions: \\hat{\\mu} = \\sum_{i=1}^3 \\frac{q_i}{2m_i} \\vec{\\sigma}_i . Act on |u u d\\rangle . The u quark has charge +\\frac{2}{3}e and mass m_u , the d quark has charge -\\frac{1}{3}e and mass m_d .\nWhen you act with the \\mu_z operator, you get a number. Doing the algebra for the full proton wave function, you figure out that once you act this operator, you don’t get the proton wave function back. The proton is not an eigenstate of the individual quark magnetic moment operator. You have to take the expectation value.\nLet’s make it clear with the quark model. Assume m_u \\approx m_d \\approx 300 \\text{ MeV} , and m_p \\approx 1 \\text{ GeV} . The calculation yields \\mu_p = \\frac{e}{2m_u} \\cdot \\frac{3}{2} . Comparing to the naive expectation \\mu_p^{\\text{naive}} = \\frac{e}{2m_p} , we get a factor of \\frac{m_p}{m_u} \\approx 3 . So we’ve got a factor of about three.\nWe can compare this result: part of it is three. Cool. We managed to understand the anomalous magnetic moment of the proton. But basically, this number is the ratio equal to mass of proton over mass of quark? It just turns out to be like this because for the neutron, the answer is approximately -1.91. So the anomalous magnetic moment for neutron is -1.91, for proton it’s +2.79. It’s not simply a ratio of masses; it’s an algebra of the charges and masses together.\n\n\n\n\n\n\nThe magnetic moment operator for a baryon is the sum of the magnetic moments of its constituent quarks: \\hat{\\mu} = \\sum_{i=1}^3 \\frac{q_i}{2m_i} \\vec{\\sigma}_i\nFor the proton, using m_u \\approx m_d , the magnetic moment is: \\mu_p = \\frac{4}{3} \\mu_u - \\frac{1}{3} \\mu_d = \\frac{4}{3} \\cdot \\frac{2e}{3 \\cdot 2m_u} - \\frac{1}{3} \\cdot \\left(-\\frac{e}{3 \\cdot 2m_d}\\right) = \\frac{e}{2m_u} \\cdot \\frac{3}{2}\nThis yields \\mu_p \\approx 2.79 \\, \\mu_N , where \\mu_N = e/(2m_p) is the nuclear magneton.\n\n\n\nI found it amazing. Essentially, what we showed today, just knowing SU(2) and spin algebra, we can build the proton wave function. Using this function, we can figure out the magnetic moment—something that experimentally shows the proton is not a point-like particle. In the homework, we have an exercise for delta, which is relatively similar, as well as dealing with the magnetic moment operator for the delta particle."
  },
  {
    "objectID": "2024-Lecture-03.html#evidence-for-three-quarks-and-color",
    "href": "2024-Lecture-03.html#evidence-for-three-quarks-and-color",
    "title": "(2024) Lecture 3",
    "section": "2 Evidence for Three Quarks and Color",
    "text": "2 Evidence for Three Quarks and Color\nAnother interesting point is understanding that there are three parts inside a proton. This evidence comes from scattering experiments.\nFrom deep inelastic scattering, we observe the distribution of form factors. The cross section is described by structure functions F_1(x, Q^2) and F_2(x, Q^2) , which reveal the proton’s internal structure:\n\\frac{d^2\\sigma}{d\\Omega\\, dE'} = \\frac{\\alpha^2}{4E^2\\sin^4(\\theta/2)} \\left[ \\frac{F_2(x, Q^2)}{\\nu} \\cos^2(\\theta/2) + \\frac{2F_1(x, Q^2)}{M} \\sin^2(\\theta/2) \\right]\nHere, \\nu = E - E' is the energy transfer, \\theta is the scattering angle, M is the proton mass, and \\alpha is the fine-structure constant. The key observation was that F_2 scales with the Bjorken variable x = \\frac{Q^2}{2M\\nu} , which provided direct evidence for point-like constituents—quarks.\nSo, how do we arrive at three quarks in the proton? It’s not about three colors yet, but three quarks.\nThe quark model magnetic moment of the proton can be calculated from three constituent quarks (two up and one down):\n\\mu_p = \\frac{4}{3}\\mu_u - \\frac{1}{3}\\mu_d\nwhere \\mu_u and \\mu_d are the magnetic moments of the up and down quarks. Explicitly, this is approximately:\n\\mu_\\text{proton} \\approx \\frac{2}{3} \\frac{2}{3 m_u} + \\frac{1}{3} \\frac{1}{3 m_d} + \\frac{1}{3} \\frac{1}{3 m_u}\nThis magnetic moment calculation was an early piece of evidence for three quarks, though the exact historical observable might be debated.\n\n\n\n\n\n\nThe Gell-Mann–Okubo mass formula from the Eightfold Way provided further evidence for quark organization. It relates the masses of hadrons within an SU(3) flavor multiplet: M = M_0 + aY + b\\left[ I(I+1) - \\frac{1}{4}Y^2 \\right]\nwhere M_0 is a base mass, Y is the hypercharge, and I is the isospin. This successful classification of mesons and baryons into octets and decuplets suggested an underlying three-quark structure.\n\n\n\nWhy does the model require exactly three quarks? This connects to the concept of color charge. The requirement for a totally antisymmetric baryon wavefunction under quark exchange forces the introduction of a new quantum number: color.\nThe total wavefunction is a product:\n\\Psi_{\\text{total}} = \\psi_{\\text{space}} \\otimes \\psi_{\\text{spin}} \\otimes \\psi_{\\text{flavor}} \\otimes \\psi_{\\text{color}}\nThe color part \\psi_{\\text{color}} must be the antisymmetric singlet state:\n\\psi_{\\text{color}} = \\frac{1}{\\sqrt{6}} \\left( RGB - RBG + BRG - BGR + GBR - GRB \\right)\nThis ensures the total wavefunction obeys \\Psi_{123} = -\\Psi_{213} under particle permutation, satisfying the Pauli exclusion principle for identical quarks. So, the need for three colors arose from spectroscopy and symmetry, not directly from the early scattering experiments, which at the time were not precise enough to reveal color."
  },
  {
    "objectID": "2024-Lecture-04.html",
    "href": "2024-Lecture-04.html",
    "title": "(2024) Lecture 4",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-04.html#computing-the-omega-baryon-magnetic-moment",
    "href": "2024-Lecture-04.html#computing-the-omega-baryon-magnetic-moment",
    "title": "(2024) Lecture 4",
    "section": "1 Computing the Omega Baryon Magnetic Moment",
    "text": "1 Computing the Omega Baryon Magnetic Moment\nToday’s lecture is dedicated to the experiments in spectroscopy and the computations of the kinematics for the experiments. But before going there, I would like to have a short recap of the last lecture and to pose two questions.\n\nCompute the magnetic moment in the current model of the Omega baryon.\nCompute the lowest 1s multiplet excitation multiplet of the Sigma particle parameter. This is essentially asking about isospin fermions.\n\nLet’s address the first question quickly because it’s rather straightforward.\n\n1.1 Calculating the Magnetic Moment of the Omega Baryon\nWhat is the quark content of the Omega baryon (Ω⁻)? It consists of three strange quarks (sss).\nThe total wave function lives in the tensor product space of color, flavor (isospin), and spin coordinates. For this magnetic moment calculation, we focus on the spin part, as the flavor part is trivial for three identical strange quarks.\nThe Omega baryon has spin J = 3/2 and positive parity. To calculate its magnetic moment, we use the maximal spin projection state, |s↑ s↑ s↑ \\rangle , where all three quark spins are aligned up.\n\n\n\n\n\n\nYou don’t need to use complicated spin configurations. For calculating the magnetic moment, you can simply take the state with the highest value of spin projection ( m_s = +3/2 ). Acting on this state with the magnetic moment operator yields an eigenvalue directly.\n\n\n\nThe total magnetic moment operator for the baryon is the sum of the magnetic moment operators for its constituent quarks: \\hat{\\mu}_z = \\sum_{i=1}^{3} \\hat{\\mu}_{i,z} = \\sum_{i=1}^{3} \\frac{e q_i}{2 m_i} \\sigma_z^{(i)}\nwhere for a strange quark, the charge q_s = -\\frac{1}{3}e and its mass m_s \\approx 500 \\text{ MeV} .\nSince all three quarks are identical, the magnetic moment of the Omega baryon is simply three times the magnetic moment of a single strange quark in this fully aligned state: \\mu_{\\Omega^-} = 3 \\cdot \\mu_s = 3 \\cdot \\left( \\frac{e q_s}{2 m_s} \\right)\nSubstituting q_s gives: \\mu_{\\Omega^-} = \\frac{e}{2 m_s} \\cdot (3 \\cdot (-\\frac{1}{3})) = -\\frac{e}{2 m_s}\nIn absolute terms, |\\mu_{\\Omega^-}| = \\frac{e}{2 m_s} .\n\n\n1.2 Interpretation and Scale\nOur intuition is correct: the magnetic moment is negative because the Omega baryon has a net negative charge. However, the mass in the denominator is the constituent quark mass (roughly 500 MeV), not the mass of the Omega baryon itself (about 1672 MeV).\nHow does this compare to an electron? The electron’s magnetic moment is \\mu_e = \\frac{e}{2 m_e} , with m_e \\approx 0.5 \\text{ MeV} . The ratio is: \\frac{|\\mu_{\\Omega^-}|}{\\mu_e} = \\frac{m_e}{m_s} \\approx \\frac{0.5}{500} = 10^{-3}\nThis shows the Omega baryon’s magnetic moment is about one thousand times smaller than the electron’s, due to the much larger mass scale of the strange quark.\nKey Lesson: With a simple, symmetric wave function, the evaluation is straightforward. You take the maximal projection state, apply the magnetic moment operator, and collect the contributions."
  },
  {
    "objectID": "2024-Lecture-04.html#excitation-pattern-of-the-σ_b-baryon",
    "href": "2024-Lecture-04.html#excitation-pattern-of-the-σ_b-baryon",
    "title": "(2024) Lecture 4",
    "section": "2 Excitation Pattern of the Σ_b Baryon",
    "text": "2 Excitation Pattern of the Σ_b Baryon\nNow, question number two is the excitation pattern of the \\Sigma_b baryon.\nI gave you a hint that the ground state of the \\Sigma_b baryon has the light diquark in the configuration with isospin I=1 and spin 1/2^+ .\nA bonus question is the isospin pattern: the partners of this baryon that one gets simply from isospin. You see that isospin equals 1. It immediately tells you the multiplicity of the isospin multiplet.\nHow many charge partners am I going to get for this baryon? Since isospin is one, there are three different projections, three different quantizations: I_3 = +1 , 0 , and -1 .\nWhat are the charges? I’m going to get \\Sigma_b^+ (uub), \\Sigma_b^0 (udb), and \\Sigma_b^- (ddb). Two up quarks and one bottom quark is like a proton, it has a charge of +1 . Once I act with a spin lowering operator, I reduce the charge by one unit. So this number tells you immediately how many particles and what their charges are. It is super simple.\n\n\n\n\n\n\nThe charges for the \\Sigma_b isospin triplet ( I=1 ) can be determined from the quark content or the Gell-Mann–Nishijima formula, Q = I_3 + Y/2 , where the hypercharge Y=1 . This gives:\n\nI_3 = +1 → Q = +1 ( \\Sigma_b^+ , uub)\nI_3 = 0 → Q = 0 ( \\Sigma_b^0 , udb)\nI_3 = -1 → Q = -1 ( \\Sigma_b^- , ddb)\n\n\n\n\nIn order to find the excitation pattern you need to work with spin, not with isospin. All three families are related by isospin, therefore their properties are going to be almost the same. Isospin is broken by different quark masses, but this breaking is tiny. I can talk about any of these three, and for all of them, the ladder of excitations is going to be the same.\nLet’s now pick one of them, put it as the lowest state as usual. For the diagram of the excitation pattern, we draw on the x-axis different quantum numbers, often the orbital angular momentum L . On the y-axis we put the energy or the rest mass of the state, which is the same as the mass of the hadron.\nTo obtain that, I start by combining the spins of the light quarks and the heavy quark.\n\n\n\n\n\n\nFigure 1: This figure schematically illustrates the excitation pattern of the \\Sigma_b baryon in terms of its quantum numbers and mass splittings, as discussed in the lecture. On the vertical axis is the energy or mass of the hadron (labeled “mass of hadron”), while the horizontal axis represents the orbital angular momentum L  of the system. - The lowest block at L=0 (S-wave) corresponds to the ground state multiplet of the \\Sigma_b , specifically the J^P=1/2^+ and J^P=3/2^+ states, arising from combining the light diquark spin ( s_\\ell = 1 ) with the heavy quark spin ( s_Q = 1/2 ). - The “radial excitation” arrow, labeled as approximately \\Lambda_{\\text{QCD}} , represents the energy gap between different principal quantum numbers (radial excitations), reflecting the typical QCD scale for hadronic structure. - The higher-lying blocks at L=1 (P-wave) display the P-wave excitation multiplet, with five total states corresponding to the possible combinations of spins and orbital motions: specifically, J^P=1/2^-, 3/2^- (from S=1/2 ) and J^P=1/2^-, 3/2^-, 5/2^- (from S=3/2 ). - The vertical separations correspond to mass splittings between S-wave and P-wave states (dominated by orbital excitation energy, of order \\Lambda_{\\text{QCD}} ), while the smaller splittings within each block are due to hyperfine interactions (suppressed by 1/m_Q for the heavy quark). - This diagram captures the overall structure of the baryon spectrum, encoding both the quantum number assignments and the physical energy scales discussed in the lectures on spectroscopy and multiplet structure.\n\n\n\nFor most hadrons, except the light meson sector, the radial excitation from 1s to 2s orbitals is much higher than the hyperfine splitting. Once you deal with heavy quarks, this is always true.\nThe energy difference from combining the spin of the heavy quark and the spin of the light quark comes with a suppression factor, 1/m_Q . When you combine the light diquark, which has spin s_\\ell=1 , and the heavy quark of spin s_Q=1/2 , for the S-wave you get two total spin combinations: J=1/2 and J=3/2 .\nGround State (S-wave) Multiplicity:\n\nCoupling s_\\ell = 1 and s_Q = 1/2 gives: J = \\frac{1}{2}, \\frac{3}{2} .\nParity is positive for S-wave states.\nThis yields the ground-state doublet: \\Sigma_b (J^P = 1/2^+) and \\Sigma_b^* (J^P = 3/2^+) .\n\nIf I want to calculate the multiplicity of states after adding one unit of orbital angular momentum, I have to consider both possibilities separately and do the spin algebra. For the P-wave ( L=1 ), combining with S=1/2 gives J^P = 1/2^-, 3/2^- . Combining with S=3/2 gives J^P = 1/2^-, 3/2^-, 5/2^- .\nP-wave ( L=1 ) Multiplicity:\n\nFor S = 1/2 : J^P = \\frac{1}{2}^-, \\frac{3}{2}^-\nFor S = 3/2 : J^P = \\frac{1}{2}^-, \\frac{3}{2}^-, \\frac{5}{2}^-\nTotal: Five distinct P-wave states (negative parity).\n\nThe multiplicity for the P-wave block is five. The multiplicity for the S-wave orbital is two. The lowest state is 1/2^+ and 3/2^+ . Then there are five states in the P-wave. That is what we call the excitation pattern.\nAll of these lines are different particles you find in the PDG. I don’t think the 2004 PDG had even the next one, because it was discovered recently. The \\Sigma_b^* entered there roughly 10 years ago. This was a discovery of the colliders.\nNow one word about energy splitting. The energy splitting between the S-wave and P-wave states is caused by the orbital excitation, with a scale given by quark dynamics of order \\Lambda_{\\text{QCD}} , roughly a few hundred MeV. That gives the elevation of the different blocks.\nWithin a block, the splitting between levels comes from the dynamics of the heavy quark spin. This splitting is suppressed inversely proportional to its mass, \\Delta E_{\\text{hyperfine}} \\sim \\kappa/m_Q . In the Lagrangian of effective theories, the spin-orbit interaction enters as a term like (C/m_Q) \\vec{S}_Q \\cdot \\vec{S}_\\ell .\nThe mass of the b quark is about 4 GeV. \\Lambda_{\\text{QCD}} is a few hundred MeV. The ratio between them is roughly 1:10. That is the difference between the orbital excitation energies and the hyperfine splittings within a multiplet.\nI think that if I remember correctly, the energy difference between \\Sigma_b with spin 3/2 and \\Sigma_b with spin 1/2 is on the order of 10 MeV."
  },
  {
    "objectID": "2024-Lecture-04.html#the-puzzle-of-exotic-hadrons",
    "href": "2024-Lecture-04.html#the-puzzle-of-exotic-hadrons",
    "title": "(2024) Lecture 4",
    "section": "3 The Puzzle of Exotic Hadrons",
    "text": "3 The Puzzle of Exotic Hadrons\nToday’s lecture is dedicated to kinematics and experimental techniques.\nI would like to start by overviewing what we do in physics on the experimental side. The direction of hadron spectroscopy has been extremely vibrant and fruitful in the last 10 years. It started around 2004, where it became a prominent and trending topic with the first observations of exotic particles.\nSince then, every few months, there would be new observations of hadrons that do not fit the simple quark model of mesons and baryons. Many experiments have since dedicated part of their programs to study these exotic hadrons.\nAcross the world, several large labs study particle collisions. One of the central, puzzling questions is to understand the very fabric of matter: how hadrons form, which combinations are possible, and what rules determine their excitation patterns and properties.\nWe have a quantum theory of strong interactions—Quantum Chromodynamics (QCD)—which seems to describe these interactions well. However, there has been no success in classifying and predicting large multiplets of exotic hadrons from first principles. We observe something and would like to predict its properties, but we cannot. This is due to:\n\nLimitations in our computational methods (e.g., Lattice QCD works well for ground states but not yet for excited states).\nThe intrinsic complexity of the theory itself.\n\nThere are many emerging phenomena. You can look at the QCD Lagrangian and see quarks and gluons, but these are not the direct degrees of freedom for describing hadrons. We seem to be facing a transition in the description of matter: from configurations where quark degrees of freedom are important, to configurations where hadrons themselves become the important degrees of freedom, binding together to form hadronic atoms or molecules.\nIn hadron spectroscopy, you face this borderline. You have a mixture of:\n\nCompact hadrons made of elementary quarks.\nLarger, sparse objects where hadrons bind into bigger entities (e.g., \\text{Hadron}_1 + \\text{Hadron}_2 \\rightarrow \\text{Molecule} ).\n\nSome hadrons are complicated exactly for this reason—they are in a mixed state of different configurations. Some properties require it to be a compact hadron, while others require it to be a sparse hadronic molecule. This is the area where, at the current stage, lattice QCD cannot help very much.\nExperiments around the world provide new data and insight. The way we understand this is by measuring the properties of hadrons and their decays. We want to:\n\nObserve hadrons in new decay configurations.\nMeasure the same hadron from different production mechanisms.\n\nMany labs explore these different mechanisms:\n\nExperiments like Belle (Japan) and BESIII (China) collide leptons (electrons and positrons). They annihilate to produce an intermediate state that decays. A typical reaction is: e^+ + e^- \\rightarrow \\psi \\rightarrow \\text{hadrons}, \\quad \\sqrt{s} \\sim 2 - 4 \\, \\text{GeV}\nThe study happens by analyzing these decay products.\nColliders at CERN, like the LHC, explore different mechanisms by colliding protons (large energetic conglomerates of quarks and gluons). This produces many particles, including long-lived particles with heavy quarks like B and D mesons.\n\nThese heavy mesons live long enough to travel a measurable distance, providing a clean environment to study hadrons. A B or D meson is produced, flies a few millimeters, and we track this with our detectors. We can then distinguish the primary vertex from the secondary decay vertex.\n\n\n\n\n\n\nKey Experimental Formulas The analysis in these experiments relies on fundamental kinematic formulas:\n\nRelativistic Energy-Momentum: E^2 = p^2 c^2 + m^2 c^4\nInvariant Mass: Used to reconstruct particle masses from decay products. M_{\\text{inv}}^2 = \\left( \\sum_i E_i \\right)^2 - \\left( \\sum_i \\vec{p}_i \\right)^2 c^2\nDecay Width & Lifetime: \\Gamma = \\hbar / \\tau\nResonance Cross-Section: Described by a Breit-Wigner form, \\sigma(E) \\propto 1/[(E - M)^2 + \\Gamma^2/4] , crucial for identifying short-lived exotic states."
  },
  {
    "objectID": "2024-Lecture-04.html#hadron-production-and-spectroscopy-experiments",
    "href": "2024-Lecture-04.html#hadron-production-and-spectroscopy-experiments",
    "title": "(2024) Lecture 4",
    "section": "4 Hadron Production and Spectroscopy Experiments",
    "text": "4 Hadron Production and Spectroscopy Experiments\nAnother class of experiments uses hadronic production. Essentially, shooting a hadron at a hadron without aiming to describe the kinematics exclusively. Those are mostly fixed-target experiments.\nI will be talking about the GlueX experiment at Jefferson Lab that has a photon beam, and the COMPASS experiment at CERN that has a pion beam. They both use a hydrogen target. The proton in the target and whatever particle comes in gets excited or scatters off the target.\n\n\n\n\n\n\nFigure 2: This figure schematically represents a generic hadronic collision in which two incoming particles interact and produce a multiparticle final state. The arrows entering the central blob on the left signify two incoming particles (such as protons, pions, photons, or leptons) participating in the collision. The arrows exiting on the right denote the production of several outgoing hadrons (“h” stands for a generic hadron), which may include resonances or decay products. In the context of this lecture, this diagram illustrates the general ** 2 \\to n process** central to experiments in hadron spectroscopy. Such processes underpin both inclusive and exclusive production mechanisms discussed above—for example, proton-proton collisions at the LHC, photon-proton collisions at GlueX, or e^+e^- annihilation at Belle and BES experiments. The central region represents the strong interaction dynamics, where the initial particles interact via Quantum Chromodynamics (QCD) to create various possible hadronic final states. Physically, this encapsulates the need to analyze multi-particle final states using Lorentz invariant phase space, mass-shell constraints, and energy-momentum conservation, as described in the kinematics section of the lecture. The schematic is a universal representation of the kind of events for which one computes invariant masses, studies resonance production, and counts independent kinematic variables.\n\n\n\nThat’s another way to study hadrons, by using different production mechanisms.\nI would say the third major way to study hadrons is to compute their properties from lattice QCD. That’s where a large piece of information comes from.\nLet’s overview the production mechanism and experiments. We start with BES.\n\nThe BES experiment (Beijing Spectrometer) is located at the BEPC (Beijing Electron Positron Collider) accelerator complex.\nIt collides electrons and positrons and is dedicated to studying hadrons in the Charmonium and Tau energy regions.\nIt is a symmetric collider; the electron has the same energy as the positron.\n\n\n\n\n\n\n\nFigure 3: This diagram represents the process of electron-positron ( e^+e^- ) annihilation and the subsequent production of hadrons in a collider experiment such as BESIII or Belle II. In this physical context, an electron ( e^- ) and a positron ( e^+ ) collide head-on, annihilate at the interaction point, and produce a virtual intermediate state—typically a photon or a vector meson with quantum numbers J^{PC} = 1^{--} . This intermediate state then decays into multiple hadrons, shown here as several arrows radiating from the interaction point. The image encodes the experimental environment where all produced hadrons fly out from the collision vertex and are detected. This is central to studies in hadron spectroscopy, where the kinematics and invariant mass distributions of the outgoing hadrons are analyzed to identify hadron resonances, determine their properties, and scan for new or exotic states. This mechanism serves as the basis for resonance production, allowing experiments to reconstruct resonance peaks and study the strong interaction via the analysis of the final-state hadrons.\n\n\n\nWhen the two particles collide, one interaction possibility is annihilation. The electron and positron produce a virtual photon that then couples to a hadron.\n\n\n\n\n\n\nQuantum Number Selection Rule In relativistic e^+ e^- collisions, the initial state quantum numbers restrict the produced virtual photon.\n\n\n\n\n\n\n\n\n\nFigure 4: This diagram depicts the fundamental process of hadron production in an electron-positron ( e^+ e^- ) collider experiment as described in the lecture. An electron ( e^- ) and a positron ( e^+ ) annihilate, producing a virtual photon ( \\gamma ). This virtual photon then couples to a hadronic resonance, specifically the J/\\psi meson, which has quantum numbers J^{PC} = 1^{--} , consistent with the selection rules discussed. The J/\\psi resonance subsequently decays into three pions: a positive pion ( \\pi^+ ), a negative pion ( \\pi^- ), and a neutral pion ( \\pi^0 ). In the context of the lecture, this process illustrates how e^+ e^- annihilation at experiments like BES or Belle/Belle II can be used to study hadron spectroscopy, especially by observing exclusive decay final states of vector mesons (like J/\\psi ) into lighter mesons. The depicted reaction is a clear example of both the initial state quantum number selection (only 1^{--} states can be directly produced) and the analysis of exclusive decays in spectroscopy experiments. The decay products ( \\pi^+ , \\pi^- , and \\pi^0 ) can be reconstructed to study the properties and dynamics of the J/\\psi resonance via invariant mass techniques and Dalitz plot analysis as highlighted in the lecture.\n\n\n\nCombining the spins and parities of the electron ( 1/2^- ) and positron ( 1/2^+ ) in an S-wave results in quantum numbers J^{PC} = 1^{--} . This means only hadronic resonances with J^{PC} = 1^{--}  (like the J/\\psi or \\psi(2S) ) can be directly produced in e^+ e^- annihilation.\n\n\n\n\n\n\nFigure 5: This figure schematically represents the total cross section \\sigma_{e^+e^- \\to X} measured as a function of the center-of-mass energy \\sqrt{s} in electron-positron annihilation experiments, such as those conducted at BES or Belle II. The vertical axis shows the cross section for producing hadronic final states X in e^+e^- collisions, while the horizontal axis is the center-of-mass energy, marked at characteristic values (e.g., 2 GeV, 4 GeV). The sharp peaks and structures correspond to the production of intermediate resonances, such as the J/\\psi and its excitations ( \\psi(2S) , etc.), which have J^{PC}=1^{--} and couple directly to the virtual photon in e^+e^- annihilation. The decomposition \\sigma_\\text{full} = \\sigma_{3\\pi} + \\sigma_{2D} + \\dots at the top indicates that the total cross section is the sum over exclusive cross sections for different final states. This plot physically illustrates how the hadronic production rate varies with \\sqrt{s} , highlighting resonance peaks where particle production is enhanced due to the formation of specific quark-antiquark bound states (quarkonia), a central method in hadron spectroscopy.\n\n\n\nTherefore, the BES experiment explores hadrons with the quantum numbers 1^{--} .\nThe experiment operates in two main modes:\n\nResonance Peak Data Taking: They set the beam energy to sit directly on a resonance peak (e.g., the J/\\psi ) and collect enormous amounts of data on its production and decays.\nEnergy Scan: They vary the beam energy point-by-point to measure the cross section \\sigma_{\\text{total}} as a function of center-of-mass energy \\sqrt{s} .\n\n\\sigma(e^+ e^- \\to R \\to \\text{hadrons}) \\propto \\frac{\\Gamma_{e^+ e^-} \\Gamma_{\\text{total}}}{(s - M_R^2)^2 + M_R^2 \\Gamma_{\\text{total}}^2}\nThe cross section is not homogeneous; it shows peaking structures (resonances) where the probability of interaction is higher. Researchers then analyze specific final states (like \\pi^+\\pi^- or 3\\pi ) from these data sets to extract hadron properties.\nThe Belle II experiment in Japan also uses an electron-positron collider (the SuperKEKB accelerator). Its primary goal was to study B mesons and CP violation, but its data is extremely valuable for hadron spectroscopy.\nIn contrast to symmetric colliders like BES, Belle II is an asymmetric collider. The electron and positron beams have different energies.\n\n\n\n\n\n\nFigure 6: This figure illustrates the production mechanism at the Belle II experiment, an asymmetric electron-positron collider. An electron beam with an energy of approximately 7 GeV collides with a positron beam of about 4.6 GeV. The collision center-of-mass energy is tuned to \\sqrt{s} \\approx 10.58\\,\\text{GeV} , which matches the mass of the \\Upsilon(4S) resonance (a bottomonium state with quantum numbers J^{PC} = 1^{--} ). The \\Upsilon(4S) then decays predominantly into a pair of B mesons ( B\\bar{B} ). The asymmetric beam energies provide a net boost to the produced B mesons, causing them to travel a measurable distance before decaying—this is essential for identifying secondary decay vertices. This process is a central feature of experimental techniques in hadron spectroscopy described in the lecture, specifically highlighting how asymmetric colliders like Belle II facilitate the study of B mesons through precise vertex separation and kinematic reconstruction.\n\n\n\n\nFor symmetric colliders: \\sqrt{s} = 2E\nFor asymmetric colliders: \\sqrt{s} = 2\\sqrt{E_- E_+}\n\nBelle II operates at a center-of-mass energy tuned to the \\Upsilon(4S) resonance mass ( \\sqrt{s} = 10.58 \\text{ GeV} ), which primarily decays to a B\\bar{B} pair.\n\n\n\n\n\n\nPurpose of the Asymmetric Design The energy asymmetry ( E_- \\neq E_+ ) creates a boost of the entire center-of-mass frame along the beam axis. \\beta_{\\text{CM}} = \\frac{|E_- - E_+|}{E_- + E_+}, \\quad \\gamma_{\\text{CM}} = \\frac{E_- + E_+}{\\sqrt{s}}\nThis boost gives the produced B mesons significant longitudinal momentum. As a result, they travel a longer, measurable distance ( L_{\\text{lab}} = \\gamma_{\\text{CM}} \\beta_{\\text{CM}} c \\tau ) from the primary interaction vertex before decaying. This secondary vertex separation is crucial for identifying and studying the short-lived B mesons.\n\n\n\nLet’s return to the spectrum. The J/\\psi is the first charmonium state discovered and appears as a clear peak in the e^+ e^- cross section. It is a 1^{--} state.\nThe charmonium spectrum is organized into multiplets based on radial ( n ) and orbital ( L ) excitations:\n\nThe lowest 1^{--} state is the J/\\psi(1S) .\nIts radial excitation is the \\psi(2S) .\nThe lowest state in the 1S multiplet is the \\eta_c(1S) ( 0^{-+} ).\nThe P-wave multiplet ( L=1 ) consists of the \\chi_{cJ} states: \\chi_{c0} ( 0^{++} ), \\chi_{c1} ( 1^{++} ), and \\chi_{c2} ( 2^{++} ).\n\nThe mass splittings within these multiplets arise from the detailed interactions in the quark model, including spin-spin and spin-orbit terms."
  },
  {
    "objectID": "2024-Lecture-04.html#from-charmonium-to-bottomonium-and-lhc-multiplicities",
    "href": "2024-Lecture-04.html#from-charmonium-to-bottomonium-and-lhc-multiplicities",
    "title": "(2024) Lecture 4",
    "section": "5 From Charmonium to Bottomonium and LHC Multiplicities",
    "text": "5 From Charmonium to Bottomonium and LHC Multiplicities\nTo reconstruct the schematics before we move away from Belle II, let me relate to what we just said before.\nEssentially it’s the same process: e^+e^- annihilation. So it’s a total cross section \\sigma(e^+e^- \\to \\text{everything}) .\n\n5.1 Quarkonium Spectroscopy: Charmonium to Bottomonium\nThe Belle experiment operated at energies covering the J/\\psi and the \\tau production threshold. Belle II operates in the region of bottomonium—the family of hadrons made of b\\bar{b} quarks, analogous to charmonium ( c\\bar{c} ).\n\nThe energy scale moves from ~3 GeV (KEK) to the ~10 GeV region.\nThe bottomonium system is very similar to charmonium, but the b quark is heavier.\nThis leads to a smaller hyperfine splitting between states. The mass difference is given by: \\Delta M_{\\text{hfs}} = M(1^{--}) - M(0^{-+})\nWhile the scale between major energy levels is still roughly a few hundred MeV, the states within each level are much more condensed in energy.\n\nThe new symbol here is upsilon ( \\Upsilon ). This is the vector particle (spin 1, quantum numbers 1^{--} ), making it the cousin of the J/\\psi .\n\nThe J/\\psi is the easiest charmonium particle to produce in e^+e^- annihilation due to its 1^{--} quantum numbers.\nIts counterpart in the bottomonium spectrum is the \\Upsilon .\nWhen scanning the energy, the states appear sequentially: \\Upsilon(1S) , \\Upsilon(2S) , \\Upsilon(3S) , \\Upsilon(4S) .\nThe \\Upsilon(4S) is notable because all these states are above the production threshold for b quarks (~9.46 GeV for the \\Upsilon(1S) ). ### Contrast with Hadron Colliders: The LHC Environment\n\n\n\n\n\n\n\nFigure 7: This figure illustrates the physical process occurring during a high-energy proton-proton collision at a hadron collider like the LHC. Each proton (denoted by “P”) enters the collision point with an energy of 7 TeV. Upon collision, the energy released results in the production of a very large number of secondary particles—on the order of 10^3 (about a thousand) per event. This reflects the high multiplicity environment typical of LHC collisions, as described in the lecture. The resulting particles are distributed in various directions with a broad range of momenta, most commonly with energies of a few hundred MeV. This environment is crucial for hadron spectroscopy studies, as it enables the observation and identification of rare and exotic hadronic states among the many produced particles. The diagram underscores the difference between the complex, high-multiplicity environment of hadron colliders and the cleaner environment of e^+ e^- colliders.\n\n\n\nProton-proton colliders like the LHC present a far more complex environment compared to clean e^+e^- annihilation.\n\nEnergy & Process: At the LHC, protons collide at energies like 7.7 TeV per beam. This is not a simple annihilation process; the beam remnants—primarily quarks and gluons—carry TeV-scale energies.\nEvent Multiplicity: The collisions produce a very high number of particles. The average multiplicity \\langle N \\rangle scales with the collision energy \\sqrt{s} : \\langle N \\rangle \\propto \\ln(\\sqrt{s})\nAt the LHC, a typical event has a multiplicity of roughly a thousand particles.\nParticle Spectrum: The transverse momentum ( p_T ) distribution of these particles follows an approximate exponential fall-off: \\frac{dN}{dp_T} \\propto e^{-p_T / \\langle p_T \\rangle}\nThis means there are many low-energy particles and a long tail extending to high energies.\n\n\n\n\n\n\n\nKey Scale: The typical energy scale for most particles produced in an LHC collision is on the order of hundreds of MeV. Even with thousands of particles sharing the total collision energy, the bulk of them have low momentum, establishing this few-hundred-MeV scale as characteristic of the hadronic environment."
  },
  {
    "objectID": "2024-Lecture-04.html#hadron-production-and-spectroscopy-at-lhcb",
    "href": "2024-Lecture-04.html#hadron-production-and-spectroscopy-at-lhcb",
    "title": "(2024) Lecture 4",
    "section": "6 Hadron Production and Spectroscopy at LHCb",
    "text": "6 Hadron Production and Spectroscopy at LHCb\nLHCb has been the most productive experiment in discovering new hadrons because of the high cross section. The cross section for two protons interacting, \\sigma_{pp \\to \\text{hadrons}} , is much larger than the cross section for annihilating two electrons, \\sigma_{e^+e^- \\to \\text{hadrons}} . This enables the detailed study of hadron production.\nThe two main production mechanisms explored in proton-proton collisions are:\n\nPrompt production: The particle of interest originates directly from the primary collision vertex.\nDisplaced production: The particle originates from the decay of a longer-lived particle, creating a secondary vertex. ### Studying Hadrons via Prompt Production\n\n\n\n\n\n\n\nFigure 8: This figure illustrates two main types of hadron production observed in high-energy collider experiments, as discussed in the lecture: prompt production and production from b -hadron ( B/\\Lambda_b ) decays. - Prompt production: The top part shows the direct (prompt) creation of hadrons at the primary interaction point. It depicts the decay of an excited charmed baryon, \\Omega_c^0 , which promptly decays into a cascade baryon \\Xi_c and a K^- meson. The \\Xi_c is then reconstructed from its decay products (e.g., proton, K^- , and \\pi^+ ), and a characteristic secondary vertex is indicated (displaced by several millimeters from the primary vertex), signifying the weak decay of the \\Xi_c . - Production from b -decays: The bottom part shows the production of hadrons via the decay of a long-lived b -hadron ( B or \\Lambda_b ). The B/\\Lambda_b baryon travels a measurable distance (on the order of \\sim 2 cm) from the primary collision before decaying. Its decay produces particles such as J/\\psi , a proton ( p ), and a kaon ( K ). The diagram notes ** P_c resonances** (pentaquark candidates observed in the J/\\psi p invariant mass spectrum) and ** \\Lambda^* resonances** (seen in the pK spectrum), illustrating how secondary vertices allow the identification of new excited hadronic states. The physical meaning centers on the use of vertex displacement to distinguish production mechanisms, the reconstruction of invariant mass spectra to identify resonances, and the importance of tracking kinematics in hadron spectroscopy studies as explained in the lecture.\n\n\n\nA prime example from charm production is the observation of the \\Omega_c baryons and the \\Xi_c^* and \\Omega_c^* baryons in prompt production. This is done by reconstructing \\Xi_c K combinations.\nThe \\Xi_c is the ground state of the cascade multiplet. For all such multiplets containing a charm or bottom quark, the ground state decays weakly because the heavy quark is stable under the strong interaction. The decay proceeds via the weak interaction, with a proper lifetime \\tau on the order of 10^{-10} seconds.\nFor a boosted particle with a momentum around 100 GeV, this lifetime results in a measurable flight distance. The decay length in the lab frame is given by:\nL = \\gamma \\beta c \\tau\nwhere \\gamma is the Lorentz factor and \\beta = v/c . This is sufficient to resolve its decay vertex from the primary vertex. The ground states of charm baryons fly millimeters; we resolve their decays from the primary vertex. In this case, the \\Xi_c produces a separate secondary vertex, displaced by roughly 5 or 6 millimeters.\nYou reconstruct this \\Xi_c secondary vertex by looking at combinations of charged particles, such as a proton, kaon, and pion. From the thousands of other particles, you then loop over all kaons and combine each with an identified \\Xi_c .\nBy examining these combinations, you find resonances that are produced promptly at the primary vertex and then decay into this pair. In the spectrum of the \\Xi_c K invariant mass, defined as:\nM_{\\Xi_c K}^2 = (E_{\\Xi_c} + E_K)^2 - (\\vec{p}_{\\Xi_c} + \\vec{p}_K)^2\nyou see distinct peaks. These peaks, five of them, correspond to the highest probability for producing a system, meaning the system resonates at a frequency corresponding to excited states in the \\Omega_c spectrum.\n\n\n\n\n\n\nIdentifying the State via Strangeness: The \\Xi_c has quark content csu and contains one strange quark (s), giving it strangeness S = -1 . The K^- has quark content s\\bar{u} and strangeness S = -1 . Therefore, \\Xi_c K combinations have a total strangeness of S = -2 . The resonances appearing in this spectrum have quark content css , which is precisely the \\Omega_c baryon.\n\n\n\n\n6.1 Studying Hadrons via Displaced Production\nAnother method is to look at separate secondary vertices from B hadrons. The ground-state hadrons containing a b quark are the B mesons and the \\Lambda_b baryon. These are easiest to produce from the fragmentation of the initial b quark.\nSince they are ground states, they also decay weakly. Their proper lifetime is longer, on the order of 10^{-9} seconds. When boosted, they produce a secondary vertex a few centimeters away from the primary interaction point, for example, two centimeters.\nThis flight distance cleanly separates the decay we want to study from the primary interaction vertex, making the kinematics very clean. You reconstruct the final-state particles, determine the decay length and the momentum of the B hadron, and study its isolated decay. (see Figure 8)\nResonances in this case appear within the decay products of the B or \\Lambda_b . A prominent recent example, which led to the discovery of pentaquark states, is the decay:\n\\Lambda_b \\to J/\\psi \\, p \\, K^-\nThis is a three-body decay. You start with the \\Lambda_b and look at the exclusive combination of the final-state particles: J/\\psi , proton, and kaon. These particles can resonate at different masses.\n\nIf you look at the invariant mass spectrum of the proton and kaon, M_{pK}^2 = (p_p + p_K)^2 , you see bumps corresponding to known \\Lambda resonances.\nIf you look at the invariant mass spectrum of the proton and J/\\psi , M_{J/\\psi p}^2 = (p_{J/\\psi} + p_p)^2 , you do not expect any known resonances. However, resonant peaks are still observed.\n\nThese peaks in the J/\\psi\\, p spectrum correspond to pentaquark resonances, meaning they are combinations of five quarks: u, u, d, c, \\bar{c} ."
  },
  {
    "objectID": "2024-Lecture-04.html#fixed-target-experiments-and-light-hadron-spectroscopy",
    "href": "2024-Lecture-04.html#fixed-target-experiments-and-light-hadron-spectroscopy",
    "title": "(2024) Lecture 4",
    "section": "7 Fixed-Target Experiments and Light Hadron Spectroscopy",
    "text": "7 Fixed-Target Experiments and Light Hadron Spectroscopy\nNow let’s quickly overview fixed-target experiments and the techniques used there.\nI will have three examples.\n\nThe GlueX experiment at Jefferson Lab operates with a 9 GeV photon beam hitting a liquid hydrogen target, which is essentially a liquid way of preparing protons as a target.\nThe COMPASS experiment at CERN explores hadron structure with a beam of pions, also using a liquid hydrogen target.\nThe CB-ELSA/TAPS experiment at Bonn uses a 2 GeV photon beam.\n\nWith these energies, we are not talking about bottom or charm quark production. Most of these experiments are focused on light hadron spectroscopy.\n\nCOMPASS studies light hadrons like protons, kaons, and light mesons.\nGlueX does similar physics but with a different setup, beam, and energy.\nCB-ELSA/TAPS also studies light mesons in a fixed-target configuration.\n\n\n\n\n\n\n\nThe center-of-mass energy available in these fixed-target collisions is a key kinematic quantity, given by: \\sqrt{s} = \\sqrt{m_{\\text{beam}}^2 + m_{\\text{target}}^2 + 2 E_{\\text{beam}} m_{\\text{target}}}\nFor photoproduction experiments like GlueX and CB-ELSA/TAPS, the threshold photon energy to produce a particle of mass m_X from a proton target is: E_{\\gamma}^{\\text{th}} = \\frac{m_X^2 - m_p^2}{2 m_p}\n\n\n\nThe event rate in these experiments depends on the luminosity. For a fixed-target setup, the luminosity is \\mathcal{L} = \\Phi \\, n \\, L , where \\Phi is the beam flux, n is the target number density, and L is the target length."
  },
  {
    "objectID": "2024-Lecture-04.html#two-mechanisms-in-fixed-target-experiments",
    "href": "2024-Lecture-04.html#two-mechanisms-in-fixed-target-experiments",
    "title": "(2024) Lecture 4",
    "section": "8 Two Mechanisms in Fixed-Target Experiments",
    "text": "8 Two Mechanisms in Fixed-Target Experiments\nIt is important to realize that there are two different mechanisms involved when you deal with fixed-target experiments at intermediate energy. These are not the same.\nThe first process is diffraction and the second one is s-channel scattering. Which process happens when you collide two particles is determined by the energy. ### Diffraction vs. s-Channel Scattering\n\n\n\n\n\n\nFigure 9: This figure illustrates the two primary physical processes occurring in fixed-target hadron experiments at intermediate energies: diffraction and s-channel scattering. - On the left, the diagram represents diffraction, where an incoming photon ( \\gamma ) interacts with a stationary proton ( p ) via the exchange of a color-neutral gluonic field, phenomenologically described as a Pomeron. This process is characteristic at higher energies (around 20 GeV), where the proton acts as a source of strong interaction fields. The photon is excited through interaction with the gluonic field, producing a final hadronic state, with the proton typically remaining intact. - On the right, the diagram depicts s-channel scattering, which occurs predominantly at lower energies (2–3 GeV). Here, an incoming pion ( \\pi ) collides with a proton ( p ), and both particles can resonate together via an intermediate state (the “X” in the middle), forming a true resonance. The final state contains specific outgoing hadrons resulting from this short-lived intermediate state. These processes are distinguished by their production mechanisms: diffraction involves exchange of a Pomeron (gluonic field) and typically dominates at higher energies, while s-channel scattering proceeds through the formation of a resonant intermediate state and is more prevalent at lower energies. This distinction is crucial for understanding hadron production and excitation patterns in experiments like GlueX and COMPASS, as described in the lecture.\n\n\n\n\nDiffraction: This process uses the proton as the source of the strong interaction field. The proton sits and emits gluons. A pion or a photon comes and interacts with these gluonic fields and gets excited. The excited state X then flies for a bit and decays.\nWhen we say “for a bit,” it’s not a physical flight in the detector. We are talking about strong interactions and hadronic resonances. Light hadronic resonances live for about 10^{-25} seconds, which is not sufficient time at these energies to move away from the primary vertex. However, on diagrams we sketch them as separate particles.\ns-Channel Scattering: This process is more plausible at lower energies, typically around 2–3 GeV. Here, the proton and the incoming beam (pion or photon) can resonate at a specific frequency.\n\nFor fixed-target kinematics, experiments like COMPASS separate the regime of diffraction from the regime of s-channel production to study baryonic excitations.\n\n\n\n\n\n\nThe exchanged object in diffraction is not a single gluon (the proton must remain color neutral). It is a color-neutral gluonic field, described phenomenologically by the Pomeron. The Pomeron is not a fundamental particle found in the Particle Data Group (PDG) listings but is a useful way to model this interaction.\n\n\n\n\n8.1 Exclusive vs. Inclusive Processes & Kinematic Counting\nWe now move to discussing exclusive reactions, where all final-state particles are measured ( 2 \\to n ). This is in contrast to inclusive processes, where a system is produced alongside many other particles that are not measured.\nTo analyze an exclusive process, we need to count its independent kinematic variables. The method is:\n\nCount the independent components of all particle momenta.\nSubtract constraints from energy-momentum conservation.\nOptionally subtract degrees of freedom fixed by choosing a specific reference frame.\n\nExample: A 2 \\to 3 Process\n\nEach of the 5 particles has a four-momentum p_i^\\mu = (E_i, \\mathbf{p}_i) .\nThe mass-shell condition p_i^2 = E_i^2 - \\mathbf{p}_i^2 = m_i^2 reduces each four-vector to 3 independent components.\nEnergy-momentum conservation, \\delta^4(P_{\\text{initial}} - \\sum p_i) , imposes 4 constraints.\n\nThe count before fixing a frame is: N_{\\text{vars}} = (5 \\text{ particles}) \\times (3 \\text{ components}) - 4 \\text{ constraints} = 11\nBy choosing a specific frame (fixing 3 rotations and 3 boosts), we lose 6 more degrees of freedom, leaving 5 independent variables to describe the kinematics.\n\n\n8.2 Phase Space and its Element\nFor cross-section calculations, we need the Lorentz Invariant Phase Space (LIPS) element, which counts the number of accessible kinematic configurations. For an n -particle final state, it is:\nd\\Phi_n = \\left[ \\prod_{i=1}^n \\frac{d^3 \\mathbf{p}_i}{(2\\pi)^3 \\, 2E_i} \\right] (2\\pi)^4 \\delta^4\\!\\left(P_{\\text{initial}} - \\sum_{i=1}^n p_i\\right)\nKey points about this formula:\n\nThe factor \\frac{d^3 \\mathbf{p}_i}{(2\\pi)^3 2E_i} for each particle comes from integrating over its four-momentum and enforcing the mass-shell condition.\nThe (2\\pi)^4 \\delta^4(...) enforces total energy and momentum conservation.\nThis element is Lorentz invariant, meaning it has the same form in any inertial reference frame.\n\nPhase space for complex processes (e.g., a 1 \\to 4 decay) can often be evaluated recursively by factorizing it into successive two-body phase spaces, which is a kinematic simplification, not a dynamical one."
  },
  {
    "objectID": "2024-Lecture-04.html#recursive-phase-space-parameterization",
    "href": "2024-Lecture-04.html#recursive-phase-space-parameterization",
    "title": "(2024) Lecture 4",
    "section": "9 Recursive Phase Space Parameterization",
    "text": "9 Recursive Phase Space Parameterization\nWhen you calculate the phase space, you see that three integrals come for every particle. That’s why I have a factor of three here for every particle in the phase space.\nHere we have a final state and an initial state. For the phase space to count, you only count the final state. So you see the initial state doesn’t enter.\nThen the four energy-momentum conservation conditions come here explicitly. That’s the number of the integrals that remain. That gives you three times four: twelve, minus four remains eight.\nThis is the five kinematic variables. So five plus three overall rotations, which is five variables. The three rotations are the Euler angles. But which five I pick to parameterize my kinematics is up to me.\nOne has to choose these five in the most convenient way to calculate dynamics, because it’s not going to tell you what interactions you have in these vertices. It doesn’t even tell you that your reactions happen in this cascade way. It’s just purely kinematical parameterization. It’s your choice of the kinematic variables.\nOne particular choice is to say I’m going to introduce M_X here and M_Y there and write my phase space as the integral \\frac{dM_X^2}{2\\pi} \\frac{dM_Y^2}{2\\pi} \\, d\\Phi_2(P \\to p_X, p_Y) \\, d\\Phi_3(p_Y \\to p_1, p_2, p_3) . That’s what is referred to as the recursive expression.\nIt’s not only valid for two, but you can also do this for three. The important thing is that they introduce a variable that is the sort of intermediate mass of the combination and you integrate over this variable, and every integral comes with a 2\\pi in the denominator.\nJust another example: if I just introduce d\\Phi_2(P \\to p_Y, p_4) and then d\\Phi_3(p_Y \\to p_1, p_2, p_3) , that’s also legal. That’s fine.\n\n\n\n\n\n\nThe general formula for an n -body final state is: d\\Phi_n(P; p_1, \\dots, p_n) = (2\\pi)^4 \\delta^{(4)}\\left(P - \\sum_{i=1}^n p_i\\right) \\prod_{i=1}^n \\frac{d^3p_i}{(2\\pi)^3 2E_i}\nThe number of independent kinematic variables is 3n - 4 .\n\n\n\n\n\n\n\n\n\nFigure 10: This diagram represents a typical cascade decay chain in a multi-particle final state process, often encountered in hadron spectroscopy experiments. Here, an initial state produces an intermediate resonance X (after vertex 1), which subsequently decays into another intermediate state (at point 2), followed by further decays resulting in final state particles labeled 3 and 4. The particle denoted “i” appears to decay into a multi-particle final state, as indicated by the several lines emerging from it. Physically, this diagram illustrates how a complex decay topology is analyzed via exclusive processes (where all final state particles are measured), as discussed in the lecture. Each vertex represents a step in the decay where energy-momentum conservation applies, and the overall structure enables the use of recursive phase space factorization. For example, the total n -body phase space d\\Phi_n can be decomposed into products of two- and three-body phase spaces at each vertex, integrating over intermediate invariant masses (e.g., M_X ). This is foundational for reconstructing resonance signals, calculating invariant mass distributions (such as those used in Dalitz plots), and determining the kinematic variables required to describe multi-body decays in hadron spectroscopy experiments.\n\n\n\nFor a 4-body decay ( n=4 ), this gives 3 \\times 4 - 4 = 8 variables, as mentioned.\nOnce you learn this trick, this calculation of the phase space is super straightforward because every two-to-two phase space is \\frac{2p}{\\sqrt{s}} \\frac{d\\Omega}{4\\pi} \\times \\frac{1}{2\\pi} . So this does not have any simplification."
  },
  {
    "objectID": "2024-Lecture-04.html#two-body-phase-space-and-introduction-to-the-dalitz-plot",
    "href": "2024-Lecture-04.html#two-body-phase-space-and-introduction-to-the-dalitz-plot",
    "title": "(2024) Lecture 4",
    "section": "10 Two-Body Phase Space and Introduction to the Dalitz Plot",
    "text": "10 Two-Body Phase Space and Introduction to the Dalitz Plot\n\nWe have now completed a more general treatment for the two-body phase space.\nWith this expression and the general formula, you are equipped to calculate any n-body phase space. As a next step, there is an exercise for you to try at home: play with the three-body phase space.\nThe three-body phase space will have:\n\nThree particles × three coordinates = 9 initial degrees of freedom.\nMinus 4 constraints from energy-momentum conservation.\nMinus 3 from overall rotations.\n\nThis leaves only two independent variables. The resulting distribution is often represented using these two variables.\nA common choice for these two variables is to use invariant masses of particle pairs. When plotted, this representation is called the Dalitz plot.\n\n\n\n\n\n\nIn a three-body decay, the Dalitz plot is a two-dimensional distribution where each point corresponds to a specific pair of invariant masses squared. It visually encodes the entire dynamics of the decay, making it a powerful tool for analyzing resonances and interaction mechanisms."
  },
  {
    "objectID": "2024-Lecture-05.html",
    "href": "2024-Lecture-05.html",
    "title": "(2024) Lecture 5",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Anna Zimmer"
  },
  {
    "objectID": "2024-Lecture-05.html#kinematics-recap-22-scattering-processes",
    "href": "2024-Lecture-05.html#kinematics-recap-22-scattering-processes",
    "title": "(2024) Lecture 5",
    "section": "1 Kinematics Recap: 2→2 Scattering Processes",
    "text": "1 Kinematics Recap: 2→2 Scattering Processes\nWe start with a recap on kinematics. The first question: how many variables does one need to describe the two-to-two scattering process? We have two particles in the initial state and two particles in the final state.\n\nInitial state: two 0⁻ scalar particles\nFinal state: two 0⁻ scalar particles\nExample: 0⁻ + 0⁻ → 3⁻ + 1⁺ scattering\n\n\n\n\n\n\n\nThe “blob” in scattering diagrams represents the interaction region where strong, electromagnetic, or gravitational interactions occur. These are not Feynman diagrams but sometimes called unitarity diagrams.\n\n\n\nThe number of kinematic variables needed depends only on the external particles - whatever happens inside the interaction blob does not affect this count."
  },
  {
    "objectID": "2024-Lecture-05.html#counting-kinematic-variables",
    "href": "2024-Lecture-05.html#counting-kinematic-variables",
    "title": "(2024) Lecture 5",
    "section": "2 Counting Kinematic Variables",
    "text": "2 Counting Kinematic Variables\nLet’s calculate systematically:\nStep 1: Initial counting\n\n4 particles × 4 momentum components each = 16 variables\n\nStep 2: Apply conservation laws\n\n4-momentum conservation (E, pₓ, pᵧ, p₂) removes 4 constraints → 12 remaining variables\n\nStep 3: Remove redundant degrees of freedom\n\n3 rotations and 3 boosts can be eliminated → subtract 6 more variables\n\nFinal count: 2 independent variables\n\n\n\n\n\n\nBoth scalar and spinning particle cases require only 2 variables to fully describe 2→2 scattering kinematics. The difference is that spinning particles have more scattering amplitudes, but all amplitudes still depend on the same 2 kinematic variables."
  },
  {
    "objectID": "2024-Lecture-05.html#choosing-the-two-variables",
    "href": "2024-Lecture-05.html#choosing-the-two-variables",
    "title": "(2024) Lecture 5",
    "section": "3 Choosing the Two Variables",
    "text": "3 Choosing the Two Variables\nPrimary Mandelstam variables: s = (p_1 + p_2)^2 = (p_3 + p_4)^2 t = (p_1 - p_3)^2 u = (p_1 - p_4)^2\nThese variables are related by: s + t + u = \\sum m_i^2, so only two are independent.\nPhysics meaning:\n\ns: Total center-of-mass energy squared\nt: Momentum transfer squared between particles 1 and 3\nu: Alternative momentum transfer variable\n\nCenter of Mass Frame Variables:\n\n\\sqrt{s}: Center-of-mass energy\n\\cos\\theta_{CM}: Scattering angle between initial and final state particles\n\nOther possibilities:\n\nLab frame energies E_1 and E_3\nAny two independent variables that characterize the process\n\n\n\n\n\n\n\nMandelstam variables are preferred because they are Lorentz invariant and provide an undistorted representation of phase space density. The transformation to these variables has a constant Jacobian."
  },
  {
    "objectID": "2024-Lecture-05.html#scattering-amplitudes-and-spin-dependence",
    "href": "2024-Lecture-05.html#scattering-amplitudes-and-spin-dependence",
    "title": "(2024) Lecture 5",
    "section": "4 Scattering Amplitudes and Spin Dependence",
    "text": "4 Scattering Amplitudes and Spin Dependence\nFor scalar particles: The scattering amplitude is a single scalar function A(s,t)\nFor spinning particles: The scattering amplitude becomes a multi-component object:\n\nSpin-3 particle: 7 dimensions\nSpin-1 particle: 3 dimensions\nTotal amplitude dimension: 7 × 3 = 21 components\n\nHowever, all 21 amplitudes are still functions of the same 2 variables (s and t)."
  },
  {
    "objectID": "2024-Lecture-05.html#extension-to-three-body-decays",
    "href": "2024-Lecture-05.html#extension-to-three-body-decays",
    "title": "(2024) Lecture 5",
    "section": "5 Extension to Three-Body Decays",
    "text": "5 Extension to Three-Body Decays\nNow considering three-body decays (1 particle → 3 particles):\nKinematic variables: Still 2 variables needed, same as 2→2 scattering\nDalitz plot variables: Typically use two invariant mass squared variables: m_{34}^2 = (p_3 + p_4)^2 m_{24}^2 = (p_2 + p_4)^2\nThree-body phase space formula: d\\Phi_3 = d\\Phi_2(m_{12}^2) \\times d\\Phi_2(m_{34}^2) \\times \\frac{dm_{34}^2}{2\\pi}\nTwo-body phase space element: d\\Phi_2 = \\frac{1}{8\\pi} \\frac{2|\\vec{p}|}{\\sqrt{s}} \\frac{d\\Omega}{4\\pi}\n\n\n\n\n\n\nThe phase space for three-body decay is flat when plotted against Mandelstam variables. (see Figure~1) This means the differential width directly reveals the dynamics of the interaction without kinematic distortions. (see Figure~2) (see Figure~3) (see Figure~6)"
  },
  {
    "objectID": "2024-Lecture-05.html#applications-and-homework",
    "href": "2024-Lecture-05.html#applications-and-homework",
    "title": "(2024) Lecture 5",
    "section": "6 Applications and Homework",
    "text": "6 Applications and Homework\nWe will continue discussing angular distributions after the Dalitz plot. The homework exercise on Dalitz plots connects directly to hadron spectroscopy, which is the focus of upcoming lectures.\nKey realization: For any N-body process, once you specify the kinematic variables, you can completely reconstruct the “rigid body” configuration of all momentum vectors in the center-of-mass frame.\nThe recursive phase space formula demonstrates that the Jacobian for transformation to Mandelstam variables is constant, making these variables ideal for studying interaction dynamics through Dalitz plot analyses.\n\n\n\n\n\n\nFigure 1: A sketch illustrating the recursive relation when computing the phase-space expression. This is not a dynamic assumption but a mathematical trick that rewrites the full three-body phase-space through lower-dimensional phase-space elements and the two-body phase-space, for which the expression is simple.\n\n\n\n\n6.1 Decoding the Λc Dalitz Plot\nYou can see the example of the triple decay that I have here of the \\Lambda_c baryon going to the proton, kaon, and pion: \\Lambda_c^+ \\to p + K^- + \\pi^+\nWe measure \\Lambda_c produced in proton-proton collisions or any other collisions. In experiments, they observe \\Lambda_c abundantly. This is one of the particles that lives long enough and is produced copiously.\nParticles with charm ground states are produced abundantly and live sufficiently long to fly from the primary vertex. That’s why we have a good sample and a good understanding of their decay kinematics—not only kinematics, but dynamics as well. (see Figure~6)\nIn this decay, there is a charm quark in the initial state and no charm quark in the final state, indicating that this occurs via weak interaction. The charm quark disappears between initial and final states: the charm quark decays, transitioning into a strange quark that ends up in the kaon. This c \\to s transition happens within one generation and is not suppressed—it is an allowed process.\nThis decay is considered a golden channel for detection because:\n\nThe final state contains three charged particles—there are no neutrals.\nThe proton is charged, travels well, and is stable.\nThe kaon and pion are stable in our accelerator experiments.\n\nThese particles fly from the decay without distraction, and we see their tracks clearly through all detectors. They point away from the primary interaction vertex.\nThere is roughly a 1 cm shift between the primary vertex and the secondary vertex in \\Lambda_c decays. This displacement occurs due to the boost and the fact that \\Lambda_c lives longer in the laboratory frame than in its rest frame.\n\n\n\n\n\n\nThe decay length in the laboratory frame is given by: L = \\beta\\gamma c\\tau At the LHC, \\Lambda_c is produced with energies of a few hundred GeV, making this decay particularly clean and well-suited for study.\n\n\n\nWe have studied this decay extensively. Here is the result of an analysis that resembles experimental data. If I showed you actual experimental data, you wouldn’t distinguish it from this plot—the statistics are so high that the distribution appears very smooth.\n\nOn the x-axis: invariant mass of the proton and kaon, m_{12}^2\nOn the y-axis: invariant mass of the kaon and pion, m_{23}^2\n\nAll allowed kinematic values for the decay are shown in color. (see Figure~6) The white area corresponds to kinematics where no physical configuration exists—energy and momentum cannot be conserved there.\nIf you select a point inside the colored region, you can compute angles between particles and reproduce the configuration with a 3D-printed rigid body. But if you choose a point in the white region, you quickly find that energy conservation cannot be satisfied.\nThe range of possible values for the invariant masses is limited, and this surface is called the Dalitz plot. The kinematic boundaries are defined by:\nm_{12}^2 + m_{23}^2 + m_{13}^2 = m_{\\Lambda_c}^2 + m_p^2 + m_K^2 + m_{\\pi}^2\nDifferent colors in the plot indicate different probabilities for the decay to occur at that kinematic point. (see Figure~6) The differential decay rate in the Dalitz plot is:\n\\frac{d^2\\Gamma}{dm_{12}^2  dm_{23}^2} \\propto |\\mathcal{M}|^2\nWe measure the decay by reconstructing particle tracks and identifying from which kinematic point the decay originated. There is an unambiguous relation between four-vectors and kinematic points. (see Figure~3)\nIt turns out that certain kinematics are more probable than others—particles prefer specific directions. For example, one configuration may be more common, while another is rare. On the border of the Dalitz plot, particles are aligned in one line, whereas inside the surface they always have an angle between them.\nThink about how to maximize the invariant mass and where on the border such a point lies.\n\n\n6.2 Dalitz Plot Kinematics in Three-Body Decay\nLet’s consider the three-body decay \\Lambda_c^+ \\to pK^-\\pi^+ and its kinematics. (see Figure~1) We want to maximize the invariant mass of the proton–Kaon system. (see Figure~6)\nThere are three outgoing momenta. The idea is that if the three momenta are arranged in opposite directions, the total three-momentum sum should be as small as possible. (see Figure~6)\nIf we add both momentum vectors, the forward momentum—or more precisely, the magnitude of the sum of the momentum vectors—should be as large as possible. Therefore, we should be on the right side of the Dalitz plot diagram.\nNow, consider the mass on the y-axis: should it be as large or as small as possible? (see Figure~3) It should be as small as possible.\nWhy? Because when the three momenta are collinear and we subtract them appropriately, the invariant mass is minimized.\nOne way to think about this is to go to the rest frame of the Kaon and pion. If they are flying nearly together, their relative momentum is small. In their mutual rest frame, they could both be at rest, so their invariant mass would simply be the sum of their rest masses—this is the minimum possible.\n\n\n\n\n\n\nThe minimum invariant mass for any two-particle system is given by M_{ij}^{\\text{min}} = m_i + m_j This occurs when the two particles are at rest relative to each other.\n\n\n\nYou are correct: we are looking for the minimal invariant mass of the proton–Kaon system.\nLet’s identify what this point corresponds to kinematically. In certain configurations, two particles can be nearly at rest while the third carries away the momentum. (see Figure~6) That corresponds to the minimal invariant mass case.\nThis plot is likely from experimental data. How would we reconstruct such an event experimentally if we don’t detect the proton directly? Even though measurements occur in the lab frame (which is boosted), the analysis is often performed in the center-of-mass frame.\nThe point of maximum invariant mass occurs when the two particles move back-to-back with maximum momentum. The point we are discussing minimizes the invariant mass.\nFor three-body decays, there is a similar way to define angular variables. (see Figure~1) Let me briefly mention this.\nI will boost into the rest frame for each kinematic setup. To clarify, I am referring to the proton, Kaon, and pion. Suppose I fix the invariant mass of the proton–Kaon system.\nThe approach is to work in the center-of-momentum frame of the \\Lambda_c, where the three final-state particles have momenta summing to zero. Then, I boost to the rest frame of the Kaon and pion. (see Figure~6) In that frame, the Kaon and pion have equal and opposite momenta. (see Figure~7)\nIf I fix the invariant mass of the proton–Kaon system and explore phase space along a line where that mass is fixed, the magnitudes of the momenta are fixed—only the angle \\theta changes.\nAs \\theta varies from 0 to \\pi, one extreme (\\theta = 0) corresponds to the proton and Kaon moving in the same direction, yielding a small invariant mass. The other extreme (\\theta = \\pi) corresponds to them moving oppositely, giving the maximum invariant mass.\n\n\n\n\n\n\nThe invariant mass squared for two particles is M_{ij}^2 = (p_i + p_j)^2 = (E_i + E_j)^2 - (\\vec{p}_i + \\vec{p}_j)^2 This quantity is Lorentz invariant and is used to define Dalitz plot axes.\n\n\n\nFor angle \\theta = 0, the invariant mass is small. As the angle increases, the invariant mass grows. The same logic applies to the other pairings.\nA straightforward analysis method is to go to the rest frame of the proton–Kaon system, where all quantities are fixed, and scan by changing the angle between the proton and Kaon relative to the pion direction. (see Figure~6)\nThus, lines in the Dalitz plot represent configurations where the angle is varied in some rest frame.\nAnother variable in 2 \\to 2 scattering kinematics is the U variable, which offers a more symmetric treatment. For three-body decays, we also have the invariant mass of the pion–proton system.\nIf I fix the invariant mass of the proton–Kaon system and scan the angle, which line do I move along? This follows from the relation that the U variable is a linear combination of the invariant masses.\nIn fact, the coefficients are such that the motion corresponds to a diagonal in the Dalitz plot. This line represents a fixed pion–proton invariant mass, moving from one kinematic endpoint to the other.\nThe standard representation in experimental analyses uses Dalitz plots with the x-axis as the invariant mass squared of one pair and the y-axis as the invariant mass squared of another pair—exactly what is shown here.\nIn homework, you may encounter a more symmetric Dalitz plot where all variables enter symmetrically. This uses the geometry of an equilateral triangle, where every point inside satisfies a conservation relation.\n\n\n\n\n\n\nIn the symmetric representation, the coordinates are x = \\frac{\\sqrt{3}}{2}(M_{12}^2 - M_{23}^2), \\quad y = M_{13}^2 - \\frac{1}{2}(M_{12}^2 + M_{23}^2) The factor \\frac{\\sqrt{3}}{2} arises from the 60° angles in an equilateral triangle.\n\n\n\nIf you sum the perpendicular distances from any interior point to the three sides of an equilateral triangle, the total is constant. This allows us to define symmetric variables representing the sum of the invariant masses.\nThe variables are interpreted as distances to the sides. This gives a very symmetric and elegant representation.\nEssentially, this is equivalent to the standard plot—they are related by a linear transformation, not just a rotation but also a skew. To plot experimental data in this form, one must apply the correct coordinate transformation.\nYesterday, I worked through the algebra relating Cartesian coordinates to the heights in the triangle—it’s straightforward but interesting.\nThis symmetric representation is nice, while the standard one is more common and easier to plot directly. Both capture the same kinematics.\nIn the Dalitz plot, regions with higher event density indicate kinematic enhancements. The purpose of this kinematic representation is to identify the dynamics and underlying processes governing the decay.\n\n\n\n\n\n\nFigure 2: A kinematic representation of the transition from the initial state to the final state in the process where particle 0 decays into particle x and particle 3. The arrows indicate the three-momenta of particles 3 and x, and the fat dot marks particle 0, which is at rest in this frame.\n\n\n\nLooking ahead, we will see that \\Lambda_c decay to three particles often proceeds via intermediate resonances. Temporarily, two particles form a resonant state that then decays, increasing the decay rate in certain invariant mass regions.\nWhen the energy of two particles matches a resonance, their interaction is stronger, making the decay more probable. This is why we observe enhanced densities along certain bands in the Dalitz plot.\n\n\n6.3 Resonance Structures and Angular Distributions in Three-Body Decays\nYou might have seen cross sections for two-particle resonances. These exhibit a characteristic bump known as a hadronic resonance. The underlying physics is that when you have a system of two particles, and the quantum numbers of that system match those of an intermediate resonance, the interaction probability increases dramatically at specific energies.\n\n\n\n\n\n\nThe Breit-Wigner resonance cross section describes this enhancement: \n\\sigma(E) \\propto \\frac{\\Gamma^2/4}{(E - E_R)^2 + \\Gamma^2/4}\n where E_R is the resonance energy and \\Gamma is the resonance width.\n\n\n\nBy adjusting the system energy, you explore how likely two particles are to interact. When passing through the resonance region, the probability increases significantly. This creates bent structures in the Dalitz distribution—when projected onto one axis, you see the characteristic resonance shape.\nThis example is particularly interesting because it shows resonances in all three particle pairs:\n\nHorizontal lines correspond to fixed K\\pi mass → K^* resonances\nVertical lines correspond to fixed proton-K\\pi mass → K-nucleon resonances\nDiagonal lines correspond to pion-proton combinations → \\Delta resonances\n\n\n\n\n\n\n\nThe Dalitz plot density for three-body decays is: \n\\frac{d^2\\Gamma}{dm_{12}^2  dm_{23}^2} = \\text{constant} \\times |\\mathcal{M}|^2\n where m_{ij} are invariant masses and \\mathcal{M} is the decay amplitude. (see Figure~1)\n\n\n\nThe lines appear parallel to the sides of the Dalitz triangle:\n\nK^* resonances parallel to one side\n\\Lambda resonances parallel to another side\n\\Delta resonances parallel to the third side\n\n\n\n\n\n\n\nFigure 3: The Dalitz plot, a representation of the phase-space for the three-body decay. (see Figure~6) It appears as an ellipse-shaped area where the internal region corresponds to allowed kinematics and the outside region is forbidden. On the x-axis lies the squared mass of two final-state particles, while the y-axis corresponds to the other subsystem. A horizontal line represents a slice of the phase-space with one mass fixed. The borders of the area correspond to configurations where all three momenta are aligned in the rest frame of the decaying particle, or equivalently, where the scattering angle in the relevant rest frame is either 0 or π.\n\n\n\nNow let’s examine angular distributions within resonance bands. When traversing phase space while keeping the mass combination fixed, you’re effectively changing the decay angle. This angle dependence reveals important physics:\n\nWithin a resonance band, probability can be inhomogeneous\nParticles often prefer aligned vs. perpendicular configurations\nThese preferences occur because intermediate resonances have spin\n\n\n\n\n\n\n\nAngular distributions are powerful tools for measuring:\n\nSpin\nParity\nOther quantum numbers\n\n\n\n\nKey observations:\n\nHigher spin particles produce more structured angular distributions\nScalar particles produce no angular asymmetries\nThe number of nodes in angular distribution often equals the spin value\nFor spin-J particles: N_{\\text{states}} = 2J + 1 spin projections\n\nWhen dealing with particle spins, we need to understand how quantum states transform under rotations. For a particle with spin J, there are 2J+1 possible projections along a quantization axis.\n\n\n\n\n\n\nThe Wigner D-function describes rotations using Euler angles (\\phi, \\theta, \\gamma): \nD^J_{m'm}(\\phi, \\theta, \\gamma) = e^{-i m' \\phi}  d^J_{m'm}(\\theta)  e^{-i m \\gamma}\n where d^J_{m'm}(\\theta) is the Wigner small d-matrix.\n\n\n\nRotation conventions in particle physics: 1.\n\n\n\n\n\n\nFigure 4: A diagram showing the spin projection. The horizontal line arrow indicates the z-axis, which is chosen as the quantization axis. The arrow denotes the particle spin, and its projection onto the axis is represented by m in the equations.\n\n\n\nRotate by \\phi about Z-axis\n\nRotate by \\theta about Y-axis\nRotate by \\gamma about Z-axis again\n\n\n\n\n\n\n\nBe careful with conventions! Mathematica uses opposite sign conventions compared to standard particle physics. Wikipedia and Python’s sympy library are reliable references.\n\n\n\nLet’s construct a model for three-body decays via cascade processes: initial particle → intermediate resonance X → particles 1 + 2, plus particle 3.\n![A unitary diagram for the three-body decay.\n\n\n\n\n\n\nFigure 5: A dynamic diagram of a cascade decay, where particle 0 decays to a three-body final state through an intermediate state x that sequentially decays into particles 1 and 2. (see Figure~6) The intermediate particle carries spin j and serves as an expansion term of the full amplitude, known as the partial projection term. Lines represent initial and final state particles, while the double line denotes the intermediate particle.\n\n\n\nThe arrows show the initial and final state particles, and the blob stands for the interaction that transforms the initial state into the final state.](2024-Lecture-05-images/fig1.png)\nThe general cascade decay amplitude structure:\n\nA_{\\lambda_0, \\lambda_1, \\lambda_2, \\lambda_3}(s, \\theta) = \\sum_{\\lambda'_X} H^X_{\\lambda_0 \\lambda'_X} D^{j_X}_{\\lambda'_X \\lambda_X}(\\theta_X, \\phi_X) H^Y_{\\lambda_X \\lambda_Y} D^{j_Y}_{\\lambda_Y \\lambda_3}(\\theta_Y, \\phi_Y)\n\nComponent breakdown:\n\nH factors: Contain dynamics from strong/weak/EM interactions\nD functions: Handle rotational kinematics and angular distributions\n\\lambda_i: Helicity projections along particle directions of motion\n\n\n\n\n\n\n\nIn the helicity formalism, we quantize spins along the direction of motion, making \\lambda_i the helicity projections.\n\n\n\nSpecial case: aligned kinematics (\\Phi = \\theta = 0)\n\nRotation matrices simplify significantly\nMany summations collapse due to delta functions\nFinal expression becomes much cleaner:\n\nThe simplified amplitude becomes: \n\\mathcal{A} = H_0 D(\\theta)^{J_X}_{\\lambda_X, \\lambda_0 + \\lambda_3} D(\\theta)^{\\lambda_0 + \\lambda_3}_{\\lambda_1 - \\lambda_2}\n\nKey insight: Angular distributions are determined primarily by rotational group properties, with only the production preferences coming from specific interactions.\n\n\n\n\n\n\nFigure 6: A kinematic configuration for the introduction of the helicity matrix in the transition of particle x decaying into particles 1 and 2. The representation is drawn in the rest frame of particle x, shown as a dot at rest, with arrows representing the three-momenta of particles 1 and 2 in this frame.\n\n\n\nThis separation makes angular analysis a powerful model-independent tool for determining particle properties.\n\n\n6.4 Angular Distributions and Partial Wave Analysis\nHow many numbers do I need in order to compute electromagnetic interactions or gravity? Specifically, to predict the angular distribution, what input parameters are required? The current framework appears to miss some fundamental components.\nWhat is inside these interaction vertices or amplitude blocks? To predict all observable values, I need the transition amplitudes for different spin configurations.\nThe number of independent amplitudes is given by the spin degeneracy factor: (2j_1 + 1)(2j_2 + 1) where j_1 and j_2 are the spins of the particles involved. These amplitude values might also be functions of particle masses, particularly the masses of the intermediate states.\nA similar number of parameters is needed for the final state amplitudes, but there are reasonable approximation methods available.\n\n\n\n\n\n\nIn experimental analysis, we often make the initial assumption that these amplitude coefficients are constant, representing fundamental particle properties rather than dynamic functions. This simplification allows us to compute angular distributions without knowing the detailed internal dynamics.\n\n\n\nWith this constant amplitude assumption, I can compute the angular distribution while fixing the mass parameters and intensity normalization.\nThe differential decay rate with respect to \\cos\\theta is given by: \\frac{d\\Gamma}{d\\cos\\theta} \\propto |\\mathcal{M}|^2\nUsing \\cos\\theta rather than \\theta itself is preferable because it has a simpler Jacobian—we avoid the \\sin\\theta factor that appears in the \\theta distribution. The matrix element squared |\\mathcal{M}|^2 is typically treated as constant in this approximation.\nThe angular distribution spans from \\cos\\theta = -1 to \\cos\\theta = 1:\n\nA flat distribution indicates isotropic decay\nFor particles with spin, we often observe parabolic distributions (second-order polynomials in \\cos\\theta)\nOther characteristic patterns may appear depending on the spin structure\n\nIt’s crucial to recognize that A represents the quantum transition amplitude—a complex-valued quantity that gets squared to give the observed probability. In experiments, we only measure the squared magnitude of amplitudes.\nFor unpolarized decays, the distributions are averaged over initial spin projections and summed over final spin projections: \\frac{d\\sigma}{d\\Omega} \\propto \\frac{1}{(2s_1+1)(2s_2+1)} \\sum_{\\text{spins}} |\\mathcal{M}|^2\nWhen analyzing experimental data, we don’t initially guess the amplitude form directly. Instead, we project the angular distributions onto orthogonal polynomials, particularly Legendre polynomials: \\frac{d\\sigma}{d\\cos\\theta} = \\sum_{\\ell=0}^{L_{\\text{max}}} a_\\ell P_\\ell(\\cos\\theta)\nThis Legendre polynomial basis connects directly to the spins of the produced particles, forming the foundation of:\n\nPartial wave analysis: Modeling cross sections with amplitude parameters to learn about internal dynamics\nMoment analysis: Projecting differential cross sections onto polynomial moments\n\nThe initial projection onto polynomials doesn’t directly reveal the internal amplitude structure but provides combinations of these parameters that can be measured experimentally.\nThis approach isn’t straightforward, and we’ll have more opportunities to discuss it in detail. We’ve only briefly touched on the differences between canonical states (defined in the rest frame) and helicity states introduced later.\nFor comprehensive coverage of this subject, I recommend Martin Spearman’s Elementary Particle Theory, particularly Chapter 4, which covers:\n\nLorentz group fundamentals\nVector construction methods\nAccessible group theory applications\nParticle state definitions\n\nThe chapter provides substantial insights without overwhelming mathematical complexity.\nExercise Assignment: I will distribute Dalitz plots from CLEO and BaBar experiments with removed particle labels. You’ll receive:\n\nOne D meson decay dataset\nOne D_s meson decay dataset Using your kinematic knowledge, your task is to:\nDetermine particle masses from the kinematic boundaries\nIdentify the specific decay processes Each group will analyze one case initially, then examine additional examples.\n\n\n\n6.5 Office Hours Arrangement\n\nPeople, I have to leave now.\n\n\n\n\n\n\nThis portion of the lecture contains only administrative announcements about homework distribution and scheduling—no physics formulas or technical content are present in this segment.\n\n\n\nHomework Distribution:\n\nIf you don’t want to take the homework now, I’ll distribute it from my office.\nPlease come with me to collect it.\nThis applies to all of you.\n\nSchedule & Apologies:\n\nThank you for coming, and I apologize for being slightly late.\nWill you have time tomorrow at 8am?\nYou may leave now."
  },
  {
    "objectID": "2024-Lecture-06.html",
    "href": "2024-Lecture-06.html",
    "title": "(2024) Lecture 6",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-06.html#lambda-decay-kinematics-and-unpolarized-width",
    "href": "2024-Lecture-06.html#lambda-decay-kinematics-and-unpolarized-width",
    "title": "(2024) Lecture 6",
    "section": "1 Lambda Decay: Kinematics and Unpolarized Width",
    "text": "1 Lambda Decay: Kinematics and Unpolarized Width\nLet’s start with the recap. The physics reaction to consider is the lambda baryon decay into the proton and a pion.\nWe go through a standard list to understand any reaction:\n\nWhat type of interaction is responsible?\nWhat variables describe the process?\nWrite the matrix element.\nCalculate the unpolarized decay width. ### 1. Identifying the Interaction\n\n\n\n\n\n\n\nFigure 1: This figure presents a schematic representation of the decay process \\Lambda \\rightarrow p + \\pi^- in the context of particle physics. The initial state is a \\Lambda baryon, with spin-parity J^P = \\frac{1}{2}^+ and quark content uds , decaying into a proton ( p ) with quark content uud and the same spin-parity, and a negatively charged pion ( \\pi^- ) with quark content \\bar{u}d and spin-parity 0^- . The diagram includes notations identifying each particle’s quantum numbers and quark composition. Importantly, the vertex connecting the initial and final states is labeled as “weak,” highlighting that this process proceeds via the weak interaction rather than the strong force. This distinction is physically significant because the decay involves a change in strangeness ( \\Delta S = 1 ), which is only possible through weak interactions due to flavor conservation by the strong interaction. The figure visually reinforces key lecture themes: the necessity of the weak force for strangeness-changing decays, and the role of quantum numbers (spin, parity, strangeness) and quark content in determining allowed interactions. The physical meaning, as discussed in the text, is that the \\Lambda baryon’s comparatively long lifetime and the observation of flavor-changing decays are direct evidence for the weak interaction’s unique properties, including parity violation.\n\n\n\nWe have a \\Lambda , a proton, and a pion. This is a flavor-changing process:\n\nInitial state ( \\Lambda ): quark content uds , strangeness S = -1 .\nFinal state ( p + \\pi^- ): quark content uud + \\bar{u}d , strangeness S = 0 .\n\nStrangeness-changing transitions can only proceed via the weak interaction, as strong and electromagnetic interactions conserve flavor. Since the weak interaction violates parity, this decay will not conserve parity.\n\n\n\n\n\n\nThe key identifier is the strangeness change: \\Delta S = 1 . This uniquely specifies the interaction as weak.\n\n\n\n\n1.1 2. Kinematics and Variables\nThis is a one-to-two body decay: \\Lambda \\to p + \\pi^- . The simplest approach is to work in the center-of-mass frame, which is the rest frame of the decaying \\Lambda .\nIn this frame:\n\nThe \\Lambda is at rest.\nThe proton and pion are emitted back-to-back.\nThe magnitude of their momentum |\\mathbf{p}| is fixed entirely by the particle masses via energy-momentum conservation:\n\n|\\mathbf{p}| = \\frac{1}{2M_\\Lambda} \\sqrt{ [M_\\Lambda^2 - (m_p + m_\\pi)^2] [M_\\Lambda^2 - (m_p - m_\\pi)^2] }\nSince there is no preferred direction when the \\Lambda is at rest, there are no free angular variables. The only remaining degrees of freedom are the discrete spin projections of the particles involved.\nParticle Spins and Parity:\n\n\\Lambda : Spin J=\\frac{1}{2} , Parity P=+ ( J^P = \\frac{1}{2}^+ )\nProton: J^P = \\frac{1}{2}^+\nPion: J^P = 0^-\n\n\n\n1.2 3. The Matrix Element and Helicity Amplitude\nThe transition amplitude H describes the process. Given the kinematics, H cannot depend on angles, but it does depend on spin projections.\nLet the spin projection (helicity) of the \\Lambda be \\lambda_\\Lambda and of the proton be \\lambda_p . The pion is spinless. Angular momentum conservation along the decay axis requires: \\lambda_\\Lambda = \\lambda_p\nWe denote this common value simply as \\lambda = \\pm\\frac{1}{2} .\nTherefore, the helicity amplitude is: H_{\\lambda} = \\langle p(\\mathbf{p}, \\lambda), \\, \\pi^-(-\\mathbf{p}) \\, | \\, \\mathcal{T} \\, | \\, \\Lambda(\\mathbf{0}, \\lambda) \\rangle\nWe have two independent amplitudes: H_{+1/2} and H_{-1/2} .\n\n\n1.3 4. Unpolarized Decay Width\nThe decay width \\Gamma for a spin- \\frac{1}{2} particle is given by: \\Gamma = \\frac{1}{2M_\\Lambda} \\times (\\text{Spin-Averaged } |\\mathcal{M}|^2) \\times (\\text{Phase Space})\n\nSpin Average/Sum: We average over the 2 initial \\Lambda spin states and sum over the 2 final proton spin states. The condition \\lambda_\\Lambda = \\lambda_p means only two terms survive: |H_{+1/2}|^2 and |H_{-1/2}|^2 .\nPhase Space: For a two-body decay in the parent’s rest frame, the Lorentz-invariant phase space integrates to \\frac{|\\mathbf{p}|}{8\\pi^2 M_\\Lambda^2} \\int d\\Omega . With no angular dependence, \\int d\\Omega = 4\\pi .\n\nPutting it all together, the unpolarized width simplifies to: \\Gamma = \\frac{|\\mathbf{p}|}{8\\pi M_\\Lambda^2} \\left( |H_{+1/2}|^2 + |H_{-1/2}|^2 \\right)\nThis width, for the dominant decay \\Lambda \\to p \\pi^- , determines the \\Lambda baryon’s lifetime: \\tau_\\Lambda = \\frac{\\hbar}{\\Gamma} \\approx 10^{-9} \\, \\text{s}\nThis lifetime is long enough that the \\Lambda travels measurable distances (e.g., meters in a detector) before decaying, creating a displaced secondary vertex—a key experimental signature.\n\n\n1.4 5. Extension: The Helicity Frame for a Moving \\Lambda\nThe discussion so far assumed a \\Lambda at rest. If the \\Lambda is moving in the lab frame, its momentum defines a preferred axis (the helicity frame). By boosting to the \\Lambda ’s rest frame along this axis, we can now measure decay angles ( \\theta, \\phi ) relative to it.\nThis introduces angular dependencies into the decay distribution. For a polarized \\Lambda , the differential decay rate takes the form: \\frac{d\\Gamma}{d\\cos\\theta} \\propto 1 + \\alpha \\, P_\\Lambda \\cos\\theta\nwhere P_\\Lambda is the \\Lambda polarization and \\alpha is the decay asymmetry parameter, which encodes the parity violation in the weak decay and is related to the helicity amplitudes: \\alpha = \\frac{|H_{+1/2}|^2 - |H_{-1/2}|^2}{|H_{+1/2}|^2 + |H_{-1/2}|^2}\nThis angular analysis allows experiments to extract spin and parity-violation information."
  },
  {
    "objectID": "2024-Lecture-06.html#spin-states-and-helicity-transformations",
    "href": "2024-Lecture-06.html#spin-states-and-helicity-transformations",
    "title": "(2024) Lecture 6",
    "section": "2 Spin States and Helicity Transformations",
    "text": "2 Spin States and Helicity Transformations\nI would like to start giving a bit more detail on the topic from last time. ### Canonical Spin States and Rotations\n\n\n\n\n\n\nFigure 2: This figure illustrates the concept of rotating a particle’s state in the context of canonical spin states. The particle, initially at position M on the Z -axis, is subjected to an active rotation—meaning the particle itself is rotated, not the coordinate system. The curved arrow represents a rotation about the Y -axis, changing the direction of the particle’s momentum from the Z -axis towards the X -axis by an angle \\theta . This visualization directly connects to the discussion in the lecture about how canonical spin states |J, M\\rangle transform under rotations, and how Wigner D-functions describe the resulting mixture of spin projections after such a rotation. This process is fundamental for constructing helicity states and understanding how the spin quantization axis changes relative to the particle’s motion.\n\n\n\nThe state |J, M\\rangle is the base state of a particle with spin J and has a projection onto the Z-axis equal to M . If you act with the J_z operator, you find that this is an eigenstate of J_z with eigenvalue M .\nJ_z |J, M\\rangle = M |J, M\\rangle\nThis defines the canonical spin state, where the quantization axis is fixed as the Z-axis. The picture to have in mind is the 2J + 1 possible projections of the state, which could be in a mixed state.\nAll transformations we will apply are active transformations. It’s easier to think of them as transformations applied to the particles themselves, not to the coordinate system. The coordinate system remains fixed. If I boost or rotate and show you a direction, that operation is applied to the physical object.\n\nIf I boost a particle in the Z direction, the particle gets faster and moves along Z.\nIf I rotate my particle by an angle about the Y axis, I rotate the particle, not the coordinates. Rotations about the Y axis are often the most nontrivial and are what we will focus on.\n\nWhen we rotate a spin state with a definite projection M , we find it becomes a combination of states with different projections:\nR(\\theta) |J, M\\rangle = \\sum_{M'} D^J_{M'M}(\\theta) |J, M'\\rangle\nThe coefficients D^J_{M'M}(\\theta) are the Wigner D-functions. They are tabulated, often alongside Clebsch-Gordan coefficients.\n\n\n\n\n\n\nSince we discussed SU(2) extensively with Isospin, the group theory here is exactly the same. To compute these rotations, you can either look up the Wigner D-functions or perform a matrix exponentiation: R(\\theta) = e^{-i J_y \\theta} . The matrix form of J_y depends on the spin J .\n\n\n\n\n2.1 Explicit Rotation Matrices\nFor a spin-1/2 particle, the generator J_y is \\frac{1}{2}\\sigma_y , where \\sigma_y is the Pauli matrix. The rotation operator is:\nR_{1/2}(\\theta) = e^{-i \\frac{\\theta}{2} \\sigma_y}, \\quad \\text{where } \\sigma_y = \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix}\nExponentiating this gives the explicit 2x2 rotation matrix:\ne^{-i \\frac{\\theta}{2} \\sigma_y} = \\begin{pmatrix} \\cos\\left(\\frac{\\theta}{2}\\right) & -\\sin\\left(\\frac{\\theta}{2}\\right) \\\\ \\sin\\left(\\frac{\\theta}{2}\\right) & \\cos\\left(\\frac{\\theta}{2}\\right) \\end{pmatrix}\nNote the half-angle \\theta/2 , which is characteristic of spinor representations. For higher spins (e.g., spin-1), the matrix in the |J, M\\rangle basis is more complicated, involving terms like (1 - \\cos\\theta) instead of just \\cos\\theta .\n\n\n2.2 Constructing Helicity States for Moving Particles\nNow, let’s understand what happens to spin states when we boost them. The goal is to define spin quantization for a moving particle.\n\n\n\n\n\n\nFigure 3: This figure illustrates the concept of a moving particle and the definition of its spin state in the context of Lorentz transformations, as discussed in the provided lecture notes. - Top Panel: Shows a coordinate system with axes x and z , and a momentum vector \\vec{p} pointing in the xz -plane. This represents a particle moving with momentum \\vec{p} in a given direction, not aligned with the coordinate axes. - Bottom Panel: Depicts the same coordinate system, with the momentum vector \\vec{p} again in the xz -plane. Additionally, a vector labeled m appears, likely representing the spin projection direction (or magnetic quantum number orientation) with respect to the axes. Physical Meaning: The image demonstrates that for a moving particle, there are two important directions to consider: 1. Momentum direction ( \\vec{p} ) – the direction of the particle’s motion. 2. Spin quantization axis ( m ) – the direction along which the particle’s spin projection is specified. The key concept depicted is the difference between the canonical basis (spin projection along the fixed z -axis, regardless of the particle’s momentum) and the helicity basis (spin projection along the direction of motion, i.e., the momentum \\vec{p} ). This figure corresponds to the lecture’s discussion on constructing helicity and canonical states for moving particles: - Helicity State: Spin is quantized along the momentum direction ( \\vec{p} ). - Canonical State: Spin is quantized along a fixed axis (typically z ), irrespective of the actual momentum direction. The illustration sets up the need to relate these two descriptions (basis choices) using appropriate Lorentz transformations (boosts and rotations). This is foundational for understanding how spin states transform for moving particles and is essential for analyzing decays and scattering processes in relativistic (high-energy) physics.\n\n\n\nConsider a particle moving in the XZ plane. There are two common ways to define its spin state:\n\nHelicity Basis: Quantize the spin along the direction of motion.\nCanonical Basis: Define the state with non-zero momentum but quantize the spin along the fixed Z-axis.\n\nThese two bases are not equal, but they are related. A state with definite helicity (spin projection along momentum) will be a mixed state in the canonical basis, and vice versa.\nThe helicity state |p, \\lambda\\rangle is constructed systematically:\n\nStart with a particle at rest in a canonical state |0, \\lambda\\rangle , with spin projection \\lambda along the Z-axis.\nBoost it along the Z-axis with a boost B_z(\\beta) to give it momentum.\nRotate the entire system using a rotation R(\\phi, \\theta, 0) to point the momentum in the desired direction p .\n\nThis construction is summarized by the formula:\n|p, \\lambda\\rangle = R(\\phi, \\theta, 0) \\, B_z(\\beta) \\, |0, \\lambda\\rangle\n\n\n2.3 Key Properties and Lorentz Algebra\nHelicity states have an important property: helicity is invariant under rotations.\nR(\\alpha) |p, \\lambda\\rangle = |p', \\lambda\\rangle\nwhere p' = R(\\alpha) p . Rotating the state simply rotates the momentum vector, but since the spin quantization axis is tied to the momentum direction, the helicity eigenvalue \\lambda remains the same.\nThe most demanding part of working with these states is managing the algebra of boosts and rotations. A key relation in the Lorentz group is that any combination of a boost, a rotation, and another boost can be rewritten as a different combination of a rotation and a boost:\nB' R B \\Leftrightarrow R^{-1} B' R\nWhen you apply this to a canonical state, you get a linear combination of helicity states, \\sum C_{\\lambda'} |p, \\lambda'\\rangle .\nWe know how Lorentz transformations act on 4-vectors like momentum. For example, a boost along the Z-axis is represented by the matrix:\nB_z(\\beta) = \\begin{pmatrix}\n\\gamma & 0 & 0 & \\gamma\\beta \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n\\gamma\\beta & 0 & 0 & \\gamma\n\\end{pmatrix}, \\quad \\gamma = (1-\\beta^2)^{-1/2}\nThe remaining task is to track how the spin projection mixes with the directional motion under these transformations. The result is intuitive: a transformation generally produces a linear combination of different spin projections, not a single one. The exact coefficients are found by applying the boost-rotation composition rules."
  },
  {
    "objectID": "2024-Lecture-06.html#boost-rotation-relations-and-state-notation",
    "href": "2024-Lecture-06.html#boost-rotation-relations-and-state-notation",
    "title": "(2024) Lecture 6",
    "section": "3 Boost-Rotation Relations and State Notation",
    "text": "3 Boost-Rotation Relations and State Notation\nWhat will happen here is that we started with a vector. Instead of boosting this vector directly—which would make it a little more inclined forward—you could start from the particle’s rest frame.\nThe boost-rotation-boost sequence applied to the particle’s thrust is equivalent to this long vector expression. This is the same as rotating and then boosting. The boost I apply to the particle at rest directly produces my vector with the desired momentum magnitude. The only additional operation needed is a rotation to orient it. So, instead of boosting twice, I can boost only once to achieve a vector of a specific speed or length. That’s the essence of the relation shown.\nNow, let’s examine the second type of state: the canonical state, and how we obtain it.\nThe canonical state is defined by the following combination of operations. First, consider the recipe for achieving a state where the momentum \\mathbf{p} is rotated by an angle \\theta from the z-axis:\n\nBegin in the particle’s rest frame.\nApply a rotation R^{-1} so that the state has a specific projection onto the z-axis. After this rotation, you can visualize the spin arrow pointing slightly downward.\nThen, boost this state forward along the new direction.\n(see Figure 3) Finally, apply the rotation R .\n\nLet me visualize this: We have the initial state, we boost it to give it momentum, then we perform the final rotation, and voila, we arrive at the desired configuration.\n\n\n\n\n\n\nOn Notation: When I write |\\mathbf{p}, j, m \\rangle , you must ask: is this a canonical state or a helicity state? Strictly speaking, seeing \\mathbf{p} , j , and another number doesn’t tell you.\nIn general notation, m usually refers to the z-axis projection (canonical), while \\lambda refers to the helicity. It is much better to indicate this explicitly, for example, by adding a subscript like _{\\text{can}} or _{\\text{hel}} . I will sometimes be less precise when rushing, but clear notation is important to avoid confusion.\n\n\n\nIt is now clear how the two types of states are related. But before discussing that relation, let’s look at the transformation property of canonical states.\nTransformation of Canonical States\nI want to apply a rotation R to a canonical state |\\mathbf{p}, j, m \\rangle_{\\text{can}} . According to the definition, this state is constructed as R B R^{-1} acting on the rest state |0, j, m \\rangle .\nSo, we compute: R |\\mathbf{p}, j, m \\rangle_{\\text{can}} = R (R' B R'^{-1}) |0, j, m \\rangle\nwhere R' and B are the specific rotation and boost used to create |\\mathbf{p}, j, m \\rangle_{\\text{can}} from the rest state.\nTo proceed, I insert an identity ( R'^{-1} R' ) in a strategic spot: = (R R') B (R'^{-1} R) R^{-1} |0, j, m \\rangle\nBy grouping the operations, the combination (R R') B (R'^{-1} R) becomes a new boost-rotation sequence that generates a canonical state with a rotated momentum \\mathbf{p}' = R\\mathbf{p} . The remaining operation R^{-1} acts directly on the rest state.\nWe know how a rotation acts on a rest-state spin projection: it’s given by the Wigner D-matrix. Therefore, the result is a linear combination: R |\\mathbf{p}, j, m \\rangle_{\\text{can}} = \\sum_{m'} D^j_{m'm}(R) |\\mathbf{p}', j, m' \\rangle_{\\text{can}}\nwhere \\mathbf{p}' = R \\mathbf{p} .\nDoes the momentum change? Yes, it gets rotated to \\mathbf{p}' . In the construction, after the initial boost along the z-axis, the momentum is p\\hat{z} . The subsequent rotation R then rotates this momentum to its final direction \\mathbf{p}' ."
  },
  {
    "objectID": "2024-Lecture-06.html#helicity-states-and-parity-violation-in-lambda-decay",
    "href": "2024-Lecture-06.html#helicity-states-and-parity-violation-in-lambda-decay",
    "title": "(2024) Lecture 6",
    "section": "4 Helicity States and Parity Violation in Lambda Decay",
    "text": "4 Helicity States and Parity Violation in Lambda Decay\nI learned you to boost yourself in the exercises, and now let’s discuss their relation to boosted states.\nSo, have a look at them and tell me how you would relate them. If you need to relate one to another: this is a boosted state, and this is a canonical state.\nHere we have the sequence B, J, N, C, T, N, J, M, \\text{can} . What I want to write clearly is: they are not equal to each other, but one can express the boosted state |\\psi(p, j, \\lambda)\\rangle as a linear combination of canonical states. These coefficients are then—I would like you to have a clear understanding of how we find them.\n\n4.1 1. Relating Boosted and Canonical States\nThis state is defined according to a specific transformation. What that means: on the left side, we have R^{-1} , a rotation. In order to apply “rotation, boost, rotation minus one” to the state, I like to introduce R^{-1} R (the identity). Once I do that, I have something like this, but then R B R^{-1} will be my boost that makes the canonical state. What remains is to apply the R to this state, and you know how to apply R . This is simply it.\n\n\n\n\n\n\nPhysics meaning: A boosted state |\\psi(p, j, \\lambda)\\rangle with definite momentum p and helicity \\lambda is connected to a rest-frame canonical state |\\psi(0, j, m)\\rangle via Lorentz transformations: |\\psi(p, j, \\lambda)\\rangle = R(B) |\\psi(0, j, m)\\rangle , where R(B) is the rotation associated with the boost direction.\n\n\n\n\n\n4.2 2. Revisiting Lambda Decay and the Helicity Frame\nI wanted to quickly come back to the \\Lambda decay and tell a little more about how we derived the formula. The large peak formula involves many D -functions and H ’s from the last lecture.\nI’m going to consider now a \\Lambda that moves in the wave frame. It has a helicity, and then it decays. To define the z -axis, we need the direction of motion of the \\Lambda in the lab frame.\n\n\n\n\n\n\nFigure 4: This figure illustrates the decay of a polarized \\Lambda baryon, focusing on the transformation between different reference frames using the concept of the helicity frame. - Leftmost: A \\Lambda baryon is moving with its spin polarization (indicated by \\lambda_\\Lambda ) along the z -axis. This represents the initial state, where the \\Lambda is in motion (lab frame). - Center: Upon decay, the \\Lambda produces a proton ( p ) and a pion ( \\pi ). Their momenta ( \\vec{p}_p and \\vec{p}_\\pi ) and spin projection \\lambda_p for the proton are shown lying in a specific plane, which is crucial for defining the decay kinematics. This plane is set by the \\Lambda ‘s momentum and the outgoing proton/pion momenta. - Rightmost: The diagram is labeled by the operation B^{-1} , representing a Lorentz boost to the \\Lambda rest frame (i.e., the “helicity frame”). In this frame, the decay products’ momenta become back-to-back and lie in the same decay plane, with the definitions of the z -axis and the helicity angle \\theta  relative to the polarization direction preserved. Physical meaning: The sequence demonstrates how, for a polarized \\Lambda baryon decay, one defines the quantization axis (the z -axis) by the \\Lambda ’s motion. Then, by boosting into the \\Lambda rest frame (helicity frame), the angular distribution of the proton (or pion) can be analyzed relative to the polarization vector. This enables measurement of the decay asymmetry and parity violation in the process, as encoded in the \\cos\\theta dependence of the decay products in the helicity frame. The figure clarifies the importance of boosting to the correct frame and defining the correct angles for extracting physical information, such as the polarization and analyzing power \\alpha in weak decays.\n\n\n\nAfter the boost, that direction gives us the z -axis. This way of defining the z -axis is called the helicity frame for the \\Lambda .\n\nYou always have to describe from which frame you are boosting, because it depends. In different frames, the direction of the \\Lambda will be different, leading to differences when you arrive at the \\Lambda ’s rest frame.\nThe helicity frame is defined as the rest frame of a particle obtained by boosting from the frame where it was moving.\nThe angle of the decay particle, when you take one of the particles (e.g., particle number one) and use it to define the angle, is called the helicity angle. That’s common jargon in hadron physics.\n\nWhen we talk about the helicity angle, it implies that we:\n\nBoosted to the particle’s rest frame.\nTook one of the decay products as a reference.\nMeasured the angle from there.\n\nAll the motion is still in the same plane as before. The boost and the two particle momenta are now exactly opposite. So here, the boost inverse has happened.\nLet’s visualize the process:\n\nWe start with a \\Lambda flying in the z -direction with a certain velocity.\nIt decays into a proton and a pion in some plane.\nWe invert the boost (go to the \\Lambda rest frame).\nThe proton and pion are still in the same plane, with exactly opposite directions.\n\nIf I removed the original \\Lambda momentum from this picture, you would no longer have a defined plane. The plane is formed by three vectors: I need the original direction of motion of the \\Lambda to define the axis with respect to which I measure the angle, and then I have a plane.\n\n\n4.3 3. Calculating the Decay Amplitude\nThis was our recap exercise. We started without knowing that, so we only had one axis. But now we have a plane and one more variable on which the amplitude depends—the scattering or helicity angle \\theta —in addition to the discrete helicity variables.\nWe have to compute a final state, which will be a two-body decay. On the right side, we have configurations of the \\Lambda sitting in its rest frame with the proton and pion. On the left side, we have the configuration of the moving \\Lambda .\nThe way to proceed is to apply a rotation to this configuration to align it. The answer for the transition matrix element in the helicity basis is H_{\\lambda_p, \\lambda_\\Lambda} .\n\\mathcal{M}_{\\lambda_p, \\lambda_\\Lambda} = \\langle p, \\pi^-; \\lambda_p | T | \\Lambda; \\lambda_\\Lambda \\rangle\nThis is the equation we had last time, describing the matrix element for the decay sequence. The way we get there is by applying the transition operator T on the final state to simplify it. This T acts on the proton-pion state.\nWe want to evaluate the application of the transition operator that takes a pion-proton state and transforms it into a \\Lambda . This operator acts on the pion-proton state that has momentum \\vec{P}=0 . We notice this state is rotated about the y -axis by the angle \\theta . We want to align it because, on the left, the state has aligned combinations. So, we have a rotation.\nWe pull out the rotation, and then we have the same combination now along the z -axis: the proton goes forward, the pion goes backward, and the rotation is explicit. Since these operators commute (strong interactions conserve spin), we can compute the transition operator and rotation, acting first with the transition and then by the rotation.\nEssentially, this transition operator transforms a pion-proton state into a \\Lambda . We explicitly do this by inserting an identity (a sum over \\Lambda states) here. This matrix element we just evaluated is related to LS coupling. The inserted identity should have all possible combinations, giving a sum over \\lambda_\\Lambda , which results in delta functions. Therefore, we select only one state.\nThe last step is to apply the rotation. Once you get the idea, it’s easy to see that for every bit of the transition, you have the product of a helicity transition matrix element and a rotation matrix (a Wigner D -function).\n\n\n\n\n\n\nRotation of Helicity States: Under a rotation R(\\theta, \\phi) , a helicity state transforms as: R(\\theta, \\phi) |p, j, \\lambda\\rangle = \\sum_{m'} D_{m'\\lambda}^j(\\phi, \\theta, 0) |p', j, m'\\rangle\nwhere D_{m'\\lambda}^j are the Wigner D-matrices. For spin-1/2, this matrix is: D^{1/2}_{m'm}(\\phi, \\theta, 0) = \\begin{pmatrix} e^{-i\\phi/2}\\cos(\\theta/2) & -e^{-i\\phi/2}\\sin(\\theta/2) \\\\\\\\ e^{i\\phi/2}\\sin(\\theta/2) & e^{i\\phi/2}\\cos(\\theta/2) \\end{pmatrix}\n\n\n\n\n\n4.4 4. Differential Cross Section and Parity Violation\nNow, the differential cross section exists as a function of the angle \\theta . We know these are our cosine and sine matrices. For spin-1/2, we just had an explicit matrix, and we have two coupling constants measured in experiment. You can take them to compute the angular distribution.\nThe answer is the same as before because \\sin^2 + \\cos^2 = 1 . In front of one term, you have \\sin^2 + \\cos^2 ; in front of the other, you have -\\sin^2 + \\cos^2 .\nWhat we learned in this example is that if you have an unpolarized particle, you will not observe any interesting angular distribution. We summed over the final and initial states, and no non-trivial angular distribution remains for d\\Gamma/d\\Omega before integrating over \\cos\\theta .\nNow we have a differential cross section. Before, we just wrote that \\Gamma is equal to something, and the phase space has d\\Omega/(4\\pi) , an integral d\\cos\\theta/2 , d\\phi/(2\\pi) .\n\n\n\n\n\n\nFigure 5: This diagram represents the angular distribution of an unpolarized two-body decay in the particle’s rest frame, specifically showing the differential decay rate \\frac{d\\Gamma}{d\\cos\\theta} as a function of \\cos\\theta for a decay like \\Lambda \\to p \\pi^- when the initial particle is unpolarized. - The horizontal axis runs from -1 to +1 , which corresponds to the allowed range of \\cos\\theta , with \\theta being the decay angle between the decay product’s momentum and some fixed axis (normally, the direction of the parent particle’s spin or momentum). - The vertical axis represents the value of the differential decay rate, \\frac{d\\Gamma}{d\\cos\\theta} . - The height of the boxes (constant for all \\cos\\theta ) indicates that the decay distribution is isotropic, i.e., independent of angle, which occurs when there is no initial polarization and no parity-violating asymmetry ( \\alpha = 0 ) in the decay. Physically, this tells us that for an unpolarized initial state, the decay products are emitted equally likely in all directions, resulting in a flat angular distribution of \\frac{d\\Gamma}{d\\cos\\theta} versus \\cos\\theta . This matches the expectation from weak decays with no preferred direction due to polarization or parity violation.\n\n\n\nNow I just move this \\cos\\theta dependence to the other side.\nPolarized decay: You get non-trivial distributions if you polarize your particle. When the \\Lambda was flying, it had a spin projection \\lambda_\\Lambda . Now we have a formula that tells us how this looks.\nLet’s think about what we see in an experiment. The \\Lambda travels with a certain momentum, and the projection of its spin onto its direction of motion is \\pm 1/2 . When it decays, we will find that it’s more likely for the proton to travel forward than backward relative to the \\Lambda spin direction. This angle is the proton’s helicity angle.\nThis violates parity. If you apply parity to the initial and final states, you flip the momentum but not the spin. Parity implies there cannot be such a forward-backward asymmetry. This is consistent with the fact that we consider the decay amplitude inside the interaction to be from the weak force.\n\n\n\n\n\n\nFigure 6: This figure illustrates the angular distribution of the decay products in the weak decay of a polarized \\Lambda baryon, such as \\Lambda \\rightarrow p + \\pi^- . The vertical axis represents the differential decay rate \\frac{d\\Gamma}{d\\cos\\theta} as a function of the cosine of the decay angle \\theta (measured relative to the \\Lambda spin or polarization axis). The diagram shows a forward-backward asymmetry, where the decay rate is higher in the forward direction (along the spin or polarization) than in the backward direction. This kind of asymmetry is a hallmark of parity violation in weak decays. The strength of the asymmetry is governed by the decay asymmetry parameter \\alpha and the polarization P : \\frac{d\\Gamma}{d\\cos\\theta} \\propto 1 + \\alpha P \\cos\\theta A nonzero slope indicates \\alpha \\neq 0 , meaning that the angular distribution can be used to measure the polarization of the parent \\Lambda baryon. The regions labeled in the plot correspond to the fraction of events moving “forward” vs. “backward”, and the observable forward-backward asymmetry A_{FB} can be extracted by comparing these event counts. This asymmetry is a direct probe of parity violation and the polarization transfer in the decay.\n\n\n\nThe parity violation appears explicitly if the two helicity amplitudes H_{1/2} and H_{-1/2} are not equal. If they were equal, \\sin^2 + \\cos^2 gives 1, and there is no angle dependence.\n\\frac{d\\Gamma}{d\\cos\\theta} = \\frac{\\Gamma_0}{2} \\left(1 + \\alpha P_\\Lambda \\cos\\theta\\right)\nThe decay asymmetry parameter \\alpha quantifies this parity violation:\n\\alpha = \\frac{|H_{1/2}|^2 - |H_{-1/2}|^2}{|H_{1/2}|^2 + |H_{-1/2}|^2}\nIf \\alpha = 0 , the angular distribution is symmetric (parity conservation). If \\alpha \\neq 0 , it indicates parity violation, as in the weak decay of the \\Lambda ."
  },
  {
    "objectID": "2024-Lecture-06.html#polarization-analyzing-power-and-polarimetry-in-lambda-decay",
    "href": "2024-Lecture-06.html#polarization-analyzing-power-and-polarimetry-in-lambda-decay",
    "title": "(2024) Lecture 6",
    "section": "5 Polarization, Analyzing Power, and Polarimetry in Lambda Decay",
    "text": "5 Polarization, Analyzing Power, and Polarimetry in Lambda Decay\nThanks for the question. That’s really important to know, and in fact they are not.\nMoreover, we consider the polarized decay: if the 100% polarization P = 1 is a pure state, it is a spin projection 1/2 and it’s a fully polarized state. One can consider a mixed state where you don’t have that, where it’s not fully polarized.\nMost realistically, the degree of polarization for the lambda hyperon is not 100% but let’s say 60%. That’s what we have. In the BES experiment case, the lambda is produced with a polarization of about 60%, and in that case the asymmetry is smaller.\nSo one finds that the differential decay rate is given by: \\frac{d\\Gamma}{d\\cos\\theta} = \\Gamma_0 ( 1 + \\alpha P \\cos\\theta )\nPhysics Meaning:\n\n\\frac{d\\Gamma}{d\\cos\\theta} is the differential decay rate.\n\\Gamma_0 is the total decay rate or normalization constant.\n\\alpha is the analyzing power (or decay asymmetry parameter).\nP is the degree of polarization of the parent particle (e.g., Λ hyperon).\n\\cos\\theta is the cosine of the angle between the decay product’s momentum and the polarization axis.\n\nWe can rewrite these equations by contracting the matrix element with the polarization matrix and find out that the difference between the two hemispheres defines how well this particular decay reflects polarization.\nThe quantity \\alpha , the analyzing power, tells you how well this decay is suited to measure the initial polarization. If the scalar and pseudoscalar coupling constants g_S and g_P are equal to each other |g_S| = |g_P| , you don’t have sensitivity to the initial polarization. The decay is insensitive.\n\n\n\n\n\n\nThis condition \\alpha = 0 when |g_S| = |g_P| means parity violation may not be observable via the angular distribution, even if the decay intrinsically violates parity. For most decays, however, there is a non-zero analyzing power.\n\n\n\nIt can happen even for big decays that the couplings are equal. Parity can be violated, but it’s not measured. But for most of them there is a non-zero analyzing power. So this \\alpha is non-zero.\nAnd that’s why by looking at the angular distribution you see parity violation. But you can also measure the initial polarization. That’s called a polarimetry technique and that’s actively used.\nThe polarization P can be extracted from the measured forward-backward asymmetry: A_{FB} = \\frac{N(\\cos\\theta &gt; 0) - N(\\cos\\theta &lt; 0)}{N(\\cos\\theta &gt; 0) + N(\\cos\\theta &lt; 0)} = \\frac{\\alpha P}{2}\nwhere N denotes the number of decays in the forward or backward hemispheres.\nLook at the angular distributions. All particles have known spin, the couplings are known. But these parameters have to be measured in advance. And in that case you can measure polarization.\nThis initial polarization is a super powerful observable. So particles like lambda hyperons with a spin carry polarization out of the interaction point, which is part of the information.\n\nHow the lambda is produced\nWith what momentum\nWith what polarization\n\nThis tells us about the internals of the interaction. For example, imagine that a lambda hyperon is produced in the quark-gluon plasma. Its polarization can now be related to the properties of that plasma.\nThis is a kind of free carrier of information out of the mess of the quark-gluon interaction. So polarization plays an important role, if not more than other observables. And this particle is not only carrying it, but also by decaying gives us a way to measure that polarization."
  },
  {
    "objectID": "2024-Lecture-06.html#a-pedagogical-pause",
    "href": "2024-Lecture-06.html#a-pedagogical-pause",
    "title": "(2024) Lecture 6",
    "section": "6 A Pedagogical Pause",
    "text": "6 A Pedagogical Pause\nWe have time. Instead of beginning a new topic, I would like to pose a question I have in mind for this lecture. This is as if I were to explain the material to you already—you would know it, but I haven’t explained it yet. Therefore, I’ll just give you a question and see if you know it without my lecture. Please let me know if you have any questions about this approach.\n\n\n\n\n\n\nThe speaker is introducing a pedagogical exercise. While no specific physics formulas are presented here, if the lecture proceeds into topics like nuclear physics, common formulas you might encounter include:\n\nRadioactive Decay Law: N(t) = N_0 e^{-\\lambda t}\nBinding Energy per Nucleon: B = \\frac{\\Delta m c^2}{A}\nCross-Section for Nuclear Reactions: \\sigma = \\frac{\\text{Number of reactions per unit time}}{\\text{Incident flux} \\times \\text{Number of target nuclei}}"
  },
  {
    "objectID": "2024-Lecture-06.html#analytic-structure-and-contour-integration-in-the-complex-plane",
    "href": "2024-Lecture-06.html#analytic-structure-and-contour-integration-in-the-complex-plane",
    "title": "(2024) Lecture 6",
    "section": "7 Analytic Structure and Contour Integration in the Complex Plane",
    "text": "7 Analytic Structure and Contour Integration in the Complex Plane\nNext lecture, we will move on to discussing analytic functions and properties of amplitudes in the complex plane. This requires you to have a little bit of complex analysis. We’ll discuss this, and even the next problem sheet has a bit of discussion on the complex plane. So we need a little bit of complex algebra.\nLet me just say where it comes from. What is written here is obtained by doing a contour integral. I started with a little circle. My function is analytic and I’m going to extend and stretch the circle in all directions. This is my x-plane, the complex plane.\nConsider the Cauchy integral of F(x) . If no singularities occur inside my integration contour, for any analytic function, the contour integration is zero. Then there is Cauchy’s theorem that tells me I can insert explicitly a singularity inside the circle. If I integrate \\frac{F(x')}{x' - x} dx' around the contour, the integral was zero. But now let me put a pole explicitly inside like this. When I integrate, my integral is not zero any longer. It’s equal to the function evaluated at the pole, and that’s my F(x) .\n\n\n\n\n\n\nThis is the essence of Cauchy’s Integral Formula. For an analytic function f(z) and a point a inside a simple closed contour C , the formula is: f(a) = \\frac{1}{2\\pi i} \\oint_C \\frac{f(z)}{z - a} \\, dz\nThis represents inserting a pole at z = a inside the contour, leading to a non-zero integral equal to the function’s value at that point.\n\n\n\nNow I have this expression here. It’s something similar. I started from a little contour, stretched it to infinity. This part of the contour dropped and the one thing that remained is the integral from 1 to 7. I’m integrating the imaginary part of F(x) from 1 to 7 and asking: can this equation be satisfied? The second question is: what is the analytic structure? What do you mean by analytic?\n\nCut both branch points. This is super maybe unusual for math courses, but that’s what we use all the time in physics is this type of integral where the leftover of the contour is from 1 to 7.\nSince the integral comes from both sides of the cut, and they have opposite signs, what remains is the imaginary part. The real part is the same and cancels. So the thing that remains is the integral of the imaginary part.\n\nThis leads to a dispersion relation: F(x) = \\frac{1}{\\pi} \\int_{1}^{7} \\frac{\\operatorname{Im} F(x')}{x' - x} \\, dx' + \\text{(possible subtractions)}\nHere, the function F(x) is reconstructed from its imaginary part along the cut from 1 to 7.\nIt’s just guessing. Yes, three is a solution. You can just take the constant three because it has no imaginary part. So the real question is if you remove the constant, are there non-trivial solutions? Sometimes we use words like non-vanishing. If I just say F(x) = 3 , then the imaginary part is not present anywhere. The question is about solutions beyond this constant.\nI think you’re completely right. But I was actually thinking of non-trivial solutions. Do they exist or not? You can probably put power expansions in. It might work, it totally could work. Correct, it can be satisfied. The answer is: give me any function \\rho(x) you want. I put it here. Any function \\rho(x) , that integral actually converges for any value.\nLet’s do \\rho(x) = \\sqrt{x} . Put it here and it’s satisfied. Just anything put inside the imaginary part, it’s satisfied. The reason we’re satisfied is this. It’s a way to construct the function. Let me show you this: I put \\sqrt{x} here instead of the imaginary part expression. Then this way I compute my function F(x) . Now this is a super special function. Its imaginary part is equal to \\sqrt{x} in the region from 1 to 7. If I evaluate, the imaginary part is equal to that. In the rest of the complex plane the function is non-zero, but there are no singularities.\nThis insertion that I made is actually done by introducing some non-trivial analytic structures.\nSo let’s now we have three candidates. What kind of non-analytic structures have I introduced? Well, I’d say it’s like a continuous stretch of poles, a stretch of poles. What is meant by a cut? They just end somewhere. Exactly. So the cut is this non-analytic structure where the function on one side is different from the function on the other side.\nIt’s like \\sqrt{-1 + i\\epsilon} and \\sqrt{-1 - i\\epsilon} . We see that this one is equal to +i and this one is equal to -i . So on different sides I have different values. This is a cut. So it’s not really anything else than a spectrum of poles. Poles have a divergence, and this thing does not have a divergence.\nSo what will you say? You go for poles. Okay, so you say that here I introduce poles. Are you attracted by the concept of branch points or cuts? I was thinking about cuts, but now I’m convinced both solutions are not poles. In the integral, there are no poles. Oh, you mean the integrand? Yeah, the integrand has poles, but they are at zero and x . You have to analytically continue something. Something like I say, it’s like you probably have to take it above the complex line or the real line, and below, probably differently. And I think you probably get different branches.\nWe say this and this. I’m not sure what the branch point is, to be honest. Oh, the branch point is where the cut starts and where it ends. So you forget about, let’s say the branch work for the elements. And then you get… Okay, what if, say, poles. So the analytic structure of my function in the x-plane, if I… This is the x-plane. My function has a branch point at 1, a branch point at 7, and then they’re connected by a cut. There are no poles. The function doesn’t have any poles.\nThat’s the way how we, I mean, the way of constructing the function here in this way, you introduce on the castle, you don’t do your space. It’s really funny to think, I mean, where this didn’t come from, go where. And then it appears that what you can do, you can look at this plane and then take a walk here. So here you walk, you never experience any poles, any singularities.\nWhat we can do, we can dive under. I mean, there. And you end up in a different world that has a gate. So it goes through the gate to the other world. And then you find that here there are poles, this is zero, it has poles. And then it has \\sqrt{x} , so it has another cut. The function has an interesting and complicated structure.\nThe complex plane on the regular complex plane where we call the function doesn’t have any singularities except one gate. Through the gate you can go to the other so-called sheet and there you have a lot of stuff going on. That’s it. I mean you just get used to it. And it’s really fun to think of this. We will discuss a little bit more of the complex chart structure and how scattering, what is actually the complex structure of the scattering amplitudes."
  },
  {
    "objectID": "2024-Lecture-06.html#complex-analysis-and-multivalued-functions",
    "href": "2024-Lecture-06.html#complex-analysis-and-multivalued-functions",
    "title": "(2024) Lecture 6",
    "section": "8 Complex Analysis and Multivalued Functions",
    "text": "8 Complex Analysis and Multivalued Functions\nWe have a two-week break next week, so we don’t have class. Have a nice holiday, everyone.\nLet’s make it simpler. The integral will always converge from 1 to 7. So this is what we have, and this is a logarithm. The logarithm itself can have a pole.\nLet’s evaluate the function at 8: \\log(1 - 8) - \\log(17 - 8) . So I’m going to say 8^+ and 8^- , and then \\log(1) = 0 . \\log(-1 - i0) is equal to \\log(-1) - i\\pi .\nWe arrived at the result that they equal each other. So dy is at -i0 and +i0 , but in the equation there is no… I mean, this is continuous. Here is the jump.\nFrom the difference here, the real part of x cannot be between 1 and 7 because we want to have a structure around it. We cannot have an x from 1 to 7 because we have the structures looping around it. Exactly. So the structure is looking around.\nYou introduced the branch point at the edges and then a cut connecting these points. It’s explicitly clear on the Riemann surface by doing a simple integral. You see this expression has this structure: a cut, a branch point at one, a branch point at seven, and then a cut.\nBut the branch point is it. Is it anything else but a pole? No. A branch point can have a divergence; the function could be infinity there. But this function doesn’t have one. So this function’s branch point is at zero and there is… Okay, but the function is zero. Here the function is infinity.\n\nA pole is something like 1/x^3 , which is a pole of third order.\n1/(x - c) \\log(x - c) is not a pole. The pole is something you can get rid of by adding an infinitesimal value in the denominator in the unique complex plane, but it would stay infinity. A pole is an isolated singularity. It means it’s just one point.\nAnd the branch point is a… Where did you hear these words? Of course, I only heard of poles for like your residue theorem and stuff like that. Probably some mathematics course, mathematics for physicists, I suppose, and I guess theoretical minimum, but quite a while ago. I’ve never heard of branch points. Well, you know this by other means, like for square root or \\log(x) . I guess I knew it existed, but I didn’t know like I… Now I fear that I scared people.\n\n\n\n\n\n\n\nOn Branch Cuts and Discontinuities The discussion of evaluating \\log(-1 - i0) relates to the discontinuity across a branch cut. For a logarithm, this is formally: \\text{Disc} \\, \\log(z) = \\log(z + i0) - \\log(z - i0) = 2\\pi i \\, \\Theta(-\\text{Re}(z))\nThis formula describes the jump of the logarithm across its branch cut along the negative real axis, which is essential for analyzing singularities in scattering amplitudes.\n\n\n\nI think for us your lectures are a bit unstructured and you’re like a bit all over the place. But it also makes it a bit more fun because your sketches of boosts, beasts, and rotations are just sketches. You don’t really prove anything in other courses; it’s like a strict or rigorous proof of everything, which is just not fun for a while.\nI wouldn’t be afraid regarding this course. I would rather be afraid regarding first semester courses. But you might confuse them obviously. So for teaching advanced people I’m fine, but you have to be more structured for younger students.\nWe go through the gate, but outside the gate. You said that function is fine, it’s continuous. But here you said it’s another gate. This is the first world, second world enter. Here we can walk around the gate, it’s fine. But then it goes through the gate and ends up another. This is another gate. This is because of how we choose; this is our first road.\nSo you can go through the gate and then appear on that world. And it has many more gates. You can go actually around this and enter on the other side; that’s where you come out here. It would somewhat make huge sense. At least you know what happens when you just return and go and then you appear here.\nBut if you do this, you are not in the end. It’s a third world. And then it’s an infinite number of worlds because it’s a logarithm. This gives an infinite number of worlds, but this one is a bit simpler. So we come here, you go to the first world. This is another world, and this guy has a gate still. You appear here and you can go around and then you appear here. So for this one, yes, it works because this one is a square root and this is logarithmic.\nBut imagine really taking the VR glasses and walking. That would be quite fun. You can suggest this to the Matrix Netflix. Make it an escape room: you only get out if you find the first gate. Escape room quest to this.\nAnd where does this function appear? All scattering amplitudes are like this. All of the scattering amplitudes as functions of Mandelstam variables have energies in the ** s -channel**.\n\n\n\n\n\n\nConnection to Physics This “multi-world” analogy describes the Riemann sheets of a complex function. In physics, scattering amplitudes \\mathcal{A}(s, t) are analytic functions of Mandelstam variables like s . They have:\n\nBranch points at physical thresholds (e.g., s_{\\text{th}} ).\nBranch cuts along the real axis, corresponding to where particle production can occur. The integral structure discussed, similar to a dispersion relation F(s) = \\int_{s_{\\text{th}}}^{\\infty} \\frac{\\rho(s')}{s' - s - i0}  ds' , gives rise to this exact analytic structure."
  },
  {
    "objectID": "2024-Lecture-07.html",
    "href": "2024-Lecture-07.html",
    "title": "(2024) Lecture 7",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-07.html#pentaquark-mass-and-quantum-numbers",
    "href": "2024-Lecture-07.html#pentaquark-mass-and-quantum-numbers",
    "title": "(2024) Lecture 7",
    "section": "1 Pentaquark Mass and Quantum Numbers",
    "text": "1 Pentaquark Mass and Quantum Numbers\nAll right, two minutes. So all of the problems are one-liners. You solved them online, but you have to know what to do. It’s okay.\n\n1.1 Question 1: The Pentaquark State\nLet’s discuss quickly question number one. First, the mass of the states. This appears as the particle. In this condition, neglecting inelastic channels, this particle is formed by the cascade \\Sigma_c and \\bar{D} .\n\n\n\n\n\n\nFigure 1: This image represents the internal structure of a hadronic molecule, specifically illustrating a bound state of two hadrons. In the context of the lecture, it shows two color-singlet clusters (hadronic “bags”), each containing three quarks—one on the left with quark content cud (likely a \\Sigma_c baryon) and one on the right with u\\bar{c} (likely a \\bar{D} meson). The connection between them indicates they are held together by residual strong forces, similar to the nuclear force binding nucleons in the deuteron. This depicts the concept of hadronic molecules discussed in the “Pentaquark State” section, where such states are interpreted as loosely bound systems of two hadrons (rather than five-quark bags), with their total mass close to the sum of the constituent hadron masses, and small binding energy.\n\n\n\nThis particle can travel, can leave. This is a regular particle, but its internal structure is a hadronic molecule.\n\n\n\n\n\n\nA hadronic molecule is a bound state of two or more hadrons, held together by residual strong forces, similar to how nucleons form a deuteron.\n\n\n\nWhat is the mass of this particle? Indeed, what is roughly the mass of this P_c particle—that’s how we call them—is the mass of the constituents. Let me put an equal sign: M_{P_c} \\approx M_{\\Sigma_c} + M_{\\bar{D}}\nThat’s the way how we define the binding energy. Binding energy is the mass difference between the mass of the constituents and the mass of the particle: B = (M_{\\Sigma_c} + M_{\\bar{D}}) - M_{P_c}\nIt used to be called P_c , and last year we updated notations. Now it’s a P_c , because with the C , you indicate that it contains charm. I think this is better. So that’s really clear. As an index, you list heavy quarks because they kind of conserve quantities with the decay; light quarks are… we don’t miss them. You can always recover them from the capital letter. If I say \\Sigma , you know, that’s a capital. The two light quarks, depending on the charge, are either u u , or d d , or u d . An SAP means pentaquark—5 quarks. An SACC , you know, the content is c \\bar{c} plus other 3. For the P_c^+ , this is u d . Likely the P_c candidates that we see in this particular channel are of this type.\nMass of the… okay, this was easy. Neglecting binding energy, you really get the mass of two particles that are called the threshold. The language that we use is saying that the state is… since the binding energy is small, the state sits at the threshold. So the hadronic threshold is there.\nHow much is the binding energy? Approximately like 10 MeV? 100 MeV? What’s the scale? 10. Less than 10. More than 1. Yes. The mass of the \\Sigma_c is 2.5 or so, the mass of the D is around 2 GeV. So the sum is 4.5 GeV. That’s roughly where one would search for such formations.\nNow, quantum numbers, spin algebra—my favorite exercise in this course. We have 1/2 and 3/2 constituents. Parity should be minus minus because we have s-wave. Exactly. Very good. So then it tells you that you expect two states. One of them with spin-parity one-half minus, another one with spin-parity three-halves minus.\nThey have a lower bound on lifetime. Where does the lower bound really come from? It is the binding of the two constituents. Any idea why this state would ever decay and how it would decay? When we talk about lifetime, the particle then decays. That’s what happens with all the particles.\nHow does this particle decay? The energy of the system is conserved. Once you split it into two, the minimal energy that is in a system of two is their mass, like mass one plus mass two. This is already high energy. If they fly apart, its energy is even higher. So this is not allowed. Energy must be conserved. We sit in the rest frame of this particle, and all the energy you have is the mass of this particle. That’s it.\nBecause the c and the \\bar{c} charm quark travel via the electromagnetic process? So annihilation of these two quarks is possible. But this is a slow process. Since it’s an electromagnetic interaction, the probability of this process is much smaller than the process that I would like you to come up with.\nWhy have c \\bar{c} ? It will. Why do they have to annihilate electromagnetically? Can they annihilate via the strong interaction? I mean, like when he says that we take c \\bar{c} and then, even if they have different color, they can produce… then you can create some other quarks. This is… it’s actually suppressed for heavy particles. The heavier the particles, the smaller the chance for them to annihilate. So this is also strongly suppressed.\nNo, no. The three gluons appear only for the color neutral objects. The three gluons we need to construct the color neutral object here are living in the color octet. It’s not singular, so they don’t. The strict vertex is a different suppression. No. So you just make the strange. Yeah. Right.\nSo the big decay, that’s what happens with this object. If we neglect inelastic channels, the decay of this particle that is going to happen is one of the c quarks transitions to s emitting the W . This is a big decay. Actually if the structure of the object is like that, we can even understand the probability of this decay to happen. Because what happens is… Oh, sorry. Big decay is one thing, but there is another transition.\nOkay, big decay is what we discussed. So then one of these two objects decays since it decays weakly. This object will decay or this object would decay quickly. So we can compute the lifetime due to that. But there is another process. You see that this guy is not the lower, it’s not the ground state.\nAs I said, in the spectrum of the D , we combine quarks. So we have 1 and 0 . The lower one is called D and the upper one is called D^* . The T is D^* here is the D , here is energy. This transition is possible by emitting \\pi^0 or \\pi . Actually the most likely decay channel of this is the radiative decay of the D . That’s what happens lower bound of the lifetime. The width is smaller than the width of the D^* . So the time is bigger than the time of the D^* . That’s a bound.\nNever mind. You combine two objects and the object lives as long. It would live an infinite amount if these two particles are stable. Like deuteron is made of proton and neutron, both proton and neutron. Proton is stable, neutron is not stable, but lives long. But deuteron is a stable particle. It happens because the neutron is so bound inside that it cannot decay.\nWhat happens is that the binding mechanism suppresses the phase space of the decay and suppresses the lifetime of the particle. The D meson here would live longer than the D meson. D^* meson isolated. The width of the state is smaller than the width of the D^* . The lifetime \\tau is one over the width. So the lifetime of this object is bigger than the lifetime of the D^* .\nWill the \\Sigma_c^* also survive or also be an atomic molecule? It just goes down an energy step instead of really falling apart. Let’s try to understand what you ask. You say there is a cascade: \\Sigma_c^* and now the \\Sigma_c plus \\pi^0 this molecule. Does this exist? It does.\nMy question was just: so this molecule just makes steps down one energy step? Can it do this? Yes. But it can also dissociate into \\Sigma_c D \\pi or \\Sigma_c D \\gamma , because the energy for this is a lot. In my project, I have a fixed binding energy because my toy model is fixed for the U turn. So it’s actually this binding energy and the situation of the decays is actively discussed in the field, and at every conference you come, you see five talks roughly. That’s a really hot subject.\n\n\n1.2 Question 2: Kinematics and Mandelstam Variables\nLet’s move to other questions. Let’s move to item number two. Understand? Plane is plane of invariants. For any reaction that has a blob, an open direction center on four legs going out, X , A , B , C , you can define invariant variables that characterize the kinematics.\nThe first variable is the mass of the A and B squared. So mass of the A and B computed as the square root of P_A + P_B . So s is the mass squared and square root of s will be the mass of the system of particle A and B . Then t is mass of the system where it has B and C particles. Then the u is the mass of the system that has A and C . Oh, mass squared. Sorry: s = (p_A + p_B)^2, \\quad t = (p_A - p_C)^2, \\quad u = (p_A - p_D)^2\n\n\n\n\n\n\nFigure 2: This figure schematically represents a generic 2 → 2 scattering process in particle physics, as discussed in the context of Mandelstam variables and kinematics. The central blob denotes an unspecified interaction (“something happens”) between four particles, labeled X , A , B , and C , each with arrows indicating their directions. All arrows are pointing outward from the interaction, which is a standard convention indicating final states (except for X if it is considered an initial state). In the context of the lecture, this setup is used to define the Lorentz-invariant Mandelstam variables ( s, t, u ): - s = (p_A + p_B)^2 , the invariant mass squared of particles A and B - t = (p_A - p_C)^2 , the squared momentum transfer between A and C - u = (p_A - p_D)^2 , the squared momentum transfer between A and D This diagram is crucial for understanding how these invariants are assigned based on the flow of momenta, to analyze particle reactions and kinematic domains for scattering and decay processes. It forms the basis for further analysis of the physical kinematics, such as the allowed regions in Dalitz plots, and is central to the discussion of unitarity and analytic properties of the scattering amplitude.\n\n\n\n\n\n\n\n\n\nFigure 3: This figure represents the Dalitz plot or plane of Mandelstam invariants for a 2 → 2 scattering process as discussed in the lecture. The triangle in the center illustrates the kinematically allowed region for the Mandelstam variables s , t , and u . Each vertex and side of the triangle corresponds to one of the channels (s, t, u). The labeled arrows indicate the directions and relationships between the Mandelstam variables: - s : total energy squared for the incoming system, - t : squared momentum transfer between certain legs, - u : squared momentum transfer for the cross-channel. The shaded areas outside the triangle represent physically forbidden regions, while the interior triangle (Dalitz plot) is the physically allowed region for the process, where the transitions and resonance formations happen. The letters b , c , and d correspond respectively to the external particles, aligning with the notation A, B, C, D from the text. The points where the boundaries are marked indicate kinematic thresholds determined by the masses of the particles, and the triangle’s edges are defined by the zeros of the Källén function \\lambda . This diagram visualizes how scattering amplitudes span different kinematic domains and how all physical observable processes for the 2 → 2 system are confined within the Dalitz plot.\n\n\n\n\n\n\n\n\n\nFigure 4: This figure illustrates the kinematics of a 2 \\to 2 scattering process in particle physics, as described in the lecture. The top part of the figure shows a generic Feynman diagram with two incoming particles (labeled p_1 , p_2 ) and two outgoing particles ( p_1' , p_2' ), all connected via a central blob which represents an unspecified interaction. This visual encapsulates the general scenario discussed when introducing Mandelstam variables and the scattering amplitude. The bottom part of the figure provides a depiction of the momenta in the center-of-momentum frame. Here, the incoming momenta p_1 and p_2 are directed towards each other, while the outgoing momenta p_1' and p_2' are shown with the angle \\theta between p_1 and p_1' . The angle \\theta represents the scattering angle, the primary observable that characterizes the final state in elastic 2 \\to 2 scattering. This geometric arrangement is essential for defining variables such as the Mandelstam s , t , and u , and for expanding the scattering amplitude in terms of partial waves, where the amplitude depends on the collision energy and the scattering angle. The figure thus directly links the abstract formalism of scattering theory to concrete physical kinematics and observables.\n\n\n\n\n\n\n\n\n\nThese are the Mandelstam variables. They are Lorentz-invariant quantities that fully describe the kinematics of a 2 → 2 scattering process A + B \\to C + D .\n\n\n\nIt appears that what we figured out before is that two variables are enough to characterize kinematics of the four-legged process. It just comes from counting degrees of freedom. These two variables we have to pick could be either s and t or could be s and u , or it could be all three. But then on the plane they are connected since the sum of the three invariants is related to the masses: s + t + u = m_A^2 + m_B^2 + m_C^2 + m_D^2\nThe matrix element or the scattering amplitude or transition amplitude depends on two variables only, s and t or s and u or any. This amplitude is defined as a function on the plane of invariants and the different domains on this plane describe different processes.\nBefore making this step, let’s only focus on kinematics of the process and try to see where A , B , C , D are located. Any ideas? Number one and the way how I want to solve this is to check just the signs. I want to ask for every process: is s more or less than 0, t more or less than 0, u more or less than 0. By identifying what is the correct answer here, I should be able to place the kinematics.\nLet’s do A . The question is, is the mass of these two particles physical? If it’s physical, then it’s more than zero. If it’s unphysical, then it doesn’t, you know, like most of the dynamics. You have to see exact masses of particles to see exactly where the range of the variables for these kinematics lies. But for the exercise right now, this should be sufficient.\nOkay, A is variable s positive. Why? Because we just simply sum masses of this? Not simply sum the masses. No, that’s not what we do. It’s sum of four-vectors. It’s not equivalent of summing masses. True. But they are like real particles. So the mass of the system for these two real particles is well defined. This mass is at least the sum of masses. Since they have a momentum in the rest frame, the energy of the system is bigger than the sum of masses if they have. For the A , the answer is s more than zero. That’s actually more than (m_A + m_B)^2 .\nWhat about t ? Same logic. If you write drawing the momenta on the right side on this one. I had to say in which direction arrows are pointing out of the blob or inside of the blob. In this definition all of the particles A , B , C are pointing out of the blob and X points inside the blob and that defines the sign.\nThe t is a regular variable, the same as s . It’s a physical mass of two particles. It’s also more than zero and more than even particle threshold, m_B + m_C , and then u more than zero. So the domain. s is bigger than the threshold. This is threshold, this is threshold (m_B + m_C)^2 . u is also bigger than the threshold. The only domain that we have here is the allowed domain for the first kinematics.\nFor B , t is the physical mass of two particles, is again more than zero, more than threshold again. To discuss, to avoid redefining these variables I then discuss A and D particles. I swap p to r , p to minus. I mean if you don’t like that object and we can do it different, but I don’t know is it.\nThe point is to discuss kinematics of part of the reactions, so-called cross-channel reactions, using the same variables. For this scattering, one has to modify definition of the invariants by swapping momenta to minus momenta for particles that move to the other side.\nTwo different directions and then the sum minuses would appear in the first place there. We could start with this direction. The place for this is when t is more than zero because t is the physical mass of two particles. Then s is under A and B . This is kind of an impossible combination. They are on different sides and the variable s is going to be less than zero and then u is less than zero.\nIt’s another impossible combination and the domain, roughly speaking, is where u is below zero. Then s is above, t is above zero. So t prime, t , t . Here’s t . t is this direction. s is above zero. This and u is above zero. This color has so here this is the minimum. This one is B and same on the C . Another one D where is D ? A plus C , X plus B . A and C give us u channel. This is the positive. u is positive.\nNow to see real physical contours for the kinematics. One has to calculate what are the physical ranges of the scattering variables. Like if you work in the cosine of the scattering angle, by placing the restriction that cosine should be from minus one to one, you identify that the border—that not all points here are allowed, but only a certain region.\nThe true border for the scattering is often given by this sixth-order polynomial. In the center is this canvas. This is our Dalitz plot. This is here. Another direction could be here. So 1, 2, 3, 4. Four regions for physical reactions that are happening. It’s important to realize that connection because there’s just a single amplitude, a matrix element, that describes all four.\nIf you get this function and if you constrain it, I mean if you get precisely this function, it describes all four. Just define it on this domain and for every point you can compute, it gives you the complex number one plus three i . This is the value of the quantum transition amplitude. The amplitude itself you can compute at a different place. Now we have a complex transition amplitude for the decay. I think that’s super cool.\nIt works very well in QED. When you consider Compton scattering, photon electron going to photon electron. This is a Compton process. It’s exactly the same matrix element that describes the electron positron annihilation to two photons. It’s exactly the same process that describes two-photon production of an electron positron pair in quantum electrodynamics.\nIn hadron physics it’s a little bit more complicated. Since we don’t have perturbation theory, we always model. What we are going to do when we describe the Dalitz plot, we model it as a sum of the resonances. Then you find that once you want to compute this function right here, the scattering amplitude, it blows up. It has infinities, so it has unphysical behavior.\nThe reason is because we employ a finite range or a finite number of resonances and the physics is more complicated analytically. The fact that this amplitude is related to that domain tells you already that you have to put an infinite number of resonances. Like we saw the lines on the dispersion, these are all resonances. In order to relate this to that domain, you have to operate with infinite sums and then the infinite terms would compensate each other and then you have a reasonable amplitude.\nThere has been an effort for now, 30 years, 50 years, to find such a set of functions that works everywhere nicely and is analytic and reasonable. What’s most difficult is to come up with something that describes the data, because the data is described by Regge theory. You might have heard of Regge theory and this is one of the approaches. So you come up with a complex function that has all the nice properties; it works reasonably in the scattering domain and it works in the decay domain.\nHowever, of course, it lacks an exact understanding of the resonance properties. Like, it would put in resonances there that have zero width in Regge theory. One of the interesting developments is to implement resonances with widths.\nOkay, questions on Monday’s timeline. One more thing. If you like playing with functions, there is a very simple expression that describes the contours of the physical domain. This is called the Källén function. I think it’s worth giving. There is just one function. If you solve \\Phi(s, t, u) = 0 , you find this line, that line, that line and that line.\nJust one function, put it into a solver and for any given value of s . Let’s fix s —where is our s ? Let’s fix s to be minus, you know, 50. We’re going to get two solutions. One of them, let’s put s equal to plus 20. Then you have two solutions using this. So this function is really easy to type into code. This is the Källén function or Klein function. It’s almost a complete polynomial but it misses more terms of this table.\nSo it’s x^2 + y^2 + z^2 - 2xy - 2yz - 2zx . This is called the Källén or challenge function. I think it’s—correct me if it should be going a different direction. So challenge function or Källén function and that’s it. Then the Kibble function is the challenge of three challenge functions where every \\lambda_1 , \\lambda_2 and \\lambda_3 corresponds to a different channel.\nSo \\lambda_2 is then for B it’s \\lambda(t, m_X^2, m_A^2) . Here is the—what’s missing? Mass and t . \\lambda_3 is \\lambda(u, m_X^2, m_B^2) . Yeah, that’s it: \\Phi(s, t, u) = \\lambda(\\lambda_1, \\lambda_2, \\lambda_3) .\n\n\n\n\n\n\nThe Källén (or triangle) function is defined as \\lambda(x, y, z) = x^2 + y^2 + z^2 - 2xy - 2yz - 2zx . The Kibble function, \\Phi(s, t, u) = \\lambda(\\lambda_1, \\lambda_2, \\lambda_3) , where each \\lambda_i is a Källén function of different Mandelstam variables and masses, defines the physical boundaries of the Dalitz plot.\n\n\n\nSo then you come home, you go to Wolfram Alpha and say give me a contour plot. Then you form them and you find all this function and discussion on that in the Pikin and Calani book. Have we discussed this book? The best book on particle kinematics is written by two authors. This is the, if I got it right, see Byckling and Kajantie. The book is excellent. If you get a chance, get yourself this. You know everything about particle kinematics, particularly very peculiar properties of the Kibble function and the Chandrasekhar function, right?\n\n\n1.3 Unitarity and the Scattering Amplitude\nSo we are good to move to the topic of today and it’s unitarity. Unitarity is a constraint on the scattering amplitude. In particle physics we don’t compute from first principles the scattering amplitude, this amplitude, but rather we model it and our guiding principles are on what this amplitude can be and what it cannot be.\nYou cannot just write up an arbitrary expression for this amplitude that fits the data. There are some principles and one of them is probability conservation. Probability conservation transforms into the mathematical statement on the amplitude that is known as unitarity. You might have seen earlier in the particle scattering course, of course, the optical theorem that relates the imaginary part to the total cross section, essentially telling that the imaginary part is equal to the total cross section.\nThat’s a consequence of unitarity, a consequence of the probability conservation. It’s so important that this is a very powerful statement that we are going to derive hopefully today, that just this principle alone allows you already to get a decent low-energy scattering amplitude that describes all of the resonance phenomena. You see the bump in the spectrum due to the resonance. You know what expression you should take in order to describe this phenomenon.\nMoreover, since unitarity is about analytic properties of the amplitude, it tells you what the analytic structure of the amplitude is. In the last lecture we shortly discussed analytic functions and what singularities they might have like cuts, branch points. Unitarity also tells you what is the location of the singularities in the complex plane. That comes from the fact that we are going to deal with unitary functions. Our scattering amplitudes are real unitary functions, functions for which the imaginary part determines the locations of the cuts.\nLet’s start discussing the scattering amplitude and partial waves. For the sake of time, let me state where we arrive. We’ll arrive there first, and then the emphasis is on the derivation. We will derive the following three equations. The first, and all three are dealing with scattering amplitudes.\nThe first one tells how unitarity acts on the full amplitude. So A is the scattering amplitude that describes a certain process. Unitarity tells you that A - A^* is equal to i times A^* A integrated over the phase space of the intermediate state: T - T^\\dagger = i \\int d\\Phi \\, T^\\dagger T\n\n\n\n\n\n\nThis is the general unitarity condition. It is derived from the requirement that the S-matrix is unitary ( \\hat{S}\\hat{S}^\\dagger = \\hat{I} ), where \\hat{S} = \\hat{I} + i \\hat{T} .\n\n\n\nWhat is this diagrammatically? We are going to simplify this process for writing this. For the partial waves, and for the partial waves the variable A is a function of. So the amplitude A is a function of one variable. We’re going to find that A - A^* is equal to this expression, where A^* is very similar to that. For the partial waves you can simplify the phase space and find the expression for that.\nEssentially it tells you that amplitude minus its complex conjugate gives you the imaginary part, and the imaginary part of the amplitude is now equal to. Okay, let’s now try to get these expressions and start with the scattering amplitude and the process, and we are going to deal with the 2-to-2 scattering elastic process.\nOn the board, I draw the first diagram where the blob just indicates some interaction—something happens with two particles. Below is the kinematic representation of the reactions in the center of mass frame—the center of momentum frame. In the center of momentum, lengths of the vectors are the same, so the center of momentum means total momentum is zero.\nEven if particles have different masses, their momenta are the same and they equal to the function of square root of the \\lambda function of masses. So the p_1 is equal to p_2 is equal to \\lambda^{1/2} / (2\\sqrt{s}) , and \\lambda has s and the masses. After interactions, particles are the same, the masses are the same, breakup momentum is the same. The only thing that happens is the angle is changing.\nYou might wonder where this whole beautiful physics is sitting. Where in my variables would I see different interactions that they put in? It appears the observable for these interactions is the distribution over this angle. We have discussed this already. Whatever happens inside has only one way to manifest itself in the way how the distribution over the angle looks like. Because for two-to-two everything is fixed, energy is fixed. Once you fix the energy, the only way to manifest itself will be the angle.\nThere are two variables on it: the energy of the system and the scattering angle, right? So p_1 , p_2 is the state, is the two-particle state vector, and I’m, I also have mass, and I’m going to use the variable \\theta . The only variable that I need is the scattering angle. The one here I’m going to drop, it indicates that the angle is for particle one.\nI would like to define the amplitude. I would like to consider the contraction of the final state. I make that first: p_1' , p_2' ; p_1 , p_2 is that scattering amplitude is defined as the expectation value of two-particle states: initial state on the right and then the final state on the left. Conservation of energy and momentum comes with these four delta functions.\nNow in order to proceed, which is integrated, so this is the identity operator, or the projection operator. This phase space for 2-body is nothing but 1 / (2\\pi)^5 \\cdot (\\sqrt{s}/2) \\, d\\cos\\theta \\, d\\phi / 2 . What my state here is is the two particles back to back. I define the coordinate system as xyz . In that coordinate system I have a two-particle state with the angles \\theta and \\phi which are going back to back. The momentum of particle 1 I characterize by the angles \\theta and \\phi .\nThat’s why it actually makes sense to keep \\theta and \\phi here. I have the same state on the right and on the left. I integrate over all possible angles. The two-body phase space here just gives me all possible directions on the sphere. On the sphere for all possible combinations of angles for the 4\\pi solid angle.\nNow it’s obvious. It’s important to make sure that identity acts as an identity. You come, you act as an identity. You should get something like something similar from that you have normalization condition. What is that? I mean, you see this already. So I put it in. I have to. This is certainly not a function of the p_1 , p_2 , p_1' , p_2' . 1 / . The first phase space integral d^4 , so probably d^3 / (2\\pi)^3 . That’s the expression for this paper. 2\\pi over cube, 2\\pi over 2 and 2\\pi over 4 over here. So this should be identical.\nLet’s see if it works. We put it in. Now I have everything right. If I put this identity here, I get to integrate over p_1 , p_2 and 2\\pi .\n\n\n\n\n\n\nFigure 5: This figure represents the unitarity condition for the scattering amplitude in diagrammatic form. On the left side, there is a difference between the full amplitude and its complex conjugate (depicted as two blobs), illustrating the left-hand side of the unitarity equation. On the right side, the diagram shows the “cut” through the intermediate state, representing the sum over all possible intermediate on-shell states in the phase space. The equality reflects the mathematical expression T - T^\\dagger = i \\int d\\Phi \\, T^\\dagger T , where the imaginary part of the full amplitude is generated by the sum over amplitudes involving all possible intermediate configurations. This is a pictorial way to represent probability conservation (unitarity) at the level of Feynman diagrams.\n\n\n\nOf course, if you have one, we have a density. Now we can proceed with unitarity.\nThis two-particle scattering amplitude is defined. Now unitarity comes. Shouldn’t there also be from the unitarity the option that p_1' is p_2 ? They are distinguishable particles for me, scalar particles distinguishable, different type to avoid cross terms. The probability is a statement on the full scattering operator that it’s unitary, and part of the operator is the identity—the transition without interaction—and another one that.\nWell, by subtracting identity from the full scattering operator, we introduce our interaction operator, this T , and that’s the operator that stands here that defines our scattering amplitude. When we deal with these amplitudes in field theory we always talk about the nontrivial part, something addition to this one. The easiest way to proceed with this. This is our unitary constraint.\nThat’s a critical statement that will constrain our partial waves, will constrain our scattering amplitude. But in order to see that we need to come from this condition to the condition for T , and then the condition for A . The way goes is that by putting T , so 1 - 1 + i T , 1 - i T^\\dagger . Let’s see if i is on the right side. So minus plus here, plus minus here, i times i gives me plus. That’s why plus here T T^\\dagger , right? Then here is the i T multiplied to one and then minus i T^\\dagger here.\nOnce we multiply both parts by i , the minus appears here, this i disappears and we move to the other side. That’s correct. The only thing that remains is to put the final state and we put now the T operator here to split it into A A^* . Let me first fill this part. For the sake of time.\nRight, so the way to proceed from here is to use this expression for the amplitude here and here. That’s the product here. What to do with this is a bit more involved. We have to insert identity here and split it into intermediate states. Insert intermediate state, which is in our case just all possible orientations of the intermediate particles, and energy is fixed. Then we have to integrate over the momentum.\nWhat now happens here is that this gives us T and then (2\\pi)^4 delta function. This gives another T^\\dagger , T^* , (2\\pi)^4 delta function. It’s equal to i . This together is the delta function to the power 4 even in the phase space d\\Phi_{\\text{intermediate}} . Delta function for the energy momentum conservation is going to tell you that p_1' + p_2' should be equal to the p_{1,\\text{int}} + p_{2,\\text{int}} . That’s the first.\nThe second one is going to tell me that the p_1 + p_2 is going to equal p_{1,\\text{int}} + p_{2,\\text{int}} . This, the first one connects initial state to final state. Second connects initial state to intermediate, intermediate to final. We can just pull out the one that connects intermediate, which one connects the initial to final. Then keep the one that just constrains the sum of the momentum for the two particles and get our phase space equal to the 2\\pi equals \\delta(p_1 + p_2 - p_{1,\\text{int}}) , and then integral of the T^\\dagger T d^4 .\nNow we arrive to the first equation: T - T^\\dagger = i \\int T^\\dagger T \\, d\\Phi . The most general form of this equation that does not have none of these constraints is going to be very similar to that. It’s just you have to sum over all intermediate states and then integrate not over two-body phase space, but rather n-body phase space if there are n-body allowed.\nDiagrammatically, it says amplitude minus amplitude conjugated has to be sum over all intermediate states. Every time you have it, the means that you have to integrate over all possible configurations. That’s what now. Instead of working, we simplify variables in terms of the momentum and the transferred energy squared and transferred momentum. We can change. We can use angle and this.\nNow a function of angle can be approximated by the partial waves. That’s a very convenient series because it converges well, especially when for hadron physics. These amplitudes are. There are constraints on this amplitude that they cannot be present for the high J , so they cannot be large for high J . There is a natural suppression related to the size of hadrons. There are no, the contributions of the high values of the J are small.\nThat’s why often in experiment, in order to describe the data, you just need a few partial waves, two, three, sometimes six, but not more than ten. That’s a very convenient approximation. It’s not an approximation once you keep this sum to infinity. Once you. If you keep the sum to infinity, like in Regge theory, that’s an exact relation between left and right.\n\n\n\n\n\n\nThe scattering amplitude is often expanded in partial waves: A(s, \\theta) = \\sum_{\\ell=0}^\\infty (2\\ell + 1) a_\\ell(s) P_\\ell(\\cos\\theta) . This expansion simplifies the unitarity condition for each angular momentum component \\ell ."
  },
  {
    "objectID": "2024-Lecture-07.html#partial-wave-amplitudes-and-unitarity-constraints",
    "href": "2024-Lecture-07.html#partial-wave-amplitudes-and-unitarity-constraints",
    "title": "(2024) Lecture 7",
    "section": "2 Partial Wave Amplitudes and Unitarity Constraints",
    "text": "2 Partial Wave Amplitudes and Unitarity Constraints\nAnother thing that appears here is the partial wave amplitude. This amplitude is a function of a single variable. For every partial wave there is one function of one variable, and every partial wave has fixed quantum numbers.\nA large advantage of partial waves is that they do not talk to each other. They don’t influence each other. Every partial wave is independent. Since quantum numbers in scattering are conserved, partial waves in the initial state are only related to partial waves in the final state with the same quantum numbers.\nIn the unitarity constraint, you will see that it’s actually a single partial wave that relates to its output. There is no mixing of partial waves.\nThe way we can proceed is to insert the partial wave expansion here and then simplify the phase space. For this, you will need one magic formula, and I don’t have time to derive it. It’s present in many references, which I will send you.\nBut there is a really cool relation I would like you to see. When we insert the expansion, the initial state has an angle of zero. The final state depends on the scattering angle \\theta .\nFor the final state, the Legendre polynomial P_J(\\cos\\theta) is a function of \\theta . This is the same as the big Wigner d function d^J_{0,0}(\\cos\\theta) . We can write it differently. We know d^J_{0,0} is important, and it can be decomposed using the relation: d^J_{0,0}(\\cos\\theta) = \\sum_\\lambda d^J_{0,\\lambda} \\, d^J_{\\lambda,0}\nThis is a very powerful expression.\nHere, the capital G function is defined such that when the indices are zero, it relates to d^J_{0,0} . What happens next is that you have to integrate over all possible intermediate states, and both amplitudes are expanded in partial waves. The way to do this is to expand the cosine between the first, second, and last states into a composition of intermediate states. These are exactly the functions we need to relate the full amplitude to the partial wave amplitude.\nThe expression we arrive at for the partial wave amplitude has expected numerical coefficients because it’s essentially a base case. The next step is to divide the right part by… or multiply both parts by 1 / a_J , so that term vanishes. Then we have 1 / a_J^* , and a minus sign appears.\nFrom this, we find the imaginary part of the partial wave amplitude is simply i \\rho(s) .\n\n\n\n\n\n\nFigure 6: This figure represents the behavior of the imaginary part of the inverse partial wave amplitude, as constrained by unitarity in two-body scattering. The key relation shown in the lecture is \\operatorname{Im} a_J^{-1} = -i \\rho , which leads to a prediction for how the imaginary part of the amplitude, \\operatorname{Im} a_j , depends on the kinematic variable s (the square of the total energy in the center-of-mass frame). Physically, the plot shows that as the invariant mass \\sqrt{s} increases from the two-particle threshold (where \\sqrt{s} = m_1 + m_2 ), the phase space factor \\rho(s) also increases. This function \\rho(s) is proportional to the breakup momentum of the two outgoing particles and characterizes the available phase space for the reaction. The curve in the diagram starts from zero at the threshold (where the particles just begin to be produced), rises sharply with a square-root behavior, and then gradually saturates to a constant value 1/(16\\pi) at high energies, as described by the expression [ (s) = ] where the Källén function \\lambda encodes kinematic constraints. This plot highlights how unitarity fixes the imaginary part of the partial wave amplitude as a function of energy: it is determined entirely by kinematics and phase space, not model-dependent details. This is crucial for constructing amplitudes that respect probability conservation in scattering theory.\n\n\n\nThis is amazing because it tells us exactly how the imaginary part of the inverse amplitude looks.\n\n\n\n\n\n\nThe unitarity condition for a partial wave amplitude a_J(s) is: \\operatorname{Im} a_J(s) = \\rho(s) \\, |a_J(s)|^2\nThis leads directly to the inverse amplitude relation: \\frac{1}{a_J(s)} = \\operatorname{Re} \\left[ \\frac{1}{a_J(s)} \\right] - i \\rho(s)\nThe imaginary part of the inverse amplitude is fixed by unitarity to be -\\rho(s) .\n\n\n\nLet’s visualize this. Plot s on the horizontal axis and the imaginary part of a_J on the vertical axis. The phase space function \\rho(s) starts from threshold with a square-root behavior, \\sqrt{s - (M_1 + M_2)^2} , and approaches a constant 1/(16\\pi) at high s .\nMore precisely, the two-body phase space factor is: \\rho(s) = \\frac{1}{16\\pi} \\frac{\\lambda^{1/2}(s, m_1^2, m_2^2)}{s}\nwhere \\lambda(x, y, z) = x^2 + y^2 + z^2 - 2xy - 2xz - 2yz . This function goes to one at high s .\nNow for the last point: modeling. We know the imaginary part from unitarity, but we do not know the real part. The real part of the amplitude is genuine to the specific interaction—whether electromagnetic, strong, or gravitational. Any unitary interaction must have an imaginary part related to phase space, but the real part must be computed or modeled.\n\nTheorists extract the real part by analyzing LHC data.\nExperimentalists extract it by analyzing hadronic data.\n\nThe simplest model writes the inverse amplitude as some real function plus the unitary imaginary part. One option for this real function is a simple pole. The amplitude computed assuming the real part is a single pole is called a relativistic Breit-Wigner amplitude: a_J(s) = \\frac{g}{M^2 - s - i g \\rho(s)}\nModeling the amplitude in terms of such pole terms is often called the ** K -matrix approach, where: a_J(s) = \\frac{K(s)}{1 - i \\rho(s) K(s)}\nand K(s) is a real function, like K(s) = g / (M^2 - s) . Let me plot this unperturbed amplitude. On the vertical axis is the absolute value of A , and on the horizontal axis is s . The parameter M is the bare mass** where the peak appears, and the coupling g determines how broad the peak is. This is the simplest resonance amplitude.\n\n\n\n\n\n\nFigure 7: This figure shows the typical shape of the absolute value of the resonance scattering amplitude, |A| , as a function of the center-of-mass energy squared, s . The peak occurs near the “bare mass,” marked as m^2 , and the height of the peak is related to the coupling squared, g^2 . This diagram represents a resonant phenomenon described by the relativistic Breit-Wigner amplitude, which is commonly used in particle physics to model resonance behavior. When two particles scatter, if the energy matches the resonance mass, the scattering probability rises sharply—this is visible as the large peak in the amplitude. Away from this energy, the amplitude is small, resulting in a characteristic bump. This behavior is a direct manifestation of creating an intermediate unstable particle (a resonance), and the width of the peak encodes the lifetime (inverse of the decay width) of that resonance. The plot thus visualizes how the unitarity constraint and resonance modeling describe experimental observations in particle collision experiments.\n\n\n\nThis describes a resonant phenomenon: particles collide, form an intermediate resonance for a short time, and then decay. In an experiment, you smash particles and count how often they scatter, tuning their collision energy. You would observe:\n\nA small interaction probability at most energies.\nA huge peak in the cross-section when the energy matches the resonance mass M .\nThe probability dies out again at higher energies.\n\nThis resonance phenomenon indicates something interesting inside the interaction: an intermediate particle that can be formed."
  },
  {
    "objectID": "2024-Lecture-07.html#two-pole-structure-and-unitarity-in-scattering-amplitudes",
    "href": "2024-Lecture-07.html#two-pole-structure-and-unitarity-in-scattering-amplitudes",
    "title": "(2024) Lecture 7",
    "section": "3 Two-Pole Structure and Unitarity in Scattering Amplitudes",
    "text": "3 Two-Pole Structure and Unitarity in Scattering Amplitudes\nNow, from the two-particle K-matrix, we get two poles. The cross section has two peaks: the first corresponds to the first pole, and the second corresponds to the second pole, with a zero in between.\nThis zero comes from the fact that the K-matrix vanishes. There is a typo to correct: it should be K^{-1} in the initial expression. The correct scattering amplitude is: A = (K^{-1} - i)^{-1}\nWhen K multiplies this expression, the entire amplitude is managed, producing two poles. The K-matrix itself has one singularity, which generates another set. To reach the second singular asymptotic behavior, the function must cross zero. Therefore, K vanishes between the poles, and this zero propagates into the squared amplitude, resulting in an exact zero on the real axis.\nAnother key point is that the energy values of the peaks are not exactly the bare masses. They enter a complicated expression, so the peak occurs very close to, but not exactly at, the bare mass value. This is why the mass is called the bare mass; the process of inserting it into the amplitude dresses the bare particle mass via propagator screening. Let’s examine the amplitude expression more closely: A = (K^{-1} - i \\rho)^{-1}\nExpanding this in a Taylor series gives: A = K + K(i\\rho)K + K(i\\rho)K(i\\rho)K + \\cdots\nThis infinite series provides a diagrammatic meaning:\n\n\\rho represents the two-particle phase space (the propagator).\nK represents the point-like elementary interaction.\n\n\n\n\n\n\n\nFigure 8: This figure illustrates the decomposition and diagrammatic expansion of the two-body scattering amplitude in the K-matrix formalism. The equation a = (K^{-1} - i\\rho)^{-1} expresses the amplitude a as the sum of iterated elementary interactions (K), each connected by insertions of the two-particle phase space factor ( i\\rho ). The expansion K + K(i\\rho)K + K(i\\rho)K(i\\rho)K + \\ldots represents the resummation of all possible repeated scatterings between two particles, where each term corresponds to an additional loop (propagator) in the intermediate state. The diagrams underneath the terms show the corresponding Feynman-like representations: - The first term (K) is a single point-like interaction (no intermediate states). - The second term (K i\\rho K) describes two consecutive point-like interactions separated by a loop, indicating propagation through an intermediate two-particle state. - The third term (K i\\rho K$iK) corresponds to three such interactions connected by two intermediate propagations, and so on.  Physically, this expansion encapsulates the unitarity constraint discussed in the lecture, showing that the imaginary part (and analytic structure) of the amplitude arises from the possibility of these intermediate on-shell two-particle states, as enforced by the phase space factor $. This formalism guarantees probability conservation in the scattering process and models resonant phenomena, such as the formation of intermediate bound or quasi-bound states (resonances). The approach is foundational in constructing amplitudes that respect the analytic properties and unitarity required by quantum field theory.\n\n\n\nThe scattering amplitude is a complex function. We have discussed the magnitude (length) of this complex vector, but not its angle—the scattering phase. The argument of the scattering amplitude is this phase, and it has interesting behavior.\nIn the complex plane, the amplitude traces a circle. Starting from threshold, it increases, reaches a maximum, then decreases back to zero before making a second, similar shape. The variable here is the imaginary part of$ A$ as a function of s . The maximum is approached around m_{1,0}^2 . This plot is called an Argand diagram. A more convenient quantity to plot is often: F = A \\cdot \\rho\n\n\n\n\n\n\nThe unitarity constraint, from probability conservation, is a crucial tool for modeling amplitudes. It fixes the imaginary part of the amplitude, so we only need to model the real part. This real part represents the point-like interaction, which must be resummed to all orders.\n\n\n\nTo summarize, unitarity provides a powerful constraint for modeling. The real part of the interaction can be modeled in several ways; one common technique is the effective range expansion.\nYou can parametrize the inverse K-matrix at low energy as: K^{-1}(k) = a^{-1} + \\frac{1}{2} r_s k^2 + \\mathcal{O}(k^4)\nThis is called the effective range approximation, where:\n\na is the scattering length.\nr_s is the effective range."
  },
  {
    "objectID": "2024-Lecture-08.html",
    "href": "2024-Lecture-08.html",
    "title": "(2024) Lecture 8",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-08.html#analytic-and-holomorphic-functions",
    "href": "2024-Lecture-08.html#analytic-and-holomorphic-functions",
    "title": "(2024) Lecture 8",
    "section": "1 Analytic and Holomorphic Functions",
    "text": "1 Analytic and Holomorphic Functions\nIn today’s lecture, I would like to discuss unitarity and complex numbers and move towards discussing complex functions. We had a little too little time in the previous lecture to cover these aspects, but this is important to understand and I think it also links to what you already know from mathematics.\nI would like to introduce you to two mathematical concepts: analytic functions and holomorphic functions, which are two words for the same idea.\n\nA function is called analytic at a point x_0  if it can be represented by a Taylor series that equals the function in the vicinity of that point. This means there exist coefficients such that: f(x) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(x_0)}{n!} (x - x_0)^n\nA function is called holomorphic if its complex derivative exists, meaning you can approach the point from any direction in the complex plane and the derivative is the same. This is the same property as being analytic. Don’t be afraid of the word “holomorphic”—it’s just mathematicians inventing a cool word to say a function is analytic.\n\n\n\n\n\n\n\nKey Definitions:\n\nAnalytic/Holomorphic Function: A function that can be locally represented by a convergent power series (Taylor series) and has a well-defined complex derivative.\nTaylor Series Representation: f(x) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(x_0)}{n!} (x - x_0)^n expresses that the function’s value near x_0 is determined by its derivatives at x_0 .\n\n\n\n\n\n1.1 Examples and Properties of Analytic Functions\nAs examples, consider functions that are analytic:\n\nAll polynomials are analytic everywhere.\nA rational function (a polynomial divided by another polynomial) is analytic except at a finite number of points—the zeros of the denominator.\nWhen we say a function is analytic on a domain, it means every point in that domain is a point of analyticity.\n\nThe function \\sqrt{x} is analytic everywhere except at x = 0 . Zero is called a branch point, a point where there is no derivative and no valid Taylor series.\nReal analytic functions are another interesting class—functions that are real-valued and analytic. An example is the real function \\sqrt{x} for x \\geq 0 .\nA key property of a real analytic function extended to the complex plane is the Schwarz reflection principle. It states that for such a function f , the value at the complex conjugate of a point is the complex conjugate of the function’s value: \\overline{f(z)} = f(\\overline{z})\n\n\n1.2 Visualizing and Applying the Concepts\nWhen discussing analytic functions of a single complex argument, it’s convenient to draw the domain—the complex plane. On the x-axis is the real part of the argument ( \\Re(z) ), and on the y-axis is the imaginary part ( \\Im(z) ). We can indicate regions of analyticity on this diagram.\nThe Schwarz reflection principle implies a symmetry: the function’s values in the lower half-plane are related to those in the upper half-plane. You can compute a value in the lower half-plane by computing it at the conjugate point in the upper half-plane and then taking the complex conjugate.\nLet’s test this with an example using f(z) = \\sqrt{z} , which is real analytic for real z . We’ll compute \\sqrt{1 + i} and \\sqrt{1 - i} .\nFirst, express the numbers in polar form z = r e^{i\\theta} , where r = |z| and \\theta = \\arg(z) :\n\nFor 1 + i : r = \\sqrt{2} and \\theta = \\pi/4 . So, 1 + i = \\sqrt{2} e^{i\\pi/4} .\nFor 1 - i : r = \\sqrt{2} and \\theta = -\\pi/4 . So, 1 - i = \\sqrt{2} e^{-i\\pi/4} .\n\nNow, apply the square root using the rule \\sqrt{z} = \\sqrt{r} e^{i\\theta/2} :\n\n\\sqrt{1 + i} = \\sqrt{\\sqrt{2} e^{i\\pi/4}} = 2^{1/4} e^{i\\pi/8}\n\\sqrt{1 - i} = \\sqrt{\\sqrt{2} e^{-i\\pi/4}} = 2^{1/4} e^{-i\\pi/8}\n\nNotice that \\sqrt{1 - i} is indeed the complex conjugate of \\sqrt{1 + i} , which confirms the Schwarz reflection principle: \\overline{\\sqrt{1 + i}} = \\sqrt{\\overline{1 + i}} = \\sqrt{1 - i} ."
  },
  {
    "objectID": "2024-Lecture-08.html#cauchys-theorem-and-discontinuous-integrals",
    "href": "2024-Lecture-08.html#cauchys-theorem-and-discontinuous-integrals",
    "title": "(2024) Lecture 8",
    "section": "2 Cauchy’s Theorem and Discontinuous Integrals",
    "text": "2 Cauchy’s Theorem and Discontinuous Integrals\nCauchy’s theorem states that the integral over a closed contour of a function in the complex plane is equal to all non-analytic contributions inside this contour. If the singularity is a pole, it’s given by residues. If it’s a branch point, one must contour around it, and so on. The theorem systematically accounts for all non-analytic behavior.\nWhat is notable is that this provides a numerically well-defined procedure to integrate a function that is discontinuous. For example, we can compute the integral of the function \\sqrt{z} on the circle of radius 1, and the integral converges despite the function being discontinuous at the branch point.\n\n2.1 Contour Integral of \\sqrt{z} on the Unit Circle\nOn the circle |z|=1 , the function is parameterized as z = e^{i \\phi} . However, \\sqrt{z} jumps across the branch cut: above the cut it is +1 , and below it is -1 . The contour integral is:\n\\oint_{|z|=1} \\sqrt{z} \\, dz = \\int_{0}^{2\\pi} \\sqrt{e^{i \\phi}} \\cdot i e^{i \\phi} \\, d\\phi\nTaking the principal branch where \\sqrt{e^{i \\phi}} = e^{i \\phi/2} , this simplifies to:\n\\oint_{|z|=1} \\sqrt{z} \\, dz = i \\int_{0}^{2\\pi} e^{i (3/2) \\phi} \\, d\\phi\nCare must be taken because the function is discontinuous on the interval [0, 2\\pi] ; one cannot simply evaluate at the endpoints. To handle this properly, one can shift the integration range to [-\\pi, \\pi] , where the function is continuous on that segment:\ni \\int_{-\\pi}^{\\pi} e^{i (3/2) \\phi} \\, d\\phi\nThis yields a finite, well-defined result.\n\n\n2.2 Deforming the Contour and the Branch Cut Discontinuity\nThe key point is that this contour integral equals the integral of the discontinuity across the branch cut. By shrinking the contour around the branch cut (typically placed along the negative real axis), the integral transforms.\nFor \\sqrt{z} with a branch cut along the negative real axis, the values on either side of the cut are:\n\nAbove the cut: \\sqrt{z}_{\\text{above}} = i\\sqrt{|x|}\nBelow the cut: \\sqrt{z}_{\\text{below}} = -i\\sqrt{|x|} , for z = x &lt; 0\n\nThe discontinuity across the cut is therefore:\n\\sqrt{z}_{\\text{above}} - \\sqrt{z}_{\\text{below}} = 2i\\sqrt{|x|}\nThus, deforming the original circular contour gives an equivalent representation:\n\\oint \\sqrt{z} \\, dz = \\int_{\\text{branch cut}} \\left[ \\sqrt{z}_{\\text{above}} - \\sqrt{z}_{\\text{below}} \\right] dz = \\int_{-\\infty}^{0} 2i\\sqrt{|x|} \\, dx\nThis illustrates a core property of analytic functions and Cauchy’s theorem: the contour of integration can be deformed freely as long as no non-analytic regions are crossed. For this example, it is instructive to verify that the circular integral and the branch-cut discontinuity integral give the same result.\n\n\n\n\n\n\nThe residue theorem, \\oint_{\\mathcal{C}} f(z) \\, dz = 2\\pi i \\sum_{k} \\text{Res}(f, z_k) , is the foundation. For integrals with branch points, we extend the logic by deforming the contour around branch cuts, which reduces the problem to integrating the function’s discontinuity across that cut. This technique is powerful for evaluating real integrals and appears in physics contexts like dispersion relations and spectral representations.\n\n\n\nThe remaining step is the final evaluation, which involves the imaginary part of \\sqrt{x} times i , leading to a simple integration on the real axis. The two methods—direct parameterization and branch-cut deformation—provide a consistent answer, demonstrating the robustness of the complex analysis approach."
  },
  {
    "objectID": "2024-Lecture-08.html#analyticity-and-branch-points-in-the-scattering-amplitude",
    "href": "2024-Lecture-08.html#analyticity-and-branch-points-in-the-scattering-amplitude",
    "title": "(2024) Lecture 8",
    "section": "3 Analyticity and Branch Points in the Scattering Amplitude",
    "text": "3 Analyticity and Branch Points in the Scattering Amplitude\nThe scattering amplitude is the real magic function.\n\n\n\n\n\n\nFigure 1: This figure illustrates the derivation of the optical theorem using the principle of unitarity in scattering theory. On the left, the sum over all possible intermediate states ( \\sum_n ) is shown, representing the process where the initial state can scatter into any set of possible intermediate particles (labeled by n ). The diagram in the center shows the forward scattering amplitude, while the terms on the right represent the subtraction of the amplitude from its complex conjugate. This corresponds to taking the difference between the amplitude and its Hermitian conjugate, which isolates the imaginary part of the forward scattering amplitude. This imaginary part is related (via unitarity) to the total cross section for the process, connecting the squared modulus of the amplitude summed over all intermediate states to the discontinuity (imaginary part) of the amplitude itself. This graphical equation expresses the optical theorem in terms of analyticity and unitarity of the scattering amplitude as described in the lecture.\n\n\n\nLet’s return to our two sketches of the amplitude, for which we derived the optical theorem and discussed the analytic structure. The claim is that the amplitude is a real magic function, so part of it.\nLet’s clarify the assumptions and the physical principle. The amplitude is not accessed directly in experiment; we cannot validate its properties exactly. What we measure is the amplitude squared. Access to the amplitude itself is only available via our observables.\nHowever, scattering theory and probability conservation imply that certain properties of the amplitude, particularly constraints on its imaginary part, tell us where the imaginary part is present. The fact that it’s analytic is a postulate. This is something we have to assume.\nIt’s stronger than an assumption. We don’t assume its analytic properties; this is the building principle of our series. All series we have seen so far have unitarity built in. Therefore, not only unitarity, but also causality, which is related to analyticity.\nThe amplitude being an analytic function is a principle that is postulated in our theory. It is related to the causality of the theory—that the past does not influence the future. Events separated outside the causality cone don’t influence each other. We are not deriving this, but you can find the causality connection to analyticity in several books; we take it as a postulate.\nThe amplitude is analytic, and then unitarity tells you more. Moreover, the amplitude is real analytic below the threshold, because the imaginary part is connected to the particle’s appearance in intermediate states. This is only present once you are above threshold, because the interaction tells you that the amplitude has an imaginary part above the threshold. Below threshold it doesn’t have any imaginary part; it’s real.\nSo here I have a diagram on the x-axis. Again, it’s the complex plane of the energy. The variable s is E^2 , where E is the center-of-mass energy, and the amplitude \\mathcal{A}(s) as a function of this s is an analytic function.\nWhat we get to deal with is only the values of this amplitude above the threshold. However, the postulates of our theory tell you that using analyticity we can extend the domain of definition into the full complex plane. I hope you wrap your mind around the idea that now we can extend this analytic domain and think of our amplitude as a complex function.\nInstead of the energy of the interactions being like 5 GeV, you can put a complex number there and then you probe the function away from the real axis. This function has a certain range of singularities. The fact that the imaginary part is not present below threshold and then suddenly appears above threshold tells you that a certain singular disk pops up. These singularities are the branch points.\nEvery threshold has nice derivations of the threshold singularities for different numbers of particles. However, something to see easily is the two-body threshold. I want to show you that it introduces square root singularities. It simply follows from the fact that the imaginary part has a square root.\nLet me show you that the imaginary part of the amplitude from unitarity that we derived last time is related to the amplitude squared itself. There is a prefactor here. This prefactor is the phase space, simply the two-body phase space. The one half comes from \\mathcal{A} - \\mathcal{A}^* .\nI place the imaginary part on here, here I replace it and \\frac{1}{2} over here. The two-body phase space has the factor \\frac{2p_{\\text{cm}}}{\\sqrt{s}} . This 2p_{\\text{cm}} is the breakup momentum. This is something that actually makes a singularity, something that vanishes at the threshold.\nThe breakup momentum is the momentum particles have. Clearly if you are at the threshold, you have the minimal energy of the system. It’s simply two masses of the particles. They don’t have free energy, they don’t have momentum. That’s something that vanishes.\nMathematically you see that if you compute this two-body breakup momentum, you find that it’s equal to the Källén function.\n\n\n\n\n\n\nFigure 2: This figure represents the analytic structure of the scattering amplitude \\mathcal{A}(s) as a function of the Mandelstam variable s = E^2 , where E is the center-of-mass energy. The horizontal axis is the real axis of s , while the vertical axis would represent the imaginary part if drawn fully. The portion of the real axis labeled “real analytic” depicts the region below the two-particle threshold at s = (m_1 + m_2)^2 . In this region, the amplitude is real analytic, meaning it is a real-valued, analytic (holomorphic) function—there is no imaginary part, and the function can be represented by a convergent Taylor series. At the point s = (m_1 + m_2)^2 , the threshold for producing two particles of masses m_1 and m_2 , a branch point occurs. This marks the beginning of a branch cut along the real axis for s &gt; (m_1 + m_2)^2 , which is where the imaginary part of the amplitude appears due to physical particle production. The branch cut is related to the square root behavior of the two-body phase space, as discussed in the lecture. Thus, the figure illustrates how the analytic properties of the amplitude change at the physical threshold, emphasizing the importance of branch points and cuts in the analytic structure of scattering amplitudes.\n\n\n\nRemember \\lambda(x, y, z) = x^2 + y^2 + z^2 - 2xy - 2yz - 2zx . You can arrange this as the product, and to be precise, the product of the two terms where you have x - y + z . This is the masses of two particles and the difference between them and under the square root.\nThe first term gives you a singularity at the threshold and the second one gives you a singularity at the pseudothreshold. The integral relation as we wrote it, as we derived, is valid only above the threshold. The imaginary part is non-zero and present only once you go above the threshold.\nThis imaginary part appears to have a square root behavior. That indicates, that tells you that the function itself has a square root branch point. Essentially above that point the function has this branch cut.\nWe would like to connect this to the Schwarz reflection principle. Since our function was real and analytic on a segment of the real axis, the Schwarz reflection principle works above. It connects the amplitude in the upper half-plane with the amplitude in the lower half-plane.\nIf your function is \\mathcal{A}(s + i\\epsilon) , it simply tells you that the imaginary part flips if you go from above the real axis to below the real axis. That’s a relation where \\epsilon is small enough.\nThis is now in the pop, in the rock. People like the word. Maybe next time I bring you something. I was impressed recently. Listen to the song “Infinitesimal,” and that’s a word I like. It just means very, very small, infinitesimal.\nI’m going to use this i\\epsilon , and you’ve seen it before. This is just the little number that indicates that you are like a very, very small amount above the real axis or below the real axis. Cool.\nIt happens due to the phase space. We realized that if the function, if there were no phase space configuration summations on the right, you could relate the imaginary part to the amplitude itself and there would not be branch points. But it’s unavoidable. You have to sum over phase configurations.\nThat gives you the square root branch point. It also tells you that the amplitude has a branch point starting at the threshold and going in the positive direction.\nI wanted to quickly give an example of such a function, an example of a real analytic function, a function with a cut to the right. An example of a real analytic function like our scattering amplitude, but something very simple with a square root function that has a cut to the right.\nThe square root of x doesn’t work. Test. Cut on the left? On the left. Let’s cut to the left. How do I see where it has the cut? Simply because amplitude of 1 + \\epsilon is equal to amplitude of 1 - \\epsilon , there is no cut.\nThen \\sqrt{-1 + i\\epsilon} is equal to i , and \\sqrt{-1 - i\\epsilon} is equal to -i . On this side the function evaluated from above and the function evaluated from below have different values. That tells me in which direction I put my cut.\nThis is a branch point and this is a non-analytic point. For every branch point there is a cut attached and then it splits my manifold and analyticity into the functions, into the sort of surfaces, different sheets. All of the functions elsewhere except this point are analytic.\nBut you have to work to see this analyticity. Essentially you have to analytically continue functions. If you see the pattern, you want to make this function analytic. It’s always possible, but you have to work a little bit by extending the analyticity domain.\n\n\n\n\n\n\nKey Formulas for This Section\n\nTwo-Body Unitarity: \\operatorname{Im} \\mathcal{A}(s) = \\frac{1}{2} \\int d\\Phi_2 \\, |\\mathcal{A}(s)|^2\nBreakup Momentum & Phase Space: \\rho(s) = \\frac{2p_{\\text{cm}}}{\\sqrt{s}} , where p_{\\text{cm}} = \\frac{\\sqrt{\\lambda(s, m_1^2, m_2^2)}}{2\\sqrt{s}}\nKällén Function: \\lambda(x, y, z) = x^2 + y^2 + z^2 - 2xy - 2yz - 2zx . For two-body kinematics, this becomes \\lambda(s, m_1^2, m_2^2) = [s - (m_1 + m_2)^2][s - (m_1 - m_2)^2] , showing the square-root branch points at the threshold (m_1+m_2)^2 and pseudothreshold (m_1-m_2)^2 .\nSchwarz Reflection Principle: \\mathcal{A}(s + i\\epsilon)^* = \\mathcal{A}(s - i\\epsilon) for real s below the first threshold."
  },
  {
    "objectID": "2024-Lecture-08.html#analytic-structure-and-branch-cuts-of-a-square-root-function",
    "href": "2024-Lecture-08.html#analytic-structure-and-branch-cuts-of-a-square-root-function",
    "title": "(2024) Lecture 8",
    "section": "4 Analytic Structure and Branch Cuts of a Square Root Function",
    "text": "4 Analytic Structure and Branch Cuts of a Square Root Function\nComing back to the example, you’ll understand it better once I finish it.\nSo, if I put the minus x and evaluate the function somewhere in the complex plane, I find it’s now fully analytic here, and it has a cut to the right.\nNow, let’s evaluate this function at s = -1. What is it equal to? I want my function here, and it gives me one minus, minus. This is an example of a real analytic function.\nOr, let’s put the amplitude—the simplest amplitude. A valid amplitude would be: \\sqrt{-s + m_1^2 m_2^2}\nwhich has similar properties.\n\n\n\n\n\n\nFigure 3: This figure illustrates the analytic structure of the function \\sqrt{x} in the complex plane. The image shows a complex plane with a vertical (imaginary axis) and horizontal (real axis) line, with a thickened or darkened segment along the negative real axis. This dark segment represents the branch cut of the function \\sqrt{x} , which is a line (chosen conventionally along the negative real axis) where the function is discontinuous. The point at the origin ( x=0 ) is the branch point where the non-analytic behavior begins. Physically, this means that as you move around the origin in the complex plane, the value of \\sqrt{x} can jump discontinuously when crossing the cut, which is essential for defining the function’s analytic properties. In the context of scattering amplitudes and complex analysis, identifying such branch points and cuts is crucial for understanding where the amplitude is analytic (holomorphic) and where it develops discontinuities due to physical thresholds.\n\n\n\n\n\n\n\n\n\nThis function f(s) = \\sqrt{-s + m_1^2 m_2^2} is analytic in the complex s -plane except along a branch cut. This cut is typically placed where the expression under the square root, -s + m_1^2 m_2^2 , is real and negative, leading to a discontinuity.\n\n\n\nQuickly, while I’m cleaning the board: what is the analyticity structure of this? We are in the x-plane.\nLet’s finish here. I put -9 in the first one to make it more interesting. Anyway, this first function has the cut on the right, and the second one has a cut. They are very similar, but shifted by one.\nSo essentially, the structure is: one cut, then a second cut. When you have this situation, there is no jump here. You can jump twice and the cuts overlap, so there is no discontinuity of the function. It’s analytic right here.\nThe right answer is just the cuts connecting two points. This one is tricky. The first time I saw it in a mathematical context, I was really shocked because the locations of the branch points are the same. There are two points, x and x, where the function is non-analytic.\nBut the locations of the cut are driven by the places where the imaginary expression under the square root has an argument of \\pi or -\\pi . For a regular square root function, the cut appears where the argument is either \\pi or -\\pi .\nTo understand where your Mathematica, C, or Python library would draw a cut, you need to understand where the expression under the square root has an argument touching \\pi or -\\pi . And then, apparently, this is indeed between the points, but also along this line.\n\nThis is the first cut going to infinity.\nThis is the second cut going to infinity.\n\nIt’s crazy, and this is actually different from the previous case.\nIf you just split the product into two square roots: \\sqrt{(-s + a)(-s + b)} = \\sqrt{-s + a} \\cdot \\sqrt{-s + b}\nthen you remove these two connections. I don’t want to confuse you, but to warn you: one has to be careful how you write the expression, exactly how you split the square root, because that makes the function different on the real axis.\nI think they will be the same on the real axis, but on the complex plane the functions are different. They might even be different elsewhere…\nTo prove that \\sqrt{(-s + a)(-s + b)} is not equal to \\sqrt{-s + a} \\cdot \\sqrt{-s + b} , we can simply evaluate the function at s = -1. That’s an easy exercise.\nThe way I see that they are different is because I know the analytic structure of the first expression is one cut connecting two branch points. In order to arrive from this structure to the other, I can take this cut, rotate it over here, take this one, rotate it over there, and cancel two cuts. Making these two cuts cancel each other tells me that the function in the original configuration has a different value at s = -1.\nIf I evaluate, I should see this immediately:\n\nEvaluating the top one: \\sqrt{(-(-1) + 2)(-(-1) + 2)} = \\sqrt{(1+2)(1+2)} = \\sqrt{9} = 3\nEvaluating the product of square roots: from the first factor \\sqrt{1+2} = \\sqrt{3} and from the second \\sqrt{1+2} = \\sqrt{3} . Their product is (\\sqrt{3})^2 = 3 .\n\nHowever, with careful sign consideration from the branch choices (as hinted in my notes), the values can differ. For instance, \\sqrt{2i} \\cdot \\sqrt{2i} could be evaluated as 2i , while \\sqrt{(2i)^2} = \\sqrt{-4} could be 2i with an appropriate branch, illustrating the subtlety. The key point is their analytic structures—their branch cuts—are fundamentally different."
  },
  {
    "objectID": "2024-Lecture-08.html#complex-plane-analogy-for-scattering-amplitudes-and-resonances",
    "href": "2024-Lecture-08.html#complex-plane-analogy-for-scattering-amplitudes-and-resonances",
    "title": "(2024) Lecture 8",
    "section": "5 Complex Plane Analogy for Scattering Amplitudes and Resonances",
    "text": "5 Complex Plane Analogy for Scattering Amplitudes and Resonances\nIts resonances are poles of the scattering amplitude. You will hear that many times in the future.\nThink of the intensity flow. The function in the complex plane is like the complex structure of a house. In this house there are just a few routers. You desperately want your Internet; the farther you are from the router, the weaker signal you get. If you sit at a point and you have a really good Internet, you are probably sitting not far from the router. Similar to that, this is our couch in the house where people usually sit and they experience different strengths of the Internet. The routers are the resonances.\nHere I have combined two modes on the Y axis. I have a complex s plane, with real s on the axis. This indicates minus imaginary s . This is the same as I would have for the complex plane. I draw a square. The square is the strength of your Internet when you sit on this couch. In the middle you have the closest distance to the router, to the resonance pole, and therefore your strength is the highest. If you go far away, your Internet weakens.\nNow let’s make the house a little bit more complicated. We have several floors. In that case the cuts… Here is my map of the room. As usual, I am the couch where people sit on the real axis. But in that case I have the house a little bit complex. There is a room with different electronics, a different floor, so I can go to another room. I experience all the routers that are in another room. Essentially, if in another room I have a router sitting here, I want to see the influence of it from my couch. Let me put it here. This is floor one and the next is two. I am going to draw the sheet too. Sheet one is our floor one and then sheet two is floor two. Here is the gate. You can think of this now as the sort of stairs from one to another, and this continues. If I have my router here, I am going to see I have a really good strength here and then here as well. But if I go around the corner, I start losing the signal. Here the distance becomes high. The way to get Internet is around the wall. This is the gate to another floor and I can only enter on that side.\nIs it clear? I feel like this picture of the floors and the routers is really helpful, but might be still overwhelming. The routers are the resonances. I see the routers on each floor. If they are above the threshold, it is too complicated. Essentially, when you hear about the complex plane and the poles, just think of the intensity floor somewhere in the complex domain. There are gates to other floors. Do not think about them as changing the level, but it is simply the way to connect one to another. Somewhere on this surface that has different levels, you place the routers. These routers influence your intensity, which you see on the real axis.\nWhat is the difference between a bigger room and multiple floors? No difference. The rooms are infinitely big either way. But since at every point I can be at different sorts of floors that are connected smoothly to each other, I have to draw several maps, several sheets. In the shopping malls you also have multiple floors with shops indicated because it is really hard to show it on a single one.\nFor simplicity, unitarity tells us the cut should be to the right. But I would never do it practically like that. I know unitarity tells me that. Nothing happens if I just place the cut to the left. I will demonstrate what I want to do with the square root function, \\sqrt{x} . It has a branch cut and I am carrying my function value right here. There is nothing going to happen if I just draw the cut in different directions. I would like to say that this function is the same function. But now in that case I have a branch cut. Is it the same? Let us evaluate this function. At x = -1 you have an i . At -1 + \\epsilon you have an i . This function at -1 gives you an i again. This function and that function are exactly the same in this region. The difference between them is that I took my branch cut and rotated it to the right such that I opened the space underneath. I just made the renovation and changed the rooms how they are located in the house. It changes nothing in the strength of the amplitude essentially because the walls, I mean there are no walls. Essentially everything is continuous. The cut, the way how I draw the cut, is just a way to separate different branches. There is no wall that prevents the signal strength. That is why for this I would never do this practically like that. This is what unitarity tells us about imaginary part and real analyticity. For practical reasons it is always convenient to open up the closest branch to us to see. Therefore it is more natural to place the cut in a convenient location. The cut goes to the right, I turn it to the left and now actually my function is not real, but I now expose a bigger range of the complex plane to analyze.\nEssentially, if I sit here, this point on the real axis is influenced by all singularities in the complex plane that are nearby. If I have a pole right here, I do not have to care about the branches any longer. I just immediately see the effect in the strength of my amplitude if my pole is nearby. That is the most convenient, in my opinion, way to think of the complex plane and the scattering amplitude.\n\n\n\n\n\n\nFigure 4: This figure illustrates the physical meaning of resonances as poles in the scattering amplitude and the analytic structure of complex functions in the context of scattering theory. - Branch cuts and analyticity: The sketches at the top show the analytic structure of functions like \\sqrt{x(x-1)} versus \\sqrt{x}\\sqrt{x-1} , emphasizing that while individual square roots have branch cuts on the real axis, their product (if not written with care) might not match the full analytic structure, demonstrating the importance of how a function is defined with respect to branch points and cuts. The analytic continuation and placement of branch cuts affect the behavior and discontinuities of the function. - Poles and “intensity flow”: The middle section introduces the concept that physical resonances correspond to poles of the scattering amplitude in the complex s -plane (where s is the Mandelstam variable, often s=E^2 ), and how these influence observable data. The schematic “complex s plane” with a marked resonance pole shows that the observable intensity |A|^2 (the square of the amplitude) on the real axis is enhanced in the vicinity of such a pole—this is the resonance “peak” seen in experiment. The sketch shows this as “strength of signal” near the pole. - Sheets and analytic continuation: The two panels labeled “Sheet I” and “Sheet II” display different Riemann sheets in the complex s -plane associated with the function’s branch points and cuts. This reflects the fact that multivalued functions like those with square roots naturally extend to multiple sheets, and poles associated with resonances may appear on different sheets depending on the analytic continuation—a key concept in understanding physical resonances and thresholds. - Cuts can be rotated: The panel illustrating how branch cuts can be “rotated” or placed differently without changing the analytic nature of the function emphasizes that the mathematical convenience of cut placement aids analysis, but the physical consequences (like the influence of poles) are unchanged. - Amplitude pole formula and physical interpretation: The expression \\mathcal{A} = 1/(m_R^2 - s) and the boxed formula m_R^2 = (M_R - i \\Gamma_R/2)^2 indicate that the complex pole position encodes both the mass M_R and width \\Gamma_R of the resonance, and the concept of “Full Width at Half Maximum” (FWHM) shown on the intensity plot at bottom right links these mathematical quantities directly to physical observables. - Influence of singularities: It is noted that “data points are influenced by singularities”—meaning that the experimental measurements on the real axis “feel” the presence of nearby analytic structures (branch cuts and poles) in the complex plane. Physically, this figure captures: - How the analytic structure (branch points, cuts, and poles) of the scattering amplitude function in the complex plane directly governs the observable phenomena in scattering experiments (resonance peaks, thresholds, and cusps). - That resonances (unstable particles) are defined as poles of the amplitude in the complex s -plane, while branch cuts stem from multi-particle thresholds. - The importance of Riemann sheets and analytic continuation for understanding the full behavior of these complex amplitudes. - The freedom to draw branch cuts where convenient, reflecting the purely mathematical aspect of cuts in representing multi-valuedness, rather than physical discontinuities. - Ultimately, the physical resonances in scattering data are manifestations of the analytic structure of complex functions associated with the amplitude—particularly the positions and nature of poles and branch points in the complex plane.\n\n\n\n\n\n\n\n\n\nKey Analytic Structure The scattering amplitude \\mathcal{A}(s) has a pole at a complex value s = s_p where the denominator vanishes: \\mathcal{A}(s) \\propto \\frac{1}{s - s_p}\nThis pole defines the resonance. Its location is complex: s_p = (M_p - i\\Gamma_p/2)^2 , where M_p is the pole mass and \\Gamma_p is the pole width.\n\n\n\nI measure my amplitude above threshold. Here is (M_1 + M_2)^2 . That is where I measure my amplitude. What I measure is influenced by structures near threshold. If there is a resonance that I see in the data, it means down below there is a pole that makes this resonance. A resonance is always a pole. That is actually how we define the particles. Particles are always poles in the amplitude.\nWe have conventions for how to define the width and mass of the resonance. They come from the location of the pole. A single pole amplitude has this form: \\mathcal{A}(s) \\propto \\frac{1}{s - s_p} . When I say pole I literally mean a zero of the denominator. The location of this pole where the denominator vanishes is s_p or \\bar{m}^2 . This is a complex number. The real and imaginary part of this number are called mass parameters of the pole. This is literally the definition.\nWe call the mass of the pole the real part of the square of the pole location and the width of the pole twice the square root of the pole, twice imaginary part minus twice imaginary part of the pole location. More precisely, s_p = (M_p - i\\Gamma_p/2)^2 . They are related to the observed mass and width, because this is something you can define experimentally. If you see the signal, it has a peak location and a full width at half maximum. For narrow resonances, \\Gamma_p is approximately equal to the full width at half maximum and M_p is approximately equal to the peak location. That is not the case for broad resonances, but for narrow ones this is the case.\nWhat is the analytic structure of this function? The analytic structure is simply a pole. There are no branch points, there is nothing else. It is simply one pole.\nA little bit more complex example that we have on an exercise sheet is the relativistic case. Wigner had everything built in. It had a pole in the K-matrix and it had a square root branch point from the phase space. The K-matrix that we discussed last time is the way to incorporate poles and correct analytic structure together. It works for multiple loops. The scattering amplitude is \\mathcal{A} = K (1 - i \\rho K)^{-1} .\n\n\n\n\n\n\nParameterizing Resonances In practice, we often use specific parameterizations to fit data:\n\nThe Breit-Wigner amplitude is a common limit: \\mathcal{A}_{\\text{BW}}(s) = \\frac{g}{s - M^2 + i M \\Gamma(s)}\nThe more general K-matrix formalism ensures unitarity and can handle multiple channels: \\mathcal{A} = K (1 - i \\rho K)^{-1}\nHere, K is a real symmetric matrix, and \\rho is the phase-space factor.\n\n\n\n\nThe last comment on this subject is what we do when we analyze the data. The ultimate goal is to characterize resonances by their mass and width, or the pole location. We come up with the parameterization using a K-matrix or P-vector. Often you can use a simple Breit-Wigner, \\mathcal{A}_{\\text{BW}}(s) = \\frac{g}{s - M^2 + i M \\Gamma(s)} , which is the limit case of the K-matrix, unless you constrain your amplitude. The amplitude then has an expression that is rather complicated, has many terms, but it is an analytic function.\nYou have three parameters that you are just looking at in the data. By fitting this, you fix these parameters by analyzing data and then you explore the analytic expression. You know that it probably has a branch point. You decide either you draw it to the right or to the left. It is up to you. What is important is that everything that you see, all spikes, all peaks, everything that you see in your functions has some origin, and the origin is in the complex plane. If it has a peak, likely there is a pole there."
  },
  {
    "objectID": "2024-Lecture-08.html#thresholds-branch-points-and-poles",
    "href": "2024-Lecture-08.html#thresholds-branch-points-and-poles",
    "title": "(2024) Lecture 8",
    "section": "6 Thresholds, Branch Points, and Poles",
    "text": "6 Thresholds, Branch Points, and Poles\nAnother important phenomenon you see in the data is the cusp. This is the amplitude squared, |A|^2 , plotted against the Mandelstam variable s . You see a cusp, and that type of singularity is also known as a branch point.\nSo, do we have our branch points? The first threshold introduces a branch point; every threshold introduces a singularity. For two particles, it’s a branch point. We have already discussed this branch point. If there are more than two particles, combinations like \\pi\\pi , KK , or \\bar{K}K would give a branch point at 1 GeV. Then the amplitude might have a spike. This is an indication that in the complex plane all is fine, but there is a branch point.\nFor every branch point, we have to attach a sheet. This is the location of the cut; it’s up to us how to draw it, but it introduces more surfaces. So this is a direction.\nThe last thing to realize is about the triangle. We know that at threshold the function has a square root singularity, but thresholds are only opening new surfaces for you. The thresholds are only determining the map of your complex plane. The real singularities, or the strong singularities that make intensity peak, are poles.\nA situation where |A|^2 has this threshold behavior, but then rises very quickly and goes down, indicates that there are some poles nearby. If the poles were underneath, that kind of function would of course peak at that place. In that case, what likely happens is that there is a bound state; there is a pole here. If there is a pole on the real axis, it would not show up as a nice resonance-like peaking structure.\nIf you think again about the map of routers and the internet: if you have a router here and you sit on the couch, the signal strength will be highest here and then lower farther away. That’s simply how to understand threshold enhancements.\n\nThreshold enhancements are often indications of poles below threshold. These are bound states.\nThere is another phenomenon of poles at the same locations, but underneath another sheet, which is called a virtual state. They are not that different from each other.\nA bound state can live forever; it is a real state that can travel. It is a particle that does not decay.\nA virtual state is one that does not travel and does not decay. This is simply an enhancement.\n\nThis distinction is one of the objectives and discussion points in the field. When you observe a new structure, what kind of structure is it?\n\nIs it related to a threshold?\nIs it a pole?\nIs it a pole sitting below a certain threshold?\nOr is it a resonance that sits in the complex plane and is not related to a threshold?\n\nA relation to a threshold indicates a molecular nature. Remember, every threshold has two masses that are summed: s = (m_1 + m_2)^2 . It implies that there is a continuum; there is one particle and a second particle that interact with each other. This is our threshold. If there is a pole that is related to a threshold, likely part of the wave function for this state is of this two-particle type. This is the molecular type. That’s why identifying all thresholds and the complex structure, and where the resonance pole sits, is so important.\nNow, a quick question. What about the other threshold, s = (m_1 - m_2)^2 ? Yes, it’s a pseudo-threshold. It appears artificially in our expressions because of the breakup momentum formula: p = \\frac{\\sqrt{[s - (m_1 + m_2)^2][s - (m_1 - m_2)^2]}}{2\\sqrt{s}}\nIf you look at that place, the amplitude is not supposed to have a physical singularity. This tells you that you cannot literally take this expression and continue analytically at the place of this pseudo-threshold. This is a sort of false threshold. We don’t see it in the amplitude.\nThis is one indication that you should not take this expression literally and build it into your model. Instead of using just the phase space factor, \\rho(s) = \\frac{1}{8\\pi} \\frac{2p}{\\sqrt{s}} , note that this is actually the imaginary part of the bubble diagram. You see this simply from unitarity, because once you cut this diagram, the imaginary part would be equal to the product of the matrix elements (both equal to one) and the two-body phase space, because you cut two lines. Here is the two-body phase space.\nThe pseudo-threshold is present here because you are using only the imaginary part in your amplitude. If you were to take the full bubble diagram, you don’t have a pseudo-threshold there.\n\n\n\n\n\n\nKey Formulas Recap\n\nPhysical Threshold: s = (m_1 + m_2)^2 defines where a new two-particle channel opens, creating a branch point.\nTwo-Body Phase Space: \\rho(s) = \\frac{1}{8\\pi} \\frac{2p}{\\sqrt{s}} is the phase space factor and appears as the imaginary part of the bubble diagram from unitarity.\nUnitarity Relation: A simplified form is \\operatorname{Im} \\mathcal{M}(s) \\propto \\rho(s) |\\mathcal{M}(s)|^2 , linking the amplitude’s imaginary part to the phase space.\n\n\n\n\nI was thinking we could do the exercise in the lecture today of computing this bubble diagram literally, because it’s really closely related to unitarity."
  },
  {
    "objectID": "2024-Lecture-10.html",
    "href": "2024-Lecture-10.html",
    "title": "(2024) Lecture 10",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-10.html#cross-section-calculation-and-spin-algebra-in-scattering-problems",
    "href": "2024-Lecture-10.html#cross-section-calculation-and-spin-algebra-in-scattering-problems",
    "title": "(2024) Lecture 10",
    "section": "1 Cross Section Calculation and Spin Algebra in Scattering Problems",
    "text": "1 Cross Section Calculation and Spin Algebra in Scattering Problems\n\nFirst, calculate the cross section for the scattering of two massless particles. The matrix element is given for spin-zero scalar particles. The task is to calculate the cross section and give the answer in millibarns.\nSo, number one: calculate the cross section. That’s to remember the equation for how we compute the cross section. Essentially, putting the numbers in, the whole computation is straightforward.\nLet’s do that before moving on. The cross section is given by flux, the matrix element squared, and an average over phase space. The matrix element squared gives you 3 + 9 + 4 , which is 13 .\nHere is the flux factor. Here is the phase space factor. The phase space is \\frac{1}{8\\pi^2} \\times \\frac{2p}{\\sqrt{s}} . You have to calculate \\frac{2p}{\\sqrt{s}} knowing the masses and the energy. For this case, the momentum is p = \\sqrt{s}/2 . So this factor is actually equal to 1 . The phase space simplifies to \\frac{1}{8\\pi^2} .\nNow, what about flux? Flux is \\frac{1}{2E_1 2E_2 |v_1 - v_2|} . In the center-of-mass frame, both energies are half of the total energy, E = \\sqrt{s}/2 . For massless particles, their velocities are the speed of light, so |v_1 - v_2| = 2 . This gives a flux factor of \\frac{1}{2s} .\nPutting things together, the cross section is \\sigma = \\frac{1}{2s} \\times 13 \\times \\frac{1}{8\\pi^2} . This simplifies to \\frac{13}{16\\pi^2 s} .\nNow, for \\sqrt{s} = 3 GeV, we have s = 9 GeV². So \\sigma = \\frac{13}{16\\pi^2 \\times 9} GeV⁻². Using the conversion 1 \\text{ GeV}^{-2} = 0.389 mb, we can compute the numerical value. The π is approximately 3.14. This gives a result around 0.01 millibarns.\nWhat’s important is that you start from the right equation, use the right formulas for the cross section, for the phase space, and for the flux, and then arrive at the hopefully correct result. The starting point and knowing what to use for each factor is key.\n\n\n\n\n\n\nKey Formulas for Cross-Section Calculation:\n\nGeneral 2→2 Scattering: The differential cross section is given by \\frac{d\\sigma}{d\\Omega} = \\frac{1}{64\\pi^2 s} \\frac{|\\mathbf{p}_f|}{|\\mathbf{p}_i|} |\\mathcal{M}|^2\nFlux Factor: In the center-of-mass frame, F = 4 |\\mathbf{p}_i| \\sqrt{s} .\nTwo-Body Phase Space: d\\Phi_2 = \\frac{1}{8\\pi^2} \\frac{|\\mathbf{p}|}{\\sqrt{s}} d\\Omega .\n\n\n\n\nPlease start with the equation where you have the imaginary part of the matrix element. We didn’t end up with the final result from that. When you start with the imaginary part, you use the optical theorem. You say, “I know the imaginary part, and then I can calculate the total cross section from it.” The optical theorem states:\n\\sigma_{\\text{total}} = \\frac{1}{|\\mathbf{p}_i| \\sqrt{s}} \\operatorname{Im} \\mathcal{M}(0^\\circ)\nIt would give you the total cross section. Actually, it won’t give you the cross section for just the elastic process. That’s a different problem. That’s actually a cool question for an exam: give you this expression and ask you to calculate the elastic cross section and the total cross section. For elastic, you use the full squared matrix element. For the total, you use the imaginary part.\nA short question: why could the total cross section be different than the elastic? Physically, what one describes is just one scattering channel, and the other describes all possible processes. So it’s not just AB \\to AB , but AB \\to CD and AB \\to EF as well. All of them. Of course, the total cross section should be bigger.\nI’m curious now. After the lecture, I’m going to sit and calculate what happens if I take the imaginary part, calculate the total cross section, and find out that it’s smaller. Is the equation for the total cross section the absolute value of the imaginary part? Because otherwise, it would be negative, and that was a bit confusing. It’s not the absolute value. It should give a positive result. The imaginary part is related to the total cross section, so the imaginary part must be positive.\nIf I’m thinking of the Breit-Wigner function, its imaginary part goes up and then goes down, but it stays positive. Also, remember the Argand diagram? On the x-axis, we have the real part of the matrix element. On the y-axis, we have the imaginary part of the amplitude. Only positive values were allowed. So, giving a negative value here is illegal.\nMoreover, in the last exercise, we started discussing which are legal values and which are not. I might end up giving you a value that is not in the elastic scattering regime. If I’ve done the calculation correctly, it should be all right. Not necessarily. Well, if I’m outside the resonance, it’s fine.\nNumber two quickly. This is simple spin algebra, but I want you to be very sure what you’re doing. How do you add spins together, and how do you compute the partial waves? Something you take from this course at least is spin algebra.\nFirst, you need to calculate the quantum numbers in combination. In boson routes, you draw the table, and then you see which column of the tables has the right counting numbers. It’s as simple as that. But what’s the spin and parity of the \\pi_1 ? Minus, minus, plus. That’s straightforward.\nI don’t want you to look at the C-parity for now. When we do spin algebra and the spin composition of representations, we only care about the spin. Parity is simple to compute for every multiplet:\nP = P_1 P_2 (-1)^L\nWe combine 1^- and 1^+ to get 1^- in an S-wave. So the S-wave works. Is there another wave that works? In an S-wave, we have only spin-1. In a D-wave, we have spins 0, 1, and 2. In an F-wave, we have spins 1, 2, and 3. The parity is given by (-1)^L , so it would be different for different partial waves.\nWhat I was confused about is the charge conjugation. I got the numbers here correctly, I’m pretty sure. I just checked. The \\pi is 0^{-+} . The b_1 is 1^{+-} . I’m confident that the decay is possible. The charge conjugation for the \\pi_1 is plus. Therefore, it’s a charge conjugation eigenstate.\nIsospin is violated in this decay. Yep, it’s okay. I mean, no, it’s fine. Isospin does get violated. I will think a little bit more on that because I didn’t expect it. I saw that it’s listed as a regular strong decay.\nWhat is peculiar about that is the \\pi_1 has the quantum numbers 1^{-+} , which are not allowed in the quark model. So this is not a regular hadron. The picture that people have for the \\pi_1 is something like a gluonic excitation inside the meson. The string or gluon interaction that connects the quark and anti-quark pair in a mesonic picture also has degrees of freedom and can be excited. So it’s not sitting in the regular confined potential, but in the excitations of this real interaction. That’s how people understand it. This particle is called a hybrid meson.\nThe same for the P_1(1400) with similar quantum numbers. It’s the same idea, the same state. Finally, it was removed from the PDG because it was first seen in old data around 1400 MeV. But then, with new data and more accurate analysis, it has been realized that it’s actually around 1600 MeV that shows up, and in the \\eta\\pi channel for number three."
  },
  {
    "objectID": "2024-Lecture-10.html#relating-relativistic-and-non-relativistic-scattering-lengths",
    "href": "2024-Lecture-10.html#relating-relativistic-and-non-relativistic-scattering-lengths",
    "title": "(2024) Lecture 10",
    "section": "2 Relating Relativistic and Non-Relativistic Scattering Lengths",
    "text": "2 Relating Relativistic and Non-Relativistic Scattering Lengths\nI thought it’s important to clarify. The notations got a little bit confused at the last lecture concerning the scattering length.\nThe scattering length is indeed measured in Fermi (fm). However, when you use relativistic notations, it appears dimensionless.\nIn quantum mechanics, the scattering length is defined from the expansion of the amplitude in terms of the breakup momentum K . The breakup momentum K has units of GeV. Therefore, 1/a has units of GeV, and a itself is in Fermi.\nThe standard non-relativistic amplitude has the form: f_{\\text{NR}}(K) = \\frac{1}{a^{-1} - iK}\nThis is the leading-order effective range expansion.\nIn a relativistic formulation, unitarity tells us that the imaginary part of the amplitude is related to the dimensionless phase space. The first expansion term is again something like a scattering length, but it is dimensionless. A common parameterization is: f_{R} = \\frac{1}{\\tilde a^{-1} - i\\,\\frac{2k}{\\sqrt{s}}}\nwhere \\tilde{a} is the dimensionless relativistic scattering length.\nYou still want to talk about the physical scattering length in Fermi. Therefore, you have to relate the relativistic amplitude to the non-relativistic one, and the relation happens at the threshold. Since it’s a threshold expansion, you would like these amplitudes to match up to a numerical constant at threshold.\nIn this exercise, I want you to relate these two at threshold and determine what the relativistic amplitude looks like near threshold. I’ll give you the answer. The only thing that’s missing is the value of \\tilde{a} . The scattering length a is three Fermi. Knowing that, you need to compute \\tilde{a} .\nThe way to do that is: you cannot just make the amplitudes equal at threshold. If you set the non-relativistic amplitude equal to the relativistic one, you miss the point.\nIf you evaluate the non-relativistic amplitude at threshold, where K = 0 , you get: f_{\\text{NR}} = \\frac{1}{a^{-1}} = a\nThis would just suggest \\tilde{a} = a , which is not helpful. They are not equal; there is a numerical constant that you need to figure out.\nThe correct way to equate them is to match their structure—either equate numerators or denominators up to a numerical constant—and then compare the coefficients in front of K . One method is to perform a Taylor expansion of the relativistic expression where s is a function of the momentum and equate the first terms.\nAlternatively, just notice that the key difference in the numerators is the phase space factor. The matching condition at threshold is: \\mathcal{A}_{\\text{rel}}(s_{\\text{thr}}) \\propto \\frac{1}{8\\pi^2 s} \\cdot (-iK)\n\n\n\n\n\n\nTo solve for \\tilde{a} , you need the masses and the threshold value. The threshold s_{\\text{thr}} for \\pi^0 \\pi^0 scattering is: s_{\\text{thr}} = (2m_{\\pi^0})^2\nThe conversion between the scattering lengths is given by: \\tilde a = \\frac{a}{8\\pi\\sqrt{s_{\\text{thr}}}} = \\frac{a}{8\\pi\\,(2m_{\\pi^0})}\nGiven a = 3 \\,\\text{fm} , you substitute the pion mass to find the numerical value of \\tilde{a} . This is a low-energy relation.\n\n\n\nSo, \\tilde{a} is equal to a divided by this phase-space factor. You put them together and then you find the value of \\tilde{a} ."
  },
  {
    "objectID": "2024-Lecture-10.html#chirality-spin-and-solutions-of-the-dirac-equation",
    "href": "2024-Lecture-10.html#chirality-spin-and-solutions-of-the-dirac-equation",
    "title": "(2024) Lecture 10",
    "section": "3 Chirality, Spin, and Solutions of the Dirac Equation",
    "text": "3 Chirality, Spin, and Solutions of the Dirac Equation\nThis concept is used widely and provides very interesting insights into hydrodynamics. It relies on the extra symmetry we observe when the mass of the particles is equal to zero, called chirality.\nThat’s related to the spin orientation for particles with spin one-half. So that’s why we now come back to our consideration of particles that carry spin information and look particularly at spin 1/2 and their field theoretical representation.\nSpin 1/2 particles obey the equation of motion given by the Dirac equation: ( \\mathrlap{/}p - m ) u(p) = 0\nHere, \\mathrlap{/}p = p^\\mu \\gamma_\\mu is the contraction of the four-momentum with the Dirac gamma matrices.\nThere are two common conventions used to solve the Dirac equation:\n\nThe standard Dirac convention.\nThe Weyl convention.\n\nVarious spinors are slightly different and are more convenient when you deal with right-handed and left-handed particles. Since the Dirac convention is more commonly used, I will stick to that and proceed with the standard convention.\n\n\n\n\n\n\nThe Dirac equation in momentum space is ( \\mathrlap{/}p - m ) u(p) = 0 . The term m is a scalar mass, but it is implied to be multiplied by the 4 \\times 4 identity matrix. The object u(p) is the Dirac spinor, a four-component object that depends on the particle’s momentum and spin orientation.\n\n\n\nThe \\gamma^\\mu are four-dimensional matrices and p is the four-vector. Therefore, when you contract the two, with summation over \\mu performed, you have a four-dimensional matrix for \\mathrlap{/}p .\nThe Dirac equation has two independent solutions. Let’s consider p as a vector that has a component in space, a momentum \\vec{p} . You put this expression into the equation and have a matrix expression that has two solutions, u_1(p) and u_2(p) .\nThese correspond to the canonical states. We have an axis: X, Z, Y. We have a state with spin quantized along the Z axis. You might remember these objects: |p; j, m\\rangle_{\\text{can}} , which is a state that has a spin momentum pointing to a certain direction in space, with the spin quantized along the Z axis and its projection equal to +1/2 or -1/2 .\n\nThe solution u_1 corresponds to a state with projection +1/2 .\nThe solution u_2 corresponds to a state with projection -1/2 .\n\nYou find this by applying the spin operator, where the eigenvalue for the first one is +\\frac{1}{2} and for the second one is -\\frac{1}{2} . These are two independent solutions. Any linear combination of the two is also a solution of the Dirac equation.\nI am now going to go to the linear combinations that correspond to the spin quantized along the direction of momentum, which is also a solution. A reminder for how the canonical state is defined: it is a pure boost acting on the rest frame state, |p; j, m\\rangle_\\text{can} = B_{\\vec{p}} |0; j, m\\rangle_\\text{can} .\nThe way you relate canonical to helicity states is by introducing an extra rotation R^{-1} to match the transformation of the canonical state, and you put the rotation R that is needed. You apply R to the state. What R B R^{-1} is doing is acting on the new transformed canonical states, or states in the rest frame. Then you have the canonical state once you apply R B R^{-1} . This is a pure boost, and it’s a linear combination of canonical states with the coefficients given by these special matrices, the Wigner D-matrices: |p; \\lambda\\rangle = \\sum_{m} D^{(1/2)}_{m\\lambda}(R) \\, |p; m\\rangle_{\\text{can}}\nHere, \\lambda = \\pm 1/2 is the helicity, and R is the rotation that aligns the z-axis with the momentum direction."
  },
  {
    "objectID": "2024-Lecture-10.html#conventions-and-definitions-of-the-d-function-in-rotations",
    "href": "2024-Lecture-10.html#conventions-and-definitions-of-the-d-function-in-rotations",
    "title": "(2024) Lecture 10",
    "section": "4 Conventions and Definitions of the D Function in Rotations",
    "text": "4 Conventions and Definitions of the D Function in Rotations\nI want to mention something tricky related to conventions. Once you discuss conventions, they can’t be helped, but it’s a good moment to see that there are two different conventions for how the Wigner D-matrix is defined for the spherical angles.\n\n4.1 Convention 1: The Standard Euler Rotation\nThe first definition is the standard one, using three Euler angles. If you look at the Review of Particle Physics or the Particle Data Group booklet, they use this convention. The rotation is defined as: R(\\phi, \\theta, \\psi) = R_z(\\phi) \\, R_y(\\theta) \\, R_z(\\psi)\nSo you rotate by \\phi around the z-axis, then by \\theta around the y-axis, and then by \\psi around the z-axis again. The matrix elements of this rotation for angular momentum states are given by: D^j_{m'm}(\\phi, \\theta, \\psi) = \\langle j, m' | R(\\phi, \\theta, \\psi) | j, m \\rangle\n\n\n4.2 Convention 2: Simplified for Helicity States\nThe second definition, which appears much simpler for constructions using helicity states, uses only two angles: (\\theta, \\phi) . This corresponds to a different ordering of rotations, such as D^j_{\\lambda' \\lambda}(0, \\theta, \\phi) or D^j_{\\lambda' \\lambda}(\\phi, \\theta, 0) .\n\n\n\n\n\n\nThe choice of convention affects an extra, unobservable phase in the states. If you start with a vector that has only a z-component, both conventions give the same result because the first rotation around z does nothing. However, for general states, the phase difference is important.\n\n\n\n\n\n4.3 What the D-Matrix Actually Is\nI should have started with a reminder. The capital D function is the rotational matrix in the representation of the rotation group. Rotations about the Z-axis just give phase coefficients, while rotations about the Y-axis require tabulated functions.\nThis D-matrix gives you the weight coefficients for the transformation of a state |j, m\\rangle . When you apply a rotation and project onto \\langle j', m'| , these matrix elements are given by D^j_{m'm}(\\phi, \\theta, \\psi) .\nComing back to our problem: we want to rotate a momentum vector from the z-axis to a general direction. This rotation produces the momentum vector: \\mathbf{P} = P \\, (\\sin\\theta \\cos\\phi,\\; \\sin\\theta \\sin\\phi,\\; \\cos\\theta)\nor, as a four-vector: \\mathcal P = \\bigl(E,\\;P\\sin\\theta\\cos\\phi,\\;P\\sin\\theta\\sin\\phi,\\;P\\cos\\theta\\bigr)\n\n\n\n\n\n\nFigure 1: This figure represents the definition of the momentum vector \\mathbf{P} in three-dimensional space with respect to the coordinate axes x , y , and z . The vector \\mathbf{P} is shown at an angle relative to the axes, which corresponds to its parametrization using spherical coordinates (\\theta, \\phi) , as described in the lecture. This depiction is physically significant because it illustrates how a rotation is needed to bring a canonical state (with momentum along the z -axis) to a general helicity state aligned along the direction of \\mathbf{P} . The angles \\theta and \\phi specify the orientation of the momentum, which is crucial for building the explicit form of spinor and helicity states and for the use of Wigner D-matrices, as discussed in the context of spin, helicity, and chirality in quantum field theory.\n\n\n\nWhen we apply this rotation to a helicity state, the D-matrix pops up, parameterized by the two angles \\theta and \\phi . Depending on which convention we use, this D-matrix will include an extra phase or not.\n\n\n4.4 Explicit Helicity Spinors for a Massive Spin-1/2 Particle\nApplying the transformation gives us an expression for the helicity state. For a particle with spin 1/2, projected onto the direction of motion, the state is given by a Dirac spinor.\nI introduced the normalization constant N : N = \\sqrt{E + m}\nThis is a standard normalization that appears everywhere to ensure the correct density of states.\n\nFor helicity +1/2 , the explicit spinor is: u_+(\\mathbf{P}) = \\sqrt{E + m}\n\\begin{pmatrix}\n1 \\\\\\\\\n0 \\\\\\\\\n\\dfrac{P}{E+m} \\cos\\theta \\\\\\\\\n\\dfrac{P}{E+m} \\sin\\theta \\, e^{i\\phi}\n\\end{pmatrix}\nFor helicity -1/2 , the spinor is: u_-(\\mathbf{P}) = \\sqrt{E + m}\n\\begin{pmatrix}\n0 \\\\\\\\\n1 \\\\\\\\\n-\\dfrac{P}{E+m} \\sin\\theta \\, e^{-i\\phi} \\\\\\\\\n\\dfrac{P}{E+m} \\cos\\theta\n\\end{pmatrix}\n\nThe lower part of the spinor has the common factor \\frac{P}{E + m} .\n\n\n4.5 The High-Energy Limit\nThat factor \\frac{P}{E + m} is important. In the high-energy limit, when the mass is small compared to the energy (m \\ll E) , we have P \\approx E . Therefore: \\frac{P}{E+m} \\longrightarrow 1 \\quad \\text{as} \\quad m/E \\to 0\nIn this ultrarelativistic limit, the spinors simplify significantly. The upper and lower components become comparable, and the state approaches a form like (\\cos, \\sin, \\cos, \\sin) up to a phase and the overall normalization factor \\sqrt{E} ."
  },
  {
    "objectID": "2024-Lecture-10.html#chirality-helicity-and-the-chiral-limit",
    "href": "2024-Lecture-10.html#chirality-helicity-and-the-chiral-limit",
    "title": "(2024) Lecture 10",
    "section": "5 Chirality, Helicity, and the Chiral Limit",
    "text": "5 Chirality, Helicity, and the Chiral Limit\nNow let me introduce projection operators, which will allow us to move forward. The \\gamma^5 matrix is defined as the product of the four gamma matrices: \\gamma^5 = i \\gamma^0 \\gamma^1 \\gamma^2 \\gamma^3\nThis is the convention we choose. It is very convenient when considering interactions to introduce right-handed and left-handed projection operators.\n\n5.1 Properties of the Projection Operators\nWhy are they called projection operators? Because acting twice on a state gives the same result as acting once: P_R P_R = P_R, \\quad P_L P_L = P_L\nIt’s instructive to check this explicitly. For example: P_L = \\frac{1 - \\gamma^5}{2}, \\quad \\text{so} \\quad P_L P_L = \\frac{(1 - \\gamma^5)(1 - \\gamma^5)}{4} = \\frac{1 - 2\\gamma^5 + (\\gamma^5)^2}{4}\nSince (\\gamma^5)^2 = 1 , this simplifies to \\frac{2 - 2\\gamma^5}{4} = \\frac{1 - \\gamma^5}{2} = P_L .\nFurthermore, the subspaces they project onto are orthogonal: P_R P_L = 0\nIf you first project onto the left-handed space, there are no remaining right-handed components. Projecting next onto the right-handed space then yields zero.\nAnother crucial property stems from the fact that \\gamma^5 anti-commutes with any \\gamma^\\mu : \\{\\gamma^\\mu, \\gamma^5\\} = 0\nThis anti-commutation implies that the gamma matrices swap chirality. For instance: \\gamma^\\mu P_L = P_R \\gamma^\\mu\nConsequently, P_R \\gamma^\\mu P_L = P_R (P_R \\gamma^\\mu) = P_R \\gamma^\\mu , but also, by swapping order, this equals (\\gamma^\\mu P_L) P_L = \\gamma^\\mu P_L . The orthogonality P_R P_L = 0 leads to the important result that certain chiral combinations vanish.\n\n\n5.2 Decomposing a Spinor\nAny Dirac spinor \\psi can be decomposed into right-handed and left-handed chiral components: \\psi = \\psi_R + \\psi_L, \\quad \\text{where} \\quad \\psi_R = P_R \\psi \\quad \\text{and} \\quad \\psi_L = P_L \\psi\nTo give explicit meaning to these states, we can connect them to helicity states (spin aligned or anti-aligned with the direction of motion). The decomposition is performed by using an explicit matrix representation.\n\n\n\n\n\n\nIn the chiral representation, the projection operators have a simple block form: P_R = \\frac{1}{2} \\begin{pmatrix} I & I \\\\ I & I \\end{pmatrix}, \\quad P_L = \\frac{1}{2} \\begin{pmatrix} I & -I \\\\ -I & I \\end{pmatrix}\nUsing this representation makes the decomposition of a spinor into \\psi_R and \\psi_L more concrete, though working with 4 \\times 4 matrices can be cumbersome.\n\n\n\nWhen projecting a helicity state, one finds that for a massive particle, each helicity state contains a small component of the opposite chirality. This mixing becomes negligible at high energies where the mass is much smaller than the energy (m \\ll E) .\n\n\n5.3 Physical Interpretation: Chirality vs. Helicity\nThere is no single, always-valid intuitive picture for right-handed and left-handed chiral states. However, they are closely related to helicity (spin orientation along the direction of motion) in the limit of zero mass.\n\nFor a massless particle (or in the high-energy limit), chirality equals helicity.\nRight-handed means spin is aligned with the momentum.\nLeft-handed means spin is opposite the momentum.\nWhen the mass is significant (m \\sim E) , chirality and helicity are not the same. A massive particle’s state is a mixture of both chiral components, and its helicity can change under a Lorentz boost (like moving to its rest frame).\n\nThis distinction is fundamental in particle physics. For example, in the electroweak interaction of the Standard Model, the W boson couples only to left-handed chiral fermions and right-handed chiral anti-fermions. ### Connection to the Weak Interaction\n\n\n\n\n\n\nFigure 2: This figure illustrates the weak interaction vertex, specifically the decay of a W boson into an electron ( e^- ) and an electron neutrino ( \\nu_e ). The diagram on the left shows the Feynman diagram with a W -boson (denoted by the wavy line) decaying into an outgoing electron and neutrino. The label “Vector - Axial” refers to the V - A (vector minus axial-vector) nature of the weak interaction, which is described by the term \\bar{\\psi} \\gamma^\\mu (1-\\gamma^5) \\psi in the Lagrangian, or equivalently 2 \\bar{\\psi} \\gamma^\\mu P_L \\psi , where P_L projects onto left-handed chiral states. The diagram on the right illustrates the chirality and helicity properties of the particles involved: the electron is labeled as left-handed (LH), indicating that only the left-handed chiral component of the electron participates in the weak interaction, while the neutrino is represented as right-handed (RH) for the outgoing antineutrino—or, in standard convention, as a left-handed neutrino for the incoming channel. The arrows labeled \\frac{1}{2} and direction of spin indicate the spin projection (helicity) relative to the direction of motion. This representation reflects the maximal parity violation of the weak interaction: only left-handed electrons and right-handed antineutrinos are produced in the decay, underscoring the connection between chirality, helicity, and weak processes discussed in the text.\n\n\n\nThe weak interaction vertex is described by the ** V-A (Vector minus Axial-vector)** structure. The corresponding term in the Lagrangian is proportional to: \\bar{\\psi} \\gamma^\\mu (1 - \\gamma^5) \\psi\nThis can be rewritten using the left-handed projection operator: \\bar{\\psi} \\gamma^\\mu (1 - \\gamma^5) \\psi = 2 \\bar{\\psi} \\gamma^\\mu P_L \\psi\n\n\n\n\n\n\nThis mathematical structure has a direct physical consequence: maximal parity violation. In processes like W boson decay, it produces only left-handed electrons and right-handed antineutrinos.\n\n\n\nFor neutrinos (traditionally treated as massless in the Standard Model), this means:\n\nAll neutrinos are left-handed.\nAll anti-neutrinos are right-handed.\n\nThis is why, before neutrino masses were established, the possible existence of right-handed neutrinos was a major topic in new physics searches, with connections to theories of dark matter.\n\n\n5.4 Key Conceptual Takeaways\n\nOrthogonality & Decoupling: Due to P_R P_L = 0 , right-handed and left-handed chiral states are orthogonal.\n\n\n\n\n\n\n\nFigure 3: This figure illustrates the concept that for particles with mass, it is possible to flip the spin by changing frames of reference. The drawing shows a sequence where a massive particle’s spin orientation (represented by the smaller arrow above the momentum arrow, \\vec{p} ) can be changed relative to its direction of motion when a Lorentz boost ( B_z^{-1} or B_z ) is applied. This effect is possible because for massive particles, helicity (the projection of spin along the momentum direction) is not Lorentz-invariant; a suitable boost can reverse the direction of momentum while leaving the intrinsic spin unchanged, thereby flipping the helicity. This physical property distinguishes massive from massless particles in relativistic quantum field theory: for massive particles, helicity and chirality are not identical, and helicity depends on the observer’s frame. In contrast, for massless particles, helicity is frame-independent, and spin cannot be flipped by a boost. This is a central concept discussed in the lecture, especially in the context of chirality, helicity, and their relation in various energy regimes for spin-1/2 particles.\n\n\n\nFor massless particles, they are completely independent and do not “talk” to each other.\n\nFrame Dependence:\n\n\nHelicity is frame-dependent for massive particles (you can “flip” the spin by overtaking the particle).\nChirality is a Lorentz-invariant property for massive particles. A left-handed chiral state remains left-handed under boosts and rotations.\n\n\nThe Chiral Limit: The limit m \\to 0 is called the chiral limit. In this limit, chiral symmetry is restored, and chirality becomes identical to helicity.\nPractical Use: While helicity is easier to visualize, chirality is often easier to work with in Lagrangian field theory because projection operators provide a clean, frame-independent way to separate components."
  },
  {
    "objectID": "2024-Lecture-10.html#flavor-symmetry-and-chiral-limit-in-qcd",
    "href": "2024-Lecture-10.html#flavor-symmetry-and-chiral-limit-in-qcd",
    "title": "(2024) Lecture 10",
    "section": "6 Flavor Symmetry and Chiral Limit in QCD",
    "text": "6 Flavor Symmetry and Chiral Limit in QCD\nHere is the enhanced lecture transcription.\nLet’s look at the QCD Lagrangian. This describes the dynamics of quarks and gluons; we are not including the electroweak sector of the Standard Model here.\nThe Lagrangian has two main parts:\n\nThe gauge part, involving the gluon field strength tensor G_{\\mu\\nu}^a , describes the pure gluon interactions.\nThe matter part, involving the quark fields \\psi_i , contains their kinetic and mass terms, as well as their interactions with the gluons.\n\nIn more detail:\n\nThe term \\bar{\\psi}_i i \\mathrlap{/}\\partial \\psi_i is the kinetic term for the quarks.\nThe term m_i \\bar{\\psi}_i \\psi_i is the flavor-dependent mass term.\nThe interaction with the gluon field G_\\mu^a comes from the covariant derivative D_\\mu = \\partial_\\mu - i g_s T^a G_\\mu^a , which replaces the ordinary derivative in the kinetic term.\n\nThe indices here are important:\n\nThe index i is for flavor (e.g., u, d, c, s, t, b ). There are six flavors.\nThe index a is for color. The matrices T^a are the generators of the local SU(3)_c gauge symmetry.\n\nThe local SU(3)_c gauge symmetry is fundamental. “Gauge” means we can modify the phase of the color part of the quark wave function at every point in spacetime. The quark field \\psi is a wave function whose color components form a three-state vector.\nThe local transformation is: \\psi(x) \\rightarrow U(x) \\psi(x), \\quad U(x) = \\exp(i \\alpha^a(x) T^a)\nwhere \\alpha^a(x) are parameters that depend on the spacetime point x . This local symmetry dictates how quarks and gluons interact and is precisely why we must use the covariant derivative D_\\mu instead of the ordinary derivative \\partial_\\mu .\nNow, let’s consider flavor symmetry. For the light quarks— u , d , and s —their masses are very small compared to the characteristic energy scale of QCD, \\Lambda_{\\text{QCD}} \\sim 1 \\text{ GeV} .\n\n\n\n\n\n\nIn the chiral limit, where we set the light quark masses to zero, the QCD Lagrangian gains an approximate global SU(3)_f flavor symmetry. The transformation acts on the flavor triplet \\Psi = (u, d, s)^T as: \\Psi \\rightarrow U \\Psi, \\quad U = \\exp(i \\theta^a \\lambda^a)\nwhere \\theta^a are constants (global) and \\lambda^a are the Gell-Mann matrices. This symmetry is not exact in nature due to the small, non-zero quark masses, but it provides a powerful organizing principle for low-energy expansions.\n\n\n\nThis symmetry is straightforward to check in the Lagrangian. The flavor transformation matrix U acts on \\psi and \\bar{\\psi} . Their phases cancel in the mass term \\bar{\\psi} \\psi . For the kinetic term \\bar{\\psi} i \\gamma^\\mu D_\\mu \\psi , we must check the covariant derivative. The T^a inside D_\\mu belongs to the color SU(3)_c  group. In flavor space, it is just the identity matrix and does not mix flavors. Therefore, the flavor transformation commutes with D_\\mu , and the Lagrangian is invariant.\nFinally, we can decompose the theory by chirality. We project the quark field into its left- and right-handed components using: \\psi_{L,R} = P_{L,R} \\psi, \\quad P_{L,R} = \\frac{1}{2}(1 \\mp \\gamma_5)\n\nIn the chiral limit ( m \\rightarrow 0 ), the kinetic term separates cleanly: \\bar{\\psi} i \\mathrlap{/}\\partial \\psi = \\bar{\\psi}_L i \\mathrlap{/}\\partial \\psi_L + \\bar{\\psi}_R i \\mathrlap{/}\\partial \\psi_R\nThere is no interaction term mixing left- and right-handed quarks.\nThe mass term m \\bar{\\psi} \\psi , however, is the only term that mixes these chiralities: m \\bar{\\psi} \\psi = m (\\bar{\\psi}_L \\psi_R + \\bar{\\psi}_R \\psi_L)\n\nThis chiral decomposition reveals that in the massless limit, the global flavor symmetry is enhanced to SU(3)_L \\times SU(3)_R , acting independently on the left- and right-handed fields. The small quark masses break this chiral symmetry explicitly, which is the starting point for constructing effective low-energy theories like Chiral Perturbation Theory."
  },
  {
    "objectID": "2024-Lecture-10.html#chiral-symmetry-and-its-breaking",
    "href": "2024-Lecture-10.html#chiral-symmetry-and-its-breaking",
    "title": "(2024) Lecture 10",
    "section": "7 Chiral Symmetry and Its Breaking",
    "text": "7 Chiral Symmetry and Its Breaking\nWe consider a possible symmetry: chiral symmetry. This is the transformation of the right- and left-handed components independently. We want to consider a chiral symmetry.\nLet’s check if everything is fine. Here is the three-component vector in the flavor space, SU(3) . Here is a 3 \\times 3 matrix. The parameter \\alpha does not depend on the coordinates; it’s a global transformation.\nWe import the parameters for the left-handed rotation and the right-handed states rotation, weighted by i . We count eight numbers here and eight numbers there, for an overall 16 random numbers.\nWe apply this transformation and the Lagrangian doesn’t change unless it has mass. How do we see that it doesn’t change if the mass is zero? Because left-handed and right-handed states don’t talk to each other. There is an extra phase that appears here and an extra phase that appears there; they cancel each other. The same happens here. The symmetry is only broken when a mass term appears.\nThis is the chiral symmetry. The mass term has a mixture of the two components. A phase will appear. Here is one combination of the \\alpha parameters and here is the other one, and therefore it does not disappear. The mass term breaks chiral symmetry explicitly.\n\n\n\n\n\n\nExplicit Breaking by Mass: The quark mass term mixes left- and right-handed components: \\mathcal{L}_{\\text{mass}} = -m \\bar{\\psi} \\psi = -m (\\bar{\\psi}_L \\psi_R + \\bar{\\psi}_R \\psi_L)\nUnder a chiral transformation, the phases from \\psi_L and \\psi_R do not cancel, making the Lagrangian non-invariant. For light quarks ( u, d, s ), this explicit breaking is a small effect because m_q \\ll \\Lambda_{\\text{QCD}} .\n\n\n\nNow, something I won’t derive, but you might have heard earlier, is that the chiral symmetry is spontaneously broken. Apparently, if you look at QCD at low energy, even if you start with no mass term, the quarks by their interactions generate a non-zero expectation value. The quarks appear massive even if you don’t put mass in the Lagrangian. That’s quite spectacular.\nI have a picture in mind. We have a space in vacuum. Let me share the plane of the field expectation value. In this plane, if you are sitting at zero, we have a chiral symmetry exact in the Lagrangian and we can rotate left and right states independently. But what appears is that the vacuum where we live in is not at zero; it’s at a location different than zero.\nThat happens because if you look at the sort of potential of the theory, it has a similar shape as the Higgs potential. It appears that for quantum chromodynamics, quark-antiquark pairs acquire, by interacting with each other, a non-zero expectation value. Therefore, we live in this plane of expectation not at zero, but at a certain shifted location.\nOne sees this continuous symmetry breaking effect in many domains of physics:\n\nIn superconductors, when electron pairs form Cooper pairs.\nIn the Higgs mechanism.\n\nThese are other examples of spontaneous symmetry breaking. It’s always the same mechanism.\nYou have an exact theory when you sit at zero of the sort of coordinate space. Once you acquire a non-zero distance from the origin in the coordinate space, and this appears—think of a Mexican hat potential—once you see it moves to the minimum… and this, what is spontaneous, actually is the shape of the potential.\nThe interaction is such that when you integrate over gluons, what you have is the core part interaction potential. It appears to have this shape. We could have lived in another vacuum that is located here with perfect chiral symmetry, but it appears that energy-wise it’s better to be in a vacuum that has a non-zero expectation value. That’s the effect of spontaneous symmetry breaking.\nThat’s all consideration of the mass scale. In addition to spontaneous symmetry breaking, the chiral symmetry has explicit symmetry breaking. That’s done by introducing non-zero masses. The spontaneous symmetry breaking is a major effect, however, it’s captured by the theory.\nExplicit symmetry breaking is a small effect since the masses of the quarks are much smaller than the scale of \\Lambda_{\\text{QCD}} . You can use perturbation theory. That’s what chiral perturbation theory is about.\nThe theory builds on the fact that there is a chiral symmetry. Spontaneous symmetry breaking comes as the outcome of this consideration. This symmetry breaking is introduced as a perturbation parameter. We won’t go to the detailed consideration of chiral perturbation theory.\nI will start next lecture by just writing the chiral Lagrangian and then we move on. We won’t have time to consider it, and I would invite you to dedicated courses. We have experts in the theory department, people who work on chiral perturbation theory and they are world experts on this consideration.\nI wanted to give you the general concepts and introduce a sort of experimentalist view to this. So thanks for… Well, let’s maybe spend two minutes for questions.\nStudent Question: What is the variable you have in this plane? Is it the vacuum? When you write this, when you roll like this, this like…\nAnswer: Yes. The number \\langle \\bar{\\psi} \\psi \\rangle . So is the point that you choose the correct state always? It’s the expectation value for this correlation. This is the chiral condensate, the order parameter for spontaneous symmetry breaking.\nStudent Question: What’s on the axis? What should I imagine them to be?\nAnswer: You can’t write it down easily. I really want to talk about this value because that’s what acquires a non-zero expectation value. The axis that I mean on display is the value of the expectation. But there must be better coordinates for that. It’s a field expectation. We draw the potential of the interaction. Strictly speaking, it’s undefined in a naive sense. In quantum field theory, what is defined is the expectation value of this operator. You can draw for the theory a potential as a function of the expectation value. That expectation value is along the x-axis, and then I have my potential V .\nWhat I’m not entirely happy with my explanation, with my analogy now, is that this… I would like this thing to have also complex space, and expectation that you expect this to be real. So let me think of an analogy. It’s called the quasi-classical expansion of field theory. I’ve seen it once in a couple of books.\nI’m talking about the strict definition of this. You always see these nice potentials, but how to define these starting from the graduate street? I think it’s related to the 1/N expansion. You have your N and then you expand with respect to this parameter to obtain that. What I will do is find the source and point you to that. Maybe we discuss it.\nAnother way to understand this is to look at a simpler model. There are a few models, one of them related to spontaneous symmetry breaking in superconductors, where this thing has a simpler meaning. You don’t need quantum field theory to see it, and then that potential appears explicitly. Maybe then we find a better meaning.\nStudent Question: You said that there was an interaction between particles and antiparticles, and you said like electrons and positrons. But it’s two electrons. Two electrons form the Cooper pair. Did you have a particle physics course, right? And the electroweak and Higgs mechanism was a part of the course?\nAnswer: Some of it. No. Generally at the particle physics course. Okay. It’s really strong. We can track. Yeah, that makes sense, right? Maybe that you’re talking about QED, right? QED. No, but I mean we talked about QED but we didn’t talk about electricity. That was also strange a little bit. But maybe we did. Maybe we did. That’s it. Yeah. Thanks a lot.\nAny more questions?\nStudent Question: What do you even do about the heavy quark?\nAnswer: Oh, there is another expansion, so it’s the other way around. It’s not m_q / \\Lambda_{\\text{QCD}} , but rather they are non-relativistic and you can use pNRQCD—potential non-relativistic QCD. The expansion parameter there is the quark velocity v/c , which is small for heavy quarks.\nAll right. Thanks."
  },
  {
    "objectID": "2024-Lecture-11.html",
    "href": "2024-Lecture-11.html",
    "title": "(2024) Lecture 11",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-11.html#analytic-mapping-and-lattice-qcd-fundamentals",
    "href": "2024-Lecture-11.html#analytic-mapping-and-lattice-qcd-fundamentals",
    "title": "(2024) Lecture 11",
    "section": "1 Analytic Mapping and Lattice QCD Fundamentals",
    "text": "1 Analytic Mapping and Lattice QCD Fundamentals\n\n1.1 Lecture 11: Analytic Structure, Chiral Dynamics, and Lattice QCD\n\n\n1.2 Recap: Scattering Amplitudes and Analytic Structure\nSo far, we have discussed the scattering amplitude as a function of the Mandelstam variable S , which is defined as: S = (P_1 + P_2)^2\nThis variable S is the squared center-of-mass energy and is very convenient for describing the partial wave expansion of the amplitude.\n\n\n\n\n\n\nMandelstam Variable S : This is the primary Lorentz-invariant variable used to describe the energy in a two-particle scattering process.\n\n\n\n\n\n\n\n\n\nFigure 1: This figure illustrates the relationship between the analytic structure of the scattering amplitude in the Mandelstam variable S (the S -plane) and the breakup momentum K (the K -plane), as discussed in the lecture. - The top left and center panels show the S -plane on two Riemann sheets: - First Sheet (left): The real axis above the two-particle threshold ( S &gt; (m_1 + m_2)^2 ) represents the physical scattering region. There is a bound state pole (labeled 4) on the real axis below threshold, corresponding to a stable composite particle. The thick, shaded line on the cut indicates the branch cut beginning at threshold. - Second Sheet (center): Important features like resonances (points 1 and 2) appear off the real axis on the second sheet, along with a virtual state (point 3) below threshold. The branch cut is present here as well, representing the analytic continuation through the physical cut. - The top right panel displays the corresponding K -plane. Here, K is the breakup momentum and is related to S via K = \\sqrt{(S - (m_1 - m_2)^2)(S - (m_1 + m_2)^2)}/(2\\sqrt{S}) . The analytic structure becomes simpler: the two Riemann sheets of the S -plane are mapped onto a single K -plane. All physical and unphysical regions are now unified, branch cuts become lines on the imaginary K axis, and singularities (poles) are points in the complex K -plane. - The bottom portion of the figure gives the explicit formula for k in terms of S , and shows how the mapping works: - Different types of singularities—resonances (1,2), virtual state (3), and bound state (4)—are shown as points in the K -plane. The real K axis corresponds to the physical scattering region ( S &gt; (m_1+m_2)^2 ), while the imaginary K axis represents energies below threshold. Physical meaning: This mapping clarifies the analytic structure of scattering amplitudes, especially near threshold. The complicated two-sheet structure of the S -plane, featuring square root branch cuts and multiple types of poles (bound states, virtual states, resonances), is transformed into a single, continuous K -plane. Here, analytic continuation and the connections between different physical situations (such as how a bound state can evolve into a virtual state or a resonance) become manifest. This is crucial for understanding finite-volume effects in lattice QCD, resonance dynamics, and the analytic properties of strong-interaction amplitudes.\n\n\n\n\n\n\n\n\n\nFigure 2: This figure represents the analytic structure of the scattering amplitude in the context of two-particle scattering. The horizontal line symbolizes the real axis of the Mandelstam variable S (or energy, equivalently), marking the threshold for particle production. The vertical line emanating from the threshold point illustrates the branch cut associated with the square root behavior near the two-particle threshold, which is related to the breakup momentum K discussed in the lecture. The diagram indicates the mapping between the S -plane and K -plane, with the threshold S = (m_1 + m_2)^2 corresponding to K=0 , and the physical region lying just above this threshold. The small circles or arcs may denote the movement around the branch point to different Riemann sheets—representing the physical (first sheet) and unphysical (second sheet) regions where resonances, bound states, and virtual states may occur, as discussed when mapping the analytic structure from S to K .\n\n\n\nEquivalently, one can consider the breakup momentum K , which is essentially the magnitude of the momentum each particle carries in the center-of-mass frame. The variable K is related to S via the kinematic function: k = \\frac{\\sqrt{(s - (m_1 - m_2)^2)(s - (m_1 + m_2)^2)}}{2\\sqrt{s}}\nThe analytic structure of the amplitude is often simpler when expressed in terms of K , particularly near the reaction threshold.\n\n\n\n\n\n\nBreakup Momentum K : Using K instead of S can simplify the analytic structure near threshold ( S \\approx (m_1 + m_2)^2 ), as it “unfolds” the square root branch point present in the S -plane.\n\n\n\nI would like us to now map the analytic structure from the S -plane to the K -plane. Specifically, we need to understand how key features—such as resonances on the second Riemann sheet (points 1 and 2), a bound-state pole on the real axis of the first sheet (point 4), and a virtual state on the unphysical sheet below threshold (point 3)—are represented in the K -plane.\nThe real S axis above threshold corresponds to the physical scattering region. When mapped to the K -plane, this region remains physical. The threshold S = (m_1+m_2)^2 maps to K=0 . Below this threshold, S is real but K becomes purely imaginary because the expression under the square root becomes negative.\n\n\n\n\n\n\nMapping Riemann Sheets: The two Riemann sheets in the S -plane, related by the sign of the square root \\sqrt{s - (m_1+m_2)^2} , both map onto the single K -plane. The plus and minus signs for K are already part of the same complex plane. This is why the K -plane has a simpler, single-sheeted structure.\n\n\n\nThe key insight is that the K -plane is just an analytic mapping of the S -plane. If you have a function with a square root branch cut in S , it has two Riemann sheets. By using the variable K , which is essentially that square root, you work on a single sheet. The two-sheeted structure of the S -plane can be understood as arising from the squaring operation S \\propto K^2 , which maps the single K -plane onto the two sheets of the S -plane.\n\n\n1.3 Transition to QCD and Confinement\nNow, let’s transition to discussing Quantum Chromodynamics (QCD) and the phenomenon of confinement. The fundamental degrees of freedom in QCD are quarks and gluons. However, in the low-energy regime we observe composite particles like protons and pions—this is the signature of confinement.\n\n\n\n\n\n\nConfinement vs. QED: In Quantum Electrodynamics (QED), the coupling constant is small: \\alpha_{\\text{QED}} = e^2/(4\\pi) \\approx 1/137 . This allows us to use perturbative expansions with Feynman diagrams. In contrast, the QCD coupling \\alpha_s becomes large at low energies, leading to the non-perturbative, confining regime where quarks and gluons are bound into hadrons.\n\n\n\nAt low energies, the appropriate effective theory is Chiral Perturbation Theory. This is not an expansion in a small coupling constant, but rather in the small masses and momenta of the particles (pions). The theory is built on the concept of spontaneous chiral symmetry breaking.\n\n\n\n\n\n\nSpontaneous Symmetry Breaking and the Quark Condensate: The order parameter for chiral symmetry breaking is the quark condensate, denoted \\langle \\bar{q} q \\rangle \\neq 0 .\n\n\n\n\n\n\n\n\n\nFigure 3: This image illustrates the “Mexican hat” or “wine bottle” potential, which is used to depict spontaneous chiral symmetry breaking in QCD. The horizontal axis is labeled \\sigma , corresponding to the sigma field (magnitude of the quark condensate), while the radial direction along the rim is associated with the \\pi (pion) fields, representing the Nambu-Goldstone bosons. The minimum of the potential forms a circle in field space, and the vacuum selects a particular point on this circle, breaking the chiral symmetry. Excitations along the rim (fluctuations in the direction of the arrow labeled \\pi ) correspond to nearly massless pions, due to the flatness (zero curvature) in these directions—these are the Goldstone modes. Fluctuations in the \\sigma direction (vertical upward arrow) are associated with the \\sigma particle and correspond to oscillations in the magnitude of the quark condensate, which are massive due to the curvature of the potential at the minimum. This physical picture, directly discussed in your lecture notes, shows how the vacuum expectation value of the quark condensate gives rise to massless Goldstone bosons (pions) and a massive \\sigma resonance, visualized as classical averaged fields in the Mexican hat potential.\n\n\n\nThis means the QCD vacuum is filled with a non-zero expectation value of quark-antiquark pairs. The potential for the associated sigma field has a “Mexican hat” shape, and the vacuum settles into one point in the minimum, breaking the symmetry.\nIn this picture:\n\nThe sigma ( \\sigma ) field corresponds to the fluctuating magnitude of the condensate. Its mass is related to the curvature of the potential at the minimum.\nThe pion ( \\pi ) fields correspond to fluctuations along the “flat” directions of the potential (the rim of the Mexican hat). In the ideal chiral limit (massless quarks), these directions have zero curvature, meaning the pions are massless Goldstone bosons.\n\n\n\n\n\n\n\nGoldstone Boson Mass Relation: When small quark masses m_q are introduced, they explicitly break the chiral symmetry, giving the pions a small mass. This is described by the Gell-Mann–Oakes–Renner relation: m_\\pi^2 \\propto m_q \\langle \\bar{q} q \\rangle\n\n\n\nA common point of confusion concerns the proton mass. If pions are (nearly) massless Goldstone bosons, why is the proton heavy? The proton is not a Goldstone boson. Its mass, like that of most hadrons (e.g., the rho meson), is generated dynamically by the confining quark-gluon interactions and is of the order of the QCD scale \\Lambda_{\\text{QCD}} \\sim 1 GeV. The proton mass remains significant even in the chiral limit where quark masses are zero. ### Introduction to Lattice QCD\n\n\n\n\n\n\nFigure 4: This figure represents the discretized spacetime “box” used in Lattice QCD calculations. The physical meaning of the image is the finite four-dimensional grid (lattice) on which quark and gluon fields are defined. The spatial extent of the box is labeled L , highlighting the periodic boundary conditions that lead to quantization of momenta ( p = 2\\pi n / L ) for particles within the box. This finite, periodic volume introduces finite volume effects and causes the particle spectrum to become discrete, which is crucial for calculating correlations and extracting particle properties (such as masses and phase shifts) from first-principles QCD. The figure visually encodes the main systematic effects discussed in the lecture: finite volume and discretization, both central to interpreting results from lattice QCD.\n\n\n\nTo study QCD from first principles, we use Lattice QCD. This is a non-perturbative method where spacetime is discretized onto a four-dimensional grid (a lattice). Typical lattices might have a spatial extent of ~7 fm divided into 50 points per side, and a temporal extent of ~200 points.\n\n\n\n\n\n\nTwo Main Systematic Errors:\n\nFinite Volume Effects: The lattice has a finite size L . Physical quantities (like masses) approach their infinite-volume values with corrections that are exponentially suppressed: \\Delta m \\propto e^{-m_\\pi L} .\nDiscretization Errors: The lattice spacing a is finite. Results must be extrapolated to the continuum limit ( a \\to 0 ). Computations are therefore repeated at several lattice spacings to control this error.\n\n\n\n\nThe primary quantities computed on the lattice are correlation functions. For an operator \\mathcal{O} that creates a state of interest (like a pion), the Euclidean correlation function is: C(t) = \\langle 0 | \\mathcal{O}(t) \\mathcal{O}^\\dagger(0) | 0 \\rangle\n\n\n\n\n\n\nWick Rotation: To make the path integral weight real and positive for efficient Monte Carlo sampling, we work in Euclidean spacetime. This replaces the Minkowski action e^{iS_M} with e^{-S_E} .\n\n\n\nThis correlation function has a spectral decomposition: C(t) = \\sum_n |\\langle 0 | \\mathcal{O} | n \\rangle|^2 e^{-E_n t}\nAt large time separations t , the sum is dominated by the ground state (lightest particle with the quantum numbers of \\mathcal{O} ), because excited states are exponentially suppressed by e^{-(E_n - E_0)t} .\n\n\n\n\n\n\nExtracting the Ground State Mass: To extract the mass m = E_0 , we compute the effective mass: m_{\\text{eff}}(t) = -\\ln \\left( \\frac{C(t+1)}{C(t)} \\right)\nAt sufficiently large t , m_{\\text{eff}}(t) will plateau at the value of the ground state mass.\n\n\n\nThe lattice calculation itself involves evaluating a path integral with an astronomically high number of dimensions. This is done via Monte Carlo integration, where field configurations are sampled with a probability proportional to e^{-S_E} . The correlation functions are then averaged over these sampled “ensembles” of configurations.\nThis concludes our introductory overview. Lattice QCD is a vast and technically rich field, but these principles form the foundation for extracting hadron masses, decay constants, and other non-perturbative quantities directly from QCD."
  },
  {
    "objectID": "2024-Lecture-11.html#periodic-boundaries-and-spectral-shifts-in-lattice-systems",
    "href": "2024-Lecture-11.html#periodic-boundaries-and-spectral-shifts-in-lattice-systems",
    "title": "(2024) Lecture 11",
    "section": "2 Periodic Boundaries and Spectral Shifts in Lattice Systems",
    "text": "2 Periodic Boundaries and Spectral Shifts in Lattice Systems\nWe are already over time, but it’s important to note that the homework exercise today is to realize that a particle in a box is slightly different from a particle in this space.\nDue to the periodic boundary condition, you have a quantization of the momentum. If your wave function is e^{i p x} , and you require that \\psi(x + L) = \\psi(x) , you immediately realize that p L must be 2 \\pi n . In order for this to match, the power of the exponential should be n times 2 \\pi i .\nThe momentum of particles is quantized and can only take values in discrete steps proportional to 1/L : p = \\frac{2\\pi n}{L}, \\quad n \\in \\mathbb{Z}\nTherefore, if you consider a two-particle system, it has a discrete spectrum. This is the periodic boundary condition.\nYou can think of two particles moving in a circle of length L . The physics of the one-dimensional case of this box computation would be a circle, and the spectrum is discrete. (see Figure 4) In that case, you see that I just simply add the energy. The total energy of the system is equal to the sum of the individual particle energies: E_{\\text{total}} = \\sum_i E_i\nThe particles are freely moving; they don’t interact.\nIt appears that once they interact, the energy of the system is slightly different. So we can still write the energy as a sum, but then one has to take into account the interaction energy.\nIt’s natural that once you compute the spectrum of an interacting system, your spectrum is going to be slightly different. So there is a shift due to interaction. That’s the idea of computing interaction on the lattice and doing spectroscopy.\nYou compute the spectrum in the absence of interaction. You compute the spectrum when interactions are present, and you see how different the levels are from each other. That gives you information about the particles, essentially the phase shift of the interaction.\nSo you compute the two-point correlator: C(t) = \\langle \\mathcal{O}(t) \\mathcal{O}^\\dagger(0) \\rangle\nYou compute such a quantity for two pions.\n\n\n\n\n\n\nFigure 5: This figure represents the behavior of a two-point correlation function, \\tilde{C}(t) , as a function of Euclidean time t in a typical Lattice QCD computation. Physically, this correlator describes the probability amplitude for a quantum state—created by some operator \\mathcal{O} at time 0 —to be annihilated at a later time t , as measured on the lattice. The curve shows an exponentially decaying function, which corresponds to the spectral decomposition: C(t) = \\sum_n |\\langle 0 | \\mathcal{O} | n \\rangle|^2 e^{-E_n t} At large t , the dominant contribution comes from the ground state (lowest energy E_1 ), with excited states ( E_2 , E_3 ,…) becoming exponentially suppressed. The vertical lines at discrete time points illustrate that lattice calculations are performed only at certain values of t (due to discretization into a_t points). This plot emphasizes how, by analyzing the large- t behavior (“plateau”) of the effective mass or the correlator, one can extract the energy/mass of the ground state and learn about the excited states in the system. The stacked energies E_1, E_2, ... at the right margin represent this discrete spectrum resulting from the finite volume and lattice discretization.\n\n\n\nYou see where it separates at high energy, where it saturates.\nWhere this correlator function saturates at a large value of t , you have a measurement of this energy level. Now you do the same computation for the interacting system. You find the energy of the interacting system, and then you compare the two to find the shift.\nYou relate the shift to the scattering phase shift: \\Delta E \\propto \\delta(p)\nThe way to compare with the answer is by using another kind of technique. You always give them in configuration space or real values of the wavefunctions.\n\n\n\n\n\n\nIn lattice QCD, the two-point correlation function is used to extract energy levels. At large Euclidean time t , C(t) \\sim e^{-E t} , where E is the ground-state energy. Comparing interacting and non-interacting spectra yields energy shifts, which are related to the scattering phase shift via finite-volume formulas like the Lüscher formula.\n\n\n\nThis is the last QCD lecture. I invite you to the full lectures if someone offers them; it’s a fascinating subject. In recent years we have learned so much about the hadron spectrum from the lattice.\nThat’s amazing. The treatment on the lattice has the rather isolated setup where there are no experimental effects. You can really do things you cannot imagine doing in an experiment.\nYou can scatter two pions. You can still scatter two pions in an experiment, but scattering, for example, a photon on a sigma meson, you can never do in an experiment. On the lattice, this is a problem that people start discussing.\nYou have a 2-pion sigma meson; the sigma meson is the \\pi\\pi S-wave. This is one of the tetraquark candidates at low energy that sits in the spectrum that people observe as a broad resonance.\nWhat you can do is consider \\pi\\pi scattering, insert a current (the photon), and compute the correlation function to construct the object that gives access to such a form factor.\nThis in turn gives you access to the spatial distribution of how inside these mesons the quarks and gluons are arranged. One of the exciting frontiers of lattice QCD is understanding what hadrons look like when you insert a current.\nYou can see how quarks and gluons are distributed in the space that you can access. You can’t do that with pure QED because there you just have electromagnetic states, and you cannot look at the quarks directly.\nYou cannot compute the form factors in that way. You do not have a way to fix low-energy constants. Some people doing Lattice Perturbation Theory (LPT) might object, but I’m not aware of a way of doing that.\nAlso, in experiments for these low-lying resonances, you produce them in some process with stable particles. You only have access to the production amplitude, for example, from a pion and a proton target.\nWe have a production amplitude and constraints—unitarity constraints that we discussed are much stronger on the scattering amplitude and the elastic amplitudes. Last time I wrote a matrix element on the board in the recap.\nSome of you said, “Oh wait, shouldn’t the imaginary part be positive because of the unitarity relation?” This is about the scattering amplitude. The constraints are very severe. You cannot just take a random number and put it in for the elastic scattering amplitude.\nThe amplitude should lie inside the unitary circle. If the scattering is purely elastic, it should be on the circle; it cannot be outside. The imaginary part is always positive: \\text{Im}\\, \\mathcal{M} \\geq 0\nOn the lattice, you can access this quantity, to which you have a strong constraint. Elastic amplitudes like \\pi \\pi \\to \\pi \\pi , \\pi \\pi \\to K K , \\pi K \\to K \\pi , \\eta \\pi \\to \\eta \\pi . You can do all this, plus you have a handle on the quark masses.\n\nYou can now make your pions massless.\nYou can make them massive.\nWhat changes significantly is the region where the amplitude is elastic.\n\nWhen the pion mass is zero, you have a \\pi threshold. So the 2-pion, 3-pion, and 5-pion thresholds are at the same point. But once you move and make pions heavy, you realize that a large area opens where the 2-pion threshold is open, but the 3-pion or 4-pion thresholds are not yet open.\nThere is a large area of elastic scattering where all your constraints from unitarity give you an almost parameter-free parameterization. Then you can learn a lot of physics.\nMoreover, by moving masses you can make your particles transit in the complex momentum ( K ) plane. We started our lecture by seeing where resonances could be located in this K plane. There are analytic, smooth connections between different regimes.\nBy moving these quark masses, you can make your particle transition from a bound state to a resonance, effectively traveling in the whole plane. That’s something amazing that tells you all these phenomena are closely connected.\nA bound state, a virtual state, a resonance—these are all different manifestations of states in QCD. Depending on the quark mass, one could become another.\nI hope you’re going to like the exercise sheet that was kindly prepared and printed. It was prepared last night and printed. Thank you very much for being here, for coming today, and sorry for being a little bit overtime. Well done."
  },
  {
    "objectID": "2024-Lecture-12.html",
    "href": "2024-Lecture-12.html",
    "title": "(2024) Lecture 12",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Ilya Segal"
  },
  {
    "objectID": "2024-Lecture-12.html#pion-decay-muon-polarization-and-the-anomalous-magnetic-moment",
    "href": "2024-Lecture-12.html#pion-decay-muon-polarization-and-the-anomalous-magnetic-moment",
    "title": "(2024) Lecture 12",
    "section": "1 Pion Decay, Muon Polarization, and the Anomalous Magnetic Moment",
    "text": "1 Pion Decay, Muon Polarization, and the Anomalous Magnetic Moment\nWe are finishing the lecture cycle. Two more to go. Today is the month before last. However, content-wise, today will be more on physics, and next week I would like to discuss sort of meta issues and how the hadron community functions. I will give you a little bit of background on how research is structured in the field, how collaborations work, and what are aesthetical issues—or not aesthetical, but what are actually how scientists work in the hadron physics domain. And there will be less on physics. Perhaps I will spend the first 20 minutes next time also reviewing the recent discoveries and what experiments brought up and what the hadron community is currently up to.\nBut today I would like to talk a bit more in physics and have still to write formulas and discuss how hadronic physics is used outside of hadronic physics. How this is an important part of many other studies. And I’ve been deciding on just one lecture that I would like to dedicate to deciding between CP violation, where hadronic physics is an important part through which CP violation shows up. Another part is the… Another subject I was considering is the g-2 and hadronic contributions to the magnetic moment of the muon. And that’s what we will discuss. So I decided on that rather fundamental piece, and it touches a couple of subjects that we’ve discussed already. The exercise sheet actually is on the R ratio, something I thought of giving, and we decided to postpone. And now we enhance this with more problems that you know now. And we’ll discuss this on a kind of more advanced level, giving all the knowledge that we have. But I would like to start today’s lecture with a short recap, and that will help us to get started. Something I would like to go back to is our discussion of the helicity and chirality and discuss the pion decay. \\pi^+ goes to \\mu^+ \\nu_\\mu , and I would like you to look and compare. So I would like to look at this decay and start with that, and I will give you two minutes to set your mind and to understand what it is about. So start by drawing this two-body decay in the rest frame of the decaying particle, indicate momenta, and indicate chirality. So the vertex that is here, and I find the case is actually weak interaction. So therefore, particles that are produced are produced with their chiral properties. So they are left or right. Therefore, on this diagram we will clearly see, since chirality is related to the spin orientation in the limit of high energy, we will see clearly the chirality, and then I’ll just give you a guess. Given these chiral configurations, what are the ratios of the matrix element for the first and second? And then give you a guess for it. This is rather straightforward. Just tell which phase space is bigger for the first or second. And then, of course, the natural question you want to go to is which of these two is more likely for the pion to decay. Let’s do three minutes.\n\n\n\n\n\n\nFigure 1: This figure schematically represents the kinematics and spin-chirality structure of the two-body pion decay \\pi^+ \\to \\mu^+ \\nu_\\mu in the rest frame of the pion. The arrows indicate the directions of momenta and spin of the decay products (muon and neutrino), and the labels “LH” (left-handed) and “RH” (right-handed) denote the chirality of the outgoing particles. - The top diagram shows a configuration where both the muon and neutrino have their spins aligned, resulting in a total spin projection that is forbidden for the decay of a spin-0 pion ( J^\\pi = 0 ). This is because the weak interaction produces neutrinos with fixed left-handed chirality and muons that, unless mass corrections are included, are also overwhelmingly left-handed. The configuration where both spins point in the same direction is not possible due to angular momentum conservation. - The bottom diagram shows the allowed configuration, where the spins are anti-aligned. This state is allowed but suppressed by a factor of m/E (the ratio of the muon’s mass to its energy), since the muon’s right-handed component is suppressed compared to the left-handed component by its (small, but nonzero) mass. Physically, this illustrates why the pion decays preferentially to muons: the chirality structure of the weak vertex (the V-A interaction) only allows certain helicity combinations, and configurations not matching the required angular momentum of the pion are either forbidden or heavily suppressed. The suppression for the electron channel is even stronger due to the much smaller electron mass, leading to the observed dominance of \\pi^+ \\to \\mu^+ \\nu_\\mu over \\pi^+ \\to e^+ \\nu_e .\n\n\n\nSo draw the center-of-momentum decay kinematics, indicate chirality. I should note here: neutrino, not antineutrino. Because electron comes with antineutrino. And then indicate chirality. So we discussed that the weak interaction vertex comes with a V-A , which means \\gamma^\\mu (1 - \\gamma^5) . And it produces a projector that acts on the current. For example, if you have a \\bar{u} \\gamma^\\mu u , and this \\gamma^\\mu has 1 - \\gamma^5 , it makes your quark on the left left and then on the right right, as we want. One makes this guy left, this guy right. So then in this case, this vertex, since it’s a W boson essentially here that produces these two, it produces them in their chiral configuration. So electron is going to be right? Sorry, positron is going to be right. So electron will be left and then neutrino will be left. So for the right electron, most likely, or it has two components in its spinor, and the left component is suppressed with the mass. And antineutrino, or so neutrino is the particle, and it’s in its chiral configuration that spin is—I mean, the mass of neutrino is zero. Therefore, it’s actually purely left-handed particle. So the helicity is fixed. So for the right-handed particle, the spin component that has a spin aligned with momentum is dominant. For the left-handed particle, this is dominant. And then we do the same for the other. And now we see this. For both of these particles, the spins are equal to 1/2 , the spin projection 1/2 . Therefore, they go back-to-back in the rest frame, in the center-of-momentum frame. The total spin sum is one, which cannot be because of the pion spin. So this is forbidden by the spin of the pion, as well as this. But then other configurations: so actually, what we can do is we can flip the spin of the right-handed particle, so this one would be allowed but suppressed by—so neutrino we cannot do much. This is neutrino. Neutrino with zero mass does not have an opposite component, but electron does. So V_R^+ , and this is suppressed. There is a term of mass over energy suppressed. And actually, that leads us to the second question. So the matrix element for the electron and for the muon are suppressed slightly differently because muon mass and electron mass are different. So the lighter the particle is, the bigger the suppression? For the electron it will be tiny. And for the muon, especially, so the muon in the decay of the pion is non-relativistic because the pion mass is not much bigger than muon mass. Therefore, in that decay, the chirality state of the particle does not really imply—I mean, this suppression is not that strong. So therefore, the right answer here is—what’s the right answer? Then, more or less, is the ratio more than one or less than one? The ratio is significantly less than one. And that actually determines the fact that pion decays predominantly to muon and neutrino, not electron and neutrino.\n\n\n\n\n\n\nKey Physics of Pion Decay: The matrix element for the decay \\pi^+ \\to \\ell^+ \\nu_\\ell is proportional to the lepton mass m_\\ell due to the V-A weak interaction structure. This explains the dominance of the muonic decay over the electronic one, despite the larger phase space for electrons. \\frac{|\\mathcal{M}_{e}|^{2}}{|\\mathcal{M}_{\\mu}|^{2}} \\ll 1, \\qquad \\frac{m_{e}}{E} &lt; \\frac{m_{\\mu}}{E}\n\n\n\nAnd for the phase space, it’s easy to see the phase space is actually the number of configurations. In that case, for the two-body decays, it’s just angular configuration. They are the same, but that is also energy-dependent factor, giving you how much of the energy release you have in the decay. So that’s what phase space is. The bigger the release of energy, the bigger the phase space. And then for muon, so you think of the initial state as the system with a certain energy given by the mass of the pion. And then the final state has the particles that themselves carry some masses. And the release of the energy essentially is the difference of the masses. And for the first case, the release is tiny because the mass difference is small. And the second case, all energy goes to the kinetic energy. Because neutrino is massless, electron is almost massless, so the phase space is much bigger. For the second case, however, this does not compensate the suppression.\nLet’s go to the calculation. For the calculation, the phase space of electron and neutrino over the phase space of muon and neutrino, something like that. So the breakup momentum is something I need to evaluate. And I will double-check what I do if particles have mass. How to do this easily, I think it’s right. But I want to explain to you, you already know this. So this would be a function of s , mass of pion squared, and would be another function of s , mass of muon squared. And then the function is x, y, z . So it would be x^2 + y^2 + z^2 - 2xy - 2yz - 2zx . And once I drop the terms, x^2 + y^2 + z^2 + 2xy - 2yz - 2zx . And then b = 0 , this term is dropped. So the further is just the difference. It’s just the full square, which I then put in: (s - m_e^2) / (s - m_\\mu^2) .\n\n\n\n\n\n\nFigure 2: This figure expresses the suppression of the matrix element for the decay of a pion into an electron and a neutrino ( \\pi^+ \\to e^+ \\nu_e ) relative to the decay into a muon and neutrino ( \\pi^+ \\to \\mu^+ \\nu_\\mu ). The key point made in the lecture is that, due to the V-A structure of the weak interaction, the decay probability is proportional to the lepton mass over the available energy ( m_\\ell/E ). Since the electron mass is much less than the muon mass, m_e/E &lt; m_\\mu/E , which leads to a strong suppression of the electronic channel. The image summarizes this by showing that the squared matrix element ratio |\\mathcal{M}_e|^2 / |\\mathcal{M}_\\mu|^2 is much less than 1. This is a crucial physical factor explaining why \\pi^+ decays predominantly to muon and neutrino, not electron and neutrino, despite the larger phase space for electrons.\n\n\n\nSorry, s - m_\\pi^2 . So this full, full, full square is dropped because of the 1/2 . And this is the answer. So this factor does not compensate the suppression.\n\n\n\n\n\n\nPhase Space Ratio: The standard two-body phase space factor in the center-of-mass frame is \\Phi = \\frac{1}{8\\pi} \\frac{2p}{\\sqrt{s}} , where p is the breakup momentum. For pion decay, the ratio of phase spaces favors the electronic channel, but this is overwhelmed by the matrix element suppression. \\frac{\\Phi(e^{+}\\nu_{e})}{\\Phi(\\mu^{+}\\nu_{\\mu})} = \\frac{\\lambda^{1/2}(s,m_{e}^{2},0)}{\\lambda^{1/2}(s,m_{\\mu}^{2},0)} = \\frac{s-m_{e}^{2}}{s-m_{\\mu}^{2}} &gt; 1\n\n\n\nSo the dominant decay of the pion is to muon neutrino. And I think that’s… I mean it’s really important to realize what the steps we’ve done. Because this is a nice piece of physics. It’s how the parity violation was discovered. By seeing that the first muon is the predominant decay. For that you need for this vertex to be V-A weak interaction. And the second is another interesting fact that in this decay, in this decay the muon is produced polarized. So the pion doesn’t carry a spin. It decays to a neutrino. The neutrino you don’t register, it just flies away. And then the muon is produced polarized. So in 1967, the experiment was right. So what’s cool about the muon is that it’s actually self-analyzing. It has a self-analyzing decay. So the muon goes to electron neutrino, anti-neutrino. And the angular distributions of the electrons indicate the polarization of the muon. So it’s actually a super nice setup. You want to analyze either vertex that is here has sort of V-A current that violates parity. So this term, this gamma axial term would violate parity. So just keep this violates parity. And you can check easily by looking and then goes to the electron. Because the second decay, the weak muon decay has a charged track. And the angular distribution of this charged track in the rest frame of the muon would tell you whether the muon is polarized or not. So if it’s not polarized, you have in the rest, in the helicity frame of the muon you have all directions of the part of the electron equal, equally probable. But if it is polarized, the forward direction is preferred, forward with respect to the spin. So it’s aligned with the spin aligned around. So it’s actually either aligned or anti-aligned with the spin of the muon. So the muon flies. The muon flies. It carries the spin. And then in the rest frame of the… you’re sitting in the rest frame and you only have the spin information. So they measure the… This is called the CM frame that we discussed. And then in this frame the electron preferably goes. This is the preferred configuration. Well, of course the electron can go in any direction, it’s just the probability is different. And if you integrate over the true energies, you find out that this is the preferred configuration even for the linearly polarized muon beam.\nAnd then shortly after, the same technique was used to measure something more fundamental, namely the magnetic moment of the muon. So this we touched on in the second lecture, when we discussed the quark content of the proton. We calculated, using the quark content of the proton, to calculate the magnetic moment. Let me remind you what it is. The magnetic moment of a particle gives the interaction of this particle with a magnetic field. And for a point-like fermion, it’s given by the Bohr magneton and the gyromagnetic factor. And this is usually called g . So this is a fundamental quantity that is g = 2 for a fermion. And we found out that for the proton, actually this is 2.8. Then something is wrong. Although a fermion is… Sorry, the proton is a fermion. And why this g is not? And this indicated that it’s not. So out of these two words, “fermion” and “point-like,” the first one is not valid for the proton. So it’s actually made of quarks. And then we computed that the value you get, the right value in the quark model, and part of it comes from the charge. So this Q , this e in the numerator is the charge of the particle. For the proton it’s plus one. But for quarks it would be fractional charge. And then the mass. We have to put the mass of the quarks to be like constituent quark model masses, like 0.3 for u and d quarks. And then by doing this we found out that what is measured in experiment for the proton is actually the same. You roughly understand this in terms of the constituent correlation. But this exercise was done for the muon. The muon. We don’t doubt that the muon is an elementary particle. It doesn’t have internal structure. So for the muon you expect this g to be 2, but it turns out that this is only to first order. So there are corrections to this from all different types of virtual processes that make this g not exactly 2. But the number that I use. So g is a constant. It’s one of the numbers that we know. I mean, it’s one of the most precisely known numbers, \\pi/2 . Well, the way how it’s usually given is g/2 . So the g for muon is g , and then… And then it’s common language to introduce the quantity a , which are corrections to the g , and give it as the g-2 divided by 2. I think we know, I mean there are a few numbers in mathematics that we know more digits. But in physics such a precision does not come very often. And there is a huge effort on measuring even more digits. Because that gives us sensitivity to loop effects and to new physics, because the corrections come from quantum processes. It’s similar to the form factor of the proton that we discussed. This g characterizes the interaction of the photon with the muon. So we probe this particle with a source of photons. And g tells us how it sees. How the light sees the particle. If it were composite, then we would resolve the individual components. But here, in the case of muon, leading corrections to the vertex, such a function comes from this. From this cool process that we draw. It was first calculated. Feynman should be the one who realized that such processes in QED impact the magnetic moment. QED is a theory that we can calculate in perturbation theory. And the series converges; you calculate more and more loops. So now you can start including morphologies. These processes, these three, these four, crossing. Introducing the coils here, all of the possible processes are calculated to a fixed order. So count vertices here. 1, 2. So this gives you the first order. This is the charge of the electron. This is the charge of the muon. The product is \\alpha . So e^2 / 4\\pi is \\alpha . And that’s what here. So it’s the electron mass squared that comes from these vertices. And now we know the corrections up to the fifth order. So we know \\alpha^2, \\alpha^3, \\alpha^4 and so on, up to 5. And this \\alpha^5 correction is equal to something, \\alpha , 25 \\alpha . Let me see if I have a number. But it’s not that important to have it exactly. 17. So the number in parenthesis is always indicating the uncertainty, whatever last digits you have. So here. And actually I’m now curious. So the number is pretty big. I’m curious to compare this to the fourth order which is also… No, it’s 130. So it’s probably comparable. But anyway, so the series is converging. And now we have numerical technologies. No one can create these diagrams any longer by hand, as Schwinger did. So you set the computer. There are probably millions of terms in the fifth order that you have to all evaluate, and all loop integrals are related. Fortunately, I think you might neglect the mass of the muon later. So I don’t know exactly for the higher orders how calculations are done. The curious fact probably on the first order. So this happened around the 1970s. And then Schwinger has this \\alpha / 2\\pi pioneer, his great contribution. And then I don’t know who decided, probably Feynman. So it’s written \\alpha / 2\\pi . Schwinger did he calculate the diagrams? Yeah, well, techniques that have been at that time, I’m not sure that were Feynman diagrams. But starting from the QED Lagrangian you evaluate this process. That’s. I wrote it down here. It’s experimental, g-2 . And the way how we know it is actually quite nice and neat experimental setup. Using the \\pi decay to muon and muon going to electron and two neutrinos. So using the same setup that was proposed 50 years ago. So we have a ring in which muons. So a bunch of muons is trapped. There is a magnetic field. And then once there is a magnetic field, the charged particle moves with the momentum that the bending force acts on the particle. That’s why the muon is traveling around on the circle. So that muon goes on like a regular collider. So the setup, just for your imagination, the setup is like three of these rooms. It’s 20 meters radius. And this experiment has been done before. And the recent one is at BNL, Brookhaven National Lab. But what happens also in a magnetic field is that the spin starts precessing. So I have in mind this picture. So there is a… And there is a cone. There is a spin. And then it’s actually rotating around, precessing. And there are frequencies. It. I’m not too sure about this minus sign; it doesn’t look right to me because \\gamma is more than one. So this term gets crudely negative with the mass of equinox. So I’ll double check. I have five minus. I have in the notes you here somewhere? No, probably not. Or maybe I do. So before using this and setting up your existence experiment, double check the minus sign. And that’s. And the cool part, and actually the critical part, is that \\omega_c - \\omega_s is proportional to this a function. So it’s the g-2 over 10 D over. So the difference of the frequencies comes really proportional to these corrections to the chip. So it means that actually if you start here with this configuration and make one circle so that it comes to the same point slightly shifted, slightly tilted, and this tilting is actually proportional to the a .\n\n\n\n\n\n\nAnomalous Magnetic Moment: The anomalous magnetic moment a_\\mu is defined as the deviation of the gyromagnetic ratio g from the Dirac value of 2. It is one of the most precisely measured quantities in physics. a_{\\mu} \\equiv \\frac{g-2}{2} = 0.001165\\,8209(63)\nThe leading quantum electrodynamics (QED) correction was calculated by Julian Schwinger: a_{\\mu}^{\\text{QED}} = \\frac{\\alpha}{2\\pi}\n\n\n\n\n\n\n\n\n\nSpin Precession in the g-2 Experiment: In a uniform magnetic field \\mathbf{B} , the difference between the cyclotron frequency \\omega_c and the spin precession frequency \\omega_s for a muon is directly proportional to a_\\mu . \\omega_a = \\omega_s - \\omega_c = a_\\mu \\frac{eB}{m_\\mu}\nThis “beat frequency” \\omega_a is the observable measured in storage ring experiments.\n\n\n\nThe experiment then is as follows. You come with the proton beam—that’s a hydrogen beam, the easiest beam we can get. You hit the target and you get a bunch of pions flying forward. You collect the pions and you direct them towards your ring. So here is the tunnel through which the pions from the secondary vertex come. And in this tunnel they decay. And some of the pions get converted to muons and muons are trapped. Then in the ring they start. Since the pion produces muons polarized, they already have exactly the same, exactly the configuration that we want.\n\n\n\n\n\n\nFigure 3: This diagram illustrates the setup and principle of the g-2 measurement experiment for the muon. The image shows a storage ring (large circle) with a uniform magnetic field \\vec{B} perpendicular to the plane of the ring. Muons ( \\mu^+ ) are injected and travel in circular orbits due to the Lorentz force from the magnetic field. The key physical aspect depicted is the precession of the muon spin \\vec{S} as the muon circulates in the ring. As a result of the anomalous magnetic moment ( a_\\mu \\equiv (g-2)/2 ), the spin precesses relative to the momentum \\vec{p} with an angular frequency \\omega_a , which is proportional to a_\\mu . This precession is the observable effect measured experimentally: by detecting the angle between \\vec{S} and \\vec{p} over time (typically via the angular distribution of decay electrons), experimentalists extract the value of the muon’s anomalous magnetic moment. The diagram encapsulates the relationship between the muon’s motion, its spin precession, and the external magnetic field in the g-2 experiment context, as discussed in the lecture.\n\n\n\nThere is a muon, there is a spin. And by applying a magnetic field, this setup starts working. So the muon moving along the circle, the spin starts precessing. And the way how we measure the spin orientation is actually by looking at the electron. So muons going along the circle decay. It’s a bunch of particles, 10^7 particles or I don’t know exactly, but let’s say millions of particles in the bunch, and then they move and some of the muons decay. And then by looking at this decay… So inside of the circle here there are calorimeters and I think it’s lead glass calorimeters. It’s a big block—the regular material that we use also in COMPASS and not in LUCID, but used to be in several experiments. So this is a typical setup using lead glass. That’s a material, it’s a glass doped with lead, such that the Z of the material is higher. And once a particle comes in, it doesn’t leave, it just leaves all energy inside. But since it’s a glass, it’s transparent for the light. Therefore you just put this heavy block of glass and then a photosensor at the end. And then a particle comes in, leaves energy, and the sensor collects this energy. So these are a type of calorimeter. And these calorimeters measure the flux of electrons that come in. So if the spin points outwards, you have a loss of electrons. If the spin points inwards, you have more electrons. So along the circle you see fluctuations of the energy deposit. And that’s what—what if you hear the talk about g-2 measurements—the digital plot that you see is time on the x-axis and then energy deposit, or it’s not energy deposit that’s shown, but… oh, something that’s… And then people just cut this piece and start over.\nThe frequency of rotation stays the same. So let me just be more consistent. So frequency doesn’t change. It is determined by the charge of the electron. So what happens is that out of these muons in the batch, some of them decay. Therefore the overall energy that’s deposited decreases, decreases exponentially. But then it’s modulated by this spin rotation, fluctuating up and down. And then you collect these statistics for three years and then you have the number.\nThe analysis is blinded. So last year or two years ago, there was a big press release of the new measurements of g-2 . Apparently before setting up the data and starting the analysis, the analysts wrote down on a piece of paper in an envelope the real frequency that had been used. And then at the press conference, the analysis was unblinded. So they took the envelope, opened it, typed in the real frequency, pressed the button in the map to flip the plot, and showed the numbers that had been measured.\nSo you’re measuring \\omega_s and you… Oh no, it’s actually right. You… What enters the… What enters the fit is really this variable. So the fact that we can measure… So let me see. Just a sec. I see what you mean. So are these fluctuations related to \\omega_c or not? Yeah, as far as you explain… You would like to measure \\omega_s and then just plot down as many data points as you can. So this… Look, if the two velocities were exactly the same, the spin configurations would just propagate the same way. So nothing would change. Therefore, up and down fluctuations… No, no, no. This is \\omega_c . So I wanted to make a point that it’s a ratio, it’s a difference that enters. And this plot is sensitive to the difference. But I don’t see it now. So just looking at the way we discuss it now, I think you measure… Yeah. For some reason I thought that you really see some difference between them. But no. No, I’m not sure. No. And I think then the key is to have a lot of this wondering. Are the other muons polarized when you shoot them into the ring? Does it matter? Muons? Yeah. When they come in. Yeah, yeah, right. Exactly. Okay, I wasn’t… It happens that in the muon decay case, this vertex is actually a weak interaction vertex and it produces a certain chirality of the state. So muons are always polarized in the decay case. That’s really pretty, right? And so this spectacular experiment is… I think the next generation of it is happening right now. And I think worth mentioning that the most important quantity, or the most important concern in the setup, is the homogeneity of the field. So once you have a little inhomogeneity, the field is not exactly B , but a little bit different. So the integral over the magnetic field that the muon acquires by traveling is different and then you introduce uncertainty. And in order to achieve such precision, which is quantified in the… I don’t know if you’ve seen this… parts per billion. Yeah, that’s the precision that people talk about. So currently, how many parts per billion do you have? So we have 63 parts per billion. The uncertainty of the experimental value is 63 parts per billion. And I think the theoretical answer is similar. It’s around 100. Well, you might tell me, “Wait a second.\n\n\n\n\n\n\nFigure 4: This image shows the diagrammatic and analytic expression for the leading quantum electrodynamics (QED) correction to the muon’s anomalous magnetic moment \\left(g-2\\right)_\\mu . The Feynman diagram illustrates the process where a muon ( \\mu^+ ) emits and reabsorbs a virtual photon ( \\gamma ), representing the lowest-order radiative correction to the magnetic moment. The accompanying formula, a_\\mu^{\\text{QED}} = \\frac{\\alpha}{2\\pi} , gives the value of this leading order correction, first calculated by Schwinger. This correction arises from quantum loops and is central to understanding the muon’s magnetic anomaly within QED. In the context of the lecture, this term forms the baseline for more complex contributions, such as hadronic vacuum polarization and hadronic light-by-light effects, which provide smaller but more uncertain corrections.\n\n\n\nI have heard this already in the particle physics course. What does hadronic physics have to do with that?” And that actually appears prominently on the series side. If you want to calculate the value of the anomalous magnetic moment from a theoretical point of view, it’s not only QED corrections that are relevant, but also other corrections, among which are electroweak, which are small. We don’t talk about them, Z and W . But hadronic corrections. There are two prominent hadronic contributions to the anomalous magnetic moment. One is the… So I left it in the original abbreviations. Let’s try to guess what it is. What are the letters? H, L, B L, H, vp. So H stands for hadronic. And then let me draw a diagram. This vertex… No, so for this one, the diagram is the following. So the photon produces hadrons and then turns into a photon again. And that’s a hadronic contribution. Is it vacuum or is it the running vacuum polarization? And then the first one… Let me draw it. Yeah, it’s actually nicer than, you know, boring logarithm. It’s called light-by-light scattering. So light-by-light. And what’s inside of this blob? That maybe in three ways might look confusing. But what this actually really means is: light comes in, light goes out, and then you have a hadron here and you have another hadron. Then you have another photon. So that’s the process. And then all mesons that are coupled to photons that can decay to two photons, they contribute to the hadronic light-by-light. So which meson do you know that decays to two photons? Pion. Yeah, \\pi^0 . It’s a prominent contribution to hadronic light-by-light. And then \\eta is another one. So some of the scalar mesons and which hadrons are here. So the thing is that you see that the photon current wouldn’t change the quantum numbers. So there should be J^{PC} of the photon. And what are hadrons that have the J^{PC} of the photon? What are the quantum numbers of a photon? Spin. Perhaps you remember the spin of a photon. No doubts. The photon has spin one. So then the parity is minus. Charge conjugation is… Well, we can say it’s minus. So 1^{--} . What are examples of mesons that have 1^{--} quantum numbers? Let’s say 1^- . Let’s first do J^P . Any 1s, 1p. I just want to remind you that there are two states in the 1s multiplet. The lower one has a bottom 0^- and the other one is 1^- . So this guy… This guy and then all others, this guy. So in this plot, on the X axis I have the quantum numbers and on the Y axis the mass or energy. And this is a quark model sketch of the excitation pattern of the mesons. So everyone should give me an example. Should you start? Vector meson. K^0 ? 0^+ , 0^- doesn’t work. Why? Vector meson 1^- is a vector meson. So 1 means vector. But it’s the same thing. It’s the same spin one, it’s a vector. And \\rho . \\rho . Very good. The \\rho is your favorite meson. Not necessarily favorite. Give me… So if \\rho meson is the u \\bar{u} . So you, let’s say u \\bar{u} . We want a neutral u \\bar{u} . And in triplet. And this is a… where u has spin up and then \\bar{u} has spin up. So up up. So this is u . And if I replace here u quark to c quark, which particle do I get? This picture in the light vector in the light sector has a \\rho . In the charm sector, what does it have? What’s the name of this particle? Yes, J/\\psi . All of them are vectors. All of them are from this multiplet and 1D would also have vectors. And now strange sector. c \\bar{c} . What is the vector in the strange sector? No, strange c \\bar{c} ? Sorry. s \\bar{s} from what? So let others… I think let’s… Let’s ask the students. Yeah, that’s right. \\phi . So this is a \\rho , \\phi , \\psi or J/\\psi , and then we miss c \\bar{c} . Sorry, b \\bar{b} . Upsilon, you need d \\bar{b} ? Okay, what’s the vector in the bottomonium sector? No, of course. Yeah, but I tell you and then you say, “Of course I knew this,” but it’s called \\Upsilon . And then what do we miss? K vectors in the K sector would be K^* , but they don’t have the flavor quantum numbers of photons. So it has a… It’s non-zero flavor. It’s a u \\bar{s} . A photon cannot produce u \\bar{s} . So fine, we need neutral flavor to appear here. And these are the main particles that actually give the most contribution, and I think maybe mixing up, but I don’t exactly remember. I think more than 50% comes from \\rho . It’s… We get exactly the number. I want to give an equation for how this is computed because it’s rather straightforward. You can totally understand this. It’s… So hadronic physics is a dirty business. Cannot be calculated from first principles. The way how we calculate these kinds of corrections to the anomalous magnetic moment, namely hadronic vacuum polarization, is we use the information that we measure in other places. So the photon transition to the hadrons and back is related to the e^+ e^- cross section to hadrons because when e^+ e^- annihilate, the quantum numbers are exactly 1^{--} . So we use unitarity to relate this process to the inverse. Let me just verify that the next word… It. So the way we proceed is we do a kind of mixed theoretical-experimental evaluation. We cannot calculate from first principles, but we have analyticity and unitarity, and these tools help us to relate one process to another. So it appears that the hadronic vacuum polarization contribution is actually from optical theory related to the cross section of e^+ e^- to hadrons. Let’s look at this expression once again before proceeding. So ask me everything that is unclear in this expression. Let’s look at this together. \\alpha is the electromagnetic constant, \\mu mass, \\mu mass of the muon. Nothing surprising. I want you to pay attention to the integral and the denominator here. The kernel is a mathematical function that is related to the spin of the particles. So this appears… I mean, this is a bunch of logarithms and rational functions. It’s a kernel. If particles were scalar, K would be 1, and R is the experimental ratio. But I want to pay attention to this integral. So this integral has… It starts at the threshold of the hadron production reaction. So the idea is that we’re going to cut this loop and see what particles can be produced on-shell inside of this blob. The lowest threshold would give us the integration limit, and what is the lowest threshold? So what do you think is the lowest threshold in this setup? Or, like, think of a photon creating a particle, a bunch of particles on-shell. Hadrons, quarks cannot be on-shell. Yeah, that’s why two masses, even two quarks cannot be on-shell. Two pions. That’s our lightest particles that we have. Yes. So indeed we have to integrate from threshold, which is… So the lowest process that starts happening is two pions are produced. And as I mentioned, these two pions have to be… I mean, the energy-momentum is conserved. Therefore, these two pions have non-trivial orbital angular momentum to have 1^{--} . So then give a little thought. What orbital angular momentum for two pions to have 1^- ? In which wave would you combine them? Yeah, simply because S-wave would give you 0^+ . \\pi^0 has 0^- , 0^- plus 0^- together, and then when you add one unit of angular momentum, you get 1^- .\n\n\n\n\n\n\nFigure 5: This figure illustrates key Feynman diagrams for the hadronic contributions to the anomalous magnetic moment of the muon ( a_\\mu ). - Top diagram: This shows hadronic light-by-light scattering, where photons couple to hadronic states such as pions in an internal loop. This process represents the hadronic light-by-light (HLbL) contribution, involving interactions where virtual photons interact via hadronic intermediate states (e.g., pions). - Bottom diagram: This diagram depicts the hadronic vacuum polarization (HVP), where a virtual photon splits into a hadronic state that then re-annihilates into another photon, which then couples to the muon. The annotation “vector mesons ( \\rho , \\phi , J/\\psi , \\Upsilon )” refers to the main hadronic states (neutral vector mesons with quantum numbers J^{PC}=1^{--} ) that contribute most significantly to this process. In both diagrams, these hadronic effects modify the interaction of the muon with the magnetic field, producing corrections that are essential for precise theoretical predictions of g-2 . These contributions are difficult to calculate from first principles and are the primary source of uncertainty in the Standard Model prediction for a_\\mu .\n\n\n\nSo this construction hopefully will become familiar in a few minutes when you integrate from threshold to infinity and you have a 1/s denominator. And that’s what I would like to just explain by introducing this dispersion relation.\n\n\n\n\n\n\nHadronic Contributions to a_\\mu : The two main hadronic contributions are:\n\nHadronic Vacuum Polarization (HVP): A photon fluctuates into a hadronic state (e.g., \\rho , \\omega , \\phi mesons) and back.\nHadronic Light-by-Light Scattering (HLbL): A photon interacts via a hadronic intermediate state that couples to two photons (e.g., \\pi^0 , \\eta ).\n\nThe photon has quantum numbers J^{PC} = 1^{--} , so the dominant HVP contributions come from neutral vector mesons with the same quantum numbers: \\rho^0 , \\omega , \\phi , J/\\psi , \\Upsilon .\n\n\n\n\n\n\n\n\n\nCalculating the Hadronic Vacuum Polarization: Because we cannot calculate hadronic processes from first principles, the HVP contribution is determined using a dispersion relation that connects it to the experimentally measured cross section for e^+e^- \\to \\text{hadrons} , via the R -ratio. a_{\\mu}^{\\text{HVP}} = \\left(\\frac{\\alpha m_{\\mu}}{3\\pi}\\right)^{2} \\int_{s_{\\text{th}}}^{\\infty} \\frac{ds'}{s'} K(s') R(s')\nwhere R(s) = \\sigma(e^{+}e^{-} \\to \\text{hadrons}) / \\sigma_{0}(e^{+}e^{-} \\to \\mu^{+}\\mu^{-}) and s_{\\text{th}} = (2m_\\pi)^2 is the two-pion production threshold."
  },
  {
    "objectID": "2024-Lecture-12.html#dispersion-relations-and-analytic-continuation",
    "href": "2024-Lecture-12.html#dispersion-relations-and-analytic-continuation",
    "title": "(2024) Lecture 12",
    "section": "2 Dispersion Relations and Analytic Continuation",
    "text": "2 Dispersion Relations and Analytic Continuation\nThe Cauchy theorem tells us that in the complex plane, you can integrate within the domain of analyticity. The integral of an analytic function over a closed contour is equal to the sum of the 2\\pi i residues of the function at the poles inside the contour.\nThis should look familiar. We’ve already discussed that you can use this to obtain an integral representation for any function within its domain of analyticity. You can write this in the following way, which is what you do manually by hand—introducing a pole so that the integral equals the residue of the integrand.\nSo, for a function F(s) that is a ratio with one pole, the integral will be equal to the residue at that pole. This requires substituting s for s' at the pole to complete the derivation.\nThis is known as the Cauchy integral formula, and what follows is a consequence of it. There is a useful trick, especially for analytic functions.\nImagine you have a function that is real analytic in a domain below a cut, with the cut starting at some threshold. We would like to use a similar method to evaluate its value.\nWhat I’m going to do is write the Cauchy representation for a contour: G(s) = \\frac{1}{2\\pi i} \\oint_C \\frac{G(s')}{s' - s} \\, ds'.\nNow, I will deform or “blow up” the contour. Changing the contour does not change the integral’s value, provided we account for singularities. The only singularity encountered is the simple pole of the integrand at s' = s .\nWhen I deform the contour, it acquires two contributions:\n\nA contribution from a large circle at infinity.\nA contribution from integrating along the cut.\n\nThe contribution from the cut is evaluated along the real axis. I will use the property of the discontinuity across the cut: G(s + i\\epsilon) - G(s - i\\epsilon) = 2i \\, \\operatorname{Im} G(s),\nwhere \\epsilon is infinitesimal. This relation follows from real analyticity.\nThis might seem intuitively clear, but let’s consider an example. Take a function with a cut starting at x=1 and extending to the right, which is real analytic elsewhere. A good example is \\sqrt{1 - x} .\n\nFor x &lt; 1 , e.g., x = 0 , \\sqrt{1 - 0} = 1 (real).\nFor x &gt; 1 , e.g., x = 5 , \\sqrt{1 - 5} = \\sqrt{-4} = 2i . Here, G(5 + i0) has a positive imaginary part.\n\n\n\n\n\n\n\nFigure 6: This diagram depicts the analytic structure of a complex function in the context of dispersion relations, relevant for hadronic contributions to the muon anomalous magnetic moment ( a_\\mu ). The figure shows the complex s -plane, with a branch cut (wiggly line) starting from the hadronic production threshold s_{\\text{thr}} and extending to higher s along the real axis. A closed contour is drawn around the singularity structure, avoiding the cut, which is a standard setup in the application of the Cauchy integral theorem and for deriving dispersion relations. Physically, this illustrates how the analytic properties of the vacuum polarization function \\Pi(q^2) allow us to relate its values at any s in the complex plane to its imaginary part (and thus the experimental cross section, via the optical theorem) along the cut. The lower bound s_{\\text{thr}} represents the physical threshold for hadron production, such as 2m_\\pi for two-pion states. The dispersion relation integral runs along the cut starting at this threshold, and the contribution from the large circle at infinity vanishes if the function falls off rapidly enough. In summary, the contour encapsulates the foundational mathematical relation underlying the use of experimental R(s) data in precision Standard Model predictions of a_\\mu .\n\n\n\nFor a real analytic function, the values above and below the cut have the same real part and opposite imaginary parts. This discontinuity lets me rewrite the contour integral. If the function decays sufficiently fast as |s| \\to \\infty , the contribution from the large circle vanishes.\n\n\n\n\n\n\nThe key relation used here is the discontinuity across a cut: G(s + i\\epsilon) - G(s - i\\epsilon) = 2i \\, \\operatorname{Im} G(s).\nThis underpins the derivation of dispersion relations, allowing us to connect the real and imaginary parts of an analytic function.\n\n\n\nAccounting for the direction of integration along the cut (which introduces a minus sign) and the factor of 2i from the discontinuity, we arrive at a beautiful formula known as a dispersion relation: G(s) = \\frac{1}{\\pi} \\int_{\\text{cut}} \\frac{\\operatorname{Im} G(s')}{s' - s} \\, ds'.\nThis is quite amazing—it allows us to recover the full analytic function from just its imaginary part along the cut. Using this relation, I can determine the function anywhere in the complex plane. This is an advanced subject, but it’s part of our classwork as an exercise to understand how dispersion works.\nSometimes, the function does not decay fast enough at infinity for the unsubtracted relation to converge. In such cases, we use a subtracted dispersion relation.\n\nOnce-Subtracted Relation: We introduce a subtraction at a point s = a : G(s) = G(a) + \\frac{s - a}{\\pi} \\int_{\\text{cut}} \\frac{\\operatorname{Im} G(s')}{(s' - a)(s' - s)} \\, ds'.\nThe term G(a) ensures the relation remains correct when s = a .\nA Common Simplification: The easiest subtraction is at zero ( a = 0 ): G(s) = G(0) + \\frac{s}{\\pi} \\int \\frac{\\operatorname{Im} G(s')}{s'(s' - s)} \\, ds'.\n\nIf once is not enough, you can perform a twice-subtracted dispersion relation. It’s remarkable that this works.\nLet’s test this with our example, \\sqrt{1 - x} . Its imaginary part appears only for x &gt; 1 . The dispersion relation with one subtraction at zero (where G(0) = 1 ) would state: \\sqrt{1 - x} = 1 + \\frac{x}{\\pi} \\int_{1}^{\\infty} \\frac{\\operatorname{Im} \\sqrt{1 - s'}}{s'(s' - x)} \\, ds'.\nIt’s non-trivial to believe, but it holds mathematically because we started with an analytic function and used the Cauchy integral. The imaginary part of \\sqrt{1 - x} for x &gt; 1 is simply \\sqrt{x - 1} , leading to a valid, if surprising, identity."
  },
  {
    "objectID": "2024-Lecture-12.html#hadronic-contributions-and-the-muon-anomaly",
    "href": "2024-Lecture-12.html#hadronic-contributions-and-the-muon-anomaly",
    "title": "(2024) Lecture 12",
    "section": "3 Hadronic Contributions and the Muon Anomaly",
    "text": "3 Hadronic Contributions and the Muon Anomaly\nNow we finally come back in the last minutes to the expression and I’ll wrap up this sketch of how it works. We relate the imaginary part of the forward scattering amplitude, through the optical theorem, to the total cross section. The observable is given by the cross section. The cross section is proportional to the imaginary part. You put the imaginary part in the numerator of a dispersion integral, and we have this contribution.\nIt probably makes more sense now why we start the integral at the production threshold, and why we use this global function. Back to the vacuum polarization function \\Pi(q^2) : it is an analytic function and it only has a right-hand cut. It’s real analytic below threshold. Once we go above the threshold, it starts having an imaginary part. We compute this polarization by a dispersion relation and then relate it to the cross section.\nThe key quantity is the ** R -ratio, R(s) . It is defined as: R(s) = \\frac{\\sigma(e^{+}e^{-} \\to \\text{hadrons})}{\\sigma_{0}(e^{+}e^{-} \\to \\mu^{+}\\mu^{-})}\nThe denominator is the point-like \\mu^+ \\mu^- cross section. For the R -ratio we need in the dispersion integral, a high-precision three‑loop theoretical calculation** is used. This calculation is very close to what we measure in experiment. The exercise sheet gives you the small differences to explore.\nBut the experimental R(s) really shows all the resonances that can pop up. A plot of the experimental measurement is quite spectacular, as we expect. It has contributions from all these resonances: you see the \\rho , the \\phi , the \\Upsilon . They all sit on a continuous background. This background comes from all possible hadronic contributions—quarks that hadronize not into single pions, but into multi-particle states (pions, etc.) needed to evaluate this contribution.\n\n\n\n\n\n\nThe imaginary part of the vacuum polarization is directly proportional to the R -ratio: \\operatorname{Im} \\Pi(s) = \\frac{\\alpha}{3} R(s)\nThis allows experimental R(s) data to be fed into the dispersion integral for \\Pi(q^2) . The current status is that there is about a five‑sigma mismatch between the full Standard Model theory prediction and the experimental measurement of the muon’s anomalous magnetic moment, a_\\mu = (g-2)_\\mu/2 . (see Figure 5) This tension was more prominent a few years ago, before some issues in QED calculations were discovered, and it was considered a potential indication for new physics. The precision is at the level of tens of parts per billion.\n\n\n\nIn recent years, two developments have threatened this new physics interpretation:\n\nLattice QCD calculations of the hadronic vacuum polarization (HVP). Lattice groups calculate part of this quantity in a different domain (Euclidean time) and their results disagree with the phenomenological calculations that use dispersion relations and experimental R(s) data.\nNew experimental data from the CMD experiment in Novosibirsk, which claims measurements in the critical energy region are inconsistent with past experiments but consistent with the experimental g-2 value if used in the analysis.\n\nConsequently, the five‑sigma discrepancy is now shrinking (e.g., to 1.8 sigma with some new lattice data). The indication for new physics is getting weaker, but it remains a significant puzzle.\nThere is a major ongoing effort:\n\nNew experimental facilities are being built to measure R(s) more precisely.\nThere is a large theoretical effort to properly calculate the hadronic effects, which remain the main source of uncertainty.\nThe leading-order HVP contribution to a_\\mu is: a_\\mu^{\\text{HVP}} = \\frac{\\alpha^2}{3\\pi^2} \\int_{s_{\\text{th}}}^\\infty \\frac{ds}{s} K(s) R(s)\nThe Hadronic Light-by-Light (HLbL) scattering contribution is even more difficult, as it involves virtual photons and their Q^2 dependence.\n\nI think we’re done. So, questions. We have time for questions. Finally.\nOne note I’d like to clarify for myself: when fitting these oscillatory components, do you extract the full amplitude W or just the difference between them? I’ve seen potential typos in papers on the vacuum polarization expression and will clarify with colleagues. But roughly, that’s it. Now you have a bare idea so when you hear HLbL and HVP, you know what they mean. Thanks for coming.\nOne short question from the audience:\n\nQ: Why can’t we be sure the main contributions are hadronic? Aren’t the ones we evaluate correctly just smaller?\n\nA: That’s a good point. I may have misspoken. The hadronic contributions are not necessarily the largest in magnitude, but they have the leading uncertainty. They are difficult to calculate to the precision required to reduce the overall uncertainty further. For instance, the HVP contribution, which is around 600 parts per billion, has been refined to about 100-200 ppb, but its uncertainty still dominates. (see Figure 5) We know other contributions (like pure QED) much better—they are smaller and have smaller uncertainties. The HLbL contribution is notoriously difficult, with many terms and a complex dependence on virtual photon momenta."
  },
  {
    "objectID": "2025-Lecture-01.html",
    "href": "2025-Lecture-01.html",
    "title": "(2025) Lecture 1",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Anna Zimmer"
  },
  {
    "objectID": "2025-Lecture-01.html#starting-with-qed",
    "href": "2025-Lecture-01.html#starting-with-qed",
    "title": "(2025) Lecture 1",
    "section": "1 Starting with QED",
    "text": "1 Starting with QED\nI start with QED — quantum electrodynamics — which describes how light interacts with anything that has a charge.\nIt’s relevant for us for only two reasons:\n\nOur quarks have charge, so they interact with photons.\nThe Lagrangian for QED is much simpler than for QCD. (see Figure~4)\n\nLet’s use this chance to understand all symbols, and we’ll proceed to QCD later.\nThe equation is complicated, but once you understand the general structure, you don’t need to look it up to write it down.\nThe Lagrangian is a function of two fundamental fields:\n\n\\psi — the field of an electron, muon, or quark (something with charge)\nA — the photon field\n\nSo, \\psi is a fermion field, and A is the photon field."
  },
  {
    "objectID": "2025-Lecture-01.html#lagrangian-structure-and-notation",
    "href": "2025-Lecture-01.html#lagrangian-structure-and-notation",
    "title": "(2025) Lecture 1",
    "section": "2 Lagrangian Structure and Notation",
    "text": "2 Lagrangian Structure and Notation\nThe Lagrangian is a scalar quantity — not a vector or matrix, but a number once evaluated at any point.\nScalar quantities are achieved by contracting indices: every index introduces a dimension, and you only get a scalar when all indices match.\nWe use Einstein notation: when you see the same index twice, it means we sum over it — same as in quantum mechanics.\nHere, \\mu and \\nu are Lorentz indices living in 4 dimensions: 3 spatial (x, y, z) and 1 time dimension.\nThe \\mu here and \\mu there must be contracted. I’m skipping the explicit summation over \\mu from 1 to 4, and also over \\nu, which also appears twice.\nNow, F_{\\mu\\nu} is actually a matrix: \\mu is 4-dimensional and \\nu is 4-dimensional, so F_{\\mu\\nu} is a 4 \\times 4 matrix.\nYou don’t multiply matrices as usual; you multiply them component-wise. Every component is multiplied by itself, and then you take the trace or sum all elements.\nEach coordinate in this matrix is computed as:\nF_{\\mu\\nu} = \\partial_\\mu A_\\nu - \\partial_\\nu A_\\mu\nwhere \\partial_\\nu is the derivative in time and space — essentially \\frac{\\partial}{\\partial x^\\nu}."
  },
  {
    "objectID": "2025-Lecture-01.html#indices-and-spinor-structure",
    "href": "2025-Lecture-01.html#indices-and-spinor-structure",
    "title": "(2025) Lecture 1",
    "section": "3 Indices and Spinor Structure",
    "text": "3 Indices and Spinor Structure\nIf it were just \\mu contracted with \\mu, it would be simple. But here, we also have spinor indices.\nThere is another set of indices that I suppressed — \\tau and \\rho — which come from the spin of the particles.\nParticles are not scalar; they have spin. That’s why the fermion field \\psi has four components.\n\\tau and \\rho are spin indices, not Lorentz indices. For Lorentz indices, we distinguish covariant and contravariant, but for spin indices, we just sum.\nSomething is still fishy in this Lagrangian because I’m adding a map.\nWe agree that these are four matrices, and this is a vector, so we can contract them. We get a matrix here, and then somehow from a matrix I’m subtracting a scalar — that’s not good.\nWhat’s missing is the diagonal matrix.\n\\psi is a four-component spinor, and \\bar{\\psi} is not a four-component spinor in the same way — it’s a row vector.\nWhat we do is take the conjugate transpose (dagger), then multiply by the \\gamma matrix from the left so it remains a row of numbers. Then you’re ready to contract with whatever matrix is here.\n\n\n\n\n\n\nThe full QED Lagrangian is: \\mathcal{L}_{\\text{QED}} = -\\frac{1}{4}F_{\\mu\\nu}F^{\\mu\\nu} + \\bar{\\psi}(i\\gamma^\\mu D_\\mu - m)\\psi This describes interactions between charged fermions and photons, with the first term representing electromagnetic field energy and the second describing fermions with mass and interactions.\n\n\n\n\n\n\n\n\n\nFigure 5: Feynman diagram representing an interaction term in the Lagrangian: two fermion fields coupled to the electromagnetic current with vertex strength g. The diagram directly corresponds to the interaction term of the Lagrangian."
  },
  {
    "objectID": "2025-Lecture-01.html#moving-to-qcd",
    "href": "2025-Lecture-01.html#moving-to-qcd",
    "title": "(2025) Lecture 1",
    "section": "4 Moving to QCD",
    "text": "4 Moving to QCD\nOne exercise is to see the same structure for the QCD Lagrangian, which I’ll write next. Once you do it once, it becomes super clear.\nLet’s do QCD now — it’s not too bad.\nThe exercise says: recover the indices, the range, the number of terms. You introduce the blue one because every index is N.\nSo: F_{G\\mu\\nu}, then U_{G\\nu} minus D_G, A is contracted besides gluon. That’s a really good exercise to write down — it’s super logical.\nIt’s actually the same equation as here with more indices because there are more dimensions.\nLet me check if I forgot G in front of the term g_s — exactly, here there is another G."
  },
  {
    "objectID": "2025-Lecture-01.html#dimensionality-in-qcd",
    "href": "2025-Lecture-01.html#dimensionality-in-qcd",
    "title": "(2025) Lecture 1",
    "section": "5 Dimensionality in QCD",
    "text": "5 Dimensionality in QCD\nNow let’s figure out the dimensionality of the objects quickly.\nThere’s a new object \\lambda here. These are three-dimensional — that’s a good starting point.\nSo IJ is here. These are 2 \\times 2 matrices. IJ must be here, must be here this one. Then they come, you contract over A.\nThis has a \\mu and also ij. These are still…\nNow we go here: IJ stays I, J, I, J. Here is the trace in these IJ dimensions.\nWhen you commute two matrices, you get a matrix — it’s multiplication minus subtitled multiplication.\nOverall, this is a matrix in \\mu and \\nu (2 \\times 2), but also in ij where I is an index of 3 and j is an index of 3.\nI’ll try to make more sense of this equation in a moment. As soon as I think all indices have to be introduced.\nI really care that you understand what equations are right, at least in terms of mathematical structure. Definitely everyone is capable of tracing this."
  },
  {
    "objectID": "2025-Lecture-01.html#flavor-and-color-indices",
    "href": "2025-Lecture-01.html#flavor-and-color-indices",
    "title": "(2025) Lecture 1",
    "section": "6 Flavor and Color Indices",
    "text": "6 Flavor and Color Indices\nThe F traces the flavors — F numbers: quarks U, D, S, C, T, B. We have six flavors, so the index F goes over all six possibilities.\nWhat else? Spinors in that case had four dimensions, and now there’s an extra three for color.\nThe index I here traces the color charge.\nThe only thing I don’t track is the spinor indices. For the QED Lagrangian, we agreed there’s something related to the spin projection of the particle — that’s another \\tau\\rho indices. We don’t put it here; otherwise it’s too complicated.\nIf you think of this field, it has:\n\nA flavor (let’s fix to up quark)\nA color (let’s fix to red)\nAnother four which are spinors (spin projections)\n\n\n\n\n\n\n\nThe QCD Lagrangian is: \\mathcal{L}_{\\text{QCD}} = -\\frac{1}{2}\\mathrm{Tr}(G_{\\mu\\nu}G^{\\mu\\nu}) + \\sum_f \\bar{\\psi}_f(i\\gamma^\\mu D_\\mu - m_f)\\psi_f where f runs over the 6 quark flavors, and the field strength tensor includes non-Abelian terms due to gluons carrying color charge."
  },
  {
    "objectID": "2025-Lecture-01.html#equations-of-motion",
    "href": "2025-Lecture-01.html#equations-of-motion",
    "title": "(2025) Lecture 1",
    "section": "7 Equations of Motion",
    "text": "7 Equations of Motion\nLast thing about this expression: once you know the Lagrangian, you can get the equations of motion by applying \\frac{\\partial\\mathcal{L}}{\\partial(\\partial_\\mu \\text{field})}.\nI think it’s easier to look at this expression where such a partial derivative would be nonzero.\nFor \\psi, we can do the same for A_\\mu (the gauge field). \\psi is only sitting in this term.\nThe first derivative for the first term actually equals zero. The only place where this is nonzero is when you have \\partial_\\mu \\psi.\nThe D has the inside of it — that’s the derivative. If you expand this, you’ll have \\bar{\\psi}\\gamma^\\mu D_\\mu\\psi.\nWhen you differentiate, \\bar{\\psi} will remain, and then \\frac{\\partial\\mathcal{L}}{\\partial\\psi} would be nonzero from the other term here.\nThe mass term will also produce something for the second term.\nThat way, you get equations of motion — differential equations describing how the field evolves in time and space.\nIf we apply this to QED, do you know what the equation is called that describes the motion of a fermion?\nPerfect. Remember, what’s the equation? It says it changes, but it doesn’t have a \\bar{\\psi} side; it just has \\psi.\nNote: G plus or minus is the same term as here. I think the D_\\mu here instead of the short — yes.\nThat would be for the next portion."
  },
  {
    "objectID": "2025-Lecture-01.html#gauge-transformations",
    "href": "2025-Lecture-01.html#gauge-transformations",
    "title": "(2025) Lecture 1",
    "section": "8 Gauge Transformations",
    "text": "8 Gauge Transformations\nGo to the next portion — the Rancho Kinemic picture.\nWhile I’m cleaning the board, let me ask questions about this point.\nWe discussed the Lagrangian and equations of motion. Let’s discuss gauge transformation and gauge symmetry — an extremely important concept in field theory.\nWe’ll only touch on this briefly since we’re not doing field theory, but it’s really important you know where legs grow from it.\nSomething very familiar from quantum mechanics is the phase ambiguity of the wave function. We can update the phase, and the absolute square of the wave function won’t change because you multiply \\psi to \\psi^* and the phase drops out.\nThis is fine. First is to acknowledge that this should be a symmetry of our theory — we should be allowed to make this phase transformation.\nIt’s kind of by definition, so this overall phase you don’t even have to think about.\nThe problem appears when you demand your theory to be invariant under changes of phase at all possible space-time points simultaneously with different phases.\nWhat if I want to adjust my wave function at every space point?\nWhy is this a problem? Because in our equation of motion, in our Lagrangian — let me just write the Dirac part: \\bar{\\psi}D_\\mu\\gamma^\\mu\\psi.\nHere I have a term \\partial_\\mu\\psi, and this term becomes \\partial_\\mu\\psi' which is \\partial_\\mu(e^{i\\alpha(x)}\\psi).\nLet me take the derivative. This equals applying the derivative to the first term and then to the second term.\nWhen I apply it to the second term, I just have \\partial_\\mu\\psi. When I apply it to the first term, I get \\partial_\\mu acting on this — the exponent stays, but I have to take the derivative of the exponent.\nSo there’s an extra term. Indeed, the same equation won’t hold for \\psi'. It doesn’t transform to the same equation because the derivative yields another term with \\partial_\\mu\\alpha.\nThis means that local gauge transformation is not a symmetry of the free Lagrangian of the free moving Dirac particle.\nYou cannot adjust phase independently at different points for a free particle.\nIn simple words, this means the theory is incomplete. It only becomes complete if you consider radiation, photons, and charged particles together.\nOnce you look at the full Lagrangian (I think I get a minus here — that’s an exercise in field theory), you update simultaneously the phase of the field \\psi and the electromagnetic field A.\nThen you see that the additional term appearing in the covariant derivative D_\\mu will cancel exactly the one you get from the phase.\nThen the Lagrangian stays the same with the updated fields \\psi and A.\nThis fact led us to the D_\\mu term. Actually, writing D_\\mu minus or plus — was it plus before or minus? That’s correct.\n\n\n\n\n\n\nThe covariant derivative in QED is: D_\\mu = \\partial_\\mu - ieA_\\mu This ensures local U(1) gauge invariance by canceling the extra terms from phase transformations, with e being the electromagnetic coupling constant."
  },
  {
    "objectID": "2025-Lecture-01.html#physical-implications",
    "href": "2025-Lecture-01.html#physical-implications",
    "title": "(2025) Lecture 1",
    "section": "9 Physical Implications",
    "text": "9 Physical Implications\nFrom equations of motion, you can see how different fields are coupled to each other.\nIn our pendulum example, we would see how the pendulum affects the movement of the upper marble.\nSimilarly, from equations of motion, we can see that motion of fermion fields is affected by motion of photons, and photons are affected by fermions.\nThe way we introduce gauge symmetry tells us exactly how they affect each other — how they interact.\nGauge symmetry enforces a certain way photons and fermions interact with each other. They have to interact with strength g.\nThe structure is very simple. Again, this is a scalar quantity.\nYou can figure out and convince yourself that the same integral is a scalar quantity. I guess it comes from this G matrix — \\gamma being 4 \\times 4 and then contracting the stuff.\nThese are contracted. We’ll find — that’s important.\nI think it’s worth writing down: gauge symmetry tells us how objects interact with each other. That’s very important."
  },
  {
    "objectID": "2025-Lecture-01.html#extending-to-other-theories",
    "href": "2025-Lecture-01.html#extending-to-other-theories",
    "title": "(2025) Lecture 1",
    "section": "10 Extending to Other Theories",
    "text": "10 Extending to Other Theories\nNow we’ll take this idea and move from QED to QCD.\nBefore jumping to QCD, where we deal with wave functions in three dimensions, let’s consider wave functions in the space of two coordinates — the case for weak interaction.\nFor weak interaction, you have up components and down components. Remember how the weak charge for quarks was +1/2 or -1/2 — the same range.\nHere you have an up field and down field. Remember, it’s still a fermion, so they have hidden four spinor components (we don’t talk about that).\nIn that case, the transformation that updates the phase is more general.\nWhat we want is that the update happening here doesn’t change the observable. Our observable will be \\psi^\\dagger\\psi.\nG or the matrix that updates the field — \\psi is the 2 \\times 2 matrix, and it’s unitary because observables should not change.\nIn this case, we’re dealing with transformations that are unitary, described by unitary matrices spanning the class called the U(2) group.\nWe’ll also fix the determinant of this matrix to be 1, and then this S comes from — for all matrices with determinant equal to 1 and unitary, they can be represented as an exponent.\nWho has seen the exponent of a matrix before? If you saw, what is this? Can you tell me what I should write here and then V?\nThis is more complicated. As soon as I put here one, it gets a little bit…\nWe solved it last year, right? I think it’s either 1 or 1 - e something. So e to 1, 1, 10 gets more complicated.\n\n10.1 Matrix Exponentiation and Generators in SU(N) Groups\nExactly right. So the approach is to take the expansion and perform multiple matrix multiplications.\nI recall it’s either e^{1} or 1 - e, but here, this is certainly not zero — and in fact, I’m not entirely sure about that anyway — so you understand what I’m referring to.\nThis is matrix exponentiation, and you can represent any element of the SU(2) group using matrix exponentiation. Here, we have a 2 \\times 2 matrix with zero trace. That condition comes from the determinant: \n\\det(U) = e^{\\mathrm{Tr}(\\alpha)} = 1\n which implies the trace of \\alpha must be zero.\nIn fact, there are only three matrices that span the entire basis of such traceless matrices: the Pauli matrices. These are called the generators of the group because they generate any group element.\nOnce we identify these three generators, we can take any three real numbers \\alpha_1, \\alpha_2, \\alpha_3, compute the combination -i\\alpha_j \\sigma_j, exponentiate it, and obtain an element of SU(2) — and in fact, this spans the entire group. You need to know the generator matrices — they’re fixed — then provide three numbers, and I can plug them into a Python routine.\n\n\n\n\n\n\nAny element of SU(2) can be written as: \nU = e^{-i \\alpha_j \\sigma_j}\n where \\sigma_j are the Pauli matrices and \\alpha_j are real parameters.\n\n\n\nIs there a reason we fix the determinant to 1? Yes — because we’re working with SU(2). In general, \nU(N) = U(1) \\times SU(N)\n So U(2) is U(1) × SU(2). The U(1) part is just a simple scalar phase, while SU(2) contains the non-trivial matrix structure. The scalar phase behaves exactly as in the 2D case, but the SU(2) matrix gives something interesting.\nSo I see the relationship, but why do we fix the determinant? Because SU(2) is one of the standard groups — we know a lot about it. If we considered U(2) instead, we’d have more generators and greater complexity. SU(2) is one of the primary elementary groups — that’s the main reason. We know everything about SU(2): how many generators it has, its matrix structure — it’s a nice object to work with.\nThis factorization helps us proceed similarly for higher groups: \nU(3) = U(1) \\times SU(3)\n We factor out the phase, and what remains is the standard group SU(3), which we use to describe the global update of the wave function with the same components. This is exactly what we deal with in quantum chromodynamics (QCD).\nWhen dealing with color charge, we don’t have two components — we have three: red, blue, and green. The transformation is then a 3 \\times 3 matrix with an overall phase — that’s not too complicated. We’ve discussed this before.\nBut then there’s a non-trivial contribution where you update your fields significantly. These are 3 \\times 3 matrices with determinant equal to 1. Again, you can relate this to the matrix exponential, and the exponent must be traceless.\nThe basis of traceless matrices in three dimensions that satisfy the anti-commutation properties — should I say the output must be anti-Hermitian? Does it hold for our condition? We insert it, multiply by two, and get -i\\alpha, then move to the other part.\nIf you look at the basis in two dimensions for traceless matrices, you get three generators; in three dimensions, you get eight. The number of generators is related to the number of charge carriers in the field.\nIn fact, we identify each generator matrix with the action of the field because they appear in the interaction term. The interaction term includes this matrix: every time you attach the field \\psi and the interaction field A, it comes together with this generator matrix.\nTo connect this back: remember where this chunk came from? We were computing derivatives and found an extra derivative for the phase. This extra derivative led us to introduce an extended derivative of the field — an interaction term that appears in Feynman diagrams.\nAs soon as we deal with higher dimensions, the same derivative we compute will come together with the appropriate matrix. So \\alpha is now 2 \\times 2, and it will appear here as another matrix. These generator matrices — \\sigma for SU(2), or \\lambda for SU(3) — will appear in the interaction vertex.\nWe find that:\n\nFor SU(2): 3 generators → 3 charge carriers: Z, W^+, W^-\nFor SU(3): 8 generators → 8 gluons\n\nUnfortunately, we lack the imagination to name all eight gluons properly, but they are identified by their matrices.\nIn the case of weak interaction, one matrix is diagonal in the space — roughly corresponding to the Z boson. The W and Z are charged similarly to the gluon field; some will be diagonal, and we identify certain extra hypercharges for the states. Some will behave like W_2, W^+, depending on the matrix.\nYou’ll see the same matrices in homework exercises. Think of them as the eight different gluons — you can name them, and they act differently on the field. They appear in the interaction vertex depending on the flavor of the gluon interacting with the quark. Each vertex behaves differently, driven by the structure of the Pauli matrices or their generalizations.\nThat’s why it’s a good exercise to think about this interaction term: How does this become a skewer? How do we contract the color charge? It’s a big, old puzzle.\nNow, the last part: I have two more topics. Confinement is important to discuss, so let me say a few words about it, and then we’ll go through the basic equations quickly.\nConfinement is the property of the theory where the strong interaction grows with distance. Unlike electromagnetic interactions, which decrease with distance, the strong interaction governing color charge increases when you pull quarks apart. This confines quarks to small scales.\nThe only way to feel the strong interaction is to zoom in to the smallest objects: mesons and baryons. Let’s draw them again:\n\nThis is a meson\nThis is a baryon\n\nThe word “confined” means that the strong interaction exists only inside the bubble of the meson or baryon. There is no strong interaction outside. If you try to pull them apart with huge force, at some point they divide — but then the resulting objects are again color-neutral, confined, and travel as stable particles.\nColor neutral means having zero charge with respect to the strong interaction. Remember: as soon as a particle has color charge, gluons can interact with it — meaning it’s not confined. Therefore, matter forms into these little bubbles where strong interactions are active inside, but outside they don’t feel the strong field — they are color neutral.\nI’m not deriving this — I’m stating it as a fact of the theory, proven by the existence of life as we know it. Confinement plays a vital role in binding and making life possible.\nHowever, if you look at the Lagrangian — where did our Lagrangian go? — you can’t directly see that it’s a confined theory. There are indications of confinement in the Lagrangian, and one of them is the gluon self-interaction.\n\n\n\n\n\n\nFigure 6: Diagrams of gluon self-interactions arising from the gauge part of the Lagrangian. These illustrate the non-Abelian nature of QCD and provide the basis for color confinement.\n\n\n\nIn QED, we had photon terms; in QCD, we have G_\\mu terms like: \nG_\\mu G_\\nu - G_\\nu G_\\mu + f^{abc} G_\\nu G_\\nu\n and then G_\\mu G_\\mu with 3-gluon and 4-gluon terms. These manifest in interaction vertices like this and this — called gluon self-interactions.\nGluon self-interaction is one indication of confinement — not a proof, but a clue. People study all possible field theories; some have confinement, some don’t. Confinement remains one of the great unsolved problems — there’s even a prize waiting for whoever can explain it.\n\n\n\n\n\n\nThe running coupling \\alpha_s(Q) depends on the momentum transfer Q:\n\nAsymptotic freedom: \\alpha_s(Q) \\to 0 as Q \\to \\infty\nConfinement: \\alpha_s(Q) grows large at low Q (around 1 GeV)\n\n\n\n\n\n\n\n\n\n\nFigure 7: Running of the strong coupling \\alpha_s(Q) with momentum transfer Q. At high Q, the coupling decreases, showing asymptotic freedom; at low Q \\lesssim 1 GeV, the coupling grows large, marking the confinement region.\n\n\n\nWe define Q as the momentum with which we probe the hadron. What we experience is the effective strong coupling \\alpha_s^{\\text{eff}}. You can think of a gluon coming in, interacting with a quark, and a lot happening — effectively, one quantum bubble with an effective interaction strength that depends on the gluon’s momentum.\nThis gluon, depending on its energy, will experience different interaction strengths. In electromagnetic interactions, we discuss screening effects; here, the effective interaction depends on Q as follows:\n\nIf Q is very high, we’re in the regime of asymptotic freedom\nIf Q is low, we’re in the regime of confinement\n\nThe transition happens around 1 GeV. Hadrons live in the low-Q region.\nIf you think about it: these particles talk to each other, exchange gluons, and the gluon couples to the fermion. When they’re close together, the gluon momentum is small — below 1 GeV — and that’s where the interaction is super strong. Meanwhile, at very high momentum transfer, the coupling becomes small — that’s asymptotic freedom, which we’ll discuss more later.\n\n\n10.2 Nuclear Binding and Decay Fundamentals\nI notice you’ve provided detailed instructions and examples for editing lecture transcripts, but you haven’t included the actual nuclear physics lecture transcription that needs to be polished.\nThe helping material contains several relevant nuclear physics formulas that could be integrated if they appear in your transcript:\nKey Nuclear Physics Formulas:\n\nNuclear Binding Energy: Calculates the energy equivalent of the mass defect: B(Z,A) = [Zm_p + (A-Z)m_n - m_{\\text{nucleus}}]c^2\nSemi-Empirical Mass Formula: Approximates binding energy based on the liquid drop model: B(Z,A) = a_V A - a_S A^{2/3} - a_C \\frac{Z(Z-1)}{A^{1/3}} - a_A \\frac{(A-2Z)^2}{A} + \\delta(A,Z)\nRadioactive Decay Law: Follows exponential decay: N(t) = N_0e^{-\\lambda t}\nRutherford Scattering: Describes angular distribution: \\frac{d\\sigma}{d\\Omega} = \\left(\\frac{Z_1Z_2e^2}{8\\pi\\epsilon_0E}\\right)^2 \\frac{1}{\\sin^4(\\theta/2)}\nUniverse Evolution Timeline: Includes key phases:\nt \\sim 10^{-12} seconds: Quark-Gluon Plasma\nt \\sim 1 second: Big Bang nucleosynthesis begins\nQuark Charge Properties:\nUp-type quarks (u, c, t): Electric charge +\\frac{2}{3}\nDown-type quarks (d, s, b): Electric charge -\\frac{1}{3}\n\n\n\n\n\n\n\nThese formulas represent fundamental concepts in nuclear and particle physics that might appear in your lecture transcript. The binding energy formulas explain nuclear stability, the decay law describes radioactive processes, Rutherford scattering reveals nuclear structure, and the quark properties form the basis of particle physics.\n\n\n\nCould you please provide the actual lecture transcription you’d like me to edit? Once you share the text, I’ll apply your requested corrections while preserving all technical content, explanations, and analogies."
  },
  {
    "objectID": "2025-Lecture-02.html",
    "href": "2025-Lecture-02.html",
    "title": "(2025) Lecture 2",
    "section": "",
    "text": "Presenter: Farah Afzal\nNote Taker: Anna Zimmer"
  },
  {
    "objectID": "2025-Lecture-02.html#isospin-and-hadron-classification",
    "href": "2025-Lecture-02.html#isospin-and-hadron-classification",
    "title": "(2025) Lecture 2",
    "section": "1 Isospin and Hadron Classification",
    "text": "1 Isospin and Hadron Classification\nWelcome everyone to today’s lecture. It will be mostly about classification of hadrons. I will walk you a little bit through the history of how important discoveries were made and what we learned from there about the hadrons and how we can group them together.\nIn the 1950s and 1960s, there were a lot of new big accelerators built, like for example the Bevatron. It came into operation in 1954. It was a proton accelerator with energies of up to 13 GeV. These high energy protons were then shot at a fixed target, and a lot of different particles were produced and detected. They found over 100 new particles, which was then called the particle zoo. Physicists of the time had to think about how to organize these particles: is there some pattern? Are these all fundamental particles? This is what we will be talking about today.\nIf you think about the periodic table, for example, we had all these atoms and we were able to group them together according to their proton and neutron numbers. We knew how many electrons were in the outermost shells, which helped us to group them together in the periodic table. This is kind of what we want to do now with hadrons. In the context of particle physics or hadron physics, the characteristics that we choose to group them together are according to their quantum numbers. We will now discuss different quantum numbers and why they were introduced and how they helped us to group together certain particles.\n\n1.1 Isospin Introduction\nLet’s start with isospin. In 1932 the neutron was discovered, and different experiments showed that when we look into proton-proton interactions, proton-neutron interactions, or neutron-neutron interactions, they had a very similar interaction strength. If you look at the rate at which these interactions were taking place, then they were basically the same. Experiments showed that all of these had similar interaction strength. If you also look at the mass of the proton and neutron, it’s almost the same at 939 MeV. This led to the suggestion that we can consider proton and neutron to be the same particle, but to have two different states that it can occur in, described by the isospin.\nThis means that the strong interaction does not distinguish between proton and neutron. The only time when we know that there are different particles is in an electromagnetic field. We can describe them as the same particle, the nucleon, and put them into an isospin doublet:\nN = \\begin{pmatrix} p \\\\ n \\end{pmatrix}\nThis is an analog property like the spin: if you look at the electron, we can have either spin up or spin down. This is similar here. At the level of quarks, since protons and neutrons are composed of up and down quarks, this means that the strong interaction does not distinguish between up and down.\nThe strong interaction is not capable of distinguishing between the different flavors of down and up. We can write that the up quark has an isospin of I = \\frac{1}{2} with the third component I_3(u) = +\\frac{1}{2}, and the down quark with I_3(d) = -\\frac{1}{2}.\n\n\n\n\n\n\nThe isospin quantum numbers for quarks are:\n\nUp quark: I_3(u) = +\\frac{1}{2}\nDown quark: I_3(d) = -\\frac{1}{2} For antiquarks, the signs are reversed: I_3(\\bar{u}) = -\\frac{1}{2} and I_3(\\bar{d}) = +\\frac{1}{2} to maintain consistent SU(2) transformation properties.\n\n\n\n\n\n\n1.2 Mathematical Framework of Isospin\nIsospin is not exactly a property like the spin, but mathematically we can treat the isospin like the spin. It follows the SU(2) algebra. In the last lecture, you already heard a little bit about the SU(2) algebras. Let me remind you a couple of things. It holds for the matrices, and we can describe this as a rotation matrix. Here, these sigma matrices are just the Pauli matrices. For the isospin operator, it was the same as for the spin where you had J instead of an I.\nGenerally we write these states always with the isospin and then the third component: |I, I_3 \\rangle. If we apply, for example, the I_3 operator to up, then we just get the eigenvalue +\\frac{1}{2}. We have here the lowering operators. If you have the isospin I, then we can have different projections I_3 from I down to -I, so you have 2I + 1 projections. With these lowering operators, you can go from one projection to the next. If you apply this to a state, you get out the Clebsch-Gordan coefficients.\nThis is just to remind you how this SU(2) algebra works.\n\n\n\n\n\n\nThe SU(2) isospin algebra follows these key relations:\n\nCommutation relations: [I_i, I_j] = i\\epsilon_{ijk}I_k\nLadder operators: I_\\pm = I_1 \\pm iI_2\nCasimir operator: I^2|I,I_3\\rangle = I(I+1)|I,I_3\\rangle\n\n\n\n\n\n\n1.3 Meson Isospin Combinations\nNow let’s look at a couple of examples. For example, if you want to think about the up and down quarks: last time you heard that we can form mesons taking a quark and an antiquark. Let’s think about what kind of particles we can get if you combine up and down quarks with antiquarks for the mesons.\nIf you look here at the isospin, we have for both up and down quarks isospin \\frac{1}{2}. We combine \\frac{1}{2} with another \\frac{1}{2}. What can we get if we have two \\frac{1}{2} isospin particles? We can have isospin of 0 or 1, just like you’re used to in the spin. If you think about the dimensions here, we always have two projections for one half: +\\frac{1}{2} or -\\frac{1}{2}. This is the dimensions here: 2 \\times 2. To indicate that we have here an antiquark, I place this bar here on top.\nIf you have an isospin of 1, how many projections can we have for I_3? You can have 2I + 1 projections. For I = 1, you get three: +1, 0, -1. For I = 0, just zero. If you take these as dimensions, then you would get 3 + 1. This is how you would write it down according to group theory:\n\\mathbf{2} \\otimes \\mathbf{\\bar{2}} = \\mathbf{3} \\oplus \\mathbf{1}\nI will also discuss a little bit later how we can understand this in terms of matrices. Here basically you have a 4 \\times 4 matrix and then you can decompose it into two components: into a 3 \\times 3 and a 1 \\times 1 matrix.\n\n\n\n\n\n\nFigure 1: Excerpt of a Clebsch–Gordan coefficient table for the spin combination of 1/2 and 1/2. The table lists the coefficients used to couple two spin-1/2 particles into total spin states, showing how individual spin components combine to form singlet and triplet configurations.\n\n\n\nThis is a triplet isospin state and this is an isospin singlet. This is how these different states would look like written down in terms of up and down quarks and form mesons.\nNow I want to briefly discuss with you where these factors come from. Like in the case of spins, you can use Clebsch-Gordan coefficients if you combine two spins or two isospins to figure out what kind of signs and coefficients you have in front of them. I will just write down a small fraction of the Clebsch-Gordan coefficients. We are combining here either spin \\frac{1}{2} with \\frac{1}{2}. These are the isospins of the two particles that we want to combine, and these are then the projections, the I_3 components.\nI will write the one now on top. Here you can see the outcome: the new particles that you get out and below it you see the projection I_3 of this combination. We said we can have an isospin triplet with isospin 1, so we get here this one three times with the projection +1, 0, -1. We have here the singlet with zero and the projection zero. Then here we can see the Clebsch-Gordan coefficients, and you also have to always take the square root. If you now look here, you can then see why these states look the way they do.\n\n\n\n\n\n\nThe explicit wavefunctions for the pion triplet members are:\n\n|\\pi^+\\rangle = -|u\\bar{d}\\rangle\n|\\pi^0\\rangle = \\frac{1}{\\sqrt{2}}(|u\\bar{u}\\rangle - |d\\bar{d}\\rangle)\n|\\pi^-\\rangle = |d\\bar{u}\\rangle These come from Clebsch-Gordan coefficients for combining isospin-1/2 states.\n\n\n\n\nJust one more thing that I need to mention is that for the antiquarks we get I_3(\\bar{u}) = -\\frac{1}{2} and I_3(\\bar{d}) = +\\frac{1}{2}. This minus sign is chosen so the quarks and antiquarks behave in the same way when you apply SU(2) transformations. If you look here at the singlet, we get then from the up and anti-up we get this vector: we have these projections +\\frac{1}{2}, -\\frac{1}{2}, so we get this vector with the square root. You do the same for down anti-down: you have -\\frac{1}{2}, +\\frac{1}{2}, you get here this minus sign, but because there’s also here this minus sign, it ends up being a plus. Then you do the same with the triplet one states. I just wanted to show you how it’s done, because we also practice this a lot more in the exercises.\nNow let’s take a step forward. I also wanted to mention what kind of particles we have here. This triplet typically pions: this would be a \\pi^+, this would be a \\pi^0, and here \\pi^-. We can also have rho particles: they’re basically the same, but there’s one thing that distinguishes these two, and that’s their spin. Here we have antiparallel spin, spin zero, and here they have parallel spin, but otherwise they’re the same. For the singlets we can have here an omega and here eta prime. Choosing this isospin quantum number, we can already group together some particles.\n\n\n1.4 Meson-Nucleon Systems and Baryons\nLet’s now go one step further and think about if you take for example a pion beam and shoot it on a proton target. We have a pion with isospin 1 and a nucleon target with isospin \\frac{1}{2}. What kind of isospin states can you get out of this? If you combine isospin 1 and isospin \\frac{1}{2}, you add this up. What do you guess? It’s either \\frac{3}{2} or \\frac{1}{2}.\nLet me write this properly. What are the dimensions here? For I = 1, we know it’s three: we have three different projections that are possible. For I = \\frac{1}{2}, we have two projections. Here we get four because we have \\pm\\frac{3}{2} and \\pm\\frac{1}{2}, and we get two again for \\frac{1}{2}. This is how you write this theory:\n\\mathbf{3} \\otimes \\mathbf{2} = \\mathbf{4} \\oplus \\mathbf{2}\nI also wanted to mention what this actually means, what we’re writing down. Basically we have here a 6 \\times 6 matrix and we can decompose it into matrices of the subspaces here: we have here a 2 \\times 2 matrix and here a 4 \\times 4 matrix. These are then called irreducible representations. This is basically what we do. For small numbers it’s kind of easy to know and write it down, but if you have larger numbers, there are some methods how you can figure this out. We will not discuss it in more depth, but I just wanted to mention what this actually means.\nIf you have isospin in SU(2), you get these four projections. This can be actually assigned to particles that were found at the time: these are called delta particles. We have \\Delta^{++}, \\Delta^+, \\Delta^0, \\Delta^-. They also give you the mass m_\\Delta = 1232\\text{ MeV}.\nI want to do one last example. Right now we have looked into meson systems and combining a meson and a nucleon system. What about if you just combine three quarks to get baryons? Then you would have basically 2 \\times 2 \\times 2: three quarks, and there are always two projections possible for \\pm\\frac{1}{2}. We can now use what we have already seen here: 2 \\times 2 gives us 3 + 1. This is what we had before: \\mathbf{2} \\otimes \\mathbf{2} \\otimes \\mathbf{2} = \\mathbf{4} \\oplus \\mathbf{2} \\oplus \\mathbf{2}. This gives us four, eight: \\frac{3}{2} and we have here two out of spin doublets with isospin \\frac{1}{2}.\n\n\n1.5 Experimental Significance and Historical Context\nWhat is this good for in isospin? You will later also see in the exercises that we can actually use this quantum number to see why certain cross sections that were measured are of different sizes.\n\n\n\n\n\n\nFigure 2: Diagram showing the cross section on the y-axis and the mass on the x-axis, with two curves representing pπ⁺ and pπ⁻ interactions. A clear resonance peak appears at the Δ mass, indicating the formation of the Δ resonance during scattering.\n\n\n\nIf we take for example the cross section for \\pi^+ p and for \\pi^- p, if you look here in the delta mass region, you see that there is a factor of three difference: \\frac{\\sigma_{\\pi^+p}}{\\sigma_{\\pi^-p}} \\approx 3:1. You can figure out in the exercises and classwork why there are differences in the cross sections between the different reactions.\nI introduced this isospin concept for protons and neutrons. How was that in experiment? They also write like up and down quarks—that wasn’t there. This concept in the 1950s: how should you imagine this? They saw like, oh, well, you produce pions and rho—was it also there? Yes, they also found rho later on. They introduced this concept to find symmetries or something. They were first just looking for patterns that they could find between different particles. This was like purely mathematical looking: just how can we group these together?\nIf you take the isospin, then we can already group some of these particles together. Like I said, we can group the pions or the rhos into triplets. We can have the delta in an isospin quadruplet and things like this. Then later bigger patterns were also seen. That’s where this lecture is headed towards: we will look later next into the strangeness and then hypercharge and so on.\nThe reason why I’m asking is because if you look just at protons and neutrons, you might initially think, oh, you have spin and charge and that’s all they do. Why would you introduce isospin? But it’s only when you do these kinds of reactions: proton-proton, proton-neutron, and neutron-neutron, and if you see that the reaction rates are pretty much the same, then you can come to the conclusion: okay, maybe the strong interaction doesn’t care about whether it’s a proton or a neutron. That’s where the isospin idea came from.\nIt comes down to once you start to look at cross sections, you start to see that certain reactions are stronger and you need to introduce new concepts in the theory. Here it was actually that they are pretty much similar. If you look at these different experiments and you see that the strong interaction does not seem to care about whether it’s a proton or a neutron, on quark level it means then it doesn’t care about up or down quark. That’s why we also placed not just the proton and neutron into an isospin doublet, but also the up and down quarks."
  },
  {
    "objectID": "2025-Lecture-02.html#the-eightfold-way-and-quark-model",
    "href": "2025-Lecture-02.html#the-eightfold-way-and-quark-model",
    "title": "(2025) Lecture 2",
    "section": "2 The Eightfold Way and Quark Model",
    "text": "2 The Eightfold Way and Quark Model\nSo first, physicists had this kind of an isospin doublet. They found all these other particles like the pions and kaons and grouped them together, then looked for bigger patterns with also the strangeness included as the next quantum number.\nAround the 1960s, with the Bevatron experiment and large accelerators accessible, they found over 100 particles and didn’t know what to do with them. They later found out we can actually decompose them into smaller particles to understand how, and we are still trying to understand.\nSome particles detected behaved in a strange manner. For example, in cosmic rays with pions going to a carbon target, they could see in a cloud chamber four tracks which look like a V: \\pi^+, \\pi^-, proton, and \\pi^-.\n\n\n\n\n\n\nFigure 3: A π⁻ from cosmic rays collides with a proton, initiating decay chains involving several intermediate particles. The π⁻ decays into a K⁰ and a Λ⁰, which subsequently decay into π⁻π⁺ and pπ⁻ respectively, illustrating hadronic decay processes.\n\n\n\nThese particles always appeared in pairs and had a fairly long lifetime.\nThey concluded by introducing a new quantum number strangeness and said that it needs to be conserved. Isospin is also a quantum number conserved in strong interactions.\nHow do we assign this quantum number? Particles consisting of up and down quarks have strangeness S = 0, for example pion, neutron, proton. Particles with strangeness S = +1 include lambda, and in general these are called hyperons. There are different types of hyperons like lambda, sigmas, cascades, and kaons.\nWith this we can form two isospin doublets with K^+ and K^0, and similarly K^- and \\bar{K^0} in an isospin doublet with strangeness S = -1. They figured since these two come always in pairs that this quantum number needs to be conserved in strong interaction, but it is not conserved in weak interaction.\nLooking at the lambda decay \\Lambda \\to p + \\pi^-, both products don’t have strangeness but this decay can happen. From the long lifetime this means weak decay. They are produced in strong interaction because we have \\pi + p \\to p + K^+ and n \\to hypercharge.\nHypercharge Y is given by baryon number B and strangeness number S: Y = B + S. For baryon number, if it’s a baryon then it gets B = +1, if it’s an antibaryon then B = -1, and if it’s a meson then B = 0.\nWe can’t have certain reactions. For example, if here we didn’t have a lambda but a proton, then this would not happen. Same way here, if you have lambda then we can’t have a \\pi in here. This always comes in pairs, so the strangeness number is conserved.\nAlso if you have \\pi^- in a proton beam, then you can’t have suddenly in the end two mesons only. There needs to be a baryon as well, so the baryon number is conserved.\nFrom isospin, we had the isospin triplet with projections +1, 0, and -1 correlating to charge: -1 for \\pi^-, 0 for \\pi^0, and +1 for \\pi^+. There seems to be a relationship between isospin and charge.\nThis is what Gell-Mann and Nishijima calculation tells us: the charge can be expressed as the third component of the isospin plus the hypercharge divided by two: Q = I_3 + \\frac{Y}{2}.\nLet’s check this formula:\n\nFor proton, I = \\frac{1}{2} and I_3 = +\\frac{1}{2}. Hypercharge: strangeness S = 0 for proton, but it’s a baryon so B = 1, giving Y = 1. Using the relation, charge Q = \\frac{1}{2} + \\frac{1}{2} = +1, as expected.\nFor neutron, I_3 = -\\frac{1}{2}, Y = 1, giving Q = -\\frac{1}{2} + \\frac{1}{2} = 0.\n\n\n\n\n\n\n\nKey Formulas:\n\nGell-Mann–Nishijima Formula: Q = I_3 + \\frac{Y}{2} relates electric charge to isospin and hypercharge\nHypercharge Definition: Y = B + S combines baryon number and strangeness\nConservation Laws: \\sum B_{\\text{initial}} = \\sum B_{\\text{final}} and \\sum S_{\\text{initial}} = \\sum S_{\\text{final}} (strong interactions only)\n\n\n\n\nUsing strangeness and/or hypercharge in combination with isospin, Gell-Mann and Ne’eman found a much larger pattern for these particles. They can be arranged in bigger multiplets, called the eightfold way.\nFor these larger patterns they looked not just at the up and down quark, but also included the strange quark. Now we are in the SU(3) flavor symmetry. At the time they didn’t know these different quarks existed, but we are just going to look at it in this way.\n\n\n\n\n\n\nFigure 4: Diagram plotting the z-component of isospin on the x-axis and strangeness (S) on the y-axis. An inverted triangle connects the up, down, and strange quarks, with each vertex labeled by its corresponding quantum numbers, visualizing the quark model’s flavor structure.\n\n\n\n\n\n\n\n\n\nFigure 5: Diagram with strangeness on the y-axis and the third component of isospin on the x-axis, showing the baryon octet. Each vertex of the hexagonal arrangement represents a baryon with its quark composition, demonstrating SU(3) flavor symmetry.\n\n\n\nPlotting the third component of isospin against strangeness for the up, down, and strange quarks, let’s write down the quantum numbers:\n\nFor baryon number each gets \\frac{1}{3} because up, up, down gives total 1\nCharge for up is +\\frac{2}{3}, for down is -\\frac{1}{3}\nThey’re all fermions with spin \\frac{1}{2}\nStrangeness for strange quark is -1\n\n\n\n\n\n\n\nFigure 6: Depiction of a baryon decuplet multiplet including Ω⁻, Ξ⁻, Ξ⁰, Σ⁻, Σ⁰, Σ*⁺, and the four Δ states (Δ⁻, Δ⁰, Δ⁺, Δ⁺⁺). Diagonals denote electric charge (Q) and horizontal lines indicate strangeness, with mass differences of roughly 150 MeV between each level.\n\n\n\nNow looking at bigger patterns for baryons. Baryons are composed of three quarks from up, down, or strange: \\mathbf{3} \\otimes \\mathbf{3} \\otimes \\mathbf{3} = \\mathbf{10} \\oplus \\mathbf{8} \\oplus \\mathbf{8} \\oplus \\mathbf{1}. This gives a decuplet and octets. We look at ground state variants arranged into an octet and decuplet.\nPlotting third component of isospin against strangeness (or hypercharge), we have S = 0, -1, -2.\n\n\n\n\n\n\nFigure 7: Meson octet diagram showing K⁰, K⁺, π⁻, η, π⁰, π⁺, K⁻, and K̄⁰. The y-axis represents strangeness, the x-axis represents the third component of isospin, and diagonal lines indicate electric charge (Q), highlighting SU(3) meson symmetry.\n\n\n\nOn the horizontal axis are isospin multiplets: isospin doublet for neutron and proton, triplet for sigmas, doublet for cascades.\nPointing out positions: here is I_3 = +\\frac{1}{2}, -\\frac{1}{2}, here I_3 = 0, here S = -1. You can see quark content: here all with one strange quark, here with two strange quarks.\n\n\n\n\n\n\nFigure 8: Table listing the u, d, and s quarks along with their fundamental quantum numbers. Entries include baryon number (B), electric charge (Q), spin, strangeness (S), isospin (I), z-component of isospin (I₃), and hypercharge (Y).\n\n\n\nLooking at masses:\n\nProton and neutron masses are almost the same, difference about 1 MeV\nSimilar for isospin partners\nBut in vertical direction, mass difference is much larger: sigma mass difference about 250 MeV, here to here about 130 MeV\n\nThis tells us that isospin symmetry in SU(2) is a good symmetry, but including strange quark it’s pretty much broken. It’s only an approximate symmetry because otherwise we would have same masses for all.\nWorking out the pattern: upper row has data, down here only minus. On this axis highest third component, along this axis strangeness 0, -1, -2.\nAll these particles have spin in common. Baryons in octet have spin \\frac{1}{2} and parity +. For decuplet, spin \\frac{3}{2} and parity +. Here spins can be aligned or permutations giving \\frac{1}{2}, here all aligned.\nWhen this pattern was found, the \\Omega^- was not yet discovered. This was a big success to predict its existence, found two years later in bubble chamber experiments with K^- + p \\to \\Omega^- + K^+ + K^0. For strangeness conservation, we need two more kaons.\n\\Omega^- decays into cascade \\Xi^-, then further to \\Lambda^0 + \\pi^0, \\pi^0 \\to 2\\gamma, and \\Lambda \\to p + \\pi^-. Not only predicted existence but roughly predicted mass: looking at masses between horizontal lines, \\Delta mass 1232 MeV, sigmas, then \\Omega^- mass around 1680 MeV, with mass spacing roughly 150 MeV.\nAll these considerations come from group theory, mathematical descriptions of particles with symmetry considerations. Difference between masses in octet and decuplet is that spin is different, so mass difference accounted to spin-spin or spin-orbit interactions from dynamics. For mesons, with up, down, strange quarks, \\mathbf{3} \\otimes \\bar{\\mathbf{3}} = \\mathbf{8} \\oplus \\mathbf{1}. On diagonal you have charge: here all charge -1, middle charge 0, +1, +2. This octet or nonet including \\eta' has quantum numbers 0^-+.\n\n\n\n\n\n\nFigure 9: Vector meson octet including ρ⁻, ω, ρ⁰, ρ⁺, and the K* mesons with charges 0, +, −, and anti-0. The diagram mirrors the pseudoscalar meson octet structure, illustrating similar flavor symmetry among vector mesons.\n\n\n\nThis means quark-antiquark pair have anti-parallel spins, parity -. For spins aligned parallel, spin 1, parity -1, charge conjugation C. Parity inverts spatial coordinates, charge conjugation converts particle to antiparticle.\nFor baryons, if you know orbital angular momentum L, parity P = (-1)^L. For octet ground states L = 0, parity + for \\frac{1}{2}^+ and \\frac{3}{2}^+. For mesons, P = (-1)^{L+1}, giving - for both. Charge conjugation well-defined for neutral mesons, e.g., \\pi^0 has C = +1.\nFor decays, parity and C parity are multiplicative. Combining spins of different particles to get total spin. Example: can \\omega meson decay into two pions? For \\pi^0, C = +1, multiplied gives +1, but for \\omega, C = -1, so cannot happen.\nLastly, consider quark content for \\Omega^- or \\Delta^{++}. All spins aligned, flavor content same. With Pauli exclusion principle for fermions, they should be distinguishable by one quantum number. Looking at total wave function: spatial, spin, and flavor.\nFor L = 0, spatial wave function symmetric. Spins all aligned up, symmetric. Flavor all same, symmetric. Physicists introduced new quantum number: color charge. This part of wave function must be antisymmetric to get total antisymmetric wave function.\n\n\n\n\n\n\nFigure 10: A step-like diagram with energy ω (in GeV) on the x-axis, showing three discrete levels corresponding to accessible quark flavors. The steps mark quark sets (u,d,s), (u,d,s,c), and (u,d,s,c,b,t), each annotated with example hadrons, providing evidence for the existence of color charge.\n\n\n\nAssign each quark different color: red, green, blue.\n\n\n\n\n\n\nParity Formulas:\n\nBaryons: P = (-1)^L (ground states have L = 0, P = +)\nMesons: P = (-1)^{L+1} (ground states have L = 0, P = -)\nMultiplet Decompositions:\n\nBaryons: \\mathbf{3} \\otimes \\mathbf{3} \\otimes \\mathbf{3} = \\mathbf{10} \\oplus \\mathbf{8} \\oplus \\mathbf{8} \\oplus \\mathbf{1}\nMesons: \\mathbf{3} \\otimes \\bar{\\mathbf{3}} = \\mathbf{8} \\oplus \\mathbf{1}\n\n\n\n\n\n\n\n\n\n\n\nFigure 11: Feynman diagram illustrating electron–positron annihilation producing a virtual photon. The photon subsequently decays into either a quark–antiquark pair or a lepton pair, with an example of a μ⁺μ⁻ final state shown.\n\n\n\nBriefly discuss experiment showing three colors. Looked into e^+ e^- annihilation with virtual photon exchanged, producing different particles: quark-antiquark pairs or leptons like \\mu^+ \\mu^-.\nMeasured ratio R = \\frac{\\sigma(e^+ e^- \\to \\text{hadrons})}{\\sigma(e^+ e^- \\to \\mu^+ \\mu^-)}. For leptons no color, so dividing gives proportionality to number of colors. Photon vertex proportional to charge squared, different quark types.\nInitially up, down, strange quarks measured as peaks in spectrum (rho, omega, pi mesons). When energy high enough, produce charm-anticharm bound states (J/ψ), then B bar states. Calculated steps show number of colors should be three.\nThis was historical background on how from detected particles, patterns were seen using eightfold way strangeness, later forming quark model where particles consist of smaller quarks with six flavors and three colors."
  },
  {
    "objectID": "2025-Lecture-02.html#unraveling-strange-particles-and-quantum-numbers",
    "href": "2025-Lecture-02.html#unraveling-strange-particles-and-quantum-numbers",
    "title": "(2025) Lecture 2",
    "section": "3 Unraveling Strange Particles and Quantum Numbers",
    "text": "3 Unraveling Strange Particles and Quantum Numbers\nGenerally, what I always find difficult with histories like what is known versus what’s not known relates back to my previous question about particle identification methods.\nI should have perhaps asked this earlier when you introduced strangeness in the context of cosmic rays.\n\n3.1 Particle Identification Through Invariant Mass\nThe fundamental practical question is: how do you distinguish kaons from other particles using just invariant masses? (see Figure 3)\n\n\n\n\n\n\nInvariant Mass Formula: M^2 = \\left(\\sum E_i\\right)^2 - \\left(\\sum \\vec{p}_i\\right)^2 This relativistic invariant allows identification of particle resonances from decay products. When analyzing cosmic ray events with protons and pions, peaks in the invariant mass spectrum reveal new particles like kaons.\n\n\n\nYou can only look at the invariant mass in these cases. You detect the proton and the pions, then examine the spectra to identify what’s known versus unknown.\n\n\n3.2 Historical Discovery Timeline and Strange Particles\nThese particles were called “strange” because researchers were confused about why they only appeared in pairs and had longer lifetimes than other particles.\n\n\n\n\n\n\nStrangeness Conservation: \\Delta S = 0 This quantum number explains why strange particles (like kaons) are always produced in pairs and have unexpectedly long lifetimes. Violation occurs only through weak interactions.\n\n\n\nThe pions were discovered relatively quickly after fundamental particles:\n\nProtons were known early\nNeutrons discovered in 1932\nLater in the 1950s: antiprotons and many other particles emerged\n\nSince many are charged, you can measure them directly.\n\n\n3.3 Conservation Laws and Quantum Numbers\nYou mentioned C-parity - how was that introduced? Was it used to say certain decays aren’t allowed? (see Figure 11)\nActually, I think it worked the other way around: researchers observed that certain decays weren’t measured, suggesting some quantum number must be violated.\n\n\n\n\n\n\nCharge Conjugation (C-parity): C|\\psi\\rangle = \\eta_C|\\psi\\rangle C-parity describes how particles transform into their antiparticles under charge conjugation, providing selection rules for decays.\n\n\n\nI don’t know exactly when charge conjugation was introduced, but it emerged when people started thinking systematically about particles and antiparticles - directly with the positron in the 1930s, before the antiproton discovery.\nThis highlights the difficulty: sometimes concepts come from theory, sometimes from experiments. It’s interesting how the omega baryon was predicted, but also how quantum numbers were introduced based on cross-section measurements.\n\n\n3.4 Quark Model Development and Mass Patterns\nHistorically, the multiplets were mostly correct - I only added the quark content for clarity. When multiplets were assembled, researchers postulated there might be smaller substructure, initially called “partons” before becoming “quarks.”\n\n\n\n\n\n\nQuark Model Mass Relations: M(\\Omega^-) - M(\\Xi^*) \\approx M(\\Xi^*) - M(\\Sigma^*) \\approx M(\\Sigma^*) - M(\\Delta) \\approx 150\\text{ MeV} The regular mass spacing in baryon multiplets provided crucial evidence for the quark model, suggesting these particles differ by replacing one quark with a heavier strange quark.\n\n\n\nThe mass differences already indicated there should be different quark content in these particles - for the deltas, sigmas, cascades, and so on. Researchers observed these mass differences and reasoned that the last undetected particle would also have approximately 150 MeV more mass than the others, which turned out to be correct.\nThe original quark paper is remarkably brief - just two pages - so you can easily look up how they introduced the concept.\nIt was an exciting time: they predicted the omega-minus in the quark model, and it was experimentally detected and discovered in 1964.\n\n\n\n\n\n\nOmega-Minus Discovery: K^- + p \\to \\Omega^- + K^+ + K^0 This was the experimental reaction that discovered the \\Omega^- particle, confirming quark model predictions."
  },
  {
    "objectID": "2025-Lecture-03.html",
    "href": "2025-Lecture-03.html",
    "title": "(2025) Lecture 3",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Anna Zimmer"
  },
  {
    "objectID": "2025-Lecture-03.html#lecture-outline-hadron-structure-and-symmetry",
    "href": "2025-Lecture-03.html#lecture-outline-hadron-structure-and-symmetry",
    "title": "(2025) Lecture 3",
    "section": "1 Lecture Outline: Hadron Structure and Symmetry",
    "text": "1 Lecture Outline: Hadron Structure and Symmetry\nToday we have lecture number three.\n\n\n\n\n\n\nFigure 1: This image schematically represents the internal structure of a hadron, such as a proton, as discussed in the lecture. The large enclosing circle denotes the finite spatial extent of the hadron, indicating that it is not point-like. Inside the hadron, the three smaller circles represent its constituent quarks (e.g., two up quarks and one down quark in a proton), in line with the quark model. The lines connecting the quarks symbolize the strong interaction, or the color force, mediated by gluons that confine the quarks within the hadron. This visualization is physically meaningful because it illustrates how scattering experiments reveal that the proton has an internal structure and a spatial charge distribution. The existence of form factors in scattering cross sections, introduced in the lecture, is direct evidence of this composite, extended nature rather than a point-like particle. The drawing thus encapsulates the key idea that hadrons are quantum systems with substructure, as probed by high momentum transfer ( Q^2 ) processes.\n\n\n\nWe will follow the consideration of the symmetry from the last lecture, but also look more carefully at what we know about the structure of hadrons, how they look inside, and what are the actual experimental evidences that they are not point-like, that they’re made of quarks.\n\n1.1 Lecture Plan & Key Topics\nWe will go through this list of topics:\n\nKinematics and Cross Sections: Starting with the calculation of cross sections and multibody kinematics.\nClassical Scattering: A simple classical scattering model of an electron and a proton.\nForm Factors: Discussing the form factors that appear in scattering, and how they relate to hadron properties like charge distributions and magnetic moments.\nThe Quark Model: Discussing these quantities assuming hadrons are made of quarks, and relating experimental distributions to internal structure.\nSymmetry Considerations: Returning to flavor and spin symmetry from the last lecture.\nProton & Neutron Wavefunctions: Examining the proton and neutron spin and flavor wave functions.\nMagnetic Moments: Computing the magnetic moment in the quark model and relating it to our observables.\n\nThat’s the plan, which hopefully gives a little bit of structure to the detailed discussion we are going to have.\n\n\n1.2 1. From Classical to Quantum Scattering\nI will start with the kinematics and something very fundamental: the calculation of cross sections. We begin with a simple classical picture of electron-proton scattering.\nFor a point-like target like a proton, the differential cross section is given by the Rutherford formula: \\frac{d\\sigma}{d\\Omega} = \\left( \\frac{Z_1 Z_2 e^2}{4E} \\right)^2 \\frac{1}{\\sin^4(\\theta/2)}\nThis describes scattering via a Coulomb potential, assuming no internal structure.\nHowever, for relativistic spin-1/2 particles like electrons, we use the Mott cross section, which adds a spin-relativistic correction: \\frac{d\\sigma}{d\\Omega}_{\\text{Mott}} = \\left(\\frac{d\\sigma}{d\\Omega}_{\\text{Ruth}}\\right) \\left(1 - \\beta^2 \\sin^2 \\frac{\\theta}{2}\\right), \\quad \\beta = \\frac{v}{c}\n\n\n\n\n\n\nThe key experimental discovery was that the proton is not point-like. The measured cross section deviates from the Mott prediction, introducing a form factor F(q^2) : \\left(\\frac{d\\sigma}{d\\Omega}\\right)_{\\text{exp}} = \\left(\\frac{d\\sigma}{d\\Omega}\\right)_{\\text{Mott}} |F(q^2)|^2\nThis form factor encodes the proton’s finite size and internal structure. ### 2. Form Factors and Internal Structure\n\n\n\n\n\n\n\n\n\nFigure 2: This figure schematically represents the process of electron-proton scattering, a central topic in the lecture. The diagram shows an incoming electron ( e ) scattering off a proton ( p ), resulting in an outgoing electron and outgoing proton. The central blob indicates that the interaction is not just point-like but involves the internal structure of the proton. The lower left part of the diagram, with three small circles inside the proton, symbolizes the proton being composed of three quarks, highlighting its non-point-like nature. Physically, this figure illustrates the concept that, as discussed in the lecture, high momentum transfer ( Q^2 ) in electron-proton scattering experiments probes the internal quark structure of the proton. The departure from the predictions of point-like scattering (e.g., the Mott or Rutherford cross section) leads to the introduction of form factors, which encode the finite size and non-trivial internal structure of the proton due to its composition from quarks. The image thus visually encapsulates the main lecture theme: probing hadron structure and inferring the presence of quarks inside the proton through scattering experiments.\n\n\n\n\n\n\n\n\n\nFigure 3: This diagram represents the kinematics of elastic electron-proton scattering in the center of momentum frame (CMF). The incoming particles, an electron ( e ) and a proton ( p ), approach each other along the horizontal axis. After their interaction, they scatter into final states: the outgoing electron ( e' ) and outgoing proton ( p' ). The angle \\Theta denotes the scattering angle of the electron relative to its initial direction. In the context of the lecture, this figure is used to illustrate the basic setup for analyzing 2 \\to 2 scattering, defining important variables like the scattering angle ( \\theta or \\Theta ) and emphasizing that these kinematic variables (in particular, the angle and the corresponding transferred momentum Q^2 ) are central to measuring and interpreting cross sections and exploring the proton’s internal structure. The CMF is the natural frame for describing the energy and momentum relations used in the calculation of Mandelstam variables s and t , and for connecting experimental observables (like the scattering angle) to theoretical quantities such as form factors and phase space integrals.\n\n\n\n\n\n\n\n\n\nFigure 4: This figure represents the Feynman diagram for elastic electron-proton scattering, a key process discussed in the lecture. An incoming electron ( e^- ) scatters off a proton ( p ) by exchanging a virtual photon, depicted as a wavy line labeled by the four-momentum transfer Q . The proton vertex is marked with a shaded “blob,” indicating that the proton is not a point-like particle but possesses internal structure. The blob encodes proton form factors ( F_1 , F_2 or equivalently G_E , G_M ), which parameterize the spatial charge and magnetic distributions inside the proton and cause measurable deviations from the predictions for point-like scattering. The scattering angle and resulting momentum transfer ( Q^2 ) probe either the overall charge radius or the internal quark structure, depending on the kinematic regime, as described in the lecture.\n\n\n\n\n\n\n\n\n\nFigure 5: This figure illustrates the kinematics of electron-proton scattering in the center-of-mass frame. The incoming electron ( e^- ) approaches along the z -axis and is scattered at an angle \\theta relative to its initial direction, emerging as the outgoing electron ( e' ). The azimuthal angle \\phi represents the rotation of the scattered electron around the z -axis. These angles, \\theta and \\phi , define the entire final-state configuration for a 2-to-2 scattering process. In the context of the lecture, \\theta is directly related to the transferred momentum squared Q^2 , which determines the sensitivity to the proton’s internal structure. The azimuthal angle \\phi often drops out for unpolarized, rotationally symmetric reactions, leaving \\theta as the key observable for extracting cross section dependencies and probing hadron structure through angular distributions.\n\n\n\n\n\n\n\n\n\nFigure 6: This figure represents the Feynman diagram for elastic electron-proton scattering, also known as electron-proton scattering via single photon exchange. In the context of this lecture, it illustrates the fundamental physical process used to probe the internal structure of the proton. - The incoming electron (labeled “e”) approaches the proton (labeled “p”), and they interact through the exchange of a virtual photon (wavy line labeled “q”)—the mediating particle of the electromagnetic interaction. - The outgoing electron (labeled “e’”) and outgoing proton (labeled “p’”) are detected after the scattering event. - The exchanged photon transfers four-momentum q to the proton, with the squared four-momentum transfer Q^2 = -q^2 serving as the key variable characterizing the resolution of the probe: small Q^2 corresponds to probing the overall charge distribution (forward scattering), while large Q^2 accesses the internal, quark-level structure (deep inelastic scattering). - The black blob on the proton side of the vertex symbolizes the fact that the proton is not a point-like particle. Instead, its electromagnetic vertex is characterized by form factors, such as F_1(q^2) and F_2(q^2) , encapsulating information about its finite size and internal quark-gluon dynamics. - This process is described mathematically by the matrix element \\mathcal{M} , and the experimentally measurable cross section depends on the squared amplitude |\\mathcal{M}|^2 , the phase space, and the kinematic flux factor. Overall, the image encapsulates how high-energy electron scattering is employed to extract the electromagnetic form factors of the proton, thereby revealing its spatial charge distribution and internal structure.\n\n\n\n\n\n\n\n\n\nFigure 7: This figure illustrates the relationship between the internal charge density distribution of different particles or composite systems and their corresponding form factors, which are directly probed in scattering experiments such as electron-proton elastic scattering. - First Row (Point-like, e.g., the Electron): - Charge density: The charge is concentrated at a single point, mathematically represented by a delta function, \\delta(r)/4\\pi . - Form factor: The Fourier transform of a delta function is a constant. In scattering, this means the cross section follows the prediction for point-like particles (e.g., Mott or Rutherford formulas), with no Q^2 -dependence beyond kinematics. - Second Row (Exponential, e.g., the Proton): - Charge density: The charge is distributed according to an exponential profile, such as (a^3/8\\pi)\\exp(-ar) . This spatially extended charge means the particle is not point-like. - Form factor: The Fourier transform gives a “dipole” form factor—decreasing smoothly with increasing Q^2 . This behavior encodes the finite size of the proton, as revealed by deviations from point-like scattering in experiment. - Third Row (Sphere with Diffuse Edge, e.g., Nucleus like ^{40} Ca): - Charge density: The charge is spread over a sphere, with a possible diffuse edge (approximated as proportional to r^3 for certain nuclei). - Form factor: The result is an “oscillating” form factor, i.e., the Fourier transform has zeros and oscillations as a function of Q^2 , characteristic of sharp-edged spatial distributions. Physically, the left column identifies the spatial structure (form) of the charge distribution, the middle column shows its mathematical or qualitative profile (charge density as a function of radius r ), and the right column shows the resulting form factor, which determines how the elastic scattering cross section deviates from the point-like behavior as a function of momentum transfer Q^2 . This directly connects internal structure (probed by form factors) to experimental observations in electron scattering—central themes of this lecture.\n\n\n\nThe form factors that appear in scattering are directly related to the spatial properties of the hadron.\n\nThe electric form factor G_E(Q^2) is the Fourier transform of the spatial charge distribution \\rho(r) : G_E(Q^2) = \\int \\rho(\\mathbf{r}) \\, e^{i \\mathbf{q} \\cdot \\mathbf{r}} \\, d^3r\nFor a spherically symmetric distribution, this simplifies to: G_E(Q^2) = \\int_0^\\infty 4\\pi r^2 \\rho(r) \\frac{\\sin(qr)}{qr} \\, dr\nwhere q = |\\mathbf{q}| .\nThe mean square charge radius, a key observable, is extracted from the low- Q^2 behavior of this form factor: \\langle r^2 \\rangle = -6 \\hbar^2 \\left. \\frac{d G_E}{d Q^2} \\right|_{Q^2=0}\n\nFor a full quantum mechanical description of elastic electron-proton scattering, we use the Rosenbluth formula, which separates the contributions from the proton’s electric ( G_E ) and magnetic ( G_M ) structure: \\frac{d\\sigma}{d\\Omega} = \\left( \\frac{d\\sigma}{d\\Omega} \\right)_{\\text{Mott}} \\left[ \\frac{G_E^2(Q^2) + \\tau G_M^2(Q^2)}{1+\\tau} + 2\\tau G_M^2(Q^2) \\tan^2\\left(\\frac{\\theta}{2}\\right) \\right]\nwhere \\tau = Q^2/(4M_p^2) and Q^2 = -q^2 is the squared four-momentum transfer.\nThese Sachs form factors ( G_E, G_M ) are related to the more fundamental Dirac ( F_1 ) and Pauli ( F_2 ) form factors: G_E = F_1(Q^2) - \\frac{Q^2}{4 m^2} F_2(Q^2), \\quad G_M = F_1(Q^2) + F_2(Q^2)\n### 3. The Quark Model: Symmetry, Wavefunctions, and Predictions\n\n\n\n\n\n\nFigure 8: This figure schematically represents the three spatial axes (typically labeled as the x, y, and z axes, or 1, 2, and 3) within the proton or hadron. The dashed oval outline suggests the finite spatial extent of the hadron, emphasizing that it is not a point-like object but has an internal structure. The labeled arrows (1, 2, 3) correspond to the directions in space along which observables like spin, momentum, or angular momentum can be projected. In the context of the lecture, this visualization is relevant to the discussion of the proton’s internal charge and magnetic distributions, which are characterized via form factors. Measuring properties such as form factors or the magnetic moment requires considering the projection of physical quantities (such as spin or orbital angular momentum) onto these axes. The axes are also essential in describing how the proton’s (or nucleon’s) wave function and associated observables transform under rotations and other symmetry operations discussed in the lecture, particularly as related to the SU(3) and isospin symmetries. Thus, the image is a schematic for understanding the orientation and internal degrees of freedom accessible within a finite-sized, structured hadron.\n\n\n\nNow, we relate these observations to internal structure by assuming hadrons are made of quarks. We return to the symmetry considerations—flavor symmetry and spin symmetry—and combine them within SU(6) spin-flavor symmetry.\n\n\n\n\n\n\nFigure 9: This figure illustrates the excitation spectrum of hadrons (such as baryons or mesons) in terms of quantum numbers N (principal quantum number, or radial excitation), and L (orbital angular momentum). The lowest state (ground state) corresponds to N=0 , L=0 (labeled “1S”), while the first excited radial state is N=1 , L=0 (“2S”). The next set shown is for orbital excitation, N=0 , L=1 (“1P”), which results in a multiplet of five mass states depending on spin and angular momentum coupling. A key physical interpretation in the context of the lecture is the “mass difference” (about 600 MeV) between the S and P states, highlighted here as arising from “spin-spin interaction” between quarks inside the hadron. This difference in energies (masses) between states with the same radial quantum number but different angular momentum reflects the internal structure of hadrons: the presence of constituent quark degrees of freedom, and the influence of quantum numbers on the energy spectrum, as described through the quark model and the potential (e.g., spin-spin) interactions among quarks. The labeled mass range (1500–1700 MeV) for the 1P states corresponds to observed masses of excited hadronic states. Overall, the diagram gives a schematic representation of the energy level structure of hadrons, and how spectroscopy (mass splitting) provides evidence for internal structure, consistent with the quark model discussed in the lecture.\n\n\n\n\nThe proton wavefunction must be fully antisymmetric. Its spin-flavor wavefunction is a specific combination: |p\\uparrow\\rangle = \\frac{1}{\\sqrt{18}} \\left[ 2|u\\uparrow u\\uparrow d\\downarrow\\rangle - |u\\uparrow u\\downarrow d\\uparrow\\rangle - |u\\downarrow u\\uparrow d\\uparrow\\rangle + \\text{permutations} \\right]\nIn the quark model, the magnetic moment operator for a hadron is the sum of its constituent quarks’ moments: \\boldsymbol{\\mu} = \\sum_{i=1}^3 \\frac{q_i}{2m_i} \\boldsymbol{\\sigma}_i\nwhere q_i , m_i , and \\boldsymbol{\\sigma}_i are the charge, mass, and spin operator of quark i .\n\nAssuming m_u = m_d , we define quark magnetic moments \\mu_u = \\frac{2}{3} \\frac{e\\hbar}{2m_u c} and \\mu_d = -\\frac{1}{3} \\frac{e\\hbar}{2m_d c} .\n\nThis leads to concrete predictions for the proton and neutron magnetic moments: \\mu_p = \\frac{4}{3} \\mu_u - \\frac{1}{3} \\mu_d, \\quad \\mu_n = \\frac{4}{3} \\mu_d - \\frac{1}{3} \\mu_u\nThese can be compared to the experimental values: \\mu_p = 2.793 \\, \\mu_N, \\quad \\mu_n = -1.913 \\, \\mu_N, \\quad \\text{where } \\mu_N = \\frac{e}{2m_p}\nThe success of these predictions is a major triumph of the quark model."
  },
  {
    "objectID": "2025-Lecture-03.html#isospin-symmetry-and-quark-content-in-hadrons",
    "href": "2025-Lecture-03.html#isospin-symmetry-and-quark-content-in-hadrons",
    "title": "(2025) Lecture 3",
    "section": "2 Isospin Symmetry and Quark Content in Hadrons",
    "text": "2 Isospin Symmetry and Quark Content in Hadrons\nBut before starting, I wanted to pose a question to recap. There are two questions.\nThe first I’m sure you all will be able to solve. The second I’m sure you all won’t be able to solve, but after today’s lecture you will.\n\nFirst question: What is the isospin of the D meson? Specifically, what is the isospin of the D^+ meson and the D^0 meson?\nSecond question: What is the isospin of the \\Xi_{cc} baryon and its quark content?\n\nFor the D meson, D^+ is a charm and anti-up, c\\bar{u} , and D^0 is charm and anti-down, c\\bar{d} . So that was correct.\nThe charm quark has a charge of +\\frac{2}{3} . The anti-up quark has a charge of -\\frac{2}{3} . The anti-down quark has a charge of +\\frac{1}{3} . So then let’s get the charge correct here.\nWhat is the \\Xi_{cc} charge? It’s ++ .\nThe second question for those who are done with the first: J/\\psi decays to a pair of identical vector particles. J/\\psi has spin one, parity minus, J^P = 1^- , then decays to two vector particles, each with J^P = 1^- .\nI’m asking, what is the orbital angular momentum between these two particles to have a correct parity interaction? Who thinks that it is one? Who thinks it’s zero? Who thinks it’s one half? All right, we’ll work on that.\n\n\n\n\n\n\nParity Conservation in J/\\psi \\to VV Decay For the decay J/\\psi \\to V V , parity conservation requires: P_{J/\\psi} = P_V \\cdot P_V \\cdot (-1)^L\nSubstituting the parities P_{J/\\psi} = -1 and P_V = -1 gives: (-1) = (-1) \\cdot (-1) \\cdot (-1)^L\nThis simplifies to (-1)^L = +1 , meaning the orbital angular momentum L must be even (e.g., L = 0, 2, \\ldots ).\n\n\n\nIsospin symmetry is related to the wave functions of the light quarks. You have a u -quark or a d -quark. These are two light quarks.\nWe are dealing with the isospin wave function that has two components: up or down. Isospin has two components, \\psi_u and \\psi_d , and that corresponds to the up and down as a two-component function.\nThis multiplicity-two wave function corresponds to the +\\frac{1}{2} or -\\frac{1}{2} isospin projection onto the quantization axis, say I_3 , of the total isospin I = \\frac{1}{2} .\n\nAs soon as you see one light quark, you are dealing with isospin \\frac{1}{2} .\nIf you have two light quarks, then you deal with a system that has a combination of two \\frac{1}{2} spins that could be 1 or 0: \\frac{1}{2} \\otimes \\frac{1}{2} = 1 \\oplus 0\n\nAnswering this question is as easy as just counting the number of the light quarks. Here is one, has isospin one half. Here is one, has isospin one half. If you see two light quarks, then you have to think either it’s zero or one.\nSo, one thing I’ve always found strange about this relation to the light quarks. Why don’t you have like an isospin for a heavier quark? You can have an internal group that relates.\nNow you’re asking, let me introduce the symmetry that acts in the space of the light quarks plus charm. Or let’s extend by one. Let’s say light quarks plus strange. But it has to include the lower quarks as well.\nSomehow looking at the charm quark over here. Charm quark, let’s say, or light… it’s a bit of a weird example anyways. Charm and strange. Fine, let’s consider.\nIs there a symmetry that relates charm and strange? Every wave function we would write and consider the dimension related to the charm and strange presence. The charm quark would be the upper component, the strange would be the lower component.\nAnd we would say this is a symmetry. The entire consideration is exactly the same as SU(2). The only problem is that our Lagrangian, our nature does not obey this symmetry because as soon as you change strange to charm, they don’t have equal masses.\nTherefore you sort of get a different world. The Lagrangian is not symmetric with respect to this symmetry. So the reason why we consider u and d quarks here as a part of the multiplet is because they have the same mass, m_u \\approx m_d .\nAnd if you change u to d , nothing happens with the Lagrangian. Sort of… there is a mass difference, right? Both of them are almost zero. Six MeV versus four MeV. So then people say, you know, like the strange quark is 100 MeV. 103, not that different.\nIf you look at the scale of 1 GeV where QCD breaks, where the low-energy QCD changes the regime, maybe 100 MeV of this strange quark is not that different from the light quarks. So let’s consider the s quark to be part of the same dimension.\nAnd then you could say, let’s introduce not an isospin, but a different quantity that reflects SU(3), that reflects the sort of place of the meson in the three-quark symmetry.\nAnd then we come back from the isospin to the diagram of the hypercharge versus isospin that was drawn last time. So then I could ask the same question: where in this hypercharge versus strangeness plane does this meson lie? And that would be a question that includes the strange quark into it.\nOne could ask another question. One can include the charm quark. And people do this, say, well, the charm quark is still lighter than the top and bottom. Let’s just include it in the consideration of the symmetry.\nLet’s pretend that we live in a world where the charm quark, strange quark, and light quarks have the same mass and it’s low. Then every meson gets mapped into the three-dimensional point of the symmetry group.\nOn one axis you have isospin, another axis you have strangeness, on yet another axis you have charmness. And then all these mesons get their place in this three-dimensional symmetry pattern.\nSymmetry tells you that the D^+ meson is almost the same as the D^0 meson because the only difference between them is the light quark, and light quarks are part of the multiplet. So D^+ and D^0 are the same particle with respect to the strong interaction.\nThat’s what isospin symmetry tells you. Also that particle would be the same as yet another one with respect to the strong interaction. And please tell me which one.\nThis particle has, since its isospin is \\frac{1}{2} , it has a brother or sister, which one? Not in the last row. We are talking about light quarks and I’m saying that replacing light quark u to light quark d does not change the particle properties.\nThat’s the claim of the isospin symmetry. So if you replace a u quark to a d quark, I’m going to have particles with almost identical properties. Same mass, charge… we don’t care because it’s not a quantity that QCD cares about, it’s electromagnetic interaction, but same mass, similar width, similar interactions with other particles, similar decay modes.\nEven in the Particle Data Group, sometimes we don’t separate them into different nodes; they are in the same node. We kind of understand, it’s understood in the field that particles that differ by the presence of u and d by the isospin, they are not that different, they are the same particle.\nSo if I’m asking for the brother of this, you say well replace u to d and then you have another particle. Which one will it be? I have a question. Would that be the same case for D^+ and anti- u ? So would I have three other options in that case? Very good.\nSo yet another symmetry that we have not considered here is making an antiparticle. And then from this it will be D^- which has a \\bar{c} d , and for the other one it will be \\bar{D^0} which is \\bar{c} u .\n\nParticle to antiparticle symmetry (charge conjugation C ) is even better than isospin symmetry.\nIsospin symmetry breaks a little bit by the quark masses and by their charges. Someone said u quark is not the same mass as d quark. Yes, there is a little difference and that’s what makes this symmetry not exact.\n\nThe D^+ and D^0 are not exactly the same particles, but they have similar properties. While D and \\bar{D} are so similar to each other that we don’t even talk about them separately unless we measure tiny effects in the standard model like CP violation.\nSo charge conjugation is a super good symmetry and we will not discuss that much of charge conjugation because deviations from the property of a particle and its antiparticle are tiny. And they are addressed in the BSM studies, beyond standard model.\nBut deviation between D^+ and D^0 is an interesting question. This is related to the electromagnetic interactions and the different masses of quarks: isospin breaking effects."
  },
  {
    "objectID": "2025-Lecture-03.html#isospin-partners-and-symmetry-breaking-in-d-mesons",
    "href": "2025-Lecture-03.html#isospin-partners-and-symmetry-breaking-in-d-mesons",
    "title": "(2025) Lecture 3",
    "section": "3 Isospin Partners and Symmetry Breaking in D Mesons",
    "text": "3 Isospin Partners and Symmetry Breaking in D Mesons\nTo finish, I would like to identify the isospin partner in the multiplet. Let’s start with the quark content, and then we can name it.\nThe charm mesons form an isospin doublet. Their quark content is c\\bar{d} for the D^+ and c\\bar{u} for the D^0 : \\begin{pmatrix} D^+ \\\\ D^0 \\end{pmatrix} = \\begin{pmatrix} c\\bar{d} \\\\ c\\bar{u} \\end{pmatrix}\nThe name is the same for particles within the same isospin multiplet. If the symmetry were exact, their properties would be identical, leading to: m_{D^+} \\approx m_{D^0}\nIn your homework, you will see a display of this principle. You will also see an example where isospin breaking is strong, which results in completely different decay modes for the D^+ and D^0 .\nIsospin symmetry is broken only hardly in observable quantities. On the level of quantum couplings, it actually holds very well. The primary reason for the breaking is the mass difference.\n\n\n\n\n\n\nThe breaking is driven by the small quark mass difference: \\Delta m_q = m_d - m_u\nThis slight difference in constituent quark masses (e.g., m_u \\approx 338 \\text{ MeV}, m_d \\approx 322 \\text{ MeV} ) can sometimes lead to huge deviations in observables like decay widths.\n\n\n\nAlthough the fundamental couplings ( |\\mathcal{M}|^2 ) are similar, the phase space available for decays can differ significantly. The decay width is given by: \\Gamma \\propto |\\mathcal{M}|^2 \\times \\Phi\nwhere \\Phi is the phase space factor, which is highly sensitive to small mass differences between the initial and final states."
  },
  {
    "objectID": "2025-Lecture-03.html#spin-addition-and-quantum-number-combinations",
    "href": "2025-Lecture-03.html#spin-addition-and-quantum-number-combinations",
    "title": "(2025) Lecture 3",
    "section": "4 Spin Addition and Quantum Number Combinations",
    "text": "4 Spin Addition and Quantum Number Combinations\nOne curious fact if you look at any LHCb paper is a standard sentence on the first page. It states that charge-conjugated processes are not listed explicitly, but it is assumed every time we write in our papers. For example, when we write B \\to D \\mu \\nu , we assume the charge-conjugated sample was analyzed simultaneously, and we do not even discuss it separately.\nThe reason for this is that analyzing one charge and the other addresses the same physics. There is no difference. We combine them and forget about charges, hence the note about charge-conjugated fractions on the first page of every paper. The properties of charge-conjugated mesons are homogeneous. We might revisit this when discussing deviations from the Standard Model and CP violation, if we get to it. But that is the first point done.\nLet us quickly discuss the second question. It is easier to address from the final state. You see two vector states; you add them and ask what possible configurations exist. What is the possible length of a vector you can make with one stick one meter long and another stick one meter long? We have vector one with spin S = 1 and vector two with spin S = 1 . You are going to add them.\nThe three possible configurations—since spin is quantized in units of 1—are S = 0 , S = 1 , and S = 2 . This is one of the things I hope you will learn from this course: how to add spins. We will practice this every lecture until you understand. We combine these two vectors and can have a total spin combination of zero, a spin combination of one, or a total spin combination of two.\nHere I have J_{V1} and J_{V2} . They interact with each other. If I consider them together, I can have a total J . On one side of a table, I draw their individual quantum numbers. On the other side is the total J . The parity is multiplicative when you combine them with zero orbital angular momentum. They do not rotate relative to each other. You just take one, take the second, put them together, and look at the total J . You have J^P = 0^+ , 1^+ , 2^+ . This is called the L = 0 s-wave.\n\n\n\n\n\n\nKey Formula: Total Spin Addition For two particles with spins \\vec{S}_1 and \\vec{S}_2 , the total spin \\vec{S} is given by \\vec{S} = \\vec{S}_1 + \\vec{S}_2 . The possible quantum numbers for S range from |S_1 - S_2| to S_1 + S_2 in integer steps. For two spin-1 particles: S = 0, 1, 2 .\n\n\n\nNow we start adding orbital angular momentum. This produces another set of quantum numbers. Orbital angular momentum is easier to address by looking only at the left part and stating that every configuration spans a ladder of states: for L = 0 , L = 1 , L = 2 . I will draw in the rows of the table what is possible.\nLet me start with the 0^+ total combination and add one unit of orbital angular momentum, L = 1^- . This means multiplying this 0^+ or adding to it the vector 1^- . I add 1^- to 0^+ and get 1^- . Now these two are trickier because I have one meter stick and another meter stick together. You have three spin combinations: S = 0, 1, 2 . They will have a parity of minus. Here I have another three combinations: J = 1, 2, 3 . This is called the P-wave.\nThe last one is the D-wave, which I will consider. We can continue to F-wave, G-wave, and so on. For this project, I probably need the F-wave. Yes, because there will be one. We call it F-wave. The way I address it is by looking again only at the first row, not the second, and adding two units of orbital angular momentum, L = 2^+ . The parity for orbital angular momentum is given by (-1)^L . So we have 0^+ , 1^- , 2^+ , 3^- , 4^+ , 5^- .\n\nStarting with 0^+ , I add L = 2^+ and get 2^+ .\nAdding it to S = 1 , I have to think a little. I bring another vector of length two and add. What can I get? The minimum is when they subtract: |1-2| = 1 . The maximum is 1+2 = 3 . All integer steps are allowed. So possible J are 1, 2, 3.\nNow for S = 2 and L = 2 : I need help. Here I have a vector of length two and I add two units of orbital angular momentum. What are the possible configurations? The minimum is |2-2| = 0 . The maximum is 2+2 = 4 . All of them will have parity plus.\nFor the F-wave, I bring an even longer stick, L = 3^- . Again, I look at the first row. It will give J = 1, 2, 3, 4, 5 for the last one, all with parity minus.\n\n\n\n\n\n\n\nKey Formula: Total Angular Momentum with Parity When including orbital angular momentum \\vec{L} , the total angular momentum \\vec{J} is \\vec{J} = \\vec{L} + \\vec{S} . The possible J values range from |L - S| to L + S .\nThe total parity P for a system of two particles with intrinsic parities P_1 and P_2 is P = P_1 P_2 (-1)^L . For two vector mesons (each with parity -1 ) and L = 0 : P = (-1)(-1)(-1)^0 = +1 , giving the s-wave states J^P = 0^+, 1^+, 2^+ .\n\n\n\nNow look at what decays. First, that is the basic thing. Knowing that you can combine any particles with any spin and any orbital angular momentum, you can figure out the possible quantum numbers: total spin and orbital angular momentum for any J^P I give you. Just learn how to fill this table, how to construct it from the combination of the two quantum numbers. Then you know how to deal with spin.\nThe next step is we look at what is decaying and try to identify within this table what decays. I look at this list, and one that decays is 1^- . I have it here, here, here, and here. So four combinations. The answer to this question: it decays into two. Let me remove identical particles, because identical makes it more difficult. There is also the rule that two identical particles cannot be in certain configurations of S . I already mentioned it. We will come back to this identical particle point at some point.\nBut identical particles will make this and this forbidden. For L = 3 and the two you showed, I think I remember that L + S must be even for identical bosons. So 3 + 2 is odd. Two plus this is odd. This is why only one remains. So it will be only one state for identical particles, and four combinations for non-identical particles.\n\n\n\n\n\n\nSelection Rule for Identical Particles For two identical bosons, the total wavefunction must be symmetric under exchange. This imposes the condition (-1)^{L+S} = +1 , restricting combinations to those where L + S is even. For example, if L = 1 and S = 2 , then L + S = 3 (odd) is forbidden.\n\n\n\nAll right, second question. You read this and realize you need to draw a table like this, quickly fill it—it is super easy—and then identify what is the stable one. That is it. Questions? I promise this is a super skill you learn so that you never have trouble with combination numbers."
  },
  {
    "objectID": "2025-Lecture-03.html#probing-hadron-structure-with-electromagnetic-scattering",
    "href": "2025-Lecture-03.html#probing-hadron-structure-with-electromagnetic-scattering",
    "title": "(2025) Lecture 3",
    "section": "5 Probing Hadron Structure with Electromagnetic Scattering",
    "text": "5 Probing Hadron Structure with Electromagnetic Scattering\nTo understand the structure of hadrons, you need to study a standard, well-understood probe: a well-understood current insertion into the hadron.\nIn order to study strong interactions and how hadrons are organized inside, we will look at the electromagnetic interaction. We will scatter an electron off a proton and see how this reaction behaves in the phase space of the kinematic variables.\nThe reason is that on the side of the electron there is nothing interesting or complex. The electron is a point-like particle. It interacts with the electromagnetic field of the proton and scatters off. That’s super well understood on the electron side of the reaction.\nThe process looks more interesting on the proton side. The electric charge that the electron sees originates from the proton charge if the interaction has a very low momentum transfer, Q^2 . But then, for high Q^2 , this current—this electron—starts feeling the charge of the quarks and the properties of the quarks inside the proton, instead of just the bare proton outer field.\nSo the problem here is like a large cucumber that you get smashed with the electromagnetic current. First, if the field the electron feels, or the transferred momentum Q^2 in this reaction, is small, you get the characteristics of the proton itself. (see Figure 2) But then, if you go to the regime of high transferred momentum, where a lot of energy is taken from the proton, you start seeing internals. You can look at this regime by the scattering angle \\theta of the electron, where Q^2 = 4 E E' \\sin^2(\\theta/2) . That’s the idea behind deep inelastic scattering.\nLarge accelerator machines and facilities have been built to study that very process of scattering.\nNow the proposal. Essentially, the hadron physics program for the next 10 years promises to be more or less that. You will have an electron-ion collider, so-called. That’s what is largely discussed. Instead of the proton you will have heavier ions, like Carbon ions, and then you’ll scatter electrons and then study quantum chromodynamics.\nIn this process there is a lot to understand about the proton. It’s not just an object that I draw, but there are quarks, there are gluons, and they interact with each other. There are many dynamics, like they are also not static. They move.\nWe have many dimensions you can imagine in the proton characteristics. What we understand more or less right is how these quarks inside the proton are distributed, what fraction x of the proton momentum these quarks are carrying, as described by the sum rule:\n\\sum_i \\int_0^1 dx\\, x f_i(x) = 1\nThis is the proton momentum sum rule, where f_i(x) are the parton distribution functions (PDFs).\nWhat we don’t understand is what is the perpendicular fluctuation. The problem goes in one direction. Part of its momentum is carried by the quarks. But what’s happening off the axis, the transverse momentum, is something not well understood. That’s one of the key questions that people want to address by studying further these days.\n\n\n\n\n\n\nKey Kinematics of Deep Inelastic Scattering (DIS):\n\nThe four-momentum transfer squared, Q^2 = -(k - k')^2 , sets the resolution scale of the probe. High Q^2 lets the electron resolve internal quark structure.\nThe Bjorken scaling variable, x = Q^2 / (2p \\cdot q) , represents the fraction of the proton’s momentum carried by the struck quark in the parton model.\nThe scattering probability is described by structure functions F_1(x, Q^2) and F_2(x, Q^2) in the DIS cross section formula. For spin-1/2 quarks, these are related by the Callan–Gross relation: F_2(x) = 2x F_1(x) ."
  },
  {
    "objectID": "2025-Lecture-03.html#mandelstam-variables-and-center-of-momentum-frame-quantities",
    "href": "2025-Lecture-03.html#mandelstam-variables-and-center-of-momentum-frame-quantities",
    "title": "(2025) Lecture 3",
    "section": "6 Mandelstam Variables and Center-of-Momentum Frame Quantities",
    "text": "6 Mandelstam Variables and Center-of-Momentum Frame Quantities\nThis reaction is about the motivation to study it. But what are our observables essentially? A 2-to-2 reaction is very simple in terms of the observables.\nThere is the total energy in the system, determined by the energy of the colliding beams, and then the scattering angle of the electron. Essentially that’s it.\nMore familiar quantities would be the total energy and momentum in the system and the scattering angle in the center of mass frame, the center of momentum frame.\nBut what are more natural and also very often used quantities? Our Mandelstam invariants, or Mandelstam variables, which are s and t .\n\nThe variable s is computed as the square of the sum of the four-momenta of the initial state particles: s = (p_{\\text{electron}} + p_{\\text{proton}})^2\nPhysics meaning: s is the square of the total center-of-mass energy. (see Figure 3) In the CM frame, \\sqrt{s} equals the total energy E_{\\text{total}} .\nThe variable t is computed as the energy transfer from the initial to final state: t = (p_{\\text{electron}} - p_{\\text{electron}'})^2\nPhysics meaning: t is the squared four-momentum transfer from the initial to the final electron (related to the scattering angle). It represents the invariant momentum transfer in the process. For spacelike momentum exchange, it is often related to the positive definite Q^2 via Q^2 = -t .\n\nSo here you have electron prime, here I have electron. The difference of the four-momenta gives t , so that I can convince you that these two quantities are related. I can write this quickly in the center of momentum frame. This is E_{\\text{electron}} , E_{\\text{electron}} + E_{\\text{proton}} . (see Figure 3) The star indicates that it’s talking in the rest frame.\nIn that frame, \\mathbf{p}_{\\text{electron}}^{\\star} = -\\mathbf{p}_{\\text{proton}}^{\\star} . And \\sqrt{s} is equal to E_{\\text{total}} . Essentially, \\sqrt{s} = E_{\\text{total}} .\nSo the variable t we compute a slightly different way: t = (p_e - p_{e'})^2 . What I’ve done here is to explicitly write this in the components.\nThe square of the difference of the four-vectors: the first four-vector squared gives the mass, the second four-vector squared gives the mass, and then twice the product, the scalar product of the two four-vectors.\nI compute by multiplying energies and then subtracting the scalar multiplication of the vectors: t = m_e^2 + m_e^2 - 2(E_e E_{e'} - |\\mathbf{p}_e||\\mathbf{p}_{e'}|\\cos\\theta_{\\text{CM}})\nAnd this is just absolute values squared, product of the absolute values and the cosine of the angle. Super straightforward.\nBut one thing to realize is that in the center of momentum frame all of these quantities are expressed in terms of s . So for example, the momentum |\\mathbf{p}_e| .\nAnd that you find by other algebra, by e.g. writing s as the proton plus electron squared. That’s not what you want.\nYou want to write \\sqrt{s} = E_{\\text{proton}} + E_{\\text{electron}} . So the \\mathbf{p}_{\\text{proton}} , \\mathbf{p}_{\\text{electron}} is equal to…\nThe magnitude of the momentum p_{\\text{CM}} in the CM frame is given by the breakup momentum: p_{\\text{CM}} = \\frac{\\sqrt{[s - (m_p + m_e)^2][s - (m_p - m_e)^2]}}{2\\sqrt{s}}\nThen you get the electron energy that you have here: E_e^{\\text{CM}} = \\frac{s + m_e^2 - m_p^2}{2\\sqrt{s}}\nAnd in a similar way you get the momentum. Momentum is the square root of the energy squared minus the mass squared.\n\n\n\n\n\n\nThe breakup momentum formula p_{\\text{CM}} is sometimes called the Chew function. It appears in phase-space calculations, particularly for two-body final states.\n\n\n\nThis expression is a Chew function because… Have you seen the Chew function before? The breakup momentum and the… When you calculate the phase space, I think the Chew function shows up. Phase space, two-body phase space."
  },
  {
    "objectID": "2025-Lecture-03.html#kinematics-of-elastic-scattering-and-the-role-of-q2",
    "href": "2025-Lecture-03.html#kinematics-of-elastic-scattering-and-the-role-of-q2",
    "title": "(2025) Lecture 3",
    "section": "7 Kinematics of Elastic Scattering and the Role of Q^2",
    "text": "7 Kinematics of Elastic Scattering and the Role of Q^2\nOne more thing to add for kinematics: let’s look once again at the variables.\nThe total energy is fixed by the beam of colliding particles. The scattering angle is something we measure.\nKnowing the total energy, we know s . Knowing the scattering angle, we know through the kinematic relation that we can determine t . In such an elastic scattering process, a common variable we encounter is Q^2 , defined as (see Figure 3)\nQ^2 = -t .\nThis definition comes from the fact that, at high energies, the dominant mechanism is an electron passing through and interacting with the target.\nSo t , or equivalently Q^2 , is called the transferred momentum squared. This is the quantity that actually governs the physics—in fact, it is the only non‑trivial dynamical variable in the process.\nThe beam energies of the colliding particles are fixed; that is what we adjust in our accelerator. (see Figure 5) The only thing we measure is the angular distribution.\nA bunch of electrons passes through a bunch of protons. If an interaction occurs, electrons change their trajectory—they scatter.\nBefore the interaction they fly in one direction; afterward their angle changes. The change in angle tells us everything: it reveals what happened inside the process and what momentum was exchanged.\nYou might wonder why the minus sign in Q^2 = -t is so crucial. For elastic scattering kinematics, if you examine the expression for t , you find that t is always negative—the transferred momentum is always space‑like.\nThat means the square of this four‑momentum transfer is negative. We can see this quickly in the lab frame with a fixed target: t is always negative.\nThat is why physicists prefer to use a positive quantity, Q^2 = -t .\nQ^2 is fixed by the scattering angle. This defines in what regime the reaction occurs:\n\nIf Q^2 is small, we have shallow electron scattering. The charge felt by the proton current characterizes the proton as a whole—its charge distribution, not its internal partonic content.\nIf Q^2 is large, we begin to probe internal structure.\n\nThus we can quickly realize: (see Figure 5)\n\nSmall Q^2 → small scattering angles.\nLarge Q^2 → large scattering angles.\n\nIf you want to become sensitive to the quarks inside the proton, you must look at events where scattering happened at a large angle. If you are interested in the charge distribution, charge radius, and overall characterization of the proton, you look at small‑angle scattering.\nWe will discuss two quantities that are characterized by small‑angle scattering:\n\nThe charge radius of the proton – how the proton appears as a cloud of charge when viewed from a distance. A good approximation for the proton’s charge distribution is an exponential form:\n\n\\rho(r) \\propto e^{-r/R},\nwhere R is the charge radius.\n\nThe magnetic moment – how a particle behaves in a magnetic field, or how it interacts with a magnetic field. If a particle has a magnetic moment \\vec{\\mu} , placing it in a magnetic field \\vec{B} produces an extra force. This appears as an additional term in the Hamiltonian:\n\n\\Delta E = -\\vec{\\mu} \\cdot \\vec{B}.\nFor example, in a hydrogen atom placed in a magnetic field, the energy levels split (Zeeman splitting) because of the magnetic moment and the finite charge radius.\n\n\n\n\n\n\nKey kinematic relations\n\ns = (p_1 + p_2)^2 is the fixed center‑of‑mass energy squared.\nt = (p_1 - p_3)^2 is the momentum‑transfer squared (always negative for elastic scattering).\nIn the lab frame, Q^2 relates to the scattering angle \\theta via Q^2 = 4 E E' \\sin^2(\\theta/2),\nlinking large Q^2 to large angles.\nSmall Q^2 probes the extended charge cloud (exponential \\rho(r) ); large Q^2 resolves internal quark structure.\n\n\n\n\nWe have discussed these points."
  },
  {
    "objectID": "2025-Lecture-03.html#cross-section-and-phase-space-in-scattering-processes",
    "href": "2025-Lecture-03.html#cross-section-and-phase-space-in-scattering-processes",
    "title": "(2025) Lecture 3",
    "section": "8 Cross Section and Phase Space in Scattering Processes",
    "text": "8 Cross Section and Phase Space in Scattering Processes\nBefore moving to the details, let’s relate quantum process observables with something that we measure in experiment. For that, let me introduce the cross section.\nIt’s another key equation in this course: how to compute the cross section, the differential cross section, in terms of the matrix element of the reaction. You can think of the square of the matrix element, |\\mathcal{M}|^2 , as something that gives you the probability of a reaction happening at a certain kinematic point.\nThe cross section, if you measure it integrated over the whole kinematic domain, would be given by the matrix element squared summed over this domain and then the number of phase space configurations. The phase space, you can think of as the number of configurations in which the reaction can happen. It’s rather intuitive.\nIn order to calculate the total probability you need to sum over all possible configurations. That configuration for the spins when you deal with discrete indices is a super intuitive concept. But when you deal with the kinematic manifold, it’s less intuitive because the space is continuous.\nAn example you see here: one of the variables that defines the final state is \\theta , the scattering angle. This is a continuous variable. If you want to calculate the total cross section, you have to sum over all possible \\theta s. It turns out to be an integral over \\theta . So that’s what phase space takes care of: it sums over possible configurations.\nThen there is a flux factor, which determines the normalization of the wave function so that your wave packets of the colliding particles are attributed correctly in the cross section. The flux factor is the simplest thing; it’s the 2E_1 2E_2 |v_1 - v_2| kinematic factor. Just put the right energies and velocities and then you have the flux.\nThe phase space is slightly trickier, but it’s a standard expression. Phase space presents an integral over all possible configurations in continuous space.\nFor each particle in the final state you have a phase space with n particles. For every particle you want to write something like \\frac{d^4p}{(2\\pi)^4} 2\\pi \\delta(p^2 - m^2) . Every particle should be on mass shell (on-shell means energy and momentum are correlated with each other, p^2 = m^2 ).\nSo you have an integral over all energy and momentum with the energy-momentum conservation. That 4-vector squared should give a mass squared. One can demonstrate that. Here is the energy-momentum conservation.\nPhase space is nothing else but the continuous version of the counting of possible configurations. It’s very easy—well, not once you’ve done this a couple of times. It’s easy for the two-body phase space, a little bit trickier for the three-body phase space, and gets rather complicated for four-body, five-body. But it’s always a standard integral.\nWe compute this numerically if we need to. But for two-body there was a classwork to compute this. We will meet this expression very often. That’s why I will give the expression for two-body.\nLet’s first count the number of variables. You see that every delta function gives the energy-momentum constraint that I can remove by taking the differential. So you can count the number of the d ’s that appear. This is the number of the variables I have to integrate. But then you subtract the number of constraints, because every constraint I can satisfy by removing one of the integration variables. That’s how the math of the delta functions works.\nSo let’s count for the two-body: how many d ’s I have, how many dimensions in my integral before I remove constraints? Six. Now minus four constraints from energy-momentum conservation. Two. So if I proceed wisely, I should be able to trade every one of these constraints for one of the differentials.\nAt the end I can proceed by removing constraints, not actually doing integrals, but just trading constraints for the differentials. Then at the end I am left with two degrees of freedom.\nSo the expression, if I do this, is:\nd\\Phi_2 = \\frac{1}{8\\pi} \\frac{\\lambda^{1/2}(s, m_1^2, m_2^2)}{s} \\frac{d\\cos\\theta \\, d\\phi}{4\\pi}\nwhere \\lambda(s, m_1^2, m_2^2) = [s - (m_1 + m_2)^2] [s - (m_1 - m_2)^2] is the Källén triangle function.\nIt’s a great exercise because it’s totally analytic and it’s a very nice answer. This has a lot of properties inside this expression. I really recommend everyone to do this three times: do it once, put it aside, do it a second time, you do it a third time, and then you understand it.\nSo the way how to trade these delta functions and the differentials and how to receive this expression. This expression has two differentials remaining and this is an integral over the phase space over the spherical angles.\nWhen we do 2-to-2 scattering, I said that there is one variable that determines the scattering. But I didn’t tell you that there is yet another one of rotation around the axis: the particles collide and then, in case you don’t have any polarization, if the initial and final states are not polarized, your matrix element squared does not depend on this azimuthal rotation.\nThat’s why \\phi here can be safely ignored. You have a z-axis, you have an x-axis here, you have a y-axis here. Your colliding particles: here is the electron, here is the scattered electron. Between the z-axis and the electron you have a \\theta angle. The projection of this electron prime to the XZ plane gives you the \\phi angle that is immutable. So that’s \\phi rotation.\nIf there is no spin external directions, there is no dependence on \\phi , like in this expression, the matrix element does not depend on \\phi . If you want to calculate the total integral here for the cross section, total cross section, we just get rid of this and replace this with 2\\pi . Because the \\phi integral is equal to 2\\pi .\nWhat is non-trivial is the \\cos\\theta . And that’s the whole physics. The \\cos\\theta is related to the Q^2 and that gives you sensitivity to the structure of the proton.\nWhat you see here is a kinematic factor. It tells you the number of the configurations for a certain energy. If you have a little energy release, if you have an energy very small, like if your energy of the beam is very small, the number of configurations is sort of small.\nThis is sort of a non-relativistic effect that if you would count non-relativistically, the number of degrees of freedom is only given by the number of the configurations. Sort of show it: first configuration, second configuration. This outgoing particle: first configuration, second configuration, third configuration. So overall you get 4\\pi configurations.\nBut if you take into account that particles are relativistic, then you end up with this factor which is the suppression of the phase space close to the threshold as a function of the energy. This vanishes when energy is equal to the masses of the particles. If your energy of the system is very close to the threshold, your phase space is zero, is very small. Not surprising.\n\n\n\n\n\n\nThe differential cross section formula that combines these elements is: d\\sigma = \\frac{1}{4E_1 E_2 |v_1 - v_2|} \\times |\\mathcal{M}|^2 \\times d\\Phi_n\nThis relates the measurable cross section to the square of the matrix element |\\mathcal{M}|^2 (the transition probability), the flux factor, and the Lorentz-invariant phase space d\\Phi_n for the final state."
  },
  {
    "objectID": "2025-Lecture-03.html#matrix-element-in-scattering-theory",
    "href": "2025-Lecture-03.html#matrix-element-in-scattering-theory",
    "title": "(2025) Lecture 3",
    "section": "9 Matrix Element in Scattering Theory",
    "text": "9 Matrix Element in Scattering Theory\nWe discussed this in scattering.\nNow let me quickly tell you what the matrix element is. The matrix element you see there is a key input to the reactions. That is something we gain either from a theory of interaction, from which we can derive it, or, if we don’t have a theory—as is often the case in hadron physics—we can use general principles to come up with it.\nFor electromagnetic processes, we do have a theory: QED plus QCD. We know how to write an expression that, when squared and summed over final states and averaged over initial states, gives a mathematical form we can plug in and compare to experiment.\nI also know this expression can only depend on one variable, which is one in two: the energy of the beam and another one. The matrix element is defined in the domain of my phase space variables. The phase space, as we just discussed, is a function of two variables, defined by \\theta . Once I consider the unpolarized case, I don’t have a \\phi dependence, so only \\theta remains.\nTherefore, the matrix element in our case will be a function of the scattering angle. Of course, it will also depend on the total energy, but this is fixed by the energy of the colliding particles.\nThis mathematical expression is complex and is defined in field theory in a formal way as part of the scattering matrix. You have initial states asymptotically brought to minus infinity in time and a final state with non-interacting particles at T = +\\infty . You then define the matrix element as the expectation of the interaction operator between the asymptotic initial state and the asymptotic final state.\nIt is a complex function, which is important for us. It gives a real value once I take its absolute value squared and sum. So it is a complex function of the two variables s and t . In the case where s is fixed, it is a complex function of one variable, t .\n\n\n\n\n\n\nThe differential cross section, which is the experimental observable, is directly related to this matrix element. It is proportional to the squared matrix element, |\\mathcal{M}|^2 , multiplied by the Lorentz-invariant phase space factor. For unpolarized scattering at fixed center-of-mass energy s , the matrix element \\mathcal{M} and thus the cross section depend only on the Mandelstam variable t (related to the scattering angle)."
  },
  {
    "objectID": "2025-Lecture-03.html#form-factors-and-the-rosenbluth-formula",
    "href": "2025-Lecture-03.html#form-factors-and-the-rosenbluth-formula",
    "title": "(2025) Lecture 3",
    "section": "10 Form Factors and the Rosenbluth Formula",
    "text": "10 Form Factors and the Rosenbluth Formula\nLet me write something you might have seen in field theory. I will not go through the details.\nIn field theory, the way we approach scattering is by using perturbation theory. We do it order by order, expanding in the number of interactions. Every interaction of an electron with the current gives you a factor of \\frac{1}{137} . This is \\alpha , the electromagnetic fine-structure constant. That’s why you can do an expansion series: for example, a photon hitting an electron once versus a photon hitting an electron twice. Already the first term in this series gives a good bulk value of the total cross section.\nTherefore, we will consider the first-order interaction in the electromagnetic process. We write this in the following expression. Every order, every mathematical expression has its equivalent in terms of the cartoon Feynman diagrams. So here I draw the diagram like this. I have a rule in field theory for how to translate the diagram into the mathematical expression. I draw a diagram, put an arrow, make a notation, and then I immediately write the expression.\nSomething here might not be familiar: these are F_1 and F_2 , the two form factors. These are two functions that are not given by the field theory and appear because the proton is not a point-like particle. F_1(q^2) and F_2(q^2) are form factors that characterize internal properties of the proton. If the proton were point-like, F_2 would be equal to 0, but it is not. That’s why we have to deal with them, introduce them, and actually measure them in experiment.\n\nu is a spinor.\n\\Gamma is a gamma matrix.\nThe thing I discussed last time is that \\sigma^{\\mu\\nu} is \\frac{i}{2}[\\gamma^\\mu, \\gamma^\\nu] , the commutation of the gamma matrices.\n\nIt’s really important that you can identify the dimensionality and prove that the expression one writes has the dimensionality one expects. What is the dimensionality of the matrix element? Is it a tensor, is it a scalar? All objects that appear here are tensors. One has to see that all indices match. For example, this \\mu is contracted with this \\mu . This is a 2 \\times 2 matrix.\nu is a spinor with indices, but it’s contracted with a 4 \\times 4 matrix. So this is a scalar in the spinor indices, but it’s a vector in the Lorentz index. This is again a matrix, but then it’s contracted by vector and by row and column, and then this is again a scalar. This one index \\mu is the photon momentum. F_1 and F_2 are scalar functions.\nI can proceed and derive the cross section. How I deal with spinors you also learn in field theory. The way I proceed with this expression is I find the squared amplitude and then I do spin summation. There are tricks to get rid of these spinors.\nWhat I want to write is the final expression for the cross section. It’s called the Rosenbluth formula. From here to here there are many steps, and I hope you allow me to skip them and I send you to a field theory course. In the book of Peskin and Schroeder it’s derived step by step. It’s not in the Mark Thomson book, but they also give this expression. I think in the field theory course you’re also forced to do that.\nWhat I want to stress is the physics of it. What you recognize quickly is the \\frac{1}{\\sin^4(\\theta/2)} that comes from the \\frac{1}{Q^2} . Q^2 is proportional to \\sin^2(\\theta/2) . Then 1/Q^2 leads to the 1/\\sin^4(\\theta/2) . That’s a divergence for small angles. For very forward scattering, you have a very high dependence on \\theta , like 1/\\theta^4 . It’s not integrable; you have to do regularization.\nE_1 and E_3 are the electron energies. One more equation that I missed is how G_E and G_M are related to F_1 and F_2 . For convenience, to make expressions at the end a little nicer, we replace the F s with the G s and then get this answer.\n\n\n\n\n\n\nFigure 10: This figure illustrates the experimental technique used to extract the proton’s electric and magnetic Sachs form factors, G_E and G_M , from elastic electron-proton scattering data using the Rosenbluth separation method. On the vertical axis is the ratio of the experimentally measured differential cross section to the Mott cross section, \\left( \\frac{d\\sigma}{d\\Omega} \\right)_{\\mathrm{exp}} / \\left( \\frac{d\\sigma}{d\\Omega} \\right)_{\\mathrm{Mott}} , which removes trivial kinematic factors and highlights the dependence on the proton’s internal structure. The horizontal axis is \\tan^2(\\theta/2) , where \\theta is the electron scattering angle. At fixed four-momentum transfer squared ( Q^2 ), the Rosenbluth formula predicts a linear relationship between this cross section ratio and \\tan^2(\\theta/2) , due to the separate contributions of G_E^2 (electric) and G_M^2 (magnetic) form factors to the angular dependence. The vertical intercept of the line is proportional to G_M^2 , and the slope is directly related to G_E^2 . By measuring the cross section at different scattering angles (i.e., for different values of \\tan^2(\\theta/2) ) but at fixed Q^2 , one can extract the values of G_E and G_M for that Q^2 . This process provides information about the spatial distribution of charge and magnetization inside the proton, which are key experimental evidences that the proton is not point-like but possesses internal structure described by these form factors.\n\n\n\nThat’s what people measure. From the Q^2 dependence of the G functions, one gets a property of the proton.\n\n\n\n\n\n\nThe Sachs form factors G_E (electric) and G_M (magnetic) are linear combinations of the Dirac ( F_1 ) and Pauli ( F_2 ) form factors. They are defined as: G_E(Q^2) = F_1(Q^2) - \\tau F_2(Q^2)\nG_M(Q^2) = F_1(Q^2) + F_2(Q^2)\nwhere \\tau = Q^2/(4M_p^2) . These are the quantities directly measured in electron-proton scattering experiments.\n\n\n\nI can say a few words next lecture on the extraction of the G s because that’s a very nice experiment. There is a nice experimental technique for extracting these G and F quantities at small values of Q^2 .\nLet me show you something. The Q^2 dependence is in fact a dual variable to the spatial coordinate in the sense of the Fourier transformation. If you know the Q^2 dependence of these form factors, you can interpret this as the spatial distribution. These two are related by the Fourier transformation. Tell me how this depends on Q^2 , and I can relate this to how the proton charge is distributed over large distances in space.\nIn fact, that’s what people do. They assume an exponential dependence on the spatial coordinate. Once you put exponential dependence here, you get a pole-like dependence. Here it’s called the dipole parameterization. You will see this in the homework. By measuring the Q^2 dependence, for example on the lattice or from experiment, we get the parameter of the spatial distribution.\nOne of the questions that has been very hot in the field is: what is the charge radius of the proton? Many experiments have tried to measure this with various techniques. Lattice calculations are also trying to address that. One of the quantities you extract on the lattice when you do numerical computation of quantum chromodynamics from first principles is the Q^2 dependence. A Fourier transformation gives you the spatial distribution, and you get the charge radius."
  },
  {
    "objectID": "2025-Lecture-03.html#magnetic-moments-and-the-quark-model",
    "href": "2025-Lecture-03.html#magnetic-moments-and-the-quark-model",
    "title": "(2025) Lecture 3",
    "section": "11 Magnetic Moments and the Quark Model",
    "text": "11 Magnetic Moments and the Quark Model\nThis quantity is another interesting aspect. It is related to the magnetic moment of the hadron. I would like to discuss that quantity in the remaining time.\nWhat I would like to argue is that G_M(Q^2 = 0) gives the magnetic moment. If you set Q^2 = 0 , you get a total integral of the magnetic current over the whole space. That gives you the total magnetic moment of the hadron.\nSo, what is a magnetic moment? This is like the leading-order term you can derive. You can extend this to higher orders:\n\nNext-to-leading order (NLO)\nNext-to-next-to-leading order (NNLO)\n\nThe corrections come from the electron side, which we know how to handle, and from the proton side.\nThe expression involving the form factors F_1 and F_2 is the most general one you can write. While you could derive F_1 and F_2 at NLO, this is very challenging in physics and is typically not done. Instead, these functions are parameterized. We acknowledge that we cannot compute the detailed dynamics inside the interaction vertex (the “blob”), so we describe it with parameters.\nIn practical physics, this parameterized interaction is what we call the magnetic moment. You may have seen this in quantum mechanics: the interaction part of the Hamiltonian is given by the product of the particle’s magnetic moment and the magnetic field. This affects the equations of motion, adds an extra energy term to the particle, and thus enters the Lagrangian.\nThe magnetic moment for a point-like Dirac particle is given by: \\vec{\\mu} = g \\frac{e}{2m} \\vec{S}\nHere, \\vec{S} = \\frac{1}{2} \\vec{\\sigma} is the spin operator for a fermion. The factor g is the gyromagnetic ratio. For a point-like Dirac particle, g = 2 .\nThis equation implies that for a neutral point-like particle (charge e=0 ), the magnetic moment would be zero.\n\n\n\n\n\n\nWhat we actually measure for the proton and neutron provides solid evidence that they are not point-like particles. The experimental facts are quite telling:\n\nThe magnetic moment of the neutron is not zero.\nThe magnetic moment of the proton deviates from the point-like particle value ( g \\neq 2 ).\nThe ratio of the proton’s magnetic moment to the neutron’s is roughly -\\frac{3}{2} .\n\n\n\n\nMy hope was to demonstrate how this ratio arises in the quark model, but we will have to postpone that calculation to the next lecture.\n\n\n\n\n\n\nFigure 11: This figure illustrates the behavior of the electromagnetic form factors G_E and G_M for the proton and neutron as functions of the squared four-momentum transfer Q^2 . - The vertical axis represents the form factor value ( G ), and the horizontal axis represents Q^2 , the momentum transfer squared. - The black curve labeled G_E^p shows the electric form factor of the proton. It starts at G_E^p(Q^2 = 0) = 1 , reflecting the proton’s unit electric charge, and falls off with increasing Q^2 , demonstrating how the proton’s finite size affects the spatial distribution of its charge as probed by electron scattering. - The blue line labeled G_E^n for the neutron starts at zero ( G_E^n(Q^2 = 0) = 0 ), consistent with the neutron’s lack of net electric charge. - The right side lists the measured values of the form factors at Q^2 = 0  for both proton and neutron: - G_E^p(0) = 1 (proton charge) - G_M^p(0) = 2.79 , which corresponds to the proton’s magnetic moment in nuclear magnetons ( \\mu_p ) - G_E^n(0) = 0 (neutron charge) - G_M^n(0) = -1.91 , corresponding to the neutron’s magnetic moment ( \\mu_n ) - The experimental significance highlighted in the lecture is: - For a point-like particle, you would expect a different result, especially for the neutron magnetic moment, which would be zero. - The nonzero and nontrivial values (especially for G_M ) show that the proton and neutron are not point-like, but have internal quark substructure. The deviation of G_M^p and G_M^n from naïve Dirac theory is direct evidence of composite structure, and their absolute values are key benchmarks for the success of the quark model calculations. In summary, this figure visually connects the form factors measured in electron scattering to intrinsic hadron properties—electric charge and magnetic moment—and demonstrates the evidence that nucleons are composite objects made of quarks.\n\n\n\nThe result is remarkable: the neutron has a non-zero magnetic moment, the proton’s g -factor is not 2, and their ratio is approximately -3/2 . This ratio comes out exactly when you examine the flavor-spin wave function for the proton.\nThe procedure is to:\n\nWrite the proton state as a composition of its quark wave functions.\nAct with the magnetic moment operator on the proton.\nCompute the proton’s magnetic moment in terms of the magnetic moments of its constituent quarks.\nRepeat the process for the neutron.\nFind that the predicted ratio matches the experimental value.\n\nLet me discuss the foundations of this approach. As we discussed previously, the reasoning stems from confinement in the strong interaction: the color interaction is confined within the small scale of the proton where the quarks reside.\nWithin the proton, quarks and gluons interact. The emergent properties and degrees of freedom appear when we consider multiplets and symmetries based on quarks. The quarks act as the leading degrees of freedom, but they gain an effective mass.\n\nThe current quarks in the Standard Model Lagrangian have very small masses.\nThe constituent quarks that emerge have a significant mass (roughly 300 MeV each) and carry most of the proton’s degrees of freedom.\n\nThe quark model assumes we integrate out the gluonic degrees of freedom, and the effect of this integration is to give the quarks an effective, constituent mass. We start with nearly massless quarks, integrate out the gluons, and end up with a system where three massive quarks form a proton.\n\nThe u quark has a charge of +\\frac{2}{3}e and the d quark has a charge of -\\frac{1}{3}e .\nEach carries 1/3 of the baryon number.\nTogether, they constitute and govern the degrees of freedom of baryons.\n\nWe can construct the proton wave function in a simplified manner by combining representations of the flavor wave function and the spin wave function, writing the proton in terms of these lower-level quark degrees of freedom. That is what we will do next time.\n\n11.1 Today’s Lecture Summary\nToday, we discussed the kinematics of electron-proton scattering, examining different regimes based on the momentum transfer Q^2 :\n\nForward Scattering ( Q^2 small): The electron barely changes direction. This regime probes the proton as a whole, characterizing its total charge density and magnetic moment.\nDeep Inelastic Scattering ( Q^2 large): High momentum transfer probes the proton’s internal structure, providing clues about the quarks inside.\n\nWe covered the standard 2-to-2 scattering kinematics, which is essential to understand well: how to calculate phase space, flux, and, given a matrix element, how to obtain a scattering probability.\nWe examined the Rosenbluth formula, detailing how the scattering cross section is determined by form factors, and how these form factors relate to the proton’s charge distribution and magnetic moment. We began introducing the quark model to explain these properties and will continue next time with the explicit calculation of the magnetic moments."
  },
  {
    "objectID": "2025-Lecture-03.html#conclusion",
    "href": "2025-Lecture-03.html#conclusion",
    "title": "(2025) Lecture 3",
    "section": "12 Conclusion",
    "text": "12 Conclusion\n\nAll right, thanks for your attention.\n\n\n\n\n\n\nThis concludes the current segment. The following section will build upon the concepts covered here. Please ensure you have reviewed the material before proceeding. If you have any questions, note them for the upcoming discussion."
  },
  {
    "objectID": "2025-Lecture-05.html",
    "href": "2025-Lecture-05.html",
    "title": "(2025) Lecture 5",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Anna Zimmer"
  },
  {
    "objectID": "2025-Lecture-05.html#production-mechanisms-and-kinematic-frames",
    "href": "2025-Lecture-05.html#production-mechanisms-and-kinematic-frames",
    "title": "(2025) Lecture 5",
    "section": "1 Production Mechanisms and Kinematic Frames",
    "text": "1 Production Mechanisms and Kinematic Frames\nAll right, let’s start this lecture. Today, lecture number five will be dedicated to the production mechanisms in different directions across the world to study hadron spectroscopy. We will also go into depth on the kinematics of different reactions, discuss numerical algorithms to produce distributions of particles, particularly decays, and look at one of the most important kinematic setups: frames and then kinematic representation of the phase space for different reactions.\n\n\n\n\n\n\nFigure 1: This figure illustrates the weak decay process of a \\Lambda baryon into a proton and a \\pi^- , emphasizing both the quark-level transition and the kinematics in different reference frames. - In the top left, the diagram shows the underlying weak process: a strange quark ( s ) inside the \\Lambda baryon converts into an up quark ( u ) via emission of a W^- boson, which subsequently produces a u\\bar{u} quark pair. The u quark, together with the spectator u and d quarks, forms the final state proton, while the \\bar{u} combines with a spectator d to form the \\pi^- . - The bottom left diagram depicts the decay kinematics in the laboratory (or production) frame. The \\Lambda moves along the z -axis, then decays, producing a proton and a \\pi^- emitted in a shared “decay plane”. - The right side of the figure shows what occurs after boosting into the rest frame of the \\Lambda (the so-called helicity frame, where the \\Lambda is at rest). In this frame, the proton and \\pi^- are emitted back-to-back, forming a specific angle \\theta_H with respect to the \\Lambda polarization (or motion) axis. The labels \\lambda_{\\Lambda} and \\lambda_{p\\pi} refer to the helicities (spin projections) of the \\Lambda and the p\\pi system, respectively. This setup is central in hadron spectroscopy, as analyzing the angular distribution of the decay products in the helicity frame allows measurement of spin and parity properties of the parent particle ( \\Lambda baryon in this case), as well as the dynamics of weak decay processes. The transformation from lab frame to rest frame and the interpretation of the resulting angular variables are key topics in the lecture’s discussion of kinematics and phase space in particle production and decay.\n\n\n\nBefore starting, we go through the recap and I ask quickly to give the answers. Who feels confident on question number one? Let’s break it down.\n\nFlavor: In this context, flavor is a quantum number for the multiplet. It refers to quark types like up, down, strange, and charm. It is distinct from color charge.\nMultiplet: This refers to the different possible combinations or configurations for a given quantum number, like the different states for a total spin.\n\nThe whole question was: What are the flavor multiplets of Σ_b? We are looking for other baryons that belong to the same multiplet, meaning they share the same quantum numbers but have different projections of the flavor wave function. The Σ_b baryon has quark content (u s b).\n\n\n\n\n\n\nIsospin and SU(3) Multiplets:\n\nIsospin SU(2): This is a flavor symmetry where you can change a u quark to a d quark. For Σ_b, this gives two particles in the isospin multiplet: Σ_b⁺ (u s b) and Σ_b⁰ (d s b). They have different charges.\nSU(3) Flavor: This symmetry allows flipping the strange quark to others (u, d), leading to larger multiplets like decuplets, which were discussed in lecture two.\n\n\n\n\nThe next question was about the spin of two pions in a D-wave. The quantum numbers of a single pion are 0^- . When combining two scalar (spin-0) particles:\n\nIn an s-wave, the total spin is 0^+ .\nIn a p-wave, the total spin is 1^- .\nIn a D-wave, the total spin is ** 2^+ **.\n\nThe final question: Is flavor symmetry gauge and Lorentz symmetry gauge?\n\nGauge symmetry is a local symmetry, where transformations can be made independently at every point in spacetime. The electromagnetic field arises from promoting a global phase symmetry to a local one.\nFlavor symmetry is a global symmetry, not a gauge symmetry.\nLorentz symmetry (boosts and rotations) is typically applied uniformly across spacetime in our considerations. While it can be treated as a local gauge symmetry in theories of gravity, in standard particle physics it is not considered a gauge symmetry. Today we start this lecture on particle production. The first section is “A Dictionary and Slang of Particle Production,” as a follow-up to discussing different production mechanisms. When we talk about production kinematics, it makes sense to distinguish a few different classes. This classification depends on the reaction kinematics, but also on practicalities.\n\n\n\n\n\n\n\nFigure 2: This figure illustrates the basic setup of a fixed-target experiment, one of the two main classes of particle production experiments discussed in the lecture. In this arrangement, a particle beam (such as photons, pions, or muons) is directed onto a stationary target material. The collision produces a variety of final state particles, which emerge from the interaction region and can be measured by detectors. This figure emphasizes the directional nature of fixed-target experiments—where the target remains at rest in the laboratory frame and the beam delivers energy, resulting in final-state particles that are typically boosted forward. Fixed-target experiments, such as GlueX and COMPASS, are historically important in hadron spectroscopy and provide specific kinematic features distinct from collider setups.\n\n\n\nWe start by separating two different classes of experiments:\n\nFixed-target experiments: A beam is shot at a stationary target.\nCollider experiments: Two beams are collided head-on.\n\nPractical Differences:\n\nEnergy: Colliders can achieve much higher center-of-mass energy.\nBoost: Fixed-target experiments produce decay products that are more boosted in the forward direction.\nComplexity: Fixed-target setups are historically simpler, requiring only a beam and a target.\n\nExamples of Fixed-Target Experiments:\n\nGlueX: Photon beam on a liquid hydrogen target.\nCOMPASS: Pion or muon beam on various targets (hydrogen, lead, ammonia, beryllium).\n\n\n\n\n\n\n\nTarget Materials in Practice:\n\nLiquid Hydrogen: Popular for hadron spectroscopy. It’s a 1-meter long pipe (~30 cm active length) requiring careful handling under pressure.\nBeryllium: A simple, cheap disk target (e.g., 3 cm thick).\nLead (High-Z): Used for higher production rates, as cross sections scale with the number of protons (Z) in the target.\n\n\n\n\nIn experiments like GlueX, a photon beam is produced via bremsstrahlung: electrons pass through a thin foil, emit photons, and are then bent away by a magnet, leaving a pure photon beam. To discuss the physics of the production mechanism, we draw diagrams where incoming particles enter a blob on the left and outgoing particles appear on the right.\n\n\n\n\n\n\nFigure 3: This figure represents a generic diagram for an exclusive particle production reaction in hadron spectroscopy. Here, a photon ( \\gamma ) and a proton ( p ) are shown as incoming particles on the left, entering a central “blob” that symbolizes the underlying interaction or production mechanism. The outgoing particles emerging from the blob are a proton ( p ), a positive pion ( \\pi^+ ), and a negative pion ( \\pi^- ). This setup formalizes a reaction such as \\gamma p \\to p \\pi^+ \\pi^- . In the context of this lecture, this type of diagram is used to discuss the kinematics of exclusive processes, where all final-state particles are measured. The “blob” represents all possible strong-interaction physics that can occur, while the external lines denote incoming and outgoing real particles. The study of such reactions often involves analyzing the event in the center-of-momentum (CM) frame, using conservation of four-momentum to reconstruct invariant masses (like m_{\\pi\\pi} ), and transitioning to frames such as the Gottfried-Jackson frame to further analyze the decay angular distributions of the particle systems produced. In summary, this figure encapsulates the essential ingredients for investigating production mechanisms, kinematics, and resonance identification in exclusive photoproduction experiments, using the tools discussed throughout the lecture.\n\n\n\n\nExclusive Processes: We measure all final-state particles. This is necessary to understand detailed production mechanisms and specific resonances.\nInclusive Processes: We measure only a specific final-state particle (e.g., a kaon), summing over all other unmeasured particles. This gives access to averaged quantities, like parton distribution functions inside the proton.\n\n\n\n\n\n\n\nFigure 4: This figure illustrates an inclusive particle production process, as discussed in the lecture. In this context, the diagram shows a proton (p) and a muon ( \\mu^- ) entering a reaction (the blob), and in the final state, a kaon ( K^- ), a muon ( \\mu^- ), and any other unmeasured particles (“anything”, often denoted as X) emerging. This type of process, e.g. \\mu^- p \\to \\mu^- K^- X , is typical for inclusive measurements, where only one or a subset of final-state particles (here, the K^- ) is detected and the rest summed over. Such processes are used to probe the internal structure of particles like the proton—specifically, to gain information about the strange quark content (sea quarks) inside the proton through virtual photon exchange. This approach contrasts with exclusive processes, where all final-state particles are reconstructed in detail to study specific resonances or reaction mechanisms.\n\n\n\n\n\n\n\n\n\nExample: Probing Proton Strangeness An inclusive process like \\mu^- p \\to \\mu^- K^+ X (studied at COMPASS) allows us to probe the strange quark content (“sea quarks”) inside the proton via the exchanged virtual photon.\n\n\n\nFor now, let’s focus on the kinematics of exclusive reactions. I will introduce two important kinematic frames used for these studies.\nIn particle physics, we deal with four-vectors. While physics is frame-independent, practical calculations are easier in specific frames. Quantities like angle or energy must always be specified with respect to a chosen frame.\n\n1.1 Center-of-Momentum (CM) Frame\nIn this frame, the three-momenta of the initial particles sum to zero. They are back-to-back. For a reaction like \\gamma p \\to p \\pi^+ \\pi^- , we can group the two pions as a system.\n\n\n\n\n\n\nFigure 5: This figure illustrates the kinematics of an exclusive reaction—specifically, the process \\gamma p \\to p \\, (\\pi\\pi) —in the center-of-momentum (CM) frame. The incoming photon ( \\gamma ) and proton ( p ) collide, resulting in an outgoing recoil proton and a dipion system (\\pi\\pi) . The two outgoing particles, the recoil proton and the dipion system, are emitted back-to-back, with their momenta constrained to lie within a single plane, labeled here as the reaction plane. This diagram is a typical representation used to discuss production kinematics for reactions studied in fixed-target experiments, emphasizing the conservation of momentum and the definition of planes crucial for analyzing angular distributions and resonance decays.\n\n\n\nKey Invariant: Mandelstam s  The total center-of-mass energy squared is the fundamental Lorentz invariant: s = (p_{\\text{beam}} + p_{\\text{target}})^2\nEnergies and Momenta in the CM Frame The energy of a particle (e.g., the beam) in the CM frame is: E_{\\text{beam}}^* = \\frac{s + m_{\\text{beam}}^2 - m_{\\text{target}}^2}{2\\sqrt{s}}\nThe magnitude of its three-momentum is found using the Källén function \\lambda(x,y,z) = x^2 + y^2 + z^2 - 2xy - 2xz - 2yz : |\\vec{p}^{\\,*}| = \\sqrt{(E_{\\text{beam}}^*)^2 - m_{\\text{beam}}^2} = \\frac{\\sqrt{\\lambda(s, m_{\\text{beam}}^2, m_{\\text{target}}^2)}}{2\\sqrt{s}}\nThis “breakup momentum” formula is symmetric. For the final state, treating the dipion system as a resonance with mass m_{\\pi\\pi} , the momentum of the recoil proton in the CM frame is: |\\vec{p}_{p}^{\\,*}| = \\frac{\\sqrt{\\lambda(s, m_{p}^2, m_{\\pi\\pi}^2)}}{2\\sqrt{s}}\n\n\n\n\n\n\nWhy can we treat two pions as one particle? Kinematically, we use four-momentum conservation: p_{\\text{beam}} + p_{\\text{target}} = p_{\\text{recoil}} + p_{\\pi^+} + p_{\\pi^-}\nWe define the composite four-momentum p_{\\pi\\pi} = p_{\\pi^+} + p_{\\pi^-} . This allows us to analyze the reaction \\gamma p \\to p \\, (\\pi\\pi) as a quasi-two-body process initially, before studying the decay of the (\\pi\\pi) system.\n\n\n\n\n\n1.2 Gottfried-Jackson (GJ) Frame\nTo analyze the decay of the resonance (e.g., the \\pi\\pi system), we go to its rest frame.\n\n\n\n\n\n\nFigure 6: This figure illustrates the kinematic configuration in the Gottfried-Jackson (GJ) frame, which is the rest frame of a resonance decaying to two pions, such as \\pi^+\\pi^- . In this frame, the sum of the momenta of the \\pi^+ and the \\pi^- is zero, so they are emitted back-to-back. The z-axis is typically aligned along the direction of the incident beam in the overall center-of-mass frame, while the recoiling proton’s direction (not shown) defines a production plane together with the beam. The figure also shows the transverse component ( p_T ) and longitudinal component ( p_r ) of the pion momenta with respect to the beam direction. This setup is essential for studying angular distributions of the decay products, which help determine properties like the spin of the intermediate resonance. The GJ frame provides a clear separation between the production plane and the decay plane, allowing a precise analysis of the angular correlations characterizing different partial waves (e.g., S-wave, P-wave, D-wave) and resonance structures in hadron spectroscopy.\n\n\n\nThis is the Gottfried-Jackson frame.\n\n\n\n\n\n\nFigure 7: This figure represents the kinematics of a two-body decay or production process in the center-of-momentum (CM) frame or a relevant rest frame, such as the Gottfried-Jackson (GJ) frame discussed in the lecture. The axes correspond to the components of momentum: the z -axis is chosen as the reference direction, typically aligned with the beam axis or a production direction. The p_1 and p_2 vectors represent the momenta of the two outgoing particles produced back-to-back due to momentum conservation. The angle \\theta specifies the orientation of particle 1’s momentum ( p_1 ) with respect to the z -axis. This angle, often called the “decay angle,” is the primary free variable describing the decay kinematics in two-body phase space. Measuring the distribution of \\theta in this frame allows one to extract information about the spin of the intermediate resonance, the angular momentum involved in the decay, and other dynamical properties. This setup is crucial in the analysis of exclusive reactions and is used in calculations of phase space and matrix element dynamics as described in the lecture.\n\n\n\n\n\n\n\n\n\nFigure 8: This figure illustrates the concept of a particle at rest, characterized by a three-momentum \\vec{p} = \\vec{0} in its rest frame. The diagram visually represents the rest frame setup, where the spatial component of the four-momentum vanishes, and only the mass m remains as the energy component. In such a frame, the particle’s momentum vector lies at the origin, emphasizing that its velocity is zero in this particular reference frame. This scenario is especially relevant when constructing kinematic frames such as the center-of-momentum or the rest frame (e.g., the Gottfried-Jackson frame for a resonance), where total momentum is set to zero by an appropriate Lorentz boost. The configuration shown is foundational for further analysis of decays: all outgoing momenta from a decay must sum to zero in the parent’s rest frame, and the mass m can be directly associated with the system’s invariant mass. The lower right vector labeled m' hints at a different particle or system with different mass, underscoring that the same rest-frame logic applies for any particle or composite object. In summary, the physical meaning is the depiction of the rest frame of a particle—where the sum of its spatial momenta vanishes and the energy is simply the mass—serving as the starting point for analyzing more complex reactions and decays in particle physics.\n\n\n\n\n\n\n\n\n\nFigure 9: This figure illustrates the transformation of kinematic frames in the analysis of an exclusive reaction, specifically for the process \\gamma p \\to p' S^0 . Here, a photon ( \\gamma ) and a proton ( p ) collide to produce a scattered proton ( p' ) and a neutral resonance particle ( S^0 ). - Top left: The initial configuration is shown in the center-of-mass (CM) frame, where the proton and photon collide, producing p' and S^0 . The angle \\theta_S is defined between the incoming photon and the outgoing resonance S^0 in this frame. - Top right: A rotation is applied so that the z-axis aligns conveniently (typically with respect to the beam or outgoing direction) for the subsequent boost. - Bottom right: A boost along the momentum direction of S^0 takes the system into the helicity frame—the rest frame of the S^0 resonance. In this frame, the decay of S^0 can be analyzed by studying the angular distributions with respect to the new z-axis. Physically, this sequence of transformations allows us to transition from the overall production dynamics (in the CM frame) to the detailed study of the decay of a specific resonance ( S^0 ) in its rest frame (the helicity frame). This is crucial for constructing kinematic variables (like invariant masses and angular distributions) that reveal the quantum numbers and resonance structure of the produced particles, and it matches the methodology described in the lecture for analyzing decays using different reference frames such as the Gottfried-Jackson frame or the helicity frame.\n\n\n\n\n\n\n\n\n\nFigure 10: This figure illustrates the kinematic setup for the decay of a neutral resonance (for example, a \\rho^0 meson) into two pions, \\rho^0 \\to \\pi^+ \\pi^- . The diagram is drawn in the rest frame of the decaying resonance, also called the Gottfried-Jackson (GJ) frame. In this frame, the \\pi^+ and \\pi^- are produced back-to-back, and their total three-momentum vanishes. The axes (x_H, y_H, z_H) represent the coordinate system in the GJ frame. The momentum of the emitted \\pi^+ , denoted as \\vec{p}_{\\pi^+} , is shown as a vector leaving the origin. Its direction is specified by the angles \\theta_H (polar angle) and \\varphi_H (azimuthal angle), which fully determine the orientation of the decay plane of the pions relative to the chosen axis. These angular variables ( \\theta_H, \\varphi_H ) are essential observables for studying the decay dynamics and the spin-parity structure of the resonance. In hadron spectroscopy, analyzing the angular distribution of decay products in this frame reveals information about the underlying production mechanism and the quantum numbers (such as spin) of the parent particle. In summary, this figure provides a schematic representation of kinematics in two-body decay, specifying how the pion momenta are analyzed in the resonance rest frame to extract physical observables relevant for hadron spectroscopy.\n\n\n\n\nIn this frame, \\vec{p}_{\\pi^+}^{\\,GJ} + \\vec{p}_{\\pi^-}^{\\,GJ} = 0 . The pions are back-to-back.\nThe momentum of each pion in this frame is: |\\vec{p}_{\\pi}^{\\,GJ}| = \\frac{\\sqrt{\\lambda(m_{\\pi\\pi}^2, m_{\\pi^+}^2, m_{\\pi^-}^2)}}{2 m_{\\pi\\pi}}\nThis frame is defined with specific alignments (often with the beam direction along the z-axis) and is crucial for studying the angular distributions of decay products, which reveal the spin of the resonance.\n\n\n\n\n\n\n\nFigure 11: This figure illustrates the standard procedure to obtain the four-momentum of a particle with arbitrary direction in a chosen kinematic frame, using Lorentz transformations. First, you start in the rest frame (top), where the particle has zero three-momentum ( \\vec{p}=0 ). 1. The first step is to apply a Lorentz boost along the z -axis, giving the particle a momentum \\vec{p}_z in that direction. This constructs the state |\\vec{p}_z\\rangle = B_z |\\vec{0}\\rangle , where B_z is the boost operator. 2. The second step is to rotate the momentum vector from the z -axis to an arbitrary direction, specified by the polar and azimuthal angles (\\theta, \\phi) in spherical coordinates. This completes the assignment of the particle’s momentum direction in three-dimensional space. In the context of this lecture, this is the physical process used to construct event kinematics in simulations and calculations: boosting and rotating reference frames to describe particle momenta in the center-of-mass (CM) or Gottfried-Jackson (GJ) frame. This establishes the kinematic configurations necessary for calculating distributions, phase space, and for analyzing decay products’ angular distributions, which are fundamental in hadron spectroscopy. The process shown here underlies how to generate or interpret the full range of physically allowed configurations for multi-particle reactions.\n\n\n\nThe GJ frame is reached from the CM frame by boosting along the momentum of the (\\pi\\pi) system and then rotating. In this frame, we can clearly see the decay plane of the pions relative to the production plane defined by the beam and recoil proton."
  },
  {
    "objectID": "2025-Lecture-05.html#rest-frame-of-the-pion-pair",
    "href": "2025-Lecture-05.html#rest-frame-of-the-pion-pair",
    "title": "(2025) Lecture 5",
    "section": "2 Rest Frame of the Pion Pair",
    "text": "2 Rest Frame of the Pion Pair\nAbsolutely. It is the same trick I applied earlier, and now it can work for this pion pair.\nWe know that in the Gottfried-Jackson (GJ) frame—which is the center-of-momentum or rest frame of the \\pi^+ \\pi^- system—the sum of their four-momenta results in a four-vector with zero spatial components. Therefore, the total four-momentum is simply (m_{\\pi\\pi}, \\mathbf{0}) , where m_{\\pi\\pi} is the invariant mass of the two-pion system.\nThus, we can apply this trick. For completeness, let’s write it explicitly:\np_{\\pi^+}^{\\text{(GJ)}} + p_{\\pi^-}^{\\text{(GJ)}} = (m_{\\pi\\pi}, \\mathbf{0})\n\n\n\n\n\n\nThe invariant mass m_{\\pi\\pi} is a Lorentz scalar, meaning it has the same value in all reference frames. It is calculated from the four-vector dot product: m_{\\pi\\pi}^2 = (p_{\\pi^+} + p_{\\pi^-})^2\nIn the Gottfried-Jackson frame, this simplifies because the total three-momentum is zero, so m_{\\pi\\pi} is just the total energy of the system in that frame. This property is crucial for identifying resonances (like the \\rho^0 meson) in particle physics, as they appear as peaks in the m_{\\pi\\pi} distribution.\n\n\n\nKey points to remember:\n\nThe “trick” is boosting to the frame where the total three-momentum of the system vanishes.\nIn that frame, the total four-momentum has only a time component, which is the invariant mass.\nThis invariant mass m_{\\pi\\pi} = \\sqrt{(p_{\\pi^+} + p_{\\pi^-})^2} is the quantity used to reconstruct resonance masses."
  },
  {
    "objectID": "2025-Lecture-05.html#collider-experiments-and-particle-decay-dynamics",
    "href": "2025-Lecture-05.html#collider-experiments-and-particle-decay-dynamics",
    "title": "(2025) Lecture 5",
    "section": "3 Collider Experiments and Particle Decay Dynamics",
    "text": "3 Collider Experiments and Particle Decay Dynamics\nI will probably try to add a few more exercises on kinematics because that’s something worth practicing—how you get these particular expressions—and it’s all over the place. It’s a very important skill to be able to operate with four-vectors.\nBut we continue with discussing another type or class of experiments, particularly collider experiments. There are a few collider experiments in the world, and depending on the colliding particles, you have different physics.\n\nThere’s been a time where antiproton beams were collided at Fermilab.\nNow the biggest running machine is the LHC (Large Hadron Collider), where two protons are collided with each other. Hadron spectroscopy and hadrons are particularly studied by essentially all four LHC experiments. The most dedicated experiment to study strong interactions is LHCb.\nThen we have electron-positron machines. Currently running are BESIII and Belle II.\n\nTwo important words to introduce from production data are production and decays.\n\nWhen we talk about certain reactions, we can discuss the hadrons produced directly from the colliding beams. In that case, we would call it prompt production, promptly from the primary vertex.\nThe other mechanism is when you produce a long-lived particle that flies away from the primary vertex and then decays. Studying this system is what we refer to as studying decays.\n\nOne thing you can always have in mind is that the strong interaction is called strong because it makes cross sections large and processes happen very quickly. While the weak interaction is called weak because it has a smaller cross section. If a particle does not decay strongly, but rather decays weakly, it’s going to have a very small width, which corresponds to a very large lifetime.\nIf you think of the different particles with heavy flavor—like the B meson, D meson, Sigma_b baryon, Lambda_b baryon, Omega_b baryon, Omega_c baryon—their ground states always decay weakly. This is because the strong interaction doesn’t change flavor. There is no way you can decay these particles without changing the color or flavor. Once a particle decays weakly, its lifetime is large. This means once it’s produced, it manages to fly away from the primary vertex before decaying. That’s what I try to sketch here. You collide two protons. From this collision, a B^0 meson is produced, which then decays at a delayed vertex to, say, three pions.\n\n\n\n\n\n\nFigure 12: This figure illustrates the delayed (secondary) vertex topology commonly observed in collider experiments when studying weak decays of heavy flavor hadrons. Two protons (“p p”) collide at the primary vertex, producing, among other particles, a neutral B^0 meson. The B^0 travels some distance away from the primary vertex before decaying. The secondary (delayed) vertex is where the B^0 decays into three pions ( \\pi^+ , \\pi^- , \\pi^- ). This separation between vertices is a hallmark of weak decays: the B^0 ’s relatively long lifetime (compared to strong decays) allows it to move a measurable distance before decaying. The delayed production products (the three pions) can be tracked in the detector, allowing reconstruction of the displaced decay vertex and the identification of long-lived particles like B^0 . This is essential for flavor physics analyses and is used to distinguish signal events from promptly produced background.\n\n\n\nThis is an example of delayed production.\nInterestingly, despite the b quark being much heavier than the charm quark, the lifetime that B hadrons have is larger than that of charm hadrons.\nIn QCD, for energies around 70 GeV, the momentum of the B is a few hundred GeV. It manages to fly a distance of roughly 20 millimeters before decaying. For charm hadrons, this distance is smaller, about 5 millimeters.\n\n\n\n\n\n\nWhy do decay distances vary? The quoted distance (e.g., 2 cm) is an average. The actual distance a specific particle flies depends on its momentum. In relativistic physics, the observed lifetime in the lab frame is stretched by the Lorentz factor, \\gamma .\n\nIn the rest frame, a B meson has a lifetime \\tau \\approx 10^{-9} seconds.\nIn the lab frame, if the B meson has an energy of 400 GeV and a mass of 4 GeV, then \\gamma = E/m = 100 .\nThe average decay length in the lab is L \\approx \\gamma c \\tau (since \\beta \\approx 1 ). This calculation gives distances on the order of centimeters.\n\n\n\n\n\n\n\n\n\n\nFigure 13: This diagram represents the exponential decay law for unstable particles, central to the discussion of decay processes in particle physics experiments. The vertical axis shows the decay rate, \\frac{dN}{dt} , which is the number of particles decaying per unit time, while the horizontal axis indicates time t in the rest frame of the particle (labeled t_{\\text{rf}} ). The curve demonstrates that the probability for a particle to decay is constant in time, yielding an exponential decrease in the number of undecayed particles. The mathematical expression e^{-t/\\tau_{\\text{rf}}} captures this behavior, where \\tau_{\\text{rf}} is the characteristic lifetime of the particle in its rest frame. This fundamental distribution underlies the observation that decay vertices are randomly spread in distance (because flight length is tied to this distribution via relativistic time dilation), and gives the mean decay length discussed in the lecture. It emphasizes that, even though the mean lifetime \\tau is quoted (e.g., in the PDG), individual decays occur randomly and stochastically according to this law.\n\n\n\nBut this is not the full story. The lifetime \\tau you find in the Particle Data Group (PDG) review is the characteristic time of a distribution. What is that distribution? It’s the same as in nuclear physics: an exponential decay law.\nThe number of undecayed particles N at time t follows: N(t) = N_0 e^{-t/\\tau}\nThis arises because, at every moment, the probability for a given particle to decay is constant. We observe the same exponential behavior in particle physics for the B , D , or any unstable particle—it’s a fundamental quantum property.\nTherefore, when we say a B meson flies about 2 cm, this is really the mean of a convoluted distribution. There is a distribution of production momenta (and thus \\gamma factors) from collision to collision, and each individual B meson decays at a random time drawn from the exponential distribution.\nSo, we’ve discussed the B meson. How do you actually observe such events in an experiment? You don’t measure the decaying particle directly. The only way to observe them is by tracking the final state particles.\nYou get a track for each of the pions. You trace them back—they are straight lines without a magnetic field, or curved lines if a magnetic field is present. You then realize these tracks do not point back to the primary vertex where the protons collided. They appear to come from a common point that is displaced from the primary vertex. This is how you reconstruct a secondary decay vertex.\nFor every track, we define the closest distance to the primary vertex, called the Impact Parameter (IP). To account for measurement precision, we use the Impact Parameter Significance: \\text{IP} \\chi^2 = \\left( \\frac{d}{\\sigma_d} \\right)^2\nHere, d is the closest distance, and \\sigma_d is its uncertainty. A large IP \\chi^2 indicates the track is inconsistent with originating from the primary vertex. Analysts use this variable to select events containing displaced decays, like those from B mesons or \\Lambda baryons.\n\n\n\n\n\n\nThe Power of the Boost The measurable flight distance is entirely due to relativistic time dilation. (see Figure 12) A \\Lambda baryon, with a similar rest-frame lifetime to a B meson but often produced with a much higher \\gamma at the LHC, can fly meters—sometimes up to 5 meters—from the primary vertex. This makes its decay vertex easily distinguishable."
  },
  {
    "objectID": "2025-Lecture-05.html#peak-background-and-misidentification-in-three-pion-invariant-mass-spectra",
    "href": "2025-Lecture-05.html#peak-background-and-misidentification-in-three-pion-invariant-mass-spectra",
    "title": "(2025) Lecture 5",
    "section": "4 Peak, Background, and Misidentification in Three-Pion Invariant Mass Spectra",
    "text": "4 Peak, Background, and Misidentification in Three-Pion Invariant Mass Spectra\nA typical observation would be the following. An experiment is performed a million times. The million records are processed and events are selected where there are three particles with a large impact parameter and they must come from the same vertex. The impact parameter with respect to the primary vertex is large, while with respect to the secondary vertex it is small.\nThree particles are forced to come from the same secondary vertex and the invariant mass of the particles is computed. This mass M is defined as M = \\sqrt{(p_1 + p_2 + p_3)^2} , where the four-vectors p_i of the particles are measured in the experiment. Then a square root is taken to get the mass of the three particles and a spectrum is observed that peaks around M_{B^-} .\n\n\n\n\n\n\nFigure 14: This figure illustrates a typical invariant mass spectrum ( \\frac{dN}{dm_{3\\pi}} versus m_{\\pi^+\\pi^-\\pi^-} ) for three-pion final states in a particle physics experiment searching for B^- meson decays. The plot demonstrates three key physical features from hadron spectroscopy production experiments: 1. Resonance Peak: There is a prominent peak at the invariant mass m_{B^-} , labeled as such. This peak corresponds to true B^-\\to\\pi^+\\pi^-\\pi^- decays; due to energy-momentum conservation, the invariant mass of the three final-state pions reconstructs the original B^- mass. In an ideal experiment with perfect resolution, this peak would be a delta function. Realistically, detector resolution broadens it into a Gaussian shape. 2. Combinatorial Background: There is a nearly flat (green dashed) background beneath the peak, representing combinatorial background. This arises from random combinations of tracks (pions) that do not originate from a genuine B^- decay, but nonetheless satisfy the selection criteria. They create a smooth distribution across the mass spectrum. 3. Misidentification Peaks: Another peak is indicated, arising from B^-\\to K^-\\pi^+\\pi^- decays, where the kaon has been misidentified as a pion. Since tracking alone cannot distinguish between pions and kaons (without additional particle identification detectors), the wrong mass hypothesis for one of the tracks leads to a shifted peak in the reconstructed invariant mass distribution. Overall, this figure encapsulates how resonance signals (true decays) are observed as mass peaks, how backgrounds and misidentified decays complicate the spectra, and highlights the fundamental role of invariant mass calculations—here, m_{3\\pi} = \\sqrt{(p_{\\pi^+} + p_{\\pi^-} + p_{\\pi^-})^2} —in experimental hadron spectroscopy. It also underlines the necessity for additional information, such as particle identification, to distinguish between decay channels with similar track signatures.\n\n\n\nI would like to discuss three features of the spectrum that are always present.\n\nThe first is the peaking in the spectrum. The spectrum looks like the number of counts for the lower mass of three pions is small. Suddenly it rises and then again the distribution has the bell shape with a certain width. Most of the events are gathered around this value.\nThe second feature is the presence of background. This peak is sitting on a sort of constant, barely moving floor, which we call the combinatorial background.\nThe third feature is that sometimes you have more peaks that would be associated with misidentifying particles.\n\nLet’s discuss one by one quickly why the peak appears in the spectrum and what impacts its position and shape.\nIf the process is the signal process—a B meson flying and decaying to three pions—the mass of the three pions will be exactly that of the B . Once we combine the three four-vectors, their invariant mass is equal to the mass of the beam particle.\n\n\n\n\n\n\nIn the ideal, theoretical case with no experimental uncertainties, the invariant mass spectrum would be a delta function at the true parent particle mass M_B , representing exact energy-momentum conservation: \\frac{dN}{dM} = N_0 \\, \\delta(M - M_B)\n\n\n\nIn the experimental situation, we don’t observe delta functions; we observe a Gaussian curve. The reason for this spreading is measurement uncertainty. (see Figure 14) All tracks come with a certain precision from the hit positions and tracking.\n\n\n\n\n\n\nDue to finite detector resolution, the ideal delta function is smeared into a Gaussian distribution. The observed peak is described by: \\frac{dN}{dM} = \\frac{N_0}{\\sqrt{2\\pi}\\sigma} \\exp\\left[-\\frac{(M - M_B)^2}{2\\sigma^2}\\right]\nwhere \\sigma represents the experimental mass resolution.\n\n\n\nThis shape is very close to a Gaussian. For all particles that decay weakly, like the B meson with a lifetime of \\sim 10^{-9} seconds, the natural decay width (on the order of eV) is completely negligible compared to the GeV-scale experimental resolution. The resonance peak we see is therefore dominated by the resolution of the experiment.\nThe second item is combinatorial background. This refers to the random associations of pions that pass the selection criteria. When you collide two protons at high energy (e.g., 7 TeV), many particles are produced.\n\nWhat is the average number of charged particles produced in one collision? The right answer is a few hundred to a few thousand.\nThere is a significant chance that tracks originating from the primary vertex get combined and pass the impact parameter criteria simply due to measurement uncertainties.\nThe combinatorics are huge. In an event with a thousand tracks, if you have 300 \\pi^+ and 200 \\pi^- , the number of possible triple combinations is enormous. All these random combinations produce a roughly flat background under the mass distribution.\n\nThe last feature is particle misidentification (mis-ID). This is crucial for all experiments. When we track charged particles, we measure their momentum from the track curvature in a magnetic field. However, we do not directly measure the particle’s mass.\n\nTo compute the particle’s energy and complete its four-vector, we must assume a mass (e.g., assume it’s a pion).\nWithout extra information from particle identification detectors, all charged tracks look similar. We cannot distinguish pions, kaons, or protons from tracking alone.\nIf we make the wrong mass assumption, we compute the wrong energy. For example, consider a real event where a B decays to K^- \\pi^+ \\pi^- . If we misidentify the kaon as a pion, we use the smaller pion mass to compute its energy. (see Figure 14) This leads to an incorrect calculation of the invariant mass for that combination, creating a shifted peak or background elsewhere in the spectrum.\n\n\n\n\n\n\n\nThis misidentification background is why experiments must have good particle identification systems, such as Ring Imaging Cherenkov (RICH) detectors or Time-of-Flight (ToF) systems, to suppress these errors."
  },
  {
    "objectID": "2025-Lecture-05.html#phase-space-factorization-and-the-dalitz-plot",
    "href": "2025-Lecture-05.html#phase-space-factorization-and-the-dalitz-plot",
    "title": "(2025) Lecture 5",
    "section": "5 Phase Space Factorization and the Dalitz Plot",
    "text": "5 Phase Space Factorization and the Dalitz Plot\nWhen we do experiments, it’s always important to simulate and see what we expect, to simulate different reactions. For this, we have exactly the same setup as we have in the experiment. But in the modeling, there are computer programs that simulate particle collisions, simulate all possible decays, all possible processes that happen, and simulate their movement through a detector.\nIt’s very important to know the cross section of different processes. But what’s also important is to know the available configuration space for different particles. That’s driven by the phase space, the available phase space of possible configurations.\n\n5.1 The N-Body Phase Space Formula\nFor the N -particle phase space, the differential element is given by:\nd\\phi_n = \\prod_{i=1}^n \\frac{d^3 p_i}{(2\\pi)^3 2 E_i} (2\\pi)^4 \\delta^4(p_0 - \\sum p_i)\nThis expression has 3N - 4 independent integrals. It reflects the fact that for N particles, we have the on-shell mass constraints and overall four-momentum conservation.\n\n\n5.2 Two-Body Phase Space\nThe expression for the two-body phase space is more direct. For two particles, you start with eight integrals (three momentum components for each particle). You subtract two from the mass-shell constraint for each particle and four from the momentum conservation delta function. What remains are two differentials.\nThis can be arranged so that you only integrate over angles. Essentially, that’s the only freedom you have: the direction orientation, because in the center-of-mass frame, particle one and particle two go back-to-back. The space of configurations in that case is simply 4\\pi non-relativistically, with a relativistic correction factor.\nThe final, Lorentz-invariant form is:\nd\\phi_2 = \\frac{1}{8\\pi} \\frac{2p^*}{\\sqrt{s}} d\\cos\\theta \\frac{d\\varphi}{2\\pi}\nHere, p^* is the magnitude of the momentum for each particle in the center-of-mass frame, and \\sqrt{s} is the total center-of-mass energy.\n\n\n\n\n\n\nPhysics Meaning: This formula represents the simplified phase space for a decay into two particles. The factor \\frac{1}{8\\pi} arises from integrating over the delta functions, and \\frac{2|\\mathbf{p}|}{\\sqrt{s}} is the relativistic kinematic factor. The only free variables are the angular orientation (\\theta, \\phi) .\n\n\n\n\n\n5.3 Three-Body Phase Space and Factorization\nFor the three-body case, it’s more involved: d\\phi_3(1, 2, 3) . It’s a Lorentz-invariant expression we can evaluate in any frame.\nA powerful trick is to rewrite the three-body phase space using a two-body topology. We can factorize it by considering the decay as happening in two steps:\n\nThe initial particle decays into a composite system (1,2) and particle 3.\nThe composite system (1,2) then decays into particles 1 and 2.\n\nThis is done by introducing the invariant mass squared of the (1,2) pair, m_{12}^2 , as an integration variable.\nThe claim is that the full three-body phase space can be written as:\nd\\phi_3 = d\\phi_2(0 \\to (1,2), 3) \\times d\\phi_2((1,2) \\to 1,2) \\times \\frac{d m_{12}^2}{2\\pi}\nThis is intuitive: you split your phase space into a sequential pair of two-body decays. This is a general method to reduce an N -body phase space to combinations of lower-body phase spaces.\nSubstituting the explicit form for the two-body phase spaces, we get:\nd\\phi_3 = \\frac{1}{8\\pi} \\frac{2 p_3^*}{\\sqrt{s}} \\frac{d\\Omega_{12,3}}{4\\pi} \\times \\frac{1}{8\\pi} \\frac{2 k_{1,2}}{m_{12}} \\frac{d\\Omega_{1,2}}{4\\pi} \\times \\frac{d m_{12}^2}{2\\pi}\nHere, p_3^* is the momentum of particle 3 in the rest frame of the initial particle, and k_{1,2} is the momentum of particle 1 (or 2) in the rest frame of the (1,2) system.\n\n\n5.4 From Angles to Invariant Masses: The Dalitz Plot\nThe final step is to trade the angular variable, specifically \\cos\\theta_{1,2} from the decay of the (1,2) system, for another invariant mass squared, like m_{23}^2 = (p_2 + p_3)^2 .\nThe relation is linear: m_{23}^2 = m_2^2 + m_3^2 + \\frac{1}{2 m_{12}^2} (m_{12}^2 + m_2^2 - m_1^2)(-m_{12}^2 + s - m_3^2) - \\frac{1}{2 m_{12}} \\lambda_{12}^{1/2} \\lambda_{30}^{1/2} \\cos \\theta_{1,2}\nwhere \\lambda_{12} = \\lambda(m_{12}^2, m_1^2, m_2^2) and \\lambda_{30} = \\lambda(s, m_{12}^2, m_3^2) .\nThis allows us to replace the integration over d\\cos\\theta_{1,2} with an integration over dm_{23}^2 .\n\n\n\n\n\n\nFigure 15: This figure represents a Dalitz plot, a fundamental tool for analyzing the kinematics of three-body decays in particle physics. The plot uses invariant mass squared variables— m_{12}^2 on the horizontal axis and m_{23}^2 on the vertical axis—to represent all possible configurations of final-state particle momenta. Each physically allowed set of momenta for the three particles corresponds to a single point within the bounded region (the “circle”) shown in the plot, which is defined by the constraints of energy-momentum conservation and the masses of the particles (the phase space boundaries determined by the Kibble function). The text annotates that every possible configuration is mapped inside this region, meaning the entire phase space is represented within the plot. At the bottom, the differential decay rate formula d\\Gamma = \\frac{1}{2\\sqrt{s}}|\\mathcal{M}|^2 d\\phi is shown, emphasizing that the observed distribution in the Dalitz plot is shaped by both the available phase space ( d\\phi ) and the dynamics of the decay process ( |\\mathcal{M}|^2 ). For pure phase space (i.e., no dynamical structure), the density of events would be uniform across the allowed region. Any non-uniformity reflects physical processes, such as resonances or interaction dynamics among the decay products.\n\n\n\n\n\n\n\n\n\nFigure 16: This figure illustrates the angular distribution of decay products, specifically showing how the differential decay rate \\frac{d\\Gamma}{d\\cos\\theta} depends on the angle \\theta for a particle decay process (such as a \\Lambda baryon). The top plot shows a flat, uniform distribution in \\cos\\theta , which is expected “in case of no \\Lambda polarisation”—that is, when the decaying particle is completely unpolarized, the decay is isotropic and all directions are equally likely, matching the prediction of phase space for an unpolarized system. The bottom plot shows a linear, asymmetric distribution, which is labeled as “observed: backward-forward-asymmetry.” This means that in real data, an asymmetry is measured indicating a preference in the decay direction (either forward or backward along an axis such as the parent momentum or beam direction). This asymmetry is a physical effect, revealing information about polarization, parity violation, or possible new physics in the production or decay process. The use of the variable \\cos\\theta connects this directly to the kinematics and angular distributions discussed in the lecture, and measuring such asymmetries is a key tool for characterizing particle properties in hadron spectroscopy experiments.\n\n\n\nWhat we obtain is that the three-body phase space can be expressed purely in terms of two invariant mass squares, for example m_{12}^2 and m_{23}^2 :\n\\frac{d\\phi_3}{d m_{12}^2 d m_{23}^2} \\text{ is flat (uniform)}\n\n\n\n\n\n\nFigure 17: This figure illustrates the physical interpretation of a Dalitz plot and its projections in the context of three-body decays, as discussed in the lecture. The leftmost plot is a schematic Dalitz plot: a two-dimensional plot where each event in a three-body final state is represented by a point with coordinates given by two invariant mass squares, m_{12}^2 and m_{23}^2 . The kinematically allowed region is typically a solid shape (here represented as a circle or oval), defined by the boundaries of energy-momentum conservation and visualized using the Kibble function. The lines labeled “1” and “2” depict paths or loci within this physical region where substructures may occur, for example, if two of the final-state particles resonate to form an intermediate particle (resonance). “Look at m_{ij} on the axes” is a prompt to consider projections onto the axes—i.e., the invariant mass squared distributions for different particle pairs. The subsequent small plots to the right show the projected invariant mass squared spectra ( d\\Gamma/dm_{12}^2 , d\\Gamma/dm_{23}^2 , d\\Gamma/dm_{13}^2 ): these are the one-dimensional distributions obtained by integrating over the Dalitz plot along one variable. Each projection picks out how often particular mass combinations occur. Peaks in these distributions correspond to resonant substructures or enhancements in the decay rate for specific two-body combinations. The text “if the Dalitz plot had diagonal lines there would be peaks for 3” emphasizes that if correlations along diagonals existed (e.g., due to a third resonance in the third pair), they would manifest as peaks in the respective projection. Overall, this figure visually conveys how the Dalitz plot encodes all three-body decay kinematics and how physical resonances or substructures of the matrix element |\\mathcal{M}|^2 manifest as features (such as peaks) in the projections of the invariant mass distributions. This framework is fundamental for analyzing and interpreting exclusive three-body decays in hadron spectroscopy.\n\n\n\n\n\n\n\n\n\nFigure 18: This figure illustrates the Dalitz plot for a three-body decay of an unknown particle x into a proton ( p ), a kaon ( K^- ), and a pion ( \\pi^+ ), specifically x \\to p K^- \\pi^+ . The Dalitz plot represents each event as a point in the space defined by the squared invariant masses m^2(pK^-) (horizontal axis) and m^2(K^- \\pi^+) (vertical axis). The physical meaning of the plot comes from how regions in this space correspond to different kinematic configurations of the decay products: - The allowed kinematic region is bounded by curves representing the minimum and maximum possible values for these invariant masses, determined by the masses of the initial and final particles (as shown by the various labeled bounds such as (m_p + m_{K^-})^2 , (m_K + m_{\\pi^+})^2 , (m_x - m_p)^2 , and (m_x - m_{\\pi^+})^2 ). - A horizontal band (parallel to the x-axis) indicates a resonance in the K^- \\pi^+ subsystem: this appears when two final state particles form an intermediate resonance (e.g., a K^* ), which would show up as many events clustered at a specific value of m^2(K^- \\pi^+) . - A vertical band (parallel to the y-axis) indicates a resonance in the pK^- subsystem: this denotes the presence of an intermediate resonance involving the proton and the kaon. - The distributions along the sides of the plot (represented by horizontal and vertical projections) show the invariant mass spectra of the respective pairs, with peaks corresponding to resonance masses smeared by experimental resolution and possible backgrounds. Overall, the Dalitz plot is a powerful tool in hadron spectroscopy, as it allows experimenters to identify intermediate resonances and study the dynamics of three-body decays by observing the density and structure of events within the kinematic boundaries. The uniformity or enhancement in certain regions of the plot reveal physical processes beyond pure phase space, specifically the effects of the matrix element |\\mathcal{M}|^2 and the presence of resonances.\n\n\n\nThis flatness is a key point. The differential decay width is d\\Gamma = \\frac{1}{2\\sqrt{s}} |\\mathcal{M}|^2 d\\phi . It means the phase space density itself does not depend on m_{12}^2 and m_{23}^2 ; all configurations within the kinematically allowed region are equally probable from a phase space perspective. Any suppression or enhancement comes purely from the dynamics encoded in the matrix element squared |\\mathcal{M}|^2 .\n\n\n\n\n\n\nThe Dalitz Plot: Every configuration of the three particles’ momenta can be mapped to a single point inside a two-dimensional plot defined by m_{12}^2 and m_{23}^2 . This is the Dalitz plot. It’s a powerful way to visualize how a decay proceeds, as structures in the plot directly reflect the behavior of the matrix element.\n\n\n\n\n\n5.5 The Kinematic Boundary: The Kibble Function\nThe interior of the Dalitz plot—the region where points are physically allowed—is described by the Kibble function. The condition for a point (m_{12}^2, m_{23}^2) to be inside the plot is: (see Figure 15) (see Figure 17) (see Figure 18)\n\\Phi = \\lambda( \\lambda(s, m_1^2, m_{23}^2), \\lambda(s, m_2^2, m_{13}^2), \\lambda(s, m_3^2, m_{12}^2) ) &lt; 0\nHere, \\lambda(x, y, z) = x^2 + y^2 + z^2 - 2(xy + yz + zx) is the Källén (or triangle) function.\nIn summary, for a three-body decay:\n\nThe phase space density in the Dalitz plot variables (m_{12}^2, m_{23}^2) is uniform.\nThe kinematically allowed region is defined by the Kibble function.\nAny non-uniformity in the distribution of events across the Dalitz plot is a direct signature of the dynamics in |\\mathcal{M}|^2 .\n\nThis gives us a very nice picture to analyze decays. For instance, you could be given a set of three momenta (which sum to zero) from an experiment and your task would be to compute m_{12}^2 and m_{23}^2 to place that event as a point on the Dalitz plot."
  },
  {
    "objectID": "2025-Lecture-07.html",
    "href": "2025-Lecture-07.html",
    "title": "(2025) Lecture 7",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Anna Zimmer"
  },
  {
    "objectID": "2025-Lecture-07.html#helicity-formalism-and-problem-review",
    "href": "2025-Lecture-07.html#helicity-formalism-and-problem-review",
    "title": "(2025) Lecture 7",
    "section": "1 Helicity Formalism and Problem Review",
    "text": "1 Helicity Formalism and Problem Review\nWelcome everyone. Today we have the seventh meeting on hadron physics. In today’s lecture we will expand on the previous lecture on helicity formalism. We will discuss partial wave expansion, which you have already seen in homework, and also move toward general principles discussing the Mandelstam plane and analyticity.\n\n\n\n\n\n\nFigure 1: This figure represents the expansion of the scattering amplitude \\mathcal{M} in terms of multiple contributions, illustrating both the mathematical series and the corresponding Feynman diagrams. The first term shows a direct transition from the initial ( i ) to final ( f ) state, corresponding to the simplest process, often called the “Born term.” The subsequent terms add the effects of intermediate states: the second term represents a process with a single intermediate state (“rescattering” or “loop” correction), and the third term includes two such intermediate interactions, and so on. Physically, this expansion encodes the idea that the total amplitude for a scattering process includes not only the direct transition but also all possible pathways involving one or more intermediate states, corresponding to multiple exchanges or rescatterings. This iterative structure is central to the understanding of unitarity and analyticity in quantum scattering theory, as each term contributes to the full, analytic amplitude in line with principles discussed in the lecture, such as the requirements imposed by the Lorentz group and the Mandelstam plane. The formalism shown here lays the groundwork for constructing amplitudes that respect these fundamental symmetries, providing the basis for resonance models and partial wave expansions described throughout the lecture.\n\n\n\n\n\n\n\n\n\nFigure 2: This figure is an Argand diagram illustrating the complex scattering amplitude f in partial wave analysis, key to understanding resonance behavior in hadron physics. The horizontal axis represents the real part of f , Re( f ), and the vertical axis represents the imaginary part, Im( f ). The black circle, centered at (0,\\,1/2) with radius 1/2 , reflects the unitarity condition for the scattering amplitude in a single partial wave. This means that as energy varies, the amplitude f must remain within or on this circle, encoding probability conservation. The arc \\mathcal{R} drawn in red shows how the amplitude associated with a resonance moves through the complex plane as a function of energy. As the energy sweeps through the resonance, the point representing f traces out this characteristic arc. In the context of the lecture, this geometric representation is fundamental for visualizing how resonances manifest in scattering: the circular trajectory and its tangency to the unitarity circle demonstrate crucial connections between analytic properties, unitarity, and resonance phenomenology, all of which underpin the Breit-Wigner parameterizations and the more advanced analytic models discussed.\n\n\n\n\n1.1 📝 Review of Previous Problems\nAt the beginning, as always, I invite you to look at the problems to recap the material from the previous lecture. I will give you five minutes to think about them, and then we will discuss together.\nWe will go through them in this order: Problem 1, then Problem 3, and finally Problem 2.\nProblem 1: Which interaction is responsible for the \\Lambda decay to a proton and a pion? Is isospin conserved? Is parity conserved? Is angular momentum conserved?\nProblem 3: This involves analyzing a Dalitz plot to determine which decay is occurring.\nProblem 2: This demonstrates that the rotations we discussed are part of the same SU(2) group structure as isospin rotations. The question asks: what is the 30‑degree isospin rotation about the Y axis, and how does it act on the \\Delta^+ state?\n\n\n1.2 ✅ Discussion of Problem 1\nLet’s start with the first problem. The weak interaction is responsible for the decay \\Lambda \\to p + \\pi^- .\n\n\n\n\n\n\nThe decay involves a flavor change: the \\Lambda contains a strange quark ( s ), while the final-state proton and pion contain only up ( u ) and down ( d ) quarks. In the Standard Model, flavor-changing processes are mediated exclusively by the weak interaction. For ground-state baryons, most decays are indeed weak.\n\n\n\nThe reasoning is correct: a flavor change always indicates the weak interaction. For ground state baryons, they all decay weakly—or at least, most of them do. ### 🔧 Relevant Theoretical Context\n\n\n\n\n\n\nFigure 3: This figure illustrates the basic kinematic structures for two-to-two particle scattering processes ( A + B \\to C + D ) as discussed in the lecture. At the top, it shows a generic 2 \\to 2 scattering diagram with incoming particles A and B and outgoing particles C and D . Below, it shows two specific “channel” diagrams labeled s and t : - The ** s -channel** (left diagram) corresponds to the situation where particles A and B annihilate or interact to form an intermediate state, which subsequently decays into C and D . This configuration is directly related to the Mandelstam variable s = (p_A + p_B)^2 , which represents the square of the total energy in the center-of-mass frame. - The ** t -channel** (right diagram) illustrates a different process where A exchanges a particle with B , resulting in C and D . Here the relevant Mandelstam variable is t = (p_A - p_C)^2 , representing the squared momentum transfer between the initial and final states. Physically, these diagrams represent different ways the scattering can occur, or equivalently, different regions of the Mandelstam plane. The figure emphasizes how the full amplitude for the process can receive contributions from multiple kinematic configurations, each characterized by its corresponding Mandelstam variable ( s , t , or u channels, with u not shown). These considerations are fundamental to the partial wave expansion, crossing symmetry, analyticity, and the broader analytic structure of the scattering amplitude being discussed in the lecture.\n\n\n\n\n\n\n\n\n\nFigure 4: This figure represents the Mandelstam plane, a key tool in scattering theory used to visualize and analyze the kinematics of 2 \\to 2 scattering processes. The axes correspond to two of the three Mandelstam variables (s, t, u) , which are Lorentz-invariant quantities that fully specify the kinematics. The colored regions indicate the physically allowed regions for different scattering channels: - The upper blue shaded region labeled “s-channel” corresponds to physical values where s is positive and the process describes direct 2 \\to 2 scattering. - The left blue shaded region labeled “t-channel” corresponds to kinematics where t is positive and describes exchange processes. - The right red shaded region labeled “u-channel” represents the physical region for the u channel. The lines labeled s=0 , t=0 , and u=0 denote the boundaries between different kinematic regions. The areas marked “unphysical” lie outside the regions allowed by energy-momentum conservation for real particles, but can be accessed in analytic continuations of the scattering amplitude. The central green region indicates an overlap of physical boundaries. Physically, the Mandelstam plane illustrates the domains where each scattering channel (s, t, u) is physical, a concept crucial for understanding particle processes, crossing symmetry, and the analytic properties of scattering amplitudes discussed in this lecture.\n\n\n\n\n\n\n\n\n\nFigure 5: This figure shows the physical setup of a generic 2 \\to 2 scattering process, which is a fundamental context for partial wave expansion and the use of Mandelstam variables in hadron physics. - Left Panel: This diagram represents a generic scattering process, where particles with initial 4-momenta p_1 and p_2 scatter via some interaction (potentially mediated by resonances, as in strong interaction processes) into final-state particles with 4-momenta p_1' and p_2' . The blob indicates that the interaction can be complex and model-independent. - Right Panel: This is the same process drawn in the center-of-mass frame and projected onto the scattering plane. It shows how the initial particle momenta are oriented, and how, after the collision, the outgoing particles are deflected by an angle \\theta . This angle \\theta is the scattering angle, a key variable in describing differential cross sections and in the partial wave expansion of the amplitude: f(E, \\theta) = \\frac{1}{k} \\sum_\\ell (2\\ell+1) e^{i\\delta_\\ell(E)} \\sin\\delta_\\ell(E) P_\\ell(\\cos\\theta) The scattering angle is thus fundamental in decomposing the amplitude into components of definite orbital angular momentum. This image provides the kinematic basis for introducing the Mandelstam variables ( s , t , and u ), which are Lorentz-invariant and fully characterize the process. It underpins the analysis of resonance production, angular distributions, and the formal structure of amplitudes discussed in the lecture, including their expansion in terms of Legendre polynomials as dictated by rotational symmetry.\n\n\n\n\n\n\n\n\n\nFigure 6: This figure illustrates the Mandelstam plane for the three-body decay process \\pi^-(1800) \\to \\pi^- \\pi^0 \\omega . The axes represent the squared invariant masses of two different pairs in the final state: m^2_{\\omega\\pi^-} and m^2_{\\omega\\pi^0} . The Mandelstam variables s , t , and u are labeled along corresponding directions in this plane. The hatched red regions denote the kinematical boundaries associated with each channel—these are the physically accessible regions for the respective invariant mass combinations. The diagram emphasizes how the amplitude for this process is defined over the entire Mandelstam plane but physical decay events are restricted to a particular domain (with the allowed phase space marked). Internal loops or resonant contributions, depicted by circles with arrows, indicate the presence of intermediate resonances or rescattering effects in specific channels. This setup is crucial for understanding the analytic structure of the amplitude, as discussed in the lecture, especially when considering partial wave expansions and analytic continuation across the Mandelstam variables. Such visualization is foundational for modern approaches to amplitude analysis, like the Khuri-Treiman formalism, where constraints of analyticity and crossing symmetry are imposed using the geometry of the Mandelstam plane.\n\n\n\n\n\n\n\n\n\nFigure 7: This figure illustrates the unitarity condition for the scattering amplitude in quantum field theory, specifically showing how the imaginary part of the two-to-two scattering amplitude is related to the sum over all possible on-shell intermediate states. On the left, “Im” denotes the imaginary part of the full amplitude (indicated by the blob diagram with two incoming and two outgoing legs), which is fundamentally connected to the physical processes allowed by the system’s quantum numbers and kinematics. On the right, the diagram shows this imaginary part decomposed into a product of amplitudes for all possible intermediate state contributions, where the amplitude A for the process is paired with its complex conjugate A^* , and the intermediate states are indicated by a vertical cut through the loop. This cut signifies that the particles in the loop go on-shell—a process known as “cutting” the diagram in the context of the optical theorem or Cutkosky rules. In the context of the lecture, this is a graphical representation of a unitarity relation or discontinuity equation for the scattering amplitude. It states that the imaginary part (or discontinuity across the real axis in the complex energy plane) can be expressed as a sum over products of amplitudes involving all possible intermediate states. This underpins the concept of analyticity in the Mandelstam plane: the physical amplitude is constrained by the requirement of unitarity and is analytic except for known cuts and poles corresponding to physical processes like particle production and resonances. This relation is fundamental in constructing partial wave expansions and in understanding the analytic structure of amplitudes, and serves as the starting point for more sophisticated theoretical models such as the Khuri-Treiman model, which imposes these constraints on three-body decays using dispersion relations.\n\n\n\nThe topics for today—partial wave expansion and the Mandelstam plane—are built on foundational formulas from scattering theory.\nPartial Wave Expansion expresses the scattering amplitude in terms of angular momentum eigenstates: f(E, \\theta) = \\frac{1}{k} \\sum_{\\ell=0}^{\\infty} (2\\ell + 1) e^{i\\delta_\\ell(E)} \\sin \\delta_\\ell(E) P_\\ell(\\cos \\theta)\nwhere k is the momentum, \\ell is the orbital angular momentum, \\delta_\\ell(E) is the phase shift, and P_\\ell are Legendre polynomials.\nMandelstam Variables s , t , and u are the Lorentz-invariant quantities that describe 2 \\to 2 scattering kinematics: s = (p_1 + p_2)^2, \\quad t = (p_1 - p_3)^2, \\quad u = (p_1 - p_4)^2\nwith the constraint s + t + u = m_1^2 + m_2^2 + m_3^2 + m_4^2 . These define the Mandelstam plane.\nIsospin Rotations, mentioned in Problem 2, are described by the SU(2) rotation operator: U(\\theta, \\hat{n}) = \\exp\\left(-i \\theta \\, \\hat{n} \\cdot \\vec{I}\\right)\nwhere \\vec{I} = (I_1, I_2, I_3) are the isospin generators, \\theta is the rotation angle, and \\hat{n} is the rotation axis."
  },
  {
    "objectID": "2025-Lecture-07.html#parity-angular-momentum-and-isospin-in-weak-decays",
    "href": "2025-Lecture-07.html#parity-angular-momentum-and-isospin-in-weak-decays",
    "title": "(2025) Lecture 7",
    "section": "2 Parity, Angular Momentum, and Isospin in Weak Decays",
    "text": "2 Parity, Angular Momentum, and Isospin in Weak Decays\nIs parity conserved in the decay \\Lambda^0 \\to p + \\pi^- ? I would say yes, for the strong interaction. On the left side, the proton has parity 1/2^+ and the pion has parity 0^- . How is it conserved? Due to angular momentum. You introduce orbital angular momentum L = 1 . That works. So the process can proceed as a parity-conserving process, but parity is not conserved in that decay because it also happens in S wave ( L=0 ).\nThe sensitivity to the polarization of the \\Lambda in this decay arises because there are two components: a parity-conserving and a parity-violating one. In a weak decay, parity is always broken. It doesn’t have to be 100% broken; in this case, 99% might proceed via the parity-conserving channel, but there will always be about 1% from the parity-violating part. So in weak decays, parity does not have to be conserved. In fact, it’s not; here there is a significant fraction of the L = 0 component.\n\n\n\n\n\n\nThe general rule is: In weak decays, parity is not conserved. The total parity in a decay is given by the product of the intrinsic parities and the parity from orbital angular momentum: P_{\\text{total}} = P_{\\text{initial}} = P_{\\text{final}} \\times (-1)^L\n\n\n\nIs angular momentum conserved? For hadron physics, in the course of particle physics events, angular momentum is always conserved. This is due to Lorentz group symmetry. If you don’t violate Lorentz symmetry, angular momentum is always conserved. You make it conserved by putting in the correct orbital angular momentum, but you don’t destroy the Lorentz invariance.\nIs isospin conserved? No. How do we see that it’s not conserved? Simply counting the number of light quarks is not reliable because u\\bar{u} pairs can pop up from the vacuum. It’s better to check isospin the same formal way we check for spin and parity.\n\nThe isospin of the \\Lambda^0 is 0 .\nThe isospin of the proton is 1/2 .\nThe isospin for the pion is 1 , because there are three pions of different charges in the multiplet.\n\nIsospin is related to charge partners; the multiplicity is 2I + 1 . The proton exists in two species (proton and neutron), so its isospin is 1/2 . The \\Lambda exists alone, so it is the only particle in its multiplet. For the transition \\Lambda^0 \\to p + \\pi^- , you cannot combine a vector of length 1/2 and a vector of length 1 to make 0 . Therefore, isospin is broken.\nIn fact, this is also a property of the weak interaction. Isospin is always broken in weak decays, similar to parity. It could be broken severely or just a little bit.\nAll right, let’s move to the three-body decay shown in the Dalitz plot.\n\nHow many particles are in the final state? Three.\nHow many in the initial state? One.\nTherefore, it’s a 1-to-3 decay. That’s why we represent it on a Dalitz plot.\n\nWhat is the final state? The particles are a proton ( p ), a kaon ( K^- ), and a pion ( \\pi^- ). How do you know? Because those are the three particles mentioned on the axes. On the X-axis you have the invariant mass squared of one pair, m^2(pK^-) , and on the Y-axis the other pair, m^2(K^-\\pi^-) . A Dalitz plot always shows the mass squared of one subsystem versus the mass squared of the second subsystem.\nWhat remains to figure out? We need to identify the decaying mother particle. There are a few clues:\n\nResonance bands: The Dalitz plot shows a horizontal band, which is the strongest resonance. The particle that decays into the proton and K^- is that resonance. That line projects into a peak in the m(pK^-) dimension. Similarly, vertical bands would correspond to resonances in the K^-\\pi^- system (these are K^* states).\nMass from phase space borders: The phase space is limited by the mass of the decaying particle M_0 . The borders on the plot are given by: m_{ij,\\text{min}}^2 = (m_i + m_j)^2, \\quad m_{ij,\\text{max}}^2 = (M_0 - m_k)^2\nYou can find M_0 by looking at the highest value on an axis. For example: M_0 = \\sqrt{m^2(pK^-)_{\\text{max}}} + m_\\pi\nFrom the plot, this gives a mass around 2.4 - 2.6 GeV.\nQuark content and interaction type: The final state is p\\,(uud) , K^-\\,(s\\bar{u}) , \\pi^-\\,(u\\bar{d}) . The \\bar{u}u and \\bar{d}d pairs could come from the vacuum. The net quark content is u d s u \\bar{d} . Could this be a pentaquark decaying strongly, or is it a weak decay? The presence of both parity and isospin violation points to a weak decay.\n\nPutting it together—the mass near 2.6 GeV and the weak decay into p K^- \\pi^- —identifies the mother particle as the charmed baryon \\Xi_c^+ . Its weak decay allows for the observed violation of parity and isospin, and the Dalitz plot reveals the intermediate resonant substructure ( \\Lambda^* and K^* states) in the three-body final state."
  },
  {
    "objectID": "2025-Lecture-07.html#isospin-operators-and-rotations-in-su2",
    "href": "2025-Lecture-07.html#isospin-operators-and-rotations-in-su2",
    "title": "(2025) Lecture 7",
    "section": "3 Isospin Operators and Rotations in SU(2)",
    "text": "3 Isospin Operators and Rotations in SU(2)\nQuestion 2: Isospin Operators\nWe are given isospin operators. Let’s check the statements:\n\nIs it true that \\hat{I}^2 acting on \\Delta^+ gives 15/4 ? Yes, this is true. The \\Delta baryon has total isospin I = 3/2 . The operator \\hat{I}^2 acting on an eigenstate yields I(I+1) .\n\n\nFor the \\Delta , this is \\frac{3}{2} \\times \\frac{5}{2} = \\frac{15}{4} .\n\n\nIs it true that \\hat{I}_z acting on \\Delta^+ gives 1/2 ? This is also true. The \\Delta multiplet contains four states with different projections I_3 :\n\n\n| \\frac{3}{2}, \\frac{3}{2} \\rangle\n| \\frac{3}{2}, \\frac{1}{2} \\rangle ← This is the \\Delta^+ state.\n| \\frac{3}{2}, -\\frac{1}{2} \\rangle\n| \\frac{3}{2}, -\\frac{3}{2} \\rangle\n\nThe operator \\hat{I}_z gives the projection I_3 , so acting on the \\Delta^+ state yields \\frac{1}{2} .\nApplying a Rotation in Isospin Space\nWhat happens if we apply a rotation? This connects to how states transform under SU(2). If you act with a rotation (e.g., a 30° rotation around the y-axis) on the \\Delta^+ state, you get a mixed state of different \\Delta states.\nThe transformation is governed by the Wigner D-matrices:\n\\mathcal{R}(\\theta) |J, M\\rangle = \\sum_{M'} D^J_{M',M}(\\theta) |J, M'\\rangle\nThe coefficients D^J_{M',M}(\\theta) are known functions, often found in tables alongside Clebsch-Gordan coefficients. They are trigonometric functions.\nFor example, to find the specific coefficient D^{3/2}_{3/2, 1/2}(30°) , you would consult such a table. The key point is that applying a rotation not aligned with the quantization axis produces a superposition.\n\n\n\n\n\n\nThe transformation preserves total probability. For a given initial state |J, M\\rangle , the sum of the squared magnitudes of the D-matrix coefficients is one: \\sum_{M'} |D^J_{M',M}(\\theta)|^2 = 1\nThis is the unitarity condition, ensuring probability is conserved under rotation.\n\n\n\nThis demonstrates that rotations in isospin space work identically to regular angular momentum rotations because both are governed by the group SU(2).\nSymmetry Relations for Wigner D-Matrices\nA question arose about a specific coefficient, D^{3/2}_{3/2, -3/2} , which might not be directly listed in standard tables. Such elements can be found using symmetry relations derived from the unitary nature of the rotation matrices.\nOne useful relation is:\nD^J_{-M_1,-M_2}(\\theta) = (-1)^{M_1 - M_2} D^J_{M_2,M_1}(\\theta)\nThis allows you to compute coefficients with negative indices from those with positive indices (or vice versa) by swapping the lower indices and applying a phase factor. If this approach doesn’t yield a tabulated value, another method is to use the property that for a unitary matrix, a negative sign in the arguments can be related to complex conjugation and transposition, which effectively swaps indices.\nThe core takeaway is that these various relations all stem from the unitarity of the transformation.\nTransition to Today’s Topic\nToday’s lecture will focus on the Källén calculation. We will discuss the application of the helicity formalism to scattering amplitudes.\nA major goal is to avoid confusion between general, model-independent statements and the specific approximations we will introduce to build and simplify our expressions."
  },
  {
    "objectID": "2025-Lecture-07.html#two-body-decay-matrix-elements-and-cascade-decay-construction",
    "href": "2025-Lecture-07.html#two-body-decay-matrix-elements-and-cascade-decay-construction",
    "title": "(2025) Lecture 7",
    "section": "4 Two-Body Decay Matrix Elements and Cascade Decay Construction",
    "text": "4 Two-Body Decay Matrix Elements and Cascade Decay Construction\nI would like to start with a reminder: for the two-body case we have a particle decaying into two, and in its rest frame we have the following configuration.\n\n\n\n\n\n\nFigure 8: This figure illustrates the kinematic setup for a two-body decay in the context of the helicity formalism. On the left, a Feynman-like diagram represents the decay of a parent particle (labeled “0”) into two daughter particles (labeled “1” and “2”). On the right, the physical configuration in the rest frame of the parent particle (labeled “0-rest frame”) is shown. The z-axis is chosen as the quantization axis for spin. The outgoing particles 1 and 2 emerge back-to-back, with their momenta and helicities (λ₁ and λ₂) indicated. The angles θ (polar) and φ (azimuthal) specify the direction of particle 1 in spherical coordinates with respect to the z-axis. The figure encapsulates the geometric meaning of the helicity formalism: the matrix element for the decay depends on the spin projections and the angular orientation of the outgoing particles, captured here by θ and φ. The angular dependence of the decay amplitude is encoded in the Wigner D-matrix, reflecting how spin and momentum are coupled in the rest frame of the decaying particle. This diagram provides the foundational visualization for expanding amplitudes in terms of partial waves and for connecting angular momentum conservation to observed decay distributions.\n\n\n\nWe are sitting in the rest frame of the decaying particle, and the quantized spin with respect to the z-axis is represented by the canonical state. We use helicity states for particle 1 and particle 2.\nThe matrix element represents a transition amplitude between the initial and final state. It must carry all dependencies on the kinematic variables and on the configuration of the particles with respect to the quantization axis. So it must depend on the initial spin projection M_0 , the helicities \\lambda_1 , \\lambda_2 , as well as the angles.\nThe total spin of the system controls the angular dependence of the final state particles. In that case, it is given by the Wigner D-matrix that comes with the angles of the decay products in this rest frame.\nParticle one and two go back-to-back, and we pick one of them. We call it particle number one. We measure its spherical angles, polar \\theta and azimuthal \\phi , and they enter as an argument of the D function. This comes from the same algebra as we just discussed for the isospin.\nThese functions are the same functions that you find on the page of the Clebsch-Gordan coefficients. The capital D as a matrix is just a little d with a phase factor.\n\n\n\n\n\n\nFigure 9: This figure schematically represents the decay of a parent particle into two daughter particles, labeled 1 and 2, within the helicity formalism framework. Each arrow denotes the direction of momentum of the outgoing particles, and the accompanying symbols \\lambda_1 and \\lambda_2 denote their helicities in their respective rest frames. The relation m = \\lambda_1 - \\lambda_2 indicates the conservation of angular momentum along the quantization (typically z ) axis in the parent’s rest frame: the difference in the helicities of the two final-state particles equals the spin projection m of the parent particle along that axis. In the helicity formalism, this physical configuration underpins the angular dependence of the decay amplitude. Specifically, it determines which element of the Wigner D-matrix encodes the angular correlations between the spin projections of the initial and final states, a key concept that translates into the general partial wave expansion discussed in this lecture.\n\n\n\nHere it comes in the expression for the matrix element:\n\\mathcal{M}^{M_0}_{\\lambda_1, \\lambda_2}(\\theta, \\phi) = H_{\\lambda_1, \\lambda_2} \\, D^{J_0*}_{M_0,\\, \\lambda_1 - \\lambda_2}(0, \\theta, \\phi)\n\n\n\n\n\n\nPhysics meaning: This formula describes the decay amplitude for a particle with spin J_0 and spin projection M_0 along the z-axis, decaying into two particles with helicities \\lambda_1 and \\lambda_2 . The Wigner D-matrix D^{J_0*} encodes the angular dependence, while H_{\\lambda_1, \\lambda_2} is the reduced matrix element that contains dynamical information (like coupling constants and mass dependencies) and is independent of angles.\n\n\n\nIt comes conjugated because the particles in the final state are rotated with the rotation \\theta and \\phi . We use active transformations, active rotations. In order to obtain the configuration of the final state we have to apply R_y and R_z .\nHere’s an example for the regular rotations. In order to obtain the particle with the spherical coordinates \\theta and \\phi , you have to apply to something aligned along the Z axis the rotation first about Y by angle \\theta and then about Z by angle \\phi . That’s exactly what you see in arguments of the D function.\nThat’s just a series of transformations: first apply rotation about Z. These arguments of the D functions follow the Z-Y-Z convention of the Euler angles. The first is the Z rotation by angle 0, then Y rotation by angle \\theta , and then Z rotation by angle \\phi . You don’t need to apply this first Z rotation.\nOne of the simplest conventions that is used often is to have no angle for the first rest frame rotation, and then you have \\theta, \\phi .\nWhat also appears in the expression is this H with indices \\lambda_1 and \\lambda_2 . That’s something that depends on the mass parameters only and does not depend any longer on angles. This is what remains as the reduced matrix element, computed as the projection of the z-aligned particle 1 and 2 with the initial state.\nHere we don’t have any angles any longer. We are dealing with the configuration of particle 1 with the helicity \\lambda_1 going in the z direction and particle 2 with the helicity \\lambda_2 going in the minus Z direction. We are projecting this into the particle 0 canonical state with the spin projection M equal to \\lambda_1 - \\lambda_2 . (see Figure 9)\n\n\n\n\n\n\nHelicity Constraint: In the parent rest frame, the z-component of angular momentum is conserved. For back-to-back decay products, the difference in helicities equals the initial spin projection: M_0 = \\lambda_1 - \\lambda_2 . This constraint is embedded in the Wigner D-matrix indices.\n\n\n\nThat’s a short reminder. Now we’re going to apply the same construction to the more complicated decays. I want to demonstrate that this essentially gives us a recipe for how to construct any cascade decay with particles with spin.\nTo illustrate and make it easier to follow, for the reaction that proceeds through an intermediate state, I’m going to put around the vertices the blocks and apply formulas that I have for every specific block. The general structure is like this.\nBut now we have to insert the indices. The first D function has two indices. First of all it has a spin. The spin will be of the decaying particle always conjugated.\n\n\n\n\n\n\nFigure 10: This figure represents a typical cascade decay process in hadron physics involving resonances and intermediate states, as discussed in the lecture. The initial interaction is a photon ( \\gamma ) scattering off a proton ( p ), which leads to the production of an intermediate resonance—in this case, the ** \\Delta baryon** (illustrated by the triangle symbol in the diagram). The \\Delta resonance then decays into a proton ( p ) and a pion ( \\pi ). Physically, this diagram illustrates a 2\\to 2 scattering process ( \\gamma p \\to \\Delta \\to p\\pi ), which is a concrete example of a reaction where a resonance (here, the \\Delta with isospin I=3/2 , spin J=3/2 ) appears as an intermediate state. In the context of the lecture, this process is used to motivate the helicity formalism and the factorization of amplitudes: the total matrix element is constructed by combining the production amplitude of the \\Delta (via U(\\theta, \\hat{n}) , rotational properties, and group theory) with the decay amplitude of the resonance, which is characterized by its Breit-Wigner propagator and spin-dependent angular distributions (Wigner D or d functions). The diagram shows how the partial wave expansion and resonance modeling (using Breit-Wigner distributions for the propagator and Wigner matrices for the angular structure) are applied in hadron spectroscopy, connecting the discussion of isospin, angular momentum conservation, and resonance dynamics from the lecture to an explicit scattering scenario.\n\n\n\nThe first index is of the particle that decays and then the difference of the helicities of particle one and particle two.\nThe reduced matrix element that appears here and there is going to have indices only of the particles that are combined. We don’t need the third one, because that comes the same from the conservation of angular momentum of the helicity.\nSo here we will go. We have a transition of particle 0 going to the intermediate state (12) and particle 3. And here we have (12) going to 1 and 2. What is missing is a dynamic function that represents the propagation of the intermediate resonance.\nThis is the model and it is a model not because of the angular functions, they are precise and exact, but because of the factorization. We are assuming that the matrix element is able to factorize the first decay from the second decay.\nThe fact that we split the interaction matrix element into the two here—here is the reduced matrix element of the first transition, here is the second—is our modeling assumption: factorization.\nWhat is missing here is that we didn’t introduce the helicity \\lambda of the intermediate state. You see that intermediate state that appears here also has a spin projection \\lambda . That’s the one that will be carried by one of the particles.\nThis is something up to a sum over the angles that appear as arguments. They are not the same, but they are specific to particular transitions here and there. Therefore we better label them differently.\nThat’s always tricky to keep consistent labeling. When you apply this cascade decay parameterization, you have a million different angles. Labeling them we need to have some rule to start labeling.\nFor example, for the pair of particles that go back to back—reason this is IJ—I can use IJ index here. They will have indices 1, 2, \\theta_{1,2} . Here is the 1, 2, 3 and here I would like to invite you to do some 3D imaging.\nI want to now sketch on the board in 2D, how it looks in 3D. The definition of the axis. And we need to access. That’s how it starts.\nHere is the representation that I think it’s easy to visualize what’s going on. We start with particle 0 in the lab frame. It flies in this frame. The particle has the helicity \\lambda_0 .\nThis particle decays into a combination of the particles 1 and 2 and 3. Then we can boost the system to its rest frame following this axis. In the rest frame, this \\lambda that used to be the helicity of the particle becomes the canonical spin projection.\nIf you think of this and here is the z axis. Here’s m_0 , that is the zero. This is the zero particle rest frame. The spin is quantized along the z axis by our construction. Since we boost in this direction, and in this frame 1, 2 and 3, they go back to back.\nNow, in order to apply the second part, you have to follow the combination of particles 1 and 2. It’s exactly the same as we started from. In this frame it flies in a certain direction and it decays into two particles.\nWhat we need here is to boost to its rest frame where it decays into particle one and going back to back.\n\n\n\n\n\n\nFigure 11: This figure illustrates the kinematic construction and reference frames relevant for the helicity formalism in cascade decays, as discussed in the lecture. It shows how to define the angles and axes necessary for correctly describing the spins and momentum directions of multiple particles in sequential decays. - The lab frame (upper left, in purple) depicts the flight of the parent particle “0” with helicity \\lambda_0 . As particle 0 decays, its spin quantization axis is defined in this frame. - The event is boosted to the rest frame of particle 0 (center), where the decay 0 \\to (12) + 3 is considered. Here, the helicities of outgoing particles (e.g., \\lambda_3 ) are defined with respect to the z-axis in this frame, and the relevant angles (\\theta_{12,3}, \\varphi_{12,3}) specify the orientation of the (12)-3 system. - A further boost (indicated by “boost ^{-1}”) brings us to the (12) rest frame (top right, red/blue), where the pair (1,2) is at rest, and their decay kinematics can be fully described by (\\theta_{12}, \\varphi_{12}) . The quantization axes and the definition of helicities \\lambda_1 , \\lambda_2 are with respect to the new z-axis in this frame. - The diagram shows how each particle’s momentum and spin orientation are defined in the appropriate rest frame along a specific z-axis, and emphasizes how the definition of the kinematic angles ( \\theta and \\varphi ) depends on these sequential boosts and rotations. Physical Meaning: The figure provides a geometrical visualization of how to construct the angular variables and reference frames needed for a full helicity amplitude calculation in a decay chain. It clarifies that: - Helicity quantization axes are defined in different rest frames (a key caveat discussed in the lecture). - Angles such as \\theta_{12} , \\varphi_{12} , \\theta_{12,3} , and \\varphi_{12,3} specify the orientation of momentum vectors after appropriate boosts. - This construction is essential for writing decay amplitudes in terms of Wigner D-functions, ensuring that rotational properties and conservation of angular momentum are properly encoded in the matrix element for sequential decays. The diagram is an explicit, practical guide for defining kinematic variables when applying the helicity formalism and partial wave expansions to multi-body (e.g., three-body) decays in particle physics.\n\n\n\nSo let’s define the angles. Angles are taken as spherical angles of one of the decay products.\n\nFirst Decay (0 → (12) + 3): The spherical angles of one of the decay products (e.g., the combined system (12)) would be \\theta_{12,3} and \\phi_{12,3} .\nSecond Decay ((12) → 1 + 2): The angles will be found as the angle with respect to the z axis in the rest frame of the particle (12). These are \\theta_{12} and \\phi_{12} .\n\nWhen you deal with this practically, you follow the chain and introduce angles while approaching certain rest frames. In experimental physics we are given the four-vectors. You’re literally given three four-vectors for particle one, particle two, particle three, and they are in the lab frame.\nTo make this transformation, you first find out what are the spherical angles of this combination 1 to 3 and you rotate to have a 1, 2, 3 vector pointing in the z direction. Then you boost your particle in this frame.\nYou take, find \\theta , the angles of the 1, 2, align this with the z axis and you boost in that direction and then apply appropriate rotations. It’s it."
  },
  {
    "objectID": "2025-Lecture-07.html#helicity-formalism-and-partial-wave-expansion-in-resonance-decays",
    "href": "2025-Lecture-07.html#helicity-formalism-and-partial-wave-expansion-in-resonance-decays",
    "title": "(2025) Lecture 7",
    "section": "5 Helicity Formalism and Partial Wave Expansion in Resonance Decays",
    "text": "5 Helicity Formalism and Partial Wave Expansion in Resonance Decays\nNow, in fact, the topology that we draw here is not the only one possible. One can imagine the same transition happening through the combination of particle 2 and 3 or 3 and 1, and one would write the same expression.\nTo incorporate the resonances in other channels, let’s first discuss this expression a little bit, because there are caveats and things to note.\n\n5.1 Caveat 1: Helicity Quantization Axes\nThe main caveat, and something that I really want you to appreciate, is that the helicities that appear in the expressions are taken from different rest frames. In order to apply our helicity formalism and to replace an expectation value by the reduced matrix element—the so-called helicity coupling—we need to be in the rest frame of the decaying particle. Therefore, when we apply this formalism, the values of the \\lambda that appear are taken in the rest frame of the particle pairs.\nThis means the quantization axis is the z-axis of the appropriate frame. From the last homework, we’ve seen that helicity is affected when you boost not along the direction of quantization, but off-axis. Consequently, if I were to write the amplitude where all \\lambda are defined in the same frame— \\lambda_1, \\lambda_2, \\lambda_3, \\lambda_0 —I would get a linear combination of my amplitudes. This is a somewhat bizarre outcome.\nThe only reason we don’t use this formalism literally is that we often don’t care about the individual \\lambda values themselves. We are going to sum over them once we add things together. So the consistency of the quantization axis is not a concern unless you are dealing with coherent processes that use different quantization axes.\nWhat is important, and what I would like to draw your attention to, is identifying on which axis in this matrix element the spins are quantized.\n\n\\lambda_0 comes from the lab frame (helicity in the lab frame).\n\\lambda_3 and the others are defined in their respective resonance rest frames.\n\nAs soon as I square the matrix element and sum over the helicities, I don’t care which axis I quantize them on; they are going to be summed or averaged anyway.\n\n\n\n\n\n\nHowever, if I want to add this amplitude to something else—for example, an amplitude from a different topology—I have to be careful with the helicity quantization axis. That’s the first important note: watch your helicity quantization axis.\n\n\n\n\n\n5.2 Caveat 2: Factorization of Vertices\nThe second important note is that we are implicitly assuming the vertices are factorized. This is usually a really good assumption, especially when discussing a narrow resonance. Even for a broad resonance, when the dynamics are driven by the resonance in the particle 1 and 2 combination, it’s a good assumption.\nThe Wigner d-functions here are a property of the rotations; they are not model assumptions. We know Lorentz symmetry is a good symmetry, so these functions must be present.\nIf we took the expression without the factorization assumption—if we treated the matrix element together with the propagator as a single entity requiring theory input—we would be computing a more complex product. The form we use is a model-independent expression for the matrix element. It is safe to pull out the rotational functions, but not safe to break their structure.\n\n\n5.3 Angular Dependence and the Scalar Case\nIn general, what we’ve done here is explicitly find the angular dependence if a particle with spin J is present in the combination of particles 1 and 2. The helicity formalism is a simple way to identify the dependence of the matrix element on the angles.\nThe only thing I’m interested in is what spin particles 1 and 2 have. Using this form doesn’t directly give me the answer; it simply gives a D^J function of the appropriate angles. Dealing with spin is more complicated, as you might have appreciated already.\nFor further discussion, let’s reduce the situation to scalar particles. Consider a scalar particle decaying to three scalar particles—the scalar case. The matrix element in that case has no helicity indices. It is simply a function that depends on the kinematic variables.\nLooking at the general helicity amplitude formula, we quickly realize that for scalars, there is no value for \\lambda except zero. You have a single state in the multiplet for spin zero. Therefore, the Wigner D-function term simplifies to a delta function for \\lambda=0 , which we can propagate through the calculation.\nThe expression becomes very simple, and we find that the matrix element in the scalar case does not depend on any angles except one polar angle, \\theta . In the rest frame of two particles, all other angles drop out.\nA convenient way to write this is using a partial wave expansion in Legendre polynomials P_J :\n\\mathcal{M}(m_{12}, \\theta) = \\sum_{J} (2J+1) \\, a_J(m_{12}) \\, P_J(\\cos \\theta)\nI’m moving towards matching the expression we derived to the partial wave expansion series you see in the homework. That’s why I pulled the terms related to the helicity couplings and the reduced matrix element into the function a_J(m_{12}) and introduced the (2J+1) coefficient.\n\n\n5.4 Interpretation and Practical Truncation\nWe started by writing the matrix element for a decay that proceeds via a resonance with spin J . We found that its angular dependence is given by d_{00}^J , which are in fact Legendre polynomials. We can match this to a general technique: for any matrix element with angular dependence, we can expand it in a series of Legendre polynomials and analyze the coefficients, with the only remaining dependence being on the mass variable m_{12} .\nThe argument is that the coefficients a_J(m_{12}) in this expansion then represent dynamics corresponding to a specific spin J of a resonance. So we started from a model, but it gives us an interpretation and intuition for what the coefficients in a partial wave expansion represent.\nThe total matrix element in the scalar case depends on only two variables: the scattering angle \\theta and the invariant mass m_{12} . This is exactly what we see in a Dalitz plot.\n\nThe expansion is an exact representation if you keep the upper limit of the series to infinity.\nIt becomes an approximation as soon as you truncate the series.\n\nIn experiment, we often use a truncated series of partial waves. This is because, due to the identification we’ve made, we can apply physical intuition:\n\nEvery term corresponds to a particle with spin J .\nHigh-spin particles are not abundant. Looking at the PDG, particles with high values of J are rare.\nAmplitudes with high J are typically suppressed.\n\nThis gives a natural limit to the expansion. We don’t actually know particles with a spin greater than 6. Spin-6 particles exist, but spin-7 or higher have never been observed experimentally (though they are possible in quark models).\nThe reason is simple: such high-spin states are very high in the excitation mass spectrum, are very broad, and thus their effect is small and hard to observe. Practically, we truncate this series at J_{\\text{max}} = 6 .\n\\mathcal{M}(m_{12}, \\theta) \\approx \\sum_{J=0}^{J_{\\text{max}}=6} (2J+1) \\, a_J(m_{12}) \\, P_J(\\cos \\theta)"
  },
  {
    "objectID": "2025-Lecture-07.html#resonance-models-in-multi-channel-decays",
    "href": "2025-Lecture-07.html#resonance-models-in-multi-channel-decays",
    "title": "(2025) Lecture 7",
    "section": "6 Resonance Models in Multi-Channel Decays",
    "text": "6 Resonance Models in Multi-Channel Decays\nOnce you deal with a channel where resonances appear in a specific pair, like (1,2), the partial wave expansion is a good model to analyze the data.\nWhen we deal with situations where a resonance can appear in different two-body channels—(1,2), (2,3), or (3,1)—instead of writing a partial wave expansion for just one pair, we use a different, more comprehensive model.\nLooking at Dalitz plots for three-body decays, we see resonances can be present in any of these pair combinations.\n\n\n\n\n\n\nFigure 12: This figure illustrates an example of an experimental topology for a three-body decay commonly found in hadron physics analyses. The diagram shows the decaying particle at the interaction point, producing three final-state particles labeled 1, 2, and 3, each with momentum vectors radiating outward. The colored boxes, labeled here as b_1 and b_2 , represent two different possible intermediate resonant subsystems (for example, the combinations of particles 1+2 and 2+3, respectively). This reflects how, in an experimental context—such as a Dalitz plot analysis—multiple two-body resonant channels can contribute to the final state. From the perspective of the helicity formalism and partial wave expansion discussed in the lecture, this topology visually encodes how the decay amplitude is constructed as a sum over possible intermediate states, each described by its own angles and rest frame. The two boxes illustrate “blocks” where specific two-body resonances may appear, as in the cascade decay/isobar model: the decay can proceed via an intermediate resonance formed by a pair of particles (e.g., 1+2 or 2+3) before decaying to the observed three-body final state. The orientation of the outgoing particles also emphasizes the need to define angles (such as \\theta and \\phi ) in the appropriate rest frames when applying the helicity formalism, as different decay chains (topologies) require consistent and careful bookkeeping of kinematic variables and spin quantization axes.\n\n\n\nTherefore, instead of writing the infinite partial wave series for just the (1,2) channel, we write the sum of three truncated series, one for each possible pair.\n\\mathcal{A}_{\\text{Isobar}}(s_{12}, s_{23}, s_{31}) = \\sum_{\\ell=1}^L (2\\ell + 1) \\, a_\\ell^{(12)}(s_{12}) \\, P_\\ell(\\cos\\theta_{12}) + \\text{cyclic permutations for (2,3) and (3,1)}\nIn fact, this model, once projected onto any single channel, still contains contributions from an infinite number of partial waves. This is a key, non-trivial point.\nThe reason we cover an infinite number of partial waves in every channel is that the angles in each expansion are defined in different rest frames. For example, the angle \\theta_{23} in the (2,3) rest frame is different from \\theta_{12} in the (1,2) rest frame. Consequently, every term in the full three-body expansion projects onto the (1,2) partial wave expansion as an infinite series of Legendre polynomials.\nThis approximated amplitude—the sum of three truncated partial wave series—is known by different names in hadron spectroscopy.\n\nIt is often called the Isobar model.\nIn this model, the dynamical functions a_\\ell^{(ij)}(s_{ij}) for the propagator are typically parameterized with simple Breit-Wigner amplitudes:\n\na_\\ell^{(ij)}(s_{ij}) \\propto \\frac{g_\\ell \\, \\Gamma_\\ell(s_{ij})}{m_R^2 - s_{ij} - i m_R \\Gamma_\\ell(s_{ij})}\nThis is a simple, phenomenological parameterization of resonance peaks that works quite well, but it is a simplistic approximation without strong theoretical constraints from unitarity or analyticity.\nI prefer to call it a cascade decay model, which refers to more general constructions. The core idea is writing the full matrix element not as a single infinite sum, but as three separate, truncated series. This same ansatz is also the starting point for the more advanced Khuri-Treiman model.\nThe Khuri-Treiman model is a theoretical framework that incorporates final-state interactions and rescattering between different decay channels. It begins with the same three-series ansatz but then introduces theoretical constraints—primarily from dispersion relations—so that the amplitudes in each channel “talk to each other” and receive corrections through rescattering processes.\n\n\n\n\n\n\nThe Khuri-Treiman model starts with the Isobar/cascade decay ansatz but adds unitarity and analyticity constraints via integral equations. This accounts for rescattering, leading to a more rigorous description of three-body decays where channel coupling is important.\n\n\n\nThis model takes into account data and different types of rescattering diagrams. The starting expression is the same, and it relates to what is known in some contexts as a reconstruction theorem, derived from dispersion relations. While powerful, for higher spins and partial waves, the Khuri-Treiman approach still involves modeling assumptions, so it is not a complete first-principles solution."
  },
  {
    "objectID": "2025-Lecture-07.html#modeling-dalitz-plots-with-helicity-formalism",
    "href": "2025-Lecture-07.html#modeling-dalitz-plots-with-helicity-formalism",
    "title": "(2025) Lecture 7",
    "section": "7 Modeling Dalitz Plots with Helicity Formalism",
    "text": "7 Modeling Dalitz Plots with Helicity Formalism\nThe last thing for today is to come back to the Dalitz plot distribution and discuss how we would model this distribution using the helicity formalism.\nIf you look at these blue Dalitz plots, let’s try to identify the components you see by eye. What kind of expansion would you put there? We will describe the decay X \\to p K \\pi .\nLooking at the plot, we are focusing not on the kinematic borders but on the dynamics. All inhomogeneities within the phase space are driven by the physics. They are produced by either resonances that create bumps, or by structures within the bands that reflect the spin and angular distributions. All these can be built in using the helicity formalism.\nLet’s quickly list what we need to incorporate to apply the helicity formalism. We need to know:\n\nThe spins of the particles.\nWhat to put for the reduced matrix elements.\nWhat to put for the resonance propagator. (see Figure 12) In the isobar model, the propagator is parameterized by a relativistic Breit-Wigner function: \\mathcal{P}_R(s) = \\frac{1}{m_R^2 - s - i m_R \\Gamma_R(s)}\nTherefore, we need the mass ( m_R ) and width ( \\Gamma_R ) for each resonant state. The formalism also requires the resonance spin J .\n\nLet’s look at the plot and identify, for every two-particle combination, the masses, widths, and spins of the prominent resonances.\n\n** K\\pi combination (horizontal bands):**\nHow many bands do you see? One clear horizontal band.\nThis is the K^*(892) . Its spin-parity is 1^- . It’s the first radial excitation, essentially the rho meson of the strange sector.\n** K p combination (vertical bands):**\nHow many do you see? Two.\nThe first is the \\Lambda(1520) , with spin-parity 3/2^- .\nThe second is likely the \\Lambda(1690) , also 3/2^- . (see Figure 10) These negative parity states belong to the P multiplet, meaning there is orbital angular momentum between the quarks.\n\n\n\n\n\n\n\nFigure 13: This figure shows a schematic representation of a resonance in a two-body invariant mass spectrum, as described in the context of the lecture’s discussion of resonance propagators and the Breit-Wigner parameterization. The horizontal axis represents the invariant mass of a two-particle system, (m_1 + m_2) , while the vertical axis corresponds to the event rate or probability amplitude. The resonance manifests as a prominent peak, centered at the resonance mass m_R . The width of the peak, denoted by \\Gamma , characterizes the decay width (or inverse lifetime) of the intermediate resonance state. This shape is modeled by the Breit-Wigner resonance amplitude, a key dynamic function used in the isobar and cascade decay models to describe intermediate resonances in multi-body decays. Physically, this plot illustrates how a resonance like K^*(892) , \\Lambda(1520) , or \\Delta(1232) appears in the invariant mass spectrum of its decay products, with the position and width of the peak directly encoding the resonance’s mass and decay properties.\n\n\n\n\n\n\n\n\n\nFigure 14: This figure illustrates the characteristic behavior of a resonance amplitude’s real and imaginary parts as a function of the Mandelstam variable s , which typically denotes the invariant mass squared of a two-body subsystem in a decay or scattering process. On the left, the plot shows the imaginary part of the amplitude, \\text{Im}(a) . It displays a peak at s = m_R , where m_R is the mass of the resonance. This reflects the fact that, according to the Breit-Wigner parameterization, the imaginary part of the amplitude becomes largest when the invariant mass of the system matches the resonance mass, representing the maximal probability for the resonance to be produced on-shell. On the right, the plot shows the real part of the amplitude, \\text{Re}(a) , versus s . Here, as s increases through the resonance region, the real part exhibits a characteristic “phase motion,” smoothly crossing zero at s = m_R and changing sign. This behavior is a direct consequence of the analytic properties of the Breit-Wigner (or more generally, resonant) amplitude and is closely related to the unitarity and analyticity constraints discussed in the lecture. The total amplitude thus traces out a circular trajectory in the complex plane as s varies, resulting in a rapid change in phase (typically by about \\pi ) as the system passes through the resonance. Physically, these features—peak in \\text{Im}(a) and phase motion in \\text{Re}(a) —are signatures of resonant behavior and are used to identify and characterize hadronic resonances in Dalitz plot analyses and partial wave expansions. The figure matches the lecture’s context, where these generic features of resonance line shapes and their relation to analytic properties of amplitudes are discussed as foundational concepts for parameterizing dynamic functions using the Breit-Wigner form.\n\n\n\n\n** \\pi p combination (diagonal band):**\nYou can see a diagonal line. This is the \\Delta(1232) with spin-parity 3/2^+ .\n\n\n\n\n\n\n\nThe total amplitude for the decay X \\to p K \\pi is a coherent sum over these intermediate resonance channels ( R ): \\mathcal{A}(X \\to p K \\pi) = \\sum_{R} \\mathcal{A}(X \\to R + \\text{spectator}) \\times \\mathcal{A}(R \\to \\text{final particles})\nEach resonance amplitude is built from a Breit-Wigner propagator, a reduced matrix element, and Wigner rotation matrices D^J that encode the spin and angular distributions via the helicity formalism.\n\n\n\nIn principle, you are now equipped to take the equations and draw the Dalitz plot. You would insert the mass and width from the PDG for these three resonances, use their spins, and construct the amplitude.\nHowever, a complication arises because we have a proton with spin in the final state. If you incorporate this particle blindly using the helicity formalism for different decay chains—each quantized along a different axis—it won’t be done correctly. If all final-state particles were scalars, the procedure would be straightforward."
  },
  {
    "objectID": "2025-Lecture-07.html#preview-of-advanced-parameterizations",
    "href": "2025-Lecture-07.html#preview-of-advanced-parameterizations",
    "title": "(2025) Lecture 7",
    "section": "8 Preview of Advanced Parameterizations",
    "text": "8 Preview of Advanced Parameterizations\nSo, any questions? We are approaching the end of our current topic.\nI believe the next lecture will focus on dynamic functions, specifically discussing the Breit-Wigner parameterization.\nWe will cover:\n\nMore advanced parameterizations of the phase shift.\nThe constraints on line shapes imposed by unitarity and analyticity. (see Figure 14)\n\n\n\n\n\n\n\nThis segment concludes the current lecture chunk (Chunk 7). The upcoming discussion on the Breit-Wigner form will build upon the foundational concepts of resonance parameterization introduced earlier."
  },
  {
    "objectID": "2025-Lecture-09.html",
    "href": "2025-Lecture-09.html",
    "title": "(2025) Lecture 9",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Anna Zimmer"
  },
  {
    "objectID": "2025-Lecture-09.html#analyticity-and-unitarity-in-scattering-amplitudes",
    "href": "2025-Lecture-09.html#analyticity-and-unitarity-in-scattering-amplitudes",
    "title": "(2025) Lecture 9",
    "section": "1 Analyticity and Unitarity in Scattering Amplitudes",
    "text": "1 Analyticity and Unitarity in Scattering Amplitudes\n\n1.1 Lecture 9: Recap and Introduction to Analyticity\nWe start with a recap of the previous lecture.\nLet’s discuss the problems. Who is finished with the first? Who is finished with the second? Good.\nThen, what’s the name of the area of the decay that we have here? The usual representation of the decay in the coordinates of the invariants is called a Dalitz plot, but you can use the same type of coordinates for the crossed process, for the scattering process.\nI don’t want you to know the equation by heart, but rather I want to stress that the same equation would be relevant not just for the Dalitz plot and the decay region, but exactly the same equation would determine the border of the scattering process.\nSo, can anyone tell me what equation that is? It’s the Kibble function. The Kibble function of s, t, u is equal to zero. The Kibble function is also known as the Chew function. The Chew function depends on the mass of the decaying particle, the pair mass of the two particles, and then the other one.\n\n\n\n\n\n\nThe Kibble (or Chew) function defines the boundary of the physical region in scattering or decay processes (e.g., a Dalitz plot) in terms of Mandelstam variables s, t, u . It ensures energy-momentum conservation and relates to the condition that the scattering angle cosine is \\pm 1 : \\Phi(s, t, u) = 0\nwhere \\Phi is often expressed as: \\Phi(s, t, u) = s t u - (m_1^2 s^2 + m_2^2 t^2 + m_3^2 u^2) + \\text{(mass-dependent terms)} = 0\nThis describes the kinematic limits for processes like \\pi^+ \\pi^0 \\to \\pi^- \\pi^0 or crossed channels.\n\n\n\nIf you want to plot the area, you just look for the solutions in the plane. It’s easy to derive this from scattering or for the decay. The fact that it describes both appears as the fact that you change one particle to the other side does not change the kinematics.\n\n\n\n\n\n\nFigure 1: This figure represents the Mandelstam plane, a plot with axes labeled by the Mandelstam variables s and t , which describe the kinematics of scattering processes. The “physical region” indicated in the diagram corresponds to the subset of allowed values of s and t where the scattering or decay process can physically occur, determined by kinematic constraints (such as the Kibble or Chew function discussed in the lecture). Outside this region, the amplitude can still be defined by analytic continuation, but does not correspond to direct physical processes—these are the unshaded or shaded regions outside the “physical region” boundary. The diagram illustrates how analytic properties of scattering amplitudes extend beyond the physical region into the complex Mandelstam plane, a concept central to the analytic approach to scattering theory described in the lecture.\n\n\n\nThis condition comes from considering the scattering angle and requiring that the scattering angle is either plus one or minus one; this determines the border. The meaning of this scattering angle changes a little bit once you go from the scattering domain to the decay domain.\nYou see it in the rest frame of two particles. Let’s say it’s the s channel: here’s particle 1, here’s particle 2, 1, 2, 3. And then this is the \\cos \\theta . The condition for the border is determined by the equations that \\cos \\theta is equal to plus one or minus one. It’s the same for the decay and for the scattering.\nIt’s just the direction of this arrow would change. For the decay, two particles collide and the system that you consider is the center of mass for the whole system. For the scattering, that’s for the scattering. For the decay, it’s just a subsystem of the final state.\nThe way how you derive it: you write the cosine in terms of the invariants and then you set \\cos \\theta = 1 and you arrive at this same equation.\nI’m surprised you need scattering. I suppose most of the variables are defined to be for momentum and then you use energy conservation, and I guess you can somehow introduce cusp functions. The channel function is just a breakup momentum.\nI would consider this once you derive it, once you can consider this as common knowledge. It’s easy to remember. You have derived this one or you look it up in the Bickerstaff-Cajandji book.\nThe recipe is you start with the scattering kinematics, and that’s unique because you know that the ranges of the physical region correspond to the cosine going to being plus one or minus one.\nBut let’s not get distracted because there’s a lot of material here. The one thing to realize is that once you put this into Mathematica and ask what are the regions in the two-dimensional plane where this equation is satisfied, you don’t get only this region; you also get the other regions that correspond to the cross process.\nHere I’m asking: what are the other physical processes that are connected by crossing and draw the regions? The answer here is that the regions will lie somewhere here, and these lines where also the Kibble function is zero are the borders of the other process.\nYou understand them by looking at your original kinematics. So if this is zero going to 1, 2, 3, that process. Then here we define s so that process would correspond to—so the variable s that you have here for any place inside of the Dalitz plot is a positive quantity and you want to keep it positive.\nFor this area it’s bigger but it’s also positive, while the other one becomes negative. For this area these two particles are still in the physical space, so they are in either initial state or final state, while the other one you get crossed to the other side.\nSo it’s a 0, \\bar{3} scattering into the 1, 2. The process that we talk about when we discuss this domain is \\pi^+ \\pi^0 , so \\pi^+ \\pi^0 scattered with the other particle that was a \\pi^- . Then we put it to there by + \\omega \\pi^0 and we talk about this domain, but in terms of \\pi^- \\pi^0 and \\omega , what is 1, 2 and 3?\nOne has to be always consistent, so this zero depends on the axis. So the \\omega \\pi . I call this one, this is two, this is three. So the process here would be zero. But why? For the first process we moved \\pi^- to the other side, not \\pi^0 .\nBecause one axis is \\omega \\pi^0 and another one is \\pi^- \\pi^0 , right? \\pi^- . No, it’s diagonal. No, it’s \\pi^- \\pi^0 . So that one. So then if there are two \\pi^0 s, shouldn’t we move \\pi^0 to the other side? So I argue that way.\nI have here \\omega and I have here \\pi^0 . That’s what my channel represents. That’s a threshold for their channel. That’s up to the threshold for that channel. And that will be production threshold for the initial state. I always have this s increasing along this axis.\nAre these asymptotes of the locus, like a hyperbola? I’m asking because like in the original Mandelstam paper, they’re not. They try to go over it. I never understood. No, going over is fine. But the question is, do they approach them at the infinite energy region and that’s where you can neglect the masses? I think so.\nAsymptotes means not here and they can cross. But when the energy gets high, do you approach this line? I think so. Well, is it that line or is it another line? The close one is that it’s slightly offset by the threshold.\nLet me draw it here, what scattering process we are dealing with. So the zero scatters with the particle. So 1, 2, 1 3, 2 3. So the energy gets positive. And here is the zero with one bar. So the process here is the \\pi^+ \\pi^0 \\omega goes to \\pi^- \\pi^0 .\nThen you see that for the particle that you cross to the other side becomes an antiparticle. But for \\omega and for \\pi^0 , particle and antiparticle is the same. Things get a bit more tricky once you take into account that particles have spin.\nSo in fact I should have written here lambda because \\omega has spin and then helicities; they also have peculiar relations with respect to the crossing. We don’t talk about that. So for the kinematical considerations it’s enough. You can think of particles as scalars.\nTo really relate the amplitudes with helicity indices requires more work. Draw regions, indicate process. I think we did draw roughly the regions together. More accurately you have to open a computational notebook, otherwise it’s intuitive.\n\n\n1.2 Unitarity and the Optical Theorem\nSo, questions here quickly. The second unitarity equations. So we consider an elastic scattering process. Shall we break this down. What does it mean? What is s and t ? Maybe you guys follow what is A ? What s for the same? A is scattering amplitude, s is Mandelstam s .\nWhat does it refer to? Like how do you compute this variable? It’s like p_0, p_1 . And t is a Mandelstam variable related to the difference of these two momenta and then scattering amplitude. I’m saying process, but in fact it’s a scattering amplitude.\nWhat does elastic mean here? I don’t think we discussed elastic, but maybe you heard of this. Energy is conserved. Energy is always conserved. That we’re doing the same check. Exactly. So the initial state and the final state are the same. That’s what I mean.\nActually here it’s somewhat slang and the elastic is used in a different context. But when we talk about elastic process we usually say initial state is the same as the final state. Elastic scattering.\nFormulate A using explicit dependence. Formulate partial wave in unitarity and optical theorem. Can you tell me in the unitarity equation for A , maybe can you help me? Is he like what should I relate.\nI mean, what is it about? I don’t know how you’ve so far introduced amplitudes. I always see that this normalized with regards to that energy which introduces a phase space factor. So I would say it’s like 1 + i \\rho A . So I want to write the unitarity equation for A .\nSo how unitarity constrains my A and in fact what you… When you do this consideration, as you say follow, you get constrained to the imaginary part of A and then the imaginary part of A is related to other amplitudes.\nSo maybe I draw it diagrammatically first and then you help me to get the equations. But this is the optical theorem, right? No, that’s the unitarity equation for A . What is different between t, t' and t'' ? Very good.\nWe are discussing the elastic process. And so s and t are defined. Here you have. Imaginary part of amplitude is related to the amplitude squared in the elastic region. This is the unitarity equation one has to integrate over all intermediate states when you contract one amplitude to another.\nBut since it’s elastic, it’s the same state that is present here. So the same particles, the only difference. Well, the integration actually takes into account that the configuration of the particles in the intermediate states could be different.\nIf I consider this process of initial state scattering to the final state, let’s say it, the intermediate state that appears in unitarity equations. Well, essentially what the unitarity equation says, is that you have to sum over all intermediate states that appear for the elastic region.\nIt’s just different configurations. There is only one type of particle states that are present. And therefore integration over phase space includes only different orientations of the particles. They are the same particles.\nOnce you go to high energy, there will be many more intermediate states that come into the unitarity equations. But to clarify, maybe this drawing can clarify the configuration. What we have to integrate over.\nWe fix the initial state, we fix the final state and then the t is the scattering angle between the initial and final state. We say they form a plane. This sits in the x-z plane. So here is the x axis, here is the z axis here in the plane.\nThe only variable that we have, t is connected to the scattering angle between initial and final state. So this angle \\theta describes is connected to the t . What appears in the intermediate state is the arbitrary configuration in the space of the vector of the intermediate state here.\nI call here the p_1, p_2 . Here is the q_3 q_4 and here is the p_3 p_4 . So here there are two scattering processes. First from p to q and then from q to p again. So we have to integrate, so the plane is fixed, the q points somewhere in the space and we have to integrate over all possible configurations.\nThat’s why the t' and t'' come in. And then this is the unitarity equation for the full amplitude. Great simplification. Can you write phase space explicitly? Because t' and t'' are, what they should be in the phase space.\nIt’s a regular two-body phase space. We have to integrate over all possible configurations of one vector and a second vector. But there is a constraint making them back to back to each other. Writing this in terms of the t' and t'' is really a highly non-trivial task.\nThe way to proceed actually to get our regular unitarity that we know and like—where amplitude is related to itself—requires partial wave expansion. So the next step would be to take each amplitude A here, A here and A there and expand them into partial waves.\nThe partial waves would involve connection between scattering angle in the t or t'' . And then we use properties of the angular momentum of the angular functions to get rid of this integral essentially.\nAnd then once we do, this equation becomes very simple. Instead of the integral of the phase space, we have simply a phase space factor. It’s not an integral, it’s just an energy-dependent factor. So this \\rho is \\frac{1}{16 \\pi^2} \\times \\frac{p}{2\\sqrt{s}} .\nThe p is the breakup momentum in the system. It’s a function of the energy. And then here A appears. That’s the unitarity equation for the partial wave. Partial wave amplitude has only one dependence on s and things drastically simplify. There is no t any longer.\n\n\n\n\n\n\nThe unitarity equation for the elastic scattering amplitude A(s, t) ensures probability conservation. It relates the imaginary part of the amplitude to an integral over intermediate states: 2 \\, \\text{Im} \\, A(s, t) = \\int d\\Phi_2 \\, A^*(s, t') \\, A(s, t'')\nwhere d\\Phi_2 is the two-body phase space, and t', t'' are momentum transfers for intermediate configurations. This is a manifestation of the optical theorem.\n\n\n\n\n\n\n\n\n\nExpanding the amplitude in partial waves a_\\ell(s) simplifies the unitarity condition, as different angular momenta decouple: \\text{Im} \\, a_\\ell(s) = \\rho(s) \\, |a_\\ell(s)|^2\nwhere \\rho(s) = \\frac{1}{16\\pi^2} \\frac{q}{2\\sqrt{s}} is the phase space factor, and q is the breakup momentum. This implies a_\\ell(s) can be written as a_\\ell(s) = \\frac{1}{\\rho(s)} \\sin \\delta_\\ell(s) e^{i\\delta_\\ell(s)} , with \\delta_\\ell(s) the phase shift.\n\n\n\nAnother thing I wanted to point out coming back here is that you see that there is a t' and t'' . The reason they are different is because t' is measured for the vector q with respect to the p_1 , right? So it’s an amplitude computed between q_3 and p_1 .\nSo this vector and that vector and then q_3 . So t'' is computed between q_3 and p_3 . So it’s an intermediate and final state. So either you take these vectors or you take these vectors or these vectors and that’s what makes the variables different.\nThere is one limit when these variables are becoming the same. When you have not just elastic scattering, but forward scattering. When you have kinematics, you collide the particles and then they just pass through. It’s forward scattering.\nIn that case A is equal to… Sorry, t is equal to 0. And in that case, if p_1 is equal to p_4 , t and t' becomes the same, t' and t'' become the same. There are two values for t , t equal to 0 and t equal to its maximum.\nAnother negative value. So for this type of scattering, forward and backwards. For the backward, the t equals to its maximum value, it’s negative. Exactly. But for the forward scattering. You’re right, but it’s a different limit.\nSo now I want to discuss the forward limit. In the forward limit, the point is that this amplitude becomes the same as this amplitude. And we can write squared amplitude already right here.\nMy question was, isn’t it the same for backward as well? No, I don’t think it’s. No, it’s not. The reason is like forward we have to consider this is a p_1 and then this is the q and this is the p_3 and this is the q , right? That’s a form q_3 , that’s forward scattering.\nAnd that’s why what makes them, what makes this angle to be the same as this angle? If you consider backward scattering, so p_3 will be in that direction, q_3 will be this and the angle is this. So it’s different.\nYou can identify t' and t'' to be the same in a backward scattering? So finishing this I wanted to give the final expression for the optical theorem that comes from this is the following. It’s, but this, nothing else but the full cross section.\nAnd here you have an optical theorem. Amplitude for the forward scattering is equal to the flux times the full cross section. It’s important to acknowledge the fact here that it’s valid in the elastic region.\nForward scattering is really important because that’s when you identify that’s how you get rid of one of the variables. The cross section is a function of s only. The total cross section doesn’t know anything about angular dependence.\nSo you integrate this and this happens once you identify two amplitudes to be the same and take into account the phase space. It’s from unitarity. So this is the first condition wrote down and what comes down.\nSo the dependence on the cross section and the flux is the optical theorem for you. So what is what here? I can understand you correctly. The first is unitarity. The second is optical theorem. The second is optical theorem.\nI’m not sure we discussed this last time, but optical theorem comes in quantum mechanics. That’s mentioned. And here is this analog of this related to the transition matrix element amplitude we have in the scattering process.\n\n\n\n\n\n\nThe Optical Theorem is a special case of unitarity for forward scattering ( t = 0 ), relating the imaginary part of the forward amplitude to the total cross section \\sigma_{\\text{tot}}(s) : \\text{Im} \\, A(s, t=0) = 2 \\sqrt{s} \\, q \\, \\sigma_{\\text{tot}}(s)\nor equivalently, \\sigma_{\\text{tot}}(s) = \\frac{1}{2q\\sqrt{s}} \\, \\text{Im} \\, A(s, t=0)\nThis connects the amplitude’s analytic properties to measurable cross sections.\n\n\n\nRecap. Well, since it’s recap, let’s recap once again the recap. The unitarity for A is this. And then explicitly all variables are mentioned. The cosine is the function that defines the t .\nSo you can either write the t as a function of the s and cosine or cosine as a function of s and t . So two of them are independent. So here is the equation for the unitarity.\nPartial wave unitarity comes when you get rid of the angle dependence. And then L here is the summation index. It’s partial waves. And then what is interesting here worth noticing is that partial waves don’t talk to each other.\nOnly L that is on the left appears on the right. So these properties of the polynomials help you to identify the terms. And a_L is a function of s only, there is no t any longer.\nFinally, optical theorem. Optical theorem is the relation of the amplitude for the forward scattering to the total cross section. Good. And then when we discussed optical theorem last time. So that’s good that we discussed today. It’s important to relate the concepts to each other.\n\n\n1.3 Introduction to Analyticity and Complex Functions\nToday in the lecture we will go through analytic functions and see how scattering matrix principles are constrained by their properties. How scattering amplitudes are constrained by the properties of the scattering matrix, such as its analyticity and particularly crossing symmetry.\nTo consider this first part, I want to make the first part a little bit more mathematical, discussing analytic functions and real analytic functions. I will say a few words about analytic continuation at the end.\nIn hadron physics we deal with interactions that are not driven by simple Lagrangian or Hamiltonian dynamics. We cannot proceed unless we restrict ourselves to specific near-threshold interactions. We cannot derive the scattering amplitudes from first principles.\n\n\n\n\n\n\nFigure 2: This figure represents a schematic energy spectrum of hadronic states, specifically showing the quantum mechanical levels of a two-particle system (for instance, a pion–pion or pion–strange meson system) as a function of a variable labeled “lqq,” which likely refers to quantum numbers or a kinematic variable relevant in the study of hadron physics. The vertical axis is energy ( E ), while the horizontal axis shows “lqq”. The diagram features boxes corresponding to different energy levels and angular momentum (orbital) quantum numbers: - “1S” and “2S” indicate the first and second S-wave (zero orbital angular momentum) states, while - “1P” indicates the first P-wave (one unit of orbital angular momentum) state. In the context of the lecture, which discusses scattering theory, analytic properties, and resonance spectroscopy, this diagram illustrates how physical resonances (hadronic states) appear as discrete levels in energy for two-particle systems, categorized by their angular momentum. The variables within the boxes—such as a_0, a_2, b_4 —represent scattering parameters or possibly resonance parameters like scattering lengths (for different partial waves). This reflects how amplitude analysis and the study of analytic functions in the S-matrix formalism enable the extraction and classification of resonance parameters from the energy dependence of scattering amplitudes. The structure of the levels ties into discussions of analytic properties, poles (resonances), and real analyticity as these physical states correspond to singularities (poles) in the complex energy plane.\n\n\n\nInstead, a different approach is used. We study the general principles of scattering theory. And it appears to be constraining enough to derive the general form of the amplitude, having parametric freedom in certain places that can be fixed from the data.\nTherefore, the approach that is utilized in hadron physics to describe the scattering of hadrons, especially from experimental data, is to use general parameterizations of the amplitudes that satisfy unitarity and analyticity.\nRarely crossing symmetry, very rarely can be included. And then we fix the parametric freedom and get the scattering amplitude as a mathematical expression and study its properties.\nWhile studying the properties of the scattering amplitude, we get properties of the objects that we describe, the resonances. So that’s the program of hadron spectroscopy: amplitude building and using scattering theory tools to have access to the properties of the objects.\nWe study resonances and analyticity is one of the constraints; unitarity is another one, especially telling that the function is constrained in different regions of the variables.\nIf a function depends on s and t , this function must extend, since its validity goes beyond the physical region, and extra constraints come in. And then we consider the amplitude as a complex function of its variables. The scattering amplitude.\nWhile observables are all real values. The cross section is a real number. The amplitude itself is a complex number and it has a value; it has an absolute value and it has a phase. And this in turn gives important information about the scattering process.\nLet me start with the fact that as we saw in the problem we discussed there, the amplitude was a function of the two variables s and t .\n\n\n\n\n\n\nFigure 3: This figure illustrates the analytic structure and kinematic channels of the pion-pion ( \\pi\\pi ) scattering amplitude as a function of the Mandelstam variable s : - Left Side (Complex s -Plane): The horizontal axis represents the real part of the complex Mandelstam variable s , and the vertical axis is the imaginary part. The amplitude A_{\\pi\\pi \\rightarrow \\pi\\pi,\\rho}(s) is analytic except along cuts, which are indicated on the real axis. The solid blue line starting at the threshold 4m_\\pi^2 (where m_\\pi is the pion mass) represents the s-channel unitarity cut, i.e., the physical region where two-pion production becomes kinematically allowed. This is the beginning of the non-analytic region associated with the opening of the \\pi\\pi channel. The blue region labeled “u-channel” on the negative real axis represents the unitarity cut for the crossed channel, corresponding to different intermediate states due to crossing symmetry. The label “cardinal sheet” refers to the principal (physical) Riemann sheet of the analytic amplitude. The threshold marks the onset of physical two-pion states, relating to where the imaginary part of the amplitude (discontinuity) develops, as discussed under analytic and real analytic functions and their branch cuts. - Right Side (Feynman Diagram): This shows a generic 2 \\to 2 pion scattering process: two incoming pions ( \\pi_1, \\pi_2 ) scatter via an interaction blob into two outgoing pions ( \\pi_3, \\pi_4 ). The Mandelstam variable s labels the center-of-mass energy squared of the incoming channel, and t labels the momentum transfer. This diagram is used to define the physical process that the complex s -plane structure corresponds to, connecting the analytic properties of the amplitude to physical scattering. Physical meaning in context: This figure visually connects the analytic properties (cuts, thresholds, Riemann sheets) of the scattering amplitude in the complex s -plane with their physical origins in pion-pion scattering. Concepts like the unitarity cut, threshold, and crossing symmetry (s-channel and u-channel) are depicted, illustrating how non-analyticities (branch cuts) in the amplitude arise from opening physical channels—key points in the study of analyticity and scattering theory as discussed in the lecture.\n\n\n\nSo it’s a multivariable function.\n\n\n\n\n\n\nFigure 4: This figure illustrates the physical manifestations of different singularities of the scattering amplitude a in the complex energy plane, as discussed in the context of analyticity and amplitude analysis. The horizontal axis represents \\sqrt{s} , where s is a Mandelstam variable related to the squared center-of-mass energy, while the vertical axis shows |a|^2 , the squared modulus of the scattering amplitude, which is related to observable probabilities or cross sections. - The top panel depicts a resonance, characterized by a pronounced peak in |a|^2 above the threshold. The resonance is associated with a pole in the complex s -plane near the real axis. The curve rises sharply, reaches a maximum (the resonance energy or mass), then falls off. The threshold marks the lowest energy where the reaction can occur. The nearby branch point is also indicated, signifying the opening of the physical channel (threshold), and the analytic continuation shows how singularities influence the physical amplitude. - The middle panel shows a bound state, which appears as a divergence in |a|^2 below the threshold, indicated by a pole on the real axis below threshold. This manifests as a sharp feature (essentially a “delta function”-like effect in the cross-section) signaling a stable particle or state that cannot decay into the considered channel. - The bottom panel demonstrates a virtual state, which manifests as a cusp or an enhancement right at the threshold, but there is no true resonance peak or bound state pole on the physical sheet. The cusp reflects the analytic structure of the amplitude due to a pole on the unphysical sheet, which doesn’t correspond to a particle but still impacts the observable cross-section near threshold. These cases illustrate how underlying singularities in the analytic structure of the scattering amplitude (poles and branch points in the complex s -plane) physically manifest as observable features—resonances, bound state divergences, or threshold cusps—in experimental scattering data. The analytic continuation concept is critical for understanding how such “hidden” (complex-plane) singularities influence real, measurable quantities due to the analyticity and real analytic properties of the amplitude.\n\n\n\nIt’s a complex multivariable function.\nIt appears that we will get some benefits and new insights into the amplitude if we consider not just the amplitude to be a complex function, but also for it to be a function of complex variables.\nSo what we are going to do as the sort of imaginary and theoretical part of the theoretical exploration is we will make our s variable—a physical thing, something that used to be physical—we will make it complex.\nWe’ll see what the properties of the amplitude are when we make the energy of the scattering complex, or when we make the angle of the scattering a complex number, not 30 degrees, but 30 degrees plus i or something. And we’ll see it gives us new insight.\nSo what is important for us is not just that the amplitude is a complex function, but also that it’s an analytic function of its arguments everywhere in the complex plane, except a few minor segments.\nBefore going into the details, I would like to discuss analytic functions. So here is the mathematical part of the lecture. I would like to remind you what analytic functions are, or the other way we call them is holomorphic.\nHolomorphic just simply means analytic. Holomorphic or analytic functions are functions that match their Taylor series in the vicinity of every point of the complex plane or of the domain.\nIf you look in mathematics books, it says an analytic function is one that is complex differentiable everywhere in the complex plane. But we will consider a domain of analyticity. The function doesn’t have to be analytic everywhere in the complex plane, but in certain domains.\nAnd then in that domain, complex differentiability simply means that it’s equal to its Taylor series. So there is a polynomial series that approximates the function exactly at every point of the plane or in the vicinity of every point.\nI could remind you what the Taylor series means, but you probably remember that expression with the derivatives—essentially a polynomial. That’s the point. And the series can go to infinity, but the function must match it.\nLet’s discuss examples. Clearly, if required, the function matches the polynomial series. Any polynomial function is analytic in \\mathbb{C} . Polynomials are excellent functions analytic everywhere, but also the boring functions like the square root of z , log z , are functions that are analytic everywhere except on a line segment.\nThis line segment is the cut. For every cut we have two branch points. Sometimes one of the branch points is at infinity, another in the finite range. And then the line that connects the branch points is called the branch cut.\n\n\n\n\n\n\nFigure 5: This figure illustrates the analytic structure of a function in the complex z -plane, focusing on the concept of branch points and branch cuts. The point at the origin is labeled as a branch point, from which a branch cut extends along the negative real axis. This reflects the analytic properties of functions like \\sqrt{z} , which are analytic everywhere except along the branch cut that starts at the branch point (here, z=0 ). Physically, in the context of the lecture, this is used to describe how complex functions (such as scattering amplitudes) behave: they are analytic in most of the complex plane, but exhibit non-analytic behavior (discontinuity) when crossing the branch cut. At points just above or below the cut (e.g., f(-1 + i\\epsilon) vs. f(-1 - i\\epsilon) ), the function takes different values, highlighting the multivalued nature due to the branch point. This property is crucial for understanding the analytic structure of scattering amplitudes, where cuts and branch points correspond to physical thresholds and the opening of new channels, and dictate how analytic continuation—and hence the exploration of resonances, unitarity, and causality—are treated in quantum field theory.\n\n\n\nLet me draw a few examples convenient to discuss. The z plane, where along the x axis we have the real part of z and the y axis is the imaginary part of z . And then for every point I can plot, it is the real part plus i times the imaginary part.\nSo what I can do using this plot is to indicate where a function is analytic and where it is not. There are regions of non-analyticity. For example, for the function square root of z , there is a branch point at zero and a branch cut going to the left, indicating that if I compute the function on one side and on the other side I get different values.\nIf I compute the square root of z at minus 1 plus a little bit, I get plus i.\n\n\n\n\n\n\nFigure 6: This figure illustrates the analytic structure of the function f(z) = \\sqrt{z - 1} in the complex z -plane. The horizontal axis represents the real part of z ( \\mathrm{Re}(z) ), and the vertical axis represents the imaginary part ( \\mathrm{Im}(z) ). The blue wavy line begins at the point z = 1 on the real axis and extends to -\\infty along the real axis. This line marks the branch cut of the function, which connects the branch point at z = 1 to -\\infty . Physically, this illustrates the concept that functions like \\sqrt{z-1} , which appear in the description of scattering amplitudes, are analytic everywhere in the complex plane except along their branch cut. The presence of the branch point and associated cut means that the value of the function is discontinuous across the cut, reflecting the multi-sheeted nature of such complex functions. This analytic structure is fundamental in understanding how scattering amplitudes behave as functions of complex variables, especially when we discuss analytic continuation and the physical meaning of singularities and discontinuities in scattering theory.\n\n\n\nAnd if I compute it from that side, I get minus i.\n\n\n\n\n\n\nFigure 7: This figure represents the analytic structure of the complex function f(z) = \\sqrt{z-1} - \\sqrt{z} in the complex z -plane. The real axis is labeled as “Re” and the imaginary axis as “Im.” The blue wavy line running from z = 0 to z = 1 along the real axis indicates a branch cut—a region where the function is non-analytic due to the multivalued nature of the square root functions. Physically, this branch cut corresponds to a discontinuity in the value of the function as you cross from just above to just below the real axis, reflecting a non-trivial analytic structure. In the context of scattering amplitudes discussed in the lecture, such branch cuts represent kinematic thresholds—boundaries in the complex energy plane (or similar Mandelstam variables) where new physical processes (such as particle production) can occur and the amplitude develops an imaginary part. This analytic feature is essential for understanding the behavior of scattering amplitudes, as the existence and location of branch cuts (and their associated branch points at z = 0 and z = 1 ) dictate where the amplitude ceases to be real and begins to have a discontinuity—properties crucial for unitarity and the correct physical description of processes.\n\n\n\nIt doesn’t happen on that side. If I compute the function at 1 plus i epsilon, I get one. And if I compute it from that direction, like 1 minus i epsilon, I also get one.\n\n\n\n\n\n\nFigure 8: This figure represents the analytic structure of the function f(z) = \\sqrt{-z} in the complex z -plane. The plot shows a branch cut along the positive real axis, indicating the line segment where the function is non-analytic. This cut starts at the branch point at the origin ( z=0 ) and extends to +\\infty along the real axis. Physically, in the context of scattering amplitudes, such branch cuts correspond to the thresholds for physical processes, such as the onset of particle production or scattering channels, and the branch point represents where a new channel opens. The function is analytic everywhere else except along this branch cut. The existence of the branch cut is a manifestation of the multi-valuedness of the function (here, due to the square root), and the discontinuity across the cut reflects the appearance of an imaginary part in the amplitude, related to inelastic processes and the unitarity cut in scattering theory. This structure illustrates how analytic functions in physics, such as scattering amplitudes, are characterized by their branch points and cuts in the complex plane, which encode essential physical information about reaction thresholds and continuations to different Riemann sheets.\n\n\n\nBut on that side there is a discontinuity of the function.\nJust to demonstrate that the branch cut doesn’t have to be at 0. For the function square root of z - 1 , the branch cut starts at 1 and goes backwards. For the function square root of -z , the branch cut starts at 0 and goes upwards.\n\n\n\n\n\n\nFigure 9: This figure illustrates the analytic structure of the function f(z) = \\sqrt{z^2 - 1} in the complex z -plane, specifically highlighting the locations of branch cuts and branch points. The real and imaginary axes are labeled as “Re” and “Im,” and the function is annotated in the upper right. Physically, in the context of the lecture, this type of function models the analytic structure one encounters in scattering amplitudes, where the square root reflects the opening of new channels or thresholds. The blue wavy lines represent branch cuts: one running from -\\infty to -1 along the real axis, and another from 1 to +\\infty , indicating non-analytic (discontinuous) behavior of f(z) across these intervals. The endpoints z = -1 and z = 1 are branch points, signaling the start of the branch cuts and corresponding to physical thresholds (like the onset of new particle production in scattering). This structure encodes how the amplitude (or any analytic function with such a branch cut structure) changes its value when moving around these points in the complex plane, which is crucial for understanding phenomena like the development of an imaginary part (related to physical processes becoming possible) and the analytic continuation to different Riemann sheets—core ideas in the analytic S-matrix approach discussed in the lecture.\n\n\n\nFor the function square root of (z - 1) z , the branch cut starts at zero and goes to 1. For the function square root of z^2 - 1 , the branch cut is more complicated. It starts at 1, goes to 0, then to plus infinity, comes back from minus infinity to minus 1.\nThe last example is the log of z . And in that case the branch cut starts at zero and goes backwards. Another class of functions and another type of singularities that is present is the poles. Poles are the functions that have poles.\nThey are isolated singularities where a function approaches infinity, complex infinity. So let’s say \\frac{1}{z - 1 + i} . So when z is equal to 1 - i , we approach the pole of the function, the function is undefined, it’s complex infinity.\n\n\n\n\n\n\nFigure 10: This figure illustrates the concept of a pole in the complex plane, which is a type of isolated singularity important in the analytic structure of scattering amplitudes. The function shown, f(z) = \\frac{1}{z - 1 + i} , has a pole at z = 1 - i , indicated by the black dot on the diagram at that coordinate in the complex z -plane (with the real and imaginary axes labeled). Physically, such poles in the scattering amplitude correspond to resonances or bound states in hadron physics; the amplitude becomes very large near the pole, signaling a strong “signal” or enhancement in the cross section. In the analogy provided in the lecture, the pole is like an “internet router”—the amplitude is strongest (largest) when you are closest to the pole in the complex plane, reflecting elevated probability or cross section values in experiments. Thus, this figure emphasizes how the analytic properties—specifically the location and nature of poles—encode key physical information about the behavior of scattering processes and resonances.\n\n\n\n\n\n\n\n\n\nFigure 11: This figure illustrates the analytic continuation of the scattering amplitude A_{\\pi\\pi \\to \\pi\\pi, \\rho}^{II}(s) onto the second Riemann sheet in the complex s -plane. In the context of this lecture, the figure shows that: - The real axis (horizontal line) represents physical values of the Mandelstam variable s , with the thick segment (branch cut) indicating the area where the imaginary part of the amplitude appears due to the opening of physical thresholds (e.g., two-pion production). - The branch cut is associated with the onset of physical intermediate states (unitarity cut), and analytic continuation through this cut leads to a different “sheet” of the function—a key concept in complex analysis of scattering amplitudes. - The second Riemann sheet (notated with II ) is accessed by analytically continuing the amplitude through the branch cut—this is where resonance poles appear. These poles correspond to unstable particles (resonances), which manifest as enhancements (“bumps”) in the cross section in physical processes. - The figure also marks a virtual state (star on the imaginary axis left of threshold), representing a singularity not associated with a physical particle, but with a non-observable state. - Thus, the physical meaning is that the analytic structure of the scattering amplitude in the complex s -plane, especially the nature and position of its singularities (poles and cuts), encodes information about observable resonances and virtual states in hadron spectroscopy. This is a direct consequence of considering the amplitude as a real analytic function and performing analytic continuation. In the context of the lecture, the figure emphasizes how complex analysis and the concept of Riemann sheets are essential for understanding the nature of resonances in scattering theory.\n\n\n\nOnce we go away from this point, the amplitude value is really high. So what I want to say is that that pole value would feel this pole value even being away from it. But we will see that all of the features that we see in the scattering, like bumps or cusps, they are related to the singularities in the complex plane.\nThe branch points are just doors to other domains of analyticity. The poles are something that makes the strength of the amplitude. I was thinking of this nice example of the complex multi-floor house that has many Internet routers and you have a router.\nSo the poles are your routers. And if you want to have a strong Internet, you better sit next to the router and that provides you a signal. And if you are as close as you are to this Internet router, the better Internet you have, it’s better. It’s a higher value of the absolute value of the amplitude you have.\nIf you measure the process and you see that this cross section is large, something must be driving this large cross section. And it’s probably a pole somewhere in the complex plane.\nInteresting things about the cuts. One thing to consider is that the cuts are the doors to other domains, every cut. You probably have heard the saying that branch points are fixed, but the way you draw the cuts is arbitrary, up to you.\nThat—I don’t like this way of putting it—but this is another way of saying that the way we draw the cut, you can draw the cut differently by extending the domain of the function. The way I’d like to think of this is that for every cut, you can come up with a different function.\nWhat I mean is the following. You deal with a function that has a branch point at zero and the cuts towards the left. And the claim is, you can come up with a different function, call it F_2 , that’s defined in the complex plane such that it’s analytically continuous.\nThe function above the cut analytically continues into the domain of analyticity. So I can come up with a different function. In that case, it’s \\sqrt{z} . But I can tell you the recipe to come up with this F_2 such that if you join the function, you take this domain and that domain, so there are no cuts any longer.\nThe branch point is still there, but the function is analytic in this domain. If I take this and that, one can see this as the way to go beneath the cut. So I can analytically continue the function down. And that’s the perspective that I offer.\nThat’s, I think, the easiest way to wrap your head around it. There is a function defined everywhere in \\mathbb{C} except a finite number of points, except a finite number of segments. And you can compute. If I ask you to compute a value, you can compute the value everywhere.\nThe cut locations are fixed; we don’t touch them. We just come up with a different function F_2 that’s, again, for starters, it has nothing to do with F . It’s again another function that I define everywhere except a finite number of segments.\nBut what makes us consider them together? The one analytically continues the other. Maybe it’s a bit late, but if you come back to this function, square root of z - 1 , minus s . Shouldn’t there be two branches? Two branch cuts. One from 1 to infinity, from 0 to infinity.\nIf it’s a minus, you’re right. But if it’s multiply, then that’s. And well, we can go back here. For all of the functions with the cuts, we can discuss what is F_2 , what function makes analytic continuation.\nFor that function we can discuss that. For any of them, you can ask me a question. What happens? What function would analytically continue the domain of analysis in that direction? And I know the answer. Just a minus sign here or here or there.\nFor any way you approach the cut, there should be analytic continuation. The other notion, the other way people talk about that is the Riemann sheets. Instead of saying that there is one function, second function, third function, people say there is just one function that is multivalued and it has a value on different Riemann sheets.\nBut that’s the same as saying that there is F_1, F_2, F_3 . So F_1 is the value of the function on the first Riemann sheet. F_2 is the value of the function on the second Riemann sheet. And so on.\nSo then, can you come up with the analytic continuation? That guy, that guy and that guy. But you tell me what F_2 would look like here if I want to analytically continue. And then here, so quickly, what is F_2 ? What is F_3 here? No, minus, simply so, when you have a square root, the other sheet or the other branch is simply minus, and you convince yourself by computing +\\epsilon .\nSo F_1 at +\\epsilon and F_3 at +\\epsilon should be equal to each other if the continuation is correct. And then here, what is F_2 ? No, it can’t be the same, because I can demonstrate that with log.\nSo here, F_1 is the log of minus 1 plus i epsilon is equal to \\pi i . And on that side, log of minus 1 minus epsilon is equal to minus \\pi i .\n\n\n\n\n\n\nFigure 12: This figure illustrates the concept of real analyticity for complex functions in the context of scattering amplitudes. The shaded segment along the real axis represents the domain where the function f(z) is real. When moving away from this segment into the complex plane (either above or below the real axis), the function develops an imaginary part: moving upward in the imaginary direction leads to a positive imaginary component, while moving downward results in a negative imaginary part. This behavior reflects the Schwarz reflection principle, which states that the value of the function at a point and its complex conjugate are related such that f(z^*) = f^*(z) . Physically, this underpins the analytic properties of scattering amplitudes and ensures that discontinuities across cuts in the complex plane are purely imaginary, as discussed in the lecture.\n\n\n\nNo, it’s a plus.\n\n\n\n\n\n\nFigure 13: This figure illustrates the analytic structure of a scattering amplitude as a function of the Mandelstam variable s in the complex s -plane. The real axis represents physically allowed values of s , while the imaginary axis corresponds to complex (unphysical) values. The branch points at (m_1 - m_2)^2 and (m_1 + m_2)^2 indicate the kinematic thresholds for particle production in the scattering process, i.e., the minimal and maximal invariant mass squared for producing particles of masses m_1 and m_2 . Between and beyond these points, the amplitude develops branch cuts (shown as wavy lines), which represent the discontinuities or non-analytic regions associated with the opening of physical channels. The blue annotation that “the branch cuts cancel out → function is continuous” emphasizes that, across certain regions (possibly when combining different contributions or sheets), the discontinuity due to the branch cuts can be made to vanish, resulting in a function that is continuous in the complex plane except at the branch points themselves. This reflects the property of real analyticity discussed in the lecture: the amplitude is analytic everywhere except along the physical cuts, and across the real axis (below threshold) it is continuous and real. The Schwarz reflection principle guarantees that the amplitude behaves smoothly except precisely along and across these branch cuts. Physically, this diagram encodes how the analytic properties of the scattering amplitude connect to physical thresholds, and how analyticity and unitarity restrict the possible singularities (cuts and poles) in the complex s -plane. The function is analytic except for these branch cuts associated with the creation of intermediate states or particles.\n\n\n\nSo, and the way to see that is we computed this already and it’s minus \\pi i .\n\n\n\n\n\n\nFigure 14: This figure illustrates the analytic structure of the scattering amplitude A(s) in the complex s -plane, demonstrating the physical meaning of different singularities and cuts as discussed in the lecture. The real axis \\mathrm{Re}(s) corresponds to physical kinematic values, with a branch cut (in magenta) starting at the threshold s &gt; s_{\\text{th}} , representing the onset of physical scattering (the unitarity or right-hand cut). The blue and green lines indicate different analytic domains or “sheets” of the amplitude. The orange point above the real axis on the imaginary axis denotes a “bound state” pole, corresponding to a stable particle below threshold on the physical sheet. The orange point below the real axis, labeled “virtual state,” represents a pole associated with an unstable or non-physical state (on the unphysical sheet). The orange crosses on the lower half-plane, labeled “resonances,” represent poles associated with resonant states—unstable particles that manifest themselves as peaks in the cross section—on the second Riemann sheet ( A^{II}(s) ). The diagram also demonstrates how the amplitude A(s) behaves in various regions, showing the importance of analytic continuation and Riemann sheets: the physical amplitude is found on the first (physical) sheet, while resonances and virtual states manifest as poles on other sheets, accessible via analytic continuation across the cut. This structure encodes the complex analytic (and real analytic) nature of the scattering amplitude, the linkage of poles to observable physical phenomena, and the impact of branch cuts associated with multi-particle thresholds.\n\n\n\nIf we add 2 \\pi i , we will have the value on that side, so F_2 equals to plus \\pi i , so it will analytically continue. Why is it Sheet 3 right away? Oh, it’s not Sheet 3, it’s just labeling. You can call it 2 or. Well, it’s up to me.\nI can call the function going in that direction. So the other function, F_3 , that is analytically continued would be the one that analytically continues from below, and the one from above is F_2 . It’s just my notation.\nAn interesting aspect that is closely related to the scattering amplitude is the concept of real analyticity. One can take the words “real analytic” literally: a real analytic function that is analytic and real.\nI would like to extend this definition and call the functions real analytic if it has a segment along the real axis, then it’s real. Like this is again my z-plane and then this is my x-axis where the z is real.\nI compute the F of the real value and I get a real value for the function. It turns out that once you have this function, it has very peculiar properties. It satisfies the reflection principle. The function is real on this segment.\nAnalyticity is sort of a special type of continuity of the function. This implies that once you start going away from the real axis, the imaginary part must appear. So the function cannot stay real once you go away from the real axis and it will start appearing in the opposite direction.\nIf an imaginary part develops in the positive direction once you go up from the real axis, it must go to the opposite negative direction if you go down from the real axis. That’s essentially what the Schwarz reflection principle tells you.\nThe imaginary part of that point is going to be opposite to the imaginary part of the symmetric point. You simply, oh, here you see that I put a star. Star means complex conjugation, which means flip the imaginary part.\nWe started by discussing the function that just has a similar single segment of real values. And then if you follow that consideration and do analytic continuation, you realize that the only way for this function to stop being real on the real axis is to get a branch point.\nThe function along the real axis is real on a segment and only becomes non‑real once you introduce the branch point. The only way for the function to get an imaginary part is to get the branch point and the cut, for exactly the same reason you have a segment where the function is real here and the imaginary part develops to the.\n\n\n\n\n\n\nFigure 15: This figure illustrates the analytic structure of the scattering amplitude A(s, t) as a function of the complex Mandelstam variable s , for fixed t . The horizontal axis represents the real part of s ( \\text{Re}(s) ), while the vertical axis is the imaginary part ( \\text{Im}(s) ). The depicted thick lines along the real axis correspond to the branch cuts associated with physical thresholds for two different scattering channels: - The threshold for the s-channel is marked on the positive real- s axis. This is where physical s-channel particle production can occur and corresponds to the opening of the unitarity cut. - The fixed threshold for the u-channel is indicated on the negative real- s axis. This relates to the production threshold for the crossed (u-channel) process. The region between the cuts, on the real s -axis below threshold, is labeled “real analytic,” indicating that the amplitude is real and analytic in that segment — in accordance with the property of real analytic functions discussed in the lecture. The cuts themselves signify the locations where the amplitude develops an imaginary part (discontinuity), corresponding to physical particle production (unitarity cuts). This diagram physically encodes how the analytic (and specifically, real analytic) properties of the scattering amplitude in the complex s -plane reflect causality and unitarity, with thresholds demarcating the transition points where new physical channels become accessible. These analytic properties are crucial for defining the amplitude’s behavior and for connecting it to physical observables.\n\n\n\nSo imaginary part on that side is positive, imaginary part on that side is negative. That’s why the discontinuity around the cut is going to be twice the imaginary part, because they are developing in opposite directions.\nSo now that’s the second lowest threshold opening. Any segment along the real axis would be like closed or open. I’m thinking about. I mean, analytic functions always have an open domain. They have to. As soon as you have an open domain, you can always come.\nSo from A to B you can always come with the closed domain. So A minus i epsilon is included. My point is that as soon as you include one of those edges, you cannot put some kind of small circle around it and then say it’s still smooth.\n\n\n\n\n\n\nScattering amplitudes are real analytic functions of s (for fixed t ), meaning they satisfy the Schwarz reflection principle. This is tied to causality and implies specific symmetry in the complex s -plane: A(s^*, t) = A^*(s, t)\nThis property ensures that the amplitude is real along the real axis below thresholds and that discontinuities across cuts are purely imaginary, e.g., \\text{Disc} \\, A(s, t) = 2i \\, \\text{Im} \\, A(s, t) along the unitarity cut."
  },
  {
    "objectID": "2025-Lecture-11.html",
    "href": "2025-Lecture-11.html",
    "title": "(2025) Lecture 11",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Anna Zimmer"
  },
  {
    "objectID": "2025-Lecture-11.html#branch-points-and-cuts-in-ππ-scattering-amplitudes",
    "href": "2025-Lecture-11.html#branch-points-and-cuts-in-ππ-scattering-amplitudes",
    "title": "(2025) Lecture 11",
    "section": "1 Branch Points and Cuts in ππ Scattering Amplitudes",
    "text": "1 Branch Points and Cuts in ππ Scattering Amplitudes\nSo the threshold for ππ scattering occurs at s = 4m_\\pi^2 .\nAre there any other open channels? For this discussion, let’s assume there are not.\nThe position of the branch point in the complex s -plane is precisely at s = 4m_\\pi^2 . The associated branch cut should be drawn from this branch point. While the exact direction is technically a matter of definition, the physical branch cut that satisfies causality is drawn along the real axis to the right, from s = 4m_\\pi^2 to infinity.\n\n\n\n\n\n\nPhysics of the s-channel branch point: This point, s_{\\text{th}} = 4m_\\pi^2 , is the minimum squared center-of-mass energy needed to produce two real pions. In the complex plane, it is a square-root branch point. Placing the cut along the positive real axis defines the physical Riemann sheet, where the scattering amplitude is analytic except for discontinuities across this cut.\n\n\n\nWe must also consider crossing symmetry. The reaction isn’t only \\pi\\pi \\to \\pi\\pi in the s -channel. If we consider the ** t -channel** (the crossed channel), a different process becomes relevant.\nFor the specific process \\pi^+ \\pi^- \\to \\pi^+ \\pi^- , the t -channel corresponds to the scattering \\pi^+ \\pi^+ \\to \\pi^+ \\pi^+ (or equivalently, \\pi^- \\pi^- \\to \\pi^- \\pi^- after crossing).\nThis leads to another branch point in the complex s -plane, appearing at negative s values for physical momentum transfer t . This is the ** t -channel threshold**.\n\n\n\n\n\n\nCross-channel analytic structure: Crossing symmetry implies the amplitude A(s,t) is analytic in s with cuts from both channels. The t -channel threshold at t = 4m_\\pi^2 corresponds to a branch point in the s -plane at s = 4m_\\pi^2 - t . For physical t &gt; 0 , this point lies on the negative real s -axis, creating a left-hand cut. The full analytic structure—with a right-hand cut from the s -channel and a left-hand cut from the t -channel—is foundational for dispersion relations."
  },
  {
    "objectID": "2025-Lecture-11.html#analytic-continuation-and-resonances-in-ππ-scattering",
    "href": "2025-Lecture-11.html#analytic-continuation-and-resonances-in-ππ-scattering",
    "title": "(2025) Lecture 11",
    "section": "2 Analytic Continuation and Resonances in ππ Scattering",
    "text": "2 Analytic Continuation and Resonances in ππ Scattering\nWhen we talk about scattering amplitudes, we are thinking of a blob connecting an initial to a final state. In that case, π₁ and π₂ scatter. We draw the blob and think of this as time going in that direction. This is the initial state. They come together, something happens, they come out of the blob, and that scattering process is referred to as a channel. This is well-defined kinematics and a physical process.\nOnce the energy in the initial state is higher than the threshold, the total energy of the system for this process to happen must be higher than 4m_\\pi^2 . Then the pions in the initial state can fly and the pions in the final state can fly. It happens that there is another process.\n\n2.1 Kinematic Variables and Analytic Continuation\nThere are the variables that we defined here: it was s and here was t . For the physical process, s was positive above the threshold; t was negative because this is a transferred momentum, and for an elastic reaction it’s actually less than zero. If we think of this amplitude as an analytic function of s and t , it is defined in the entire domain of the complex plane, in the entire domain of the variables s and t .\nOnce we define this object, it should be defined for any variable s , even negative, and for any variable t , even positive, despite them not being in the kinematics of this channel. We find out that the same amplitude would describe \\pi_1 \\bar{\\pi}_3 \\to \\pi_2 \\pi_4 .\nWhat I’ve done here is I took one particle, one leg here and said, let me just turn it, rotate this diagram. I take this leg, put it here, I take this leg, I put it here. It’s the same blob, just in a different direction, so it must be the same object. We draw it and then we realize that it’s just different variables of s and t that describe the kinematics for that process.\nIt’s a t that has to be positive because it’s above the threshold, because we are now in a different domain for this reaction. The t is defined as the sum of these two. The language that we use is that that is the cross channel for that.\n\nIn the s-channel, s = (p_1 + p_2)^2 is the squared center-of-mass energy and must satisfy s &gt; 4m_\\pi^2 for the physical process \\pi\\pi \\to \\pi\\pi .\nIn the t-channel, the same analytic function A(s,t) describes the crossed process \\pi_1 + \\bar{\\pi}_3 \\to \\pi_2 + \\pi_4 , where t becomes the positive squared center-of-mass energy.\n\n\n\n\n\n\n\nFigure 1: This figure represents a schematic illustration of a scattering process in the context of scattering theory discussed in the lecture. The large circle can be interpreted as the “blob” denoting the interaction region or amplitude where an initial two-particle state (for example, two pions) interacts. The two darkened points on the circumference symbolize the initial and final states (or, more generally, the incoming and outgoing particles). The double-headed arrow connecting these points, with an “×” at the top, indicates the scattering angle, which is a key kinematic variable in the description of the process. Physically, this diagram is used to visualize two particles approaching, interacting via the strong force inside the blob (the region where the amplitude is defined), and then emerging as outgoing particles. The scattering angle (as shown by the arrow) is directly related to the momentum transfer, which is often encapsulated by the Mandelstam variable t  in the lecture. This type of drawing is central to understanding partial wave analysis and to visualizing how the scattering amplitude depends on kinematic variables like s and t . The “×” at the top may indicate a measurement or a particular value of the angle of interest. This picture is foundational for connecting graphical representations of reactions to formal analytic properties, such as branch points and cuts in the complex plane described in the lecture.\n\n\n\nIn the s plane, once you do partial wave projections, you’re going to see the reflection of the cross channels as the branch points on the other side. For physical positive and high value of s , it’s an s-channel scattering. For negative s , it’s a partial wave projection of the t-channel scattering or u-channel. The u-channel would be when you take this four and put it to the other side.\nJust to remind you of what we discussed with this domain: if you draw here s , you put here t . Our physical reaction sits here. Then there is the cross channel positive t . There is a domain here and a domain here. That was for introducing this non-distant point.\n\n\n2.2 Riemann Sheets and Resonance Poles\nIn fact, this amplitude is a rather complex object. There are no singularities elsewhere in this plane. We discussed that we can come up with, in order to explore the full dimensionality or the full analytic structure, we can come up with another function, let’s say not A but A_2 , that analytically continues the amplitude on the other side of the branch point.\nThat was referred to as the second sheet, the second Riemann sheet. That’s where the interesting and impactful physics is lying. These are the singularities I am talking about. Virtual states are on the other and physical. What I’m saying is that I can come up with the A_2 , \\pi\\pi \\to \\pi\\pi , that analytically continues my amplitude from below the cut.\nThat amplitude will have a very similar analytic structure. We have the branch point here and this function will continue. The values right here above will be exactly the same as right below for that function. This is the location for the virtual state and this is the location for the resonances.\n\n\n\n\n\n\nThe physical amplitude A(s) has a branch cut along the real axis for s \\geq 4m_\\pi^2 . Analytic continuation through this cut leads to the second Riemann sheet, where resonance poles are located. Every particle corresponds to a pole in the complex plane of the scattering amplitude. For a resonance like the \\rho meson, the pole is at s_p = M_\\rho^2 - i M_\\rho \\Gamma_\\rho , where M_\\rho is the pole mass and \\Gamma_\\rho is the width.\n\n\n\n\n\n2.3 The ρ Meson in ππ Scattering and the Quark Model\nWhich resonance is present in this scattering \\pi\\pi in P-wave? In fact, it’s the \\rho meson. I really like to think of mesons in terms of the quark model constitution. Let me just remind you what it is about: 1s , 1p , 2s . Here I have a spin and \\rho meson. I have a pion and another \\rho meson. There’s two s excitations.\nHere I have states, four states. They’re called a… On which axis would you put energy? And here they put angular momentum. Angular momentum. But in the quark model, angular momentum between quarks L_{q\\bar{q}} . If you think of the quark of the hydrogen atom, this is what you find: the Bohr structure in the boxes, 1s , 2s . 1p is the sort of overall Bohr structure of the spectrum.\nBut then there is hyperfine splitting related to the spin-spin and spin-orbit interaction that makes splitting of the levels. Every time I’m talking about mesons, it’s really helpful to think of this picture like this. I’m saying, you know, J/\\psi , \\eta_c , \\chi_c . It’s a c \\bar{c} , right. And then where in the spectrum would it belong? It actually sits here. The first one is \\eta_c . The second one is the J/\\psi .\nAnd then you say you hear \\chi_{c2} . Where is that? Oh, this is again c \\bar{c} but sits in this box because it’s a 1^+ quantum numbers. This is the 1P state in the quark model. That’s super easy, and then you’re able to relate to get a bigger picture. There are so many mesons and resonances, but they all map into this rather simple structure, well, if you don’t talk about exotics, that’s still a minority.\nThis was a side remark and that’s… I would really like you to familiarize yourself with this type of representation for the mesons. For the baryons we can do the same. What is important for our discussion here is the singularities in the scattering amplitude.\nI just said that the \\rho meson decays to \\pi \\pi . This is one of the peculiarities of quantum chromodynamics because in the hydrogen atom, the transitions between states that are hyperfine, that are related within the same box, happen with radiation. In the hydrogen atom, the difference between these two states is actually the quark orientation.\nThe pion has the sort of the quark orientation disk like this one, q has the… So the wave function is like this. The \\rho meson has a different spin wave function. That’s the only reason, the only difference between the \\rho meson and the pion in the quark model.\nBut the transition between \\rho and \\pi , despite that it can happen radiatively by emitting a photon and flipping the spin of the quark, it prefers to happen via emitting a pion. So \\rho goes to the pion by emitting another pion. That’s something unimaginable in a hydrogen atom. Imagine that the atom would decay by emitting another atom.\nThat’s not how baryons… That’s not how it works in electrodynamics, but in quantum chromodynamics it’s sort of cheap to make quarks out of the vacuum, like quark-antiquark pairs. That’s why the \\rho -$transition happens with emitting another $.\nTherefore, a$ meson, while being a state, appears as a resonance in the scattering system. If you bring one and another together, they feel that the meson can decay to this pair. So they resonate at a certain frequency, a frequency that is equal to the bare mass of the $meson.\nIt’s not only that a$ meson can decay to the pair, but also when you bring two pions together, they feel attraction due to the presence of this $meson resonance. This attraction manifests as a peak in the spectrum when you measure the scattering amplitude, when you measure the scattering cross section. But also it manifests in a singularity in the complex plane, namely a pole.\nEvery particle is a pole in the complex plane in the scattering amplitude. In order to find this pole, we need to take the scattering amplitude with a rather clear, simple analytic structure and then look more closely at what’s the origin of the peaking. This usually hides in the analytic continuation on the second sheet in the complex plane."
  },
  {
    "objectID": "2025-Lecture-11.html#analytic-singularities-and-cross-section-signatures",
    "href": "2025-Lecture-11.html#analytic-singularities-and-cross-section-signatures",
    "title": "(2025) Lecture 11",
    "section": "3 Analytic Singularities and Cross-Section Signatures",
    "text": "3 Analytic Singularities and Cross-Section Signatures\nNow this naturally continues our discussion. To wrap up the scattering theory, I would like to talk about bound states, virtual states, and resonances. We will introduce the complex plane that doesn’t have any cuts—the key plane—and look quickly at the loop function for two-particle scattering. These concepts play a fundamental role not just in scattering theory, but also once you go to lattice field theory.\nToday’s lecture was meant to be dedicated to lattice field theory and how we use lattice computations to get a better understanding of resonances. I feel we will get to it in the last hour. So, we need to finish the classification of the states and their analytic properties before we go there. Let’s discuss virtual and bound states. Depending on where the singularity appears in the complex energy plane, we call the state differently.\n\n\n\n\n\n\nFigure 2: This figure illustrates a potential well, which is used to explain the difference between continuum states and bound states in quantum mechanics, and by analogy, in scattering theory as discussed in the lecture. The vertical axis is the potential$ V$, and the horizontal axis is the position x . - For energies E &gt; 0 , any energy is allowed, corresponding to continuum states. These are scattering states where the energy lies above the potential well, and the wavefunctions extend to infinity. - For energies E &lt; 0 , only discrete energy levels are allowed, corresponding to bound states. In this region, the wave number k becomes imaginary, leading to exponentially decaying wavefunctions (as indicated by e^{\\pm ikx} \\in \\mathbb{R} ), signifying that the particle is localized within the potential well. - The dashed lines illustrate the quantization of energy levels for bound states, while a continuum of possible energies exists above the well for scattering states. This relates to the lecture’s discussion of bound states (poles on the physical sheet below threshold), virtual states (poles on the unphysical sheet), and resonances (poles above threshold in the complex energy plane). The diagram provides a conceptual and visual context for understanding how physical and mathematical properties of quantum systems manifest as different types of states, as classified by the analytic structure of the scattering amplitude.\n\n\n\nIt also appears differently in the measured mass spectrum.\n\nIf it’s a bump above the threshold, we call it a resonance.\nThere are two more types: virtual states and bound states.\nVirtual states are located on the unphysical sheet below the threshold.\nBound states are located on the physical sheet below the threshold.\n\n\n\n\n\n\n\nFigure 3: This figure represents the energy spectrum of a quantum system, such as two particles interacting via a potential well—an important concept in scattering theory and resonance physics. The vertical axis is the energy E . The energy levels below zero ( E &lt; 0 ) are labeled as “bound states (in potential well),” indicating discrete energy levels corresponding to stable or quasi-stable configurations where the particles are held together by the potential. These states manifest as poles on the physical sheet below threshold in the scattering amplitude. Above zero energy ( E &gt; 0 ), the spectrum becomes continuous—these are the “continuum states.” Here, the particles are no longer bound and can propagate freely, representing scattering states. This continuum starts at the threshold (here, E=0 ) consistent with the discussion of branch points in the analytic structure of the S-matrix at threshold (e.g., s=4m_\\pi^2 for \\pi\\pi scattering). Physically, this separation between bound and continuum states underlies key aspects of reaction theory: bound states relate to sharp spectral lines (e.g., stable particles), while continuum states enable phenomena like scattering, resonances, and virtual states near threshold. The energy threshold itself is a branch point in the analytic properties of the amplitude, and the nature of these states (bound, virtual, resonance, continuum) determines the analytic structure observed in physical processes.\n\n\n\nLet’s think for a second what implication the pole’s position has, and let’s sketch how the measured spectrum would look in the presence of each: a bound state, a virtual state, and a resonance.\n\n\n\n\n\n\nClassification of Poles in Scattering Theory\n\nA bound state (e.g., deuteron) corresponds to a pole on the physical sheet below the two-particle threshold, representing a stable particle.\nA virtual state (e.g., neutron-neutron singlet state) corresponds to a pole on the unphysical sheet below threshold, leading to an enhancement near threshold without a true bound state.\nA resonance corresponds to a pole in the complex plane above threshold, with an imaginary part related to its width.\n\n\n\n\nThe cross section \\sigma(s) that we measure in an experiment for scattering two particles is connected to the scattering amplitude A(s) . If the amplitude is dominated by a single partial wave, we can perform the angular integration analytically. For the simple case of scalar particle scattering, the angular dependence is given by a Legendre polynomial.\nWhat remains is the following expression for the cross section in the presence of one partial wave with total angular momentum J :\n\\sigma(s) = \\frac{2J + 1}{k^2} |A(s)|^2 \\rho(s).\nHere, k is the center-of-mass momentum, and \\rho(s) is the phase space factor. For a two-body final state, this factor is:\n\\rho(s) = \\frac{2p}{\\sqrt{s}}.\nThis function \\rho(s) starts from zero at the kinematic threshold and approaches a constant ( \\frac{1}{8\\pi} ) at high energies. This factor causes the cross-section to rise from zero at threshold.\n\n\n\n\n\n\nThreshold Behavior The cross-section for a partial wave with angular momentum L is suppressed near threshold by a factor proportional to the center-of-mass momentum: \\sigma_L(s) \\propto p^{2L} as s \\to s_{\\text{thr}} .\n\nFor an S-wave ( L=0 ), the cross-section is finite at threshold.\nFor a P-wave ( L=1 ), like the \\rho meson in \\pi\\pi scattering, it vanishes at threshold.\n\n\n\n\nWhat we are exploring is how the number of interaction counts changes when you collide particles. The cross-section is essentially this probability. On the x-axis, we have the center-of-mass energy \\sqrt{s} , and on the y-axis, we have \\sigma(s) (or |A(s)|^2 ). This probability reflects the properties of the amplitude and, internally, what singularities are present in the complex plane.\n\nResonance Case: We collide two particles. If the energy is adjusted to the resonance mass, the probability to interact grows sharply. We see a peak in the cross-section. For example, the \\rho meson decays to \\pi\\pi , making the \\pi\\pi scattering amplitude resonate at the \\rho mass. The amplitude near a resonance often follows a Breit-Wigner form: A(s) \\propto \\frac{1}{s - M^2 + iM\\Gamma}\nThe distance of the pole from the real axis is related to the width \\Gamma of the resonance. A smaller width means a narrower, taller peak.\nBound State Case: A bound state corresponds to a pole on the real axis below threshold on the physical sheet. In the amplitude, this is a strong singularity (a pole, where the amplitude becomes infinite). Since we only measure above threshold, we don’t see the infinity directly, but it produces a sharp enhancement or peak right at the threshold in the cross-section. A bound state is a real, stable particle (e.g., a deuteron). In a perfect world with only strong interactions and conserved flavor, particles like the proton or pion would be such bound states.\nVirtual State Case: A virtual state corresponds to a pole on the real axis below threshold, but on the unphysical sheet. Its influence is weaker than a bound state pole. It typically does not produce a sharp peak but rather a cusp or a broad enhancement very close to the threshold in the cross-section.\n\nIn contrast to poles, a branch point (like the one at the kinematic threshold from \\rho(s) ) is a weaker singularity. The function is continuous, but its derivative is not. You might observe a slight change in slope—a cusp—but not a divergent peak."
  },
  {
    "objectID": "2025-Lecture-11.html#analyticity-and-the-breakup-momentum-plane",
    "href": "2025-Lecture-11.html#analyticity-and-the-breakup-momentum-plane",
    "title": "(2025) Lecture 11",
    "section": "4 Analyticity and the Breakup Momentum Plane",
    "text": "4 Analyticity and the Breakup Momentum Plane\nAnother convenient representation of the singularity of the scattering amplitude is the breakup momentum plane. This is because the scattering amplitude is an analytic function of the breakup momentum p in non-relativistic scattering.\nIn a non-relativistic problem, you do not have a square root of s anywhere. You only deal with p . If you look at the expression for \\rho , where \\rho = 2p / \\sqrt{s} , in the non-relativistic limit this denominator becomes 2\\mu .\nWhat you can do is expand the amplitude near the threshold. You expand the amplitude in \\sqrt{s} near the first branch point, and then you arrive at the expression for p :\np = \\sqrt{2\\mu (E - E_{\\text{th}})}\nThis quantity has a branch point at s = s_{\\text{th}} because it is under a square root, and that matches the branch point of the amplitude.\nYou can do the inverse relation and find how s is related to p . The point is that if the amplitude is an analytic function of p , the square root will never appear. There is no square root of p in the amplitude. The amplitude is actually an analytic function of p .\nWhat we have discussed with the first and second sheet now gets merged to a single complex plane. The upper part represents A(p) or A(s) , and the lower part is A_2(s) . The real physics—where p is real and positive—corresponds to the physical values of s .\nI want to quickly sketch where the bound and virtual states are. In that representation:\n\nA bound state is sitting on the real axis just below the threshold.\nA virtual state is on the real axis, above the threshold.\nResonances appear as poles off the real axis in the complex plane.\n\nThis is the breakup momentum plane. You often see this representation; people who do non-relativistic field theory always use the p -plane.\n\n\n\n\n\n\nFigure 4: This figure represents the analytic structure of the scattering amplitude in the complex energy (E) plane, focusing on the physical meaning of singularities in scattering theory. The horizontal axis is the real part of energy, with the “threshold” marked as the point where the two-particle continuum begins (e.g., E = 2m_\\pi for \\pi\\pi scattering, or generally E_{\\text{th}} ). To the left of the threshold, the X’s denote bound states—these correspond to poles of the scattering amplitude that lie on the real axis below the threshold. Such poles signal true stable particles or bound states of the two-body system. From the threshold onward, the wavy line indicates the branch cut, which corresponds to the onset of continuum states: the region where two real particles can be produced and propagate freely. This branch cut arises from the multi-particle (continuum) nature of the spectrum above threshold, reflecting the analytic (non-pole) singularity structure of the amplitude. The figure thus illustrates the key idea that the amplitude is analytic except for isolated poles (bound states) and a branch cut starting at threshold (continuum states), which together determine much of the physical and analytic behavior of scattering processes.\n\n\n\nIt is somewhat simpler because you draw one picture and you see all objects there. But it works as an expansion around the threshold. It will not work once you have higher thresholds and more branch points.\n\n\n\n\n\n\nThe breakup momentum can also be expressed relativistically in terms of the Mandelstam variable s : p = \\sqrt{2\\mu (\\sqrt{s} - \\sqrt{s_{\\text{th}}})}\nThis shows the branch point at s = s_{\\text{th}} explicitly.\n\n\n\nLet me summarize to close this chapter. We considered scattering theory or reaction theory that is widely used in hadron spectroscopy. This approach, in contrast to field theory, does not start from the Lagrangian, but rather uses general properties of scattering theory to study hadron-hadron scattering.\nIt relies on the principles of unitarity, analyticity, and crossing symmetry, and interprets and identifies resonances as the poles of the scattering amplitudes. The main object in this approach is the amplitude. The amplitude is something one has to construct satisfying these general principles.\nOnce it is constructed and fixed by experiment, it can further be studied to quantify resonance properties as pole positions and pole strength, which is the residues of the pole. The function A(s) , once fixed by the experimental data, provides us with its rich analytic structure, access to all of the artifacts that are in there, namely branch points, but also unphysical sheets where the resonance is sitting.\nWhat I do in experimental particle physics is constrain this amplitude using experimental data, and then continue it analytically. I find the poles and quantify them with the position of the pole as well as the Cauchy integral around it that gives me a residue—how strong the pole couples to a particular channel.\nThese variables, once measured, get tabulated in the Particle Data Group. The next time I want to know something about the scattering of two particles or a particular decay of a particle to a system, these numbers provide me the answer.\n\nThe mass is the real part of the pole position.\nThe width is related to how deep the pole is in the complex plane.\nThe coupling is how strong this resonance couples to this particular system or the residue of the pole.\n\nA(s) \\approx \\frac{g^2}{s - s_{\\text{pole}}}, \\quad \\text{where } s_{\\text{pole}} = M^2 - iM\\Gamma\nAll right, so questions here. What will change in all these things if we add spin to the particle? For example, you have explained how we explain \\pi\\pi scattering into \\pi\\pi . But if I want to describe \\rho\\rho scattering to \\rho\\rho , will the presence of spin interaction pop up somewhere? The short answer is no.\nWhat will change is just kinematics. Properties and analyticity—properties of the amplitudes. Kinematics is a good word to say that what will happen is the amplitude will have extra kinematic factors at threshold and it will not be a single amplitude, but rather a vector of amplitudes because there are different helicities.\nIf you sum over helicities for the cross section you sum over them. But amplitudes are still carrying the index. So if it is \\rho\\rho scattering, then you can scatter \\rho\\rho with different helicities. So there is not a single amplitude, but several amplitudes. But otherwise, that is right. Everything holds for spin.\nSince it is a very wide subject and there are a lot of technicalities, let me start by first covering the program and what we are going to overview and how lattice field theory helps in understanding QCD. Then we will fill in the details."
  },
  {
    "objectID": "2025-Lecture-11.html#lattice-qcd-discretizing-confinement",
    "href": "2025-Lecture-11.html#lattice-qcd-discretizing-confinement",
    "title": "(2025) Lecture 11",
    "section": "5 Lattice QCD: Discretizing Confinement",
    "text": "5 Lattice QCD: Discretizing Confinement\nQuantum Chromodynamics (QCD) is the gauge theory with the SU(3) gauge group that is notoriously difficult to deal with. It has the defining properties of confinement and asymptotic freedom, driven by the self-interaction of gluons described by the Lagrangian:\n\\mathcal{L}_{\\text{QCD}} = \\bar{\\psi}_i \\left( i \\gamma^\\mu D_\\mu - m_i \\right) \\psi_i - \\frac{1}{4} G^a_{\\mu\\nu} G_a^{\\mu\\nu}\nwhere the covariant derivative is D_\\mu = \\partial_\\mu - i g_s t^a A^a_\\mu and the gluon field strength tensor is G^a_{\\mu\\nu} = \\partial_\\mu A^a_\\nu - \\partial_\\nu A^a_\\mu + g_s f^{abc} A^b_\\mu A^c_\\nu .\n\n5.1 Asymptotic Freedom and Confinement\n\nAsymptotic Freedom: When the momentum with which we probe the system becomes very large, quarks appear as nearly free objects. This is described by the running of the strong coupling constant: \\mu \\frac{d\\alpha_s}{d\\mu} = \\beta(\\alpha_s) = -\\frac{\\beta_0}{2\\pi} \\alpha_s^2 - \\frac{\\beta_1}{4\\pi^2} \\alpha_s^3 + \\mathcal{O}(\\alpha_s^4)\nwhere \\alpha_s = g_s^2/(4\\pi) . The negative sign of the \\beta -function at leading order causes the coupling to decrease at high energies.\nConfinement: At low energy, the system confines. This is the reason for the appearance of all composite particles called hadrons. The interaction strength becomes large at a scale of roughly 1 femtometer, which is set by the confinement scale: \\Lambda_{\\text{QCD}} = \\mu \\, \\exp\\left( -\\frac{2\\pi}{\\beta_0 \\alpha_s(\\mu)} \\right)\nThis is the scale where color exchange happens, and only color-neutral (colorless) objects are observed.\n\nThe property of confinement, driven by a large coupling \\alpha_s at low energy, makes QCD very difficult to study analytically. Our standard methodology of perturbation theory and Feynman diagrams fails because there is no small parameter to order the diagrams—producing two or three gluons can be more probable than producing one.\n\n\n5.2 Lattice QCD: A Computational Framework\nTo study QCD non-perturbatively, we must use alternative methods. The most productive method over the last 30 years has been lattice QCD. This is a computational framework that takes the theory of strong interactions as it is and computes its properties by discretizing space-time onto a grid.\n\n\n\n\n\n\nThe core idea is to create a finite “laboratory” box in space-time (e.g., 2 fm × 2 fm × 2 fm in space), fill it with quantum fields, solve the equations to evolve these fields in time, and then evaluate any quantum properties of the objects within this box. We can place theoretical “probes” inside this laboratory to measure their properties.\n\n\n\nTo make the problem tractable for a computer, we discretize both space and time. Instead of a three-dimensional box evolving in time, we work with a four-dimensional box where time is simply another axis. This makes the problem symmetric with respect to all coordinates.\n\nThe step size in all directions (an isotropic lattice) is a small distance a , typically 0.1 fermi or less.\nThe physical box size is typically a few fermi (2 fm is common), though sometimes a larger box is needed.\n\nThe gauge part of the QCD action on this discrete lattice is given by the Wilson gauge action:\nS_G[U] = \\frac{2}{g_0^2} \\sum_{x} \\sum_{\\mu &lt; \\nu} \\text{Re}\\, \\text{Tr} \\left[ 1 - U_{\\mu\\nu}(x) \\right]\nwhere U_{\\mu\\nu}(x) = U_\\mu(x) U_\\nu(x+\\hat{\\mu}) U_\\mu^\\dagger(x+\\hat{\\nu}) U_\\nu^\\dagger(x) is called a plaquette, and g_0 is the bare lattice coupling. This formulation maintains gauge invariance on the discrete grid."
  },
  {
    "objectID": "2025-Lecture-11.html#lattice-qcd-mesons-boundary-conditions-and-quark-mass-tuning",
    "href": "2025-Lecture-11.html#lattice-qcd-mesons-boundary-conditions-and-quark-mass-tuning",
    "title": "(2025) Lecture 11",
    "section": "6 Lattice QCD: Mesons, Boundary Conditions, and Quark Mass Tuning",
    "text": "6 Lattice QCD: Mesons, Boundary Conditions, and Quark Mass Tuning\nSince the size of a meson is on the order of a Fermi, we want it to fit inside the simulation volume. Therefore, the lattice must be larger than one fermi to contain the meson and allow us to evaluate its properties.\nWe implement periodic boundary conditions, which is like mirroring the entire setup on all sides. The primary meson is placed inside this box. The lattice must be large enough so the meson fits comfortably but is also sufficiently small compared to the total box size. This prevents the meson from feeling significant forces from its mirrored images created by the periodic boundaries, an interaction we aim to neglect.\n\n\n\n\n\n\nPeriodic boundary conditions mean the field value at one coordinate equals the field value at the mirrored coordinate. This is equivalent to filling all of space with identical copies of the primary lattice cube.\n\n\n\n\n\n\n\n\n\nFigure 5: This figure represents the spectrum of energy levels in a finite volume (such as a finite-size box in lattice QCD), depicted along the “energy plane.” The threshold marks the point at which two-particle states can be produced (e.g., the \\pi\\pi threshold in \\pi\\pi scattering). To the left of threshold, discrete “bound states” are shown. When space is made finite with periodic boundary conditions (of spatial extent L ), the momenta—and therefore the energies—of the system become quantized rather than continuous. This is illustrated by the sequence of discrete x-marks (energy eigenvalues) above the threshold, with a characteristic spacing determined by the box size: the allowed momenta are separated by 2\\pi/L . Physical meaning: In a finite volume, such as on a lattice, energy levels are no longer a continuum but become discretized. The spacing between these allowed energy levels is set by the finite size of the box. Bound states remain as isolated discrete levels below the threshold, while above threshold (where, in infinite volume, one would have a continuum of scattering states), the energy spectrum consists of a series of discrete, closely spaced levels. The analysis of these discrete spectra on the lattice allows the extraction of infinite-volume scattering amplitudes via techniques like Lüscher’s method.\n\n\n\nThe evolution of fields, like a pion, happens within this lattice. While the pion itself may not propagate far, we observe the dynamics of fields bubbling in the vacuum. The typical setup uses isotropic spacing, but sometimes anisotropic lattices are used, with different spacing in time versus space.\nThe computational program proceeds as follows:\n\nStart from the QCD Lagrangian.\nPerform a Wick rotation to Euclidean time, t_E = -i t , to define fields in Euclidean space.\n\nThe resulting Euclidean action is: S_E = \\int d^4x_E \\left[ \\frac{1}{4} F_{\\mu\\nu}^a F_{\\mu\\nu}^a + \\sum_f \\bar{\\psi}_f (\\gamma_\\mu D_\\mu + m_f) \\psi_f \\right].\n\nPhysical observables are computed as expectation values via the path integral: \\langle \\mathcal{O} \\rangle = \\frac{1}{Z} \\int \\mathcal{D}[U] \\mathcal{D}[\\bar{\\psi}, \\psi] \\, \\mathcal{O} \\, e^{-S_E[U,\\bar{\\psi},\\psi]}.\n\n\n\n\n\n\n\nFigure 6: This figure illustrates the setup for two-particle scattering in a periodic box, as is common in lattice QCD calculations. The potential V sits in the center of a finite spatial region of length L , represented by the box. The wavefunction \\psi(x) describing the relative motion of the two particles is subject to periodic boundary conditions: \\psi(-L/2) = \\psi(L/2) and \\psi'(-L/2) = \\psi'(L/2) . These boundary conditions mean the system is placed in a finite, repeating (periodic) spatial volume, mimicking the setup used in lattice QCD. The physical meaning is that in this finite box, the allowed energy levels become discrete, and by analyzing these discrete levels, one can infer information about scattering phase shifts and resonance properties in infinite volume using methods like Lüscher’s formula. This technique underpins how one extracts scattering amplitudes and resonance parameters from lattice simulations of QCD.\n\n\n\nThis formulation makes the integrand real and enables the use of Monte Carlo integration techniques. From here, we can approach problems like two-particle scattering on the lattice. While direct scattering is not possible in a finite volume, we can infer interaction information using finite-volume methods like Lüscher’s formula.\nThe QCD Lagrangian has few parameters: a coupling strength g and the quark masses. In the lattice setup, we define the lattice spacing a and grid size L , and tune these parameters. For an operator with pion quantum numbers, a bound state will appear at a specific energy level, giving the pion a mass for that parameter set.\nThis mass does not have to be the physical 140 MeV. We have parameters to tune—the up, down, and strange quark masses, and the coupling g —to adjust the pion mass to its physical value. This tuning is possible because hadronic phenomena change continuously with quark mass.\n\n\n\n\n\n\nThe QCD Lagrangian and strong interactions are continuous functions of quark masses. By varying masses in simulations, we can continuously observe how hadron properties evolve, providing a powerful tool for understanding phenomena like the transition of resonances into bound states.\n\n\n\nFor example, the \\rho meson is a resonance in the \\pi\\pi system. If we make the quark masses heavier in the simulation, the resonance width becomes smaller. Eventually, the pole moves to the real axis in the complex plane, and the \\rho becomes a bound state. This trajectory is described by: \\sqrt{s_\\rho}(m_q) = M_\\rho(m_q) - \\frac{i}{2} \\Gamma_\\rho(m_q).\nLattice QCD allows us to perform this numerical experiment, tracing the pole position as a function of quark mass across different lattice sizes and discretizations.\nThe computational cost depends heavily on the quark masses. Calculations become more expensive as the pion becomes lighter because the pion mass appears in a denominator in relevant uncertainty relations. The uncertainty grows as quark masses decrease.\nThis is tied to the pion’s role as a Goldstone boson. In the chiral limit, its mass vanishes according to the relation from chiral perturbation theory: m_\\pi^2 = 2B m_q + \\mathcal{O}(m_q^2).\nTherefore, computations near the chiral limit could become infinitely expensive, necessitating the use of approximations like chiral perturbation theory to extrapolate results."
  },
  {
    "objectID": "2025-Lecture-11.html#lattice-qcd-from-continuum-fields-to-euclidean-path-integrals",
    "href": "2025-Lecture-11.html#lattice-qcd-from-continuum-fields-to-euclidean-path-integrals",
    "title": "(2025) Lecture 11",
    "section": "7 Lattice QCD: From Continuum Fields to Euclidean Path Integrals",
    "text": "7 Lattice QCD: From Continuum Fields to Euclidean Path Integrals\nFor example, what does it mean that the quark mass is very large? Does it have dimension? On the lattice, we work with dimensionless variables. How do we define the mass? It should be something dimensionless—specifically, the ratio to the lattice spacing a .\nThe computational cost depends on the magnitude of a . We use a as a natural scale, so everything is expressed in units of the discretization spacing. For instance, to have a pion at 140 MeV, we can choose different a parameters. What is optimal? A finer lattice is better but more expensive. Therefore, what constitutes a good lattice depends on your specific goals.\nThere is also the notion of the continuum limit on the lattice. When discussing computational cost, the a parameter is not the only factor. For the same value of a , different pion masses lead to different convergence rates. The number of samples needed to control statistical uncertainties varies. I will clarify this point further.\nThe QCD Lagrangian in Minkowski spacetime is a scalar quantity written as G_{\\mu\\nu} G^{\\mu\\nu} , where G_{\\mu\\nu} is the gluonic field strength tensor. This represents the gluonic field tensor contracted with itself, with all repeated indices summed over. There are eight gluonic fields. Here, \\mu and \\nu are Lorentz indices, reflecting the relativistic Lorentz group properties of the fields.\nGauge invariance is enforced by extending the ordinary derivative to include the gluonic field. The fermionic fields represent the quarks, which interact with the gluons. This interaction is prescribed by gauge theory through a specific term coupling quarks and gluons. The quark mass term is present explicitly. The parameters are the coupling constant g and the quark masses; everything else is fixed.\n\n\n\n\n\n\nThe full QCD Lagrangian density is: \\mathcal{L}_{\\text{QCD}} = -\\frac{1}{4} G_{\\mu\\nu}^a G_a^{\\mu\\nu} + \\sum_f \\bar{\\psi}_f (i \\gamma^\\mu D_\\mu - m_f) \\psi_f\nwhere D_\\mu = \\partial_\\mu - i g A_\\mu^a T^a is the covariant derivative and G_{\\mu\\nu}^a = \\partial_\\mu A_\\nu^a - \\partial_\\nu A_\\mu^a + g f^{abc} A_\\mu^b A_\\nu^c . The index f runs over quark flavors.\n\n\n\nWe have fields: the gluonic fields A_\\mu and the quark fields \\psi . By “fields,” we mean that both \\psi and A_\\mu are functions of a point in spacetime. Any physical observable can be computed as an expectation value of an operator: \\langle \\mathcal{O} \\rangle = \\frac{\\langle 0 | T \\mathcal{O} | 0 \\rangle}{\\langle 0 | 0 \\rangle}\nThis operator depends on the fields. You construct it from quarks and gluons, and its expectation value is computed by “sandwiching” it with the vacuum state; the result is an observable number, not a function of coordinates.\n\nLocal operators are evaluated at a single spacetime point.\nNon-local operators are evaluated at multiple points.\n\nFollowing Feynman’s ideas, the path integral technique provides a way to compute this expectation value using a functional integral: \\langle \\mathcal{O} \\rangle = \\frac{1}{Z} \\int \\mathcal{D}A_\\mu \\mathcal{D}\\psi \\mathcal{D}\\bar{\\psi} \\, \\mathcal{O} \\, e^{i S}\nwhere Z is the partition function (the same integral without \\mathcal{O} ) and S = \\int d^4x \\, \\mathcal{L}_{\\text{QCD}} is the action.\nThe action S weights different field configurations. For any given configuration—a complete map of what A_\\mu , \\psi , and \\bar{\\psi} are at every point in spacetime—you can compute this weight factor by integrating the Lagrangian. The functional integral sums over all possible such configurations. Here, \\psi and \\bar{\\psi} are independent Grassmann variables (anti-commuting numbers).\nThis formulation is impractical for direct computation because the weight factor e^{iS} is a complex function that oscillates rapidly, preventing convergence in numerical sampling.\nThe essential trick for lattice QCD is the Wick rotation to Euclidean time. We change from Minkowski time to Euclidean time t_E , defined by t_E = -i t . This transforms the metric and the Lagrangian.\n\n\n\n\n\n\nUnder the Wick rotation, the Minkowski action S = \\int d^4x \\, \\mathcal{L} becomes a Euclidean action S_E . The factor e^{iS} becomes e^{-S_E} , which is a real, positive weight between 0 and 1 (for a positive action). This allows configurations to be interpreted probabilistically and enables Monte Carlo sampling.\n\n\n\nFor example, in a simple scalar field theory, the transformation introduces an overall minus sign, making the Euclidean Lagrangian real. For QCD, the time derivatives and gamma matrices must be adjusted accordingly, but the outcome is the same: we obtain a real, positive weighting factor e^{-S_E} .\nFinally, another key trick is to integrate out the fermionic fields. The original path integral involves three types of fields: \\bar{\\psi} , \\psi , and A_\\mu . The fermionic part of the action has a Gaussian form in the Grassmann variables. Performing this functional integral yields the determinant of the Dirac operator matrix M .\nThe gluonic field, which drives confinement and thermodynamics, remains and is the most challenging part. Integrating out the fermions simplifies the problem to working with an effective theory involving only the gluon fields, weighted by e^{-S_g} \\det(M) . This is the basis for quenched approximations, where \\det(M) is set to a constant.\nI will put the details of the quenched calculation on the board and continue this discussion next time."
  },
  {
    "objectID": "2025-Lecture-11.html#grassmann-variables-and-lattice-qcd-computations",
    "href": "2025-Lecture-11.html#grassmann-variables-and-lattice-qcd-computations",
    "title": "(2025) Lecture 11",
    "section": "8 Grassmann Variables and Lattice QCD Computations",
    "text": "8 Grassmann Variables and Lattice QCD Computations\nOne thing to consider is to look at the simple example of the Grassmann variable. Grassmann means that they are anticommuting. So if X and Y are Grassmann variables, it means XY = -YX .\nFor every Grassmann variable, X^2 = Y^2 = 0 . That is clear because (XY)^2 is also equal to zero. If you write XYXY and anticommute, you will see X^2 and Y^2 , which are zero. So this is also zero.\nIn fact, e^{1 - XY} = 1 - XY . Isn’t it amazing? You do a fermion expansion just like that. We do not cut any higher power terms.\nFor Grassmann variables, integration is introduced as differentiation. That’s mind-blowing. It’s a definition: integration for Grassmann variables is defined as differentiation.\nSo, \\int dX \\, X = 1 and \\int dX \\, 1 = 0 . Therefore, \\int dX \\, dY \\, e^{-XY} = 1 . If you put any constant a here, it’s equal to a .\nYou didn’t explain how that determinant pops up from M . There is a formula. One can do this trick by considering two variables, say x_1, x_2 . Even in that case you get a determinant. Probably there is some expansion; it’s a determinant.\nIf we integrate over the gluonic fields, what remains of the fermionic field is that integral over all possible configurations of the quark fields. Our operator depends only on the gauge fields; the determinant remains from the quark fields and a weight factor that has the action expression.\nThis determinant represents the effect of virtual quarks. All quarks are integrated. Therefore, the only effect we see is Q \\bar{Q} popping up from the vacuum. It’s purely an expression that only cares about gluons. The only effect quarks can have in this expression is popping up in loops.\nNow another piece of important terminology: quenched and unquenched calculations refer explicitly to this term. This is used almost as slang.\n\nEvery time you hear in lattice calculations that they do quenched calculations, it simply means that this determinant term has been ignored. You literally throw it; there are no quarks in loops.\nIn fact, this universe where there are no quarks in loops is not that different. These computations already provide valuable insights into what QCD looks like. And it’s much cheaper computationally. This integral converges numerically much quicker if you throw the term.\n\nI want you to hear the words quenched and unquenched and immediately map them to the determinant that remains from the fermionic field integral.\nThe last thing I wanted to say is how we proceed with computing this integral. The naive way is to just discretize space, and then all possible values on the side of the lattice are your integration variables. The lattice is 100 by 200; this is time, this is space.\nHow many variables do we need to keep on every site? A is a function of x , and how many variables does this A have? It’s A_\\mu . Therefore, it’s 4 times 9, plus maybe times 2 for complex. So how many? I’ve got 60. If I take this approach, I need to replace this DA with 10 billion integrals because every lattice site has four variables. It’s going to be a huge amount of integrals.\nIf every integral has a certain dimension, like from A to B , numerically this integral could be computed by discretizing this A to B space. Therefore, if I put two points or three points in every dimension, I’m going to get 3^{10 \\text{ billion}} evaluations. That’s much more than the age of the universe. If an evaluation takes a nanosecond, you will probably have to wait still 10^{20} universe times. It’s impossible.\nSo that’s not what we are going to do. Instead, people use the Monte Carlo sampling method where different configurations are sampled randomly with a certain weight. That technique allows us to calculate this integral more efficiently. For lattice calculations, discretize space and space-time, use Minkowski transformations and the Monte Carlo sampling technique for the weights. You can also come to that trick of getting rid of the fermions.\n\n\n\n\n\n\nOn Splitting the Action and the Matrix M  How is it possible that we can split the fermionic and gluon part of the action? We don’t split. The fermionic part is \\int e^{\\int d^4x \\, \\bar{\\psi} (D\\!\\!\\!\\!/ + m) \\psi} . Once you integrate over \\psi , the matrix M that appears still depends on the gluon fields A .\n\nM is a discretized version of the D\\!\\!\\!\\!/ + m matrix.\nWhy is it +m and not -m ? This sign happens when we flip the derivative. The D_\\mu operator: we flip the time derivative so that dt becomes -dt . We also flip the gamma matrices differently for space and time. For time it doesn’t get flipped at all; for space it gets flipped with an i . Overall, the effect is that you have a D_4 with a minus sign here. So the minus appears here.\n\n\n\n\nHistorical & Conceptual Questions:\n\nOn the Limit of Quenched/Unquenched: Is there a limit where quenched and unquenched calculations converge into one? I don’t see a limit. So it’s just two independent approaches.\nOn Grassmann Algebra: How was Grassmann algebra developed and how did it come to physics? I know that it existed independently in mathematics. I would also be curious to learn. It’s a trick, but it turns out to be very useful. You can do quite a bit with that.\nOn the Usefulness of Grassmann Variables: What still confuses me: it looks like these variables are quite limiting. From those properties you cannot do much with them; they truncate series. You cannot square them, but apparently you can use this variable to describe fields. Even so, I do not know how, but maybe I learn one day."
  },
  {
    "objectID": "2025-Lecture-11.html#neutron-nucleus-interaction-and-cross-section",
    "href": "2025-Lecture-11.html#neutron-nucleus-interaction-and-cross-section",
    "title": "(2025) Lecture 11",
    "section": "9 Neutron-Nucleus Interaction and Cross-Section",
    "text": "9 Neutron-Nucleus Interaction and Cross-Section\nThe next thing we need to do is to look at the interaction of the neutron with the nucleus.\nThe neutron is a neutral particle, so it does not feel the Coulomb barrier. It can get very close to the nucleus, meaning the interaction is purely nuclear.\nConsequently, the cross-section for the neutron to interact with the nucleus is essentially the geometric cross-section of the nucleus: \\sigma \\approx \\pi R^2\nwhere R is the nuclear radius.\nFor a typical nucleus, the radius is given by: R \\approx 1.2 \\, A^{1/3} \\, \\text{femtometers}\nThis results in a cross-section on the order of barns, where one barn is defined as 10^{-28} square meters.\nNow, if the neutron has very low energy, we enter the regime of s-wave scattering. In this regime, the cross-section can become much larger than the geometric cross-section due to:\n\nResonance effects.\nThe presence of bound states near zero energy.\n\nThis enhanced low-energy interaction is quantitatively described by the scattering length.\n\n\n\n\n\n\nThe geometric cross-section \\pi R^2 provides a useful baseline. However, the actual neutron-nucleus interaction cross-section, especially at low energies, is governed by quantum scattering theory and can deviate significantly from this simple geometric picture.\n\n\n\n\n\n\n\n\n\nFigure 7: This figure illustrates the quantum mechanical scattering of a particle (such as a neutron) off a potential well, as applied to low-energy neutron-nucleus interactions discussed in the lecture. The horizontal axis is position x , while the vertical axis represents the potential V(x) . The central feature is a potential well of width R and depth u_0 , representing the nuclear force region. Above the well, a blue curve marked E &gt; 0 indicates the energy of an incoming neutron, which is positive, corresponding to a scattering state rather than a bound state. The blue (and yellow) wavy lines indicate the wavefunction of the incoming and outgoing neutron: outside the potential well, the wavefunction oscillates with constant amplitude, representing a free neutron; inside the well, the wavefunction is modified by the attractive potential. The figure shows that for a neutral particle like the neutron (which does not face a Coulomb barrier), the particle can approach arbitrarily close to the nucleus and interacts with the nuclear potential. If the neutron energy is low (as in the s-wave regime), it is highly sensitive to the details of the potential, which can lead to enhanced scattering cross-sections, particularly if a bound or virtual state is near threshold. The potential well depth u_0 and width R correspond to the geometric parameters of the nucleus, with the cross-section scaling as \\sigma \\sim \\pi R^2 at high energies, but possibly rising much higher at low energies due to quantum mechanical effects such as resonance or the presence of near-threshold states described in the lecture."
  },
  {
    "objectID": "2025-Lecture-13.html",
    "href": "2025-Lecture-13.html",
    "title": "(2025) Lecture 13",
    "section": "",
    "text": "Presenter: Mikhail Mikhasenko\nNote Taker: Anna Zimmer"
  },
  {
    "objectID": "2025-Lecture-13.html#hadronic-contributions-to-muon-anomalous-magnetic-moment-and-scattering-theory",
    "href": "2025-Lecture-13.html#hadronic-contributions-to-muon-anomalous-magnetic-moment-and-scattering-theory",
    "title": "(2025) Lecture 13",
    "section": "1 Hadronic Contributions to Muon Anomalous Magnetic Moment and Scattering Theory",
    "text": "1 Hadronic Contributions to Muon Anomalous Magnetic Moment and Scattering Theory\nSo let’s start. What are the two terms in the muon’s anomalous magnetic moment, a_\\mu = (g-2)/2 , that receive hadronic contributions? The first is the hadronic vacuum polarization (HVP).\n\n\n\n\n\n\nFigure 1: This figure illustrates the two key types of hadronic contributions to the anomalous magnetic moment of the muon, a_\\mu = (g-2)/2 , discussed in the lecture. On the left, the first two diagrams show the hadronic vacuum polarization (HVP) contribution: a muon interacts with a photon, and in the photon line, a hadron loop (such as a pion loop) dresses the photon and modifies the vertex, representing the hadronic correction to the photon propagator. On the right, the diagram represents the hadronic light-by-light (HLbL) contribution: multiple photons interact with a hadron loop, where hadronic states (like pions or other mesons) couple to the photons inside the loop. Both types of diagrams encode how nonperturbative effects from QCD (hadron physics) affect precision observables such as the muon’s magnetic moment. These hadronic effects are a significant source of theoretical uncertainty in precision tests of the Standard Model using g-2 .\n\n\n\nThe second is hadronic light-by-light (HLbL).\nWhat is the vacuum polarization diagram? The solid line is the fermion—the muon. The wavy line is the photon. That diagram shows how the probe (the muon) interacts with the photon. What sits in the loop is something that dresses the photon and then changes the vertex.\n\n\n\n\n\n\nFigure 2: This figure represents the hadronic vacuum polarization (HVP) diagram, which is a key contribution to the muon’s anomalous magnetic moment, a_\\mu . In the context of this lecture, the wavy lines correspond to photons, and the internal loop contains a quark-antiquark ( q\\bar{q} ) pair. The quarks inside the loop “dress” the photon propagator, modifying the way the photon interacts with the probe (e.g., the muon). This process encapsulates the effect of hadronic (strong-force) physics on electromagnetic observables, and is a significant source of theoretical uncertainty in precision calculations of g-2 . The HVP is distinct from the hadronic light-by-light (HLbL) contribution, but both reflect how hadronic physics enters precision electroweak measurements.\n\n\n\nThis is the hadronic vacuum polarization contribution, a_\\mu^{\\text{HVP}} .\nHVP is one piece. The other contribution is hadronic light-by-light, a_\\mu^{\\text{HLbL}} . This is another place where hadrons enter.\nIf we expand further, where exactly in hadronic light-by-light do hadrons enter? Precisely in the loop. It could be a loop of pions or a loop of kaons. The particles that matter are those that couple to the photon. Mesons that couple strongly to two photons contribute the most—for example, the \\eta and \\eta' . So all mesons with a strong two-photon coupling are important.\nThat’s important to realize: hadron physics gives the precision input to precision physics. That’s the hadronic contribution to g-2 . It’s very important to get a_\\mu to 10 digits, as shown last time. Experiment has measured it to this precision, but theoretical calculations rely on our understanding of these vertices—whatever happens inside these blocks.\nI believe these days I hear less discussion about hadronic light-by-light. The main uncertainty comes from the hadronic vacuum polarization.\nSecond question: What’s the time dependence of correlation functions computed on the lattice once we transform from Minkowski space to Euclidean? The expectation between the vacuum and any operator \\mathcal{O}_I for a state that’s not the vacuum, as a function of time, shows an exponentially falling dependence.\nIn the Heisenberg representation, the time dependence of the operator is given by its commutation with the Hamiltonian. When we change to Euclidean space, the time dependence becomes:\n\\mathcal{O}(\\tau) = e^{H\\tau} \\mathcal{O}(0) e^{-H\\tau}\n\n\n\n\n\n\nThis Wick rotation t \\to -i\\tau converts oscillatory time evolution into exponential decay, making lattice path integrals well-defined. The Euclidean correlation function decays as C_I(\\tau) = \\langle 0 | \\mathcal{O}_I(\\tau) \\mathcal{O}_I^\\dagger(0) | 0 \\rangle = \\sum_n |\\langle 0 | \\mathcal{O}_I | n \\rangle|^2 \\, e^{-E_n \\tau},\nwhere E_n are energy eigenvalues. At large \\tau , the ground state dominates.\n\n\n\nToday in the lecture I plan to connect the scattering problem in quantum mechanics—the scattering theory we’ve discussed during the course—and see how resonance phenomena and complex structure emerge. Then I will connect this to the methods used in lattice field theory in a finite box to obtain useful results on scattering properties of particles.\nI’ll start with the scattering problem in quantum mechanics on the basis of wave functions. The main equation for scattering is the time-independent Schrödinger equation:\nH \\psi = E \\psi\nThe Hamiltonian is the sum of two terms:\n\nThe kinetic term, where momentum maps to the derivative of the coordinate,\nand the potential V(x) .\n\nMost of the time in quantum mechanics we work in coordinate space, and the potential is a function of a single variable—the one-dimensional x coordinate.\nFor simplicity, let’s drop all constants; we can recover them from dimensionality later. The equation then reads:\n\\left[ -\\frac{d^2}{dx^2} + V(x) \\right] \\psi(x) = E \\psi(x)"
  },
  {
    "objectID": "2025-Lecture-13.html#closed-form-solutions-and-bound-states-in-the-pöschlteller-potential",
    "href": "2025-Lecture-13.html#closed-form-solutions-and-bound-states-in-the-pöschlteller-potential",
    "title": "(2025) Lecture 13",
    "section": "2 Closed-Form Solutions and Bound States in the Pöschl–Teller Potential",
    "text": "2 Closed-Form Solutions and Bound States in the Pöschl–Teller Potential\nThat’s a differential equation that can be solved numerically. However, there are several types of potentials for which a closed-form solution exists. I would like to examine one of them to gain physical insight.\nBefore that, let’s discuss the variables. The energy of the system, E , is a fixed parameter in the differential equation. This is a quantity we must probe, fix, and then solve for.\nThe general approach to investigate a system with a given potential V(x) is as follows:\n\nFix the energy E (or the related breakup momentum).\nSolve the time-independent Schrödinger equation: -\\frac{\\hbar^2}{2m} \\frac{d^2\\psi(x)}{dx^2} + V(x)\\psi(x) = E\\psi(x)\nFind the eigenvalues and eigenfunctions (wave functions \\psi(x) ) that satisfy it.\n\nWe can also frame the problem differently: the solution will not exist for arbitrary values of E . We can treat E as a parameter and ask: for which energy values does this differential equation have a physically acceptable solution? This leads us to identify the possible energy regimes of the system.\nI will look at potentials with a closed-form solution. One example is the Pöschl–Teller potential: V(x) = -\\frac{U_0}{\\cosh^2(\\alpha x)}\nIt is advantageous to have a closed form because it allows for quick visualization and coding.\nThe claim is that for this potential, an algebraic change of variables leads to an analytic, closed-form expression for the wave function, formulated in terms of hyperbolic functions and the hypergeometric function. Special functions are not a problem, as implementations exist in programming languages like Mathematica, Python, and Julia, so we can plot everything.\nThe physics is very interesting. This potential has two parameters:\n\nU_0 controls the depth of the well.\n\\alpha controls the width of the well.\n\nDepending on these parameters, many rich physical phenomena emerge.\n\n2.1 Scattering and Bound States\nIn the scattering problem ( E &gt; 0 ), the wave function’s asymptotic form far from the well is a superposition of incoming and reflected plane waves: \\psi(x) \\sim e^{ikx} + R e^{-ikx} \\quad \\text{as } x \\to -\\infty\nwhere k = \\sqrt{2mE}/\\hbar . For a symmetric potential, this can also be written as \\psi(x) \\sim \\cos(k|x| + \\delta_0) for |x| \\gg R , where \\delta_0 is the scattering phase shift.\n\n\n\n\n\n\nA physically acceptable wave function must be finite everywhere. We cannot allow exponential growth at infinity. This asymptotic condition restricts the allowed solutions.\n\n\n\nThe energy spectrum arises from solving the differential equation and imposing this finiteness condition. We must ensure the wave function does not blow up exponentially at both x \\to \\pm \\infty .\n\nContinuum of States (Scattering): For energies above the asymptotic value of the potential ( E &gt; 0 ), all energy values are allowed. This is called the continuum. The Schrödinger equation has a solution for any positive E .\nBound States: For energies below the potential threshold ( E &lt; 0 ), solutions exist only at specific, discrete energy levels. These are bound states.\n\nA bound state wave function is localized: it has oscillatory behavior inside the well and exponentially suppressed tails outside it.\n\n\n2.2 Bound States in the Pöschl–Teller Potential\nFor the Pöschl–Teller well, the properties of the bound states are known exactly.\nThe number of bound states N is finite and given by: N = \\left\\lfloor \\sqrt{\\frac{2mU_0}{\\alpha^2 \\hbar^2}} \\right\\rfloor\n\nIf the well is very deep (large U_0 ), N is large, and there can be many bound states (e.g., n = 0, 1, 2, ... ).\nIf the well is made narrower (large \\alpha ), the denominator increases and N decreases, meaning fewer states can fit inside.\n\nThe energy eigenvalues for these bound states are quantized and given by: E_n = -\\frac{\\hbar^2 \\alpha^2}{2m} \\left( \\sqrt{\\frac{2mU_0}{\\alpha^2 \\hbar^2}} - n \\right)^2\nwhere n = 0, 1, 2, \\dots, N-1 . The energy is always negative and is limited by the well depth U_0 .\nThe corresponding bound state wave functions are expressed in terms of hypergeometric functions: \\psi_n(x) \\propto \\left( \\cosh(\\alpha x) \\right)^{-\\lambda} \\cdot {}_2F_1\\left( -n, \\lambda + s; \\frac{1}{2}; 1 - \\tanh^2(\\alpha x) \\right)\nwhere \\lambda and s are parameters derived from the potential and energy."
  },
  {
    "objectID": "2025-Lecture-13.html#analytic-structure-of-scattering-amplitudes-and-boundary-conditions",
    "href": "2025-Lecture-13.html#analytic-structure-of-scattering-amplitudes-and-boundary-conditions",
    "title": "(2025) Lecture 13",
    "section": "3 Analytic Structure of Scattering Amplitudes and Boundary Conditions",
    "text": "3 Analytic Structure of Scattering Amplitudes and Boundary Conditions\nNow I want to look at this picture once again and then transform it to the way we have seen in scattering theory. We used to write energy on the x-axis. This was called the energy plane, and the continuum in scattering theory was represented by a branch cut. The bound states were appearing as poles.\nIt is actually very instructive to map what we call the scattering amplitude in scattering theory to the potential problem. In fact, that analytic structure is exactly the same for the transmission and reflection coefficients. To make it very accurate, we have to consider the different problem where we have a clear incoming wave, a reflected wave, and a transmitted wave.\nAs a side remark, consider a potential like this. We have an incoming wave, e^{ikx} + R e^{-ikx} . Then we have a transmitted wave on the other side. Here, T is the transmission coefficient and is related to the probability for the flux from the left to go to the right. R is the reflection coefficient. When you just want to solve the scattering problem, that’s the setup that you would use.\nOn the left you would send in the wave, there will be reflection. You solve the boundary conditions. You can reverse the setup, send the wave from the right and then solve the other equations. There is the relation that the probability to pass from the left is equal to the probability to pass from the right, expressed by probability flux conservation:\n|T|^2 + |R|^2 = 1\nHere we could also do this, but it’s not this type of potential. It is actually easier for a symmetric potential to use symmetric functions with odd and even parity, like the cosine and sine. That’s why I will get to that. It is important to realize that the role of the scattering amplitudes is played now by these coefficients. They are functions of the momentum and energy.\nWe are dealing with the coordinate space; e^{ikx} is a plane wave and the scattering amplitude is the coefficient in front that depends on energy. What we discuss here is the possible solution for E . But we can also ask the question: what is the analytic structure of our transmission coefficients in the complex plane? We are going to discover exactly that.\nIn the area where there is the continuum, any value of the energy is possible. You have a branch cut. Then there are bound states that are trapped in the well. The scattering amplitude has a pole structure:\n\\mathcal{A}(E) \\sim \\frac{1}{E - E_{\\text{pole}}}\nWhen we deal with the symmetric potential, instead of using that basis, we can switch to the cosine and sine basis. We can use either one or another. Let’s stick to the even wave, such wave functions that have a positive parity.\nNow I want to give you an intuitive understanding of the scattering phase shift \\delta_0 that appears here. We will look for the solution with positive energy. Say here is our potential, that’s the energy that’s fixed. What is the wave function like? It’s given by this function.\nThis satisfies the equations outside of the well asymptotically. Let’s say the well is localized in the area of radius of the size R . Outside of the well, when there is no potential, the free-particle Schrödinger equation applies:\n\\psi''(x) + E \\psi(x) = 0 \\quad \\text{for} \\quad |x| &gt; R\nIts solution is given by a cosine. It’s clear that this is a solution. If you take a second derivative, the k^2 comes out of the cosine, you still have a cosine with a minus sign. Then k^2 is E and you get exactly the terms.\nWhat I would like to argue is that this phase shift \\delta_0 is something that doesn’t spoil the solution. It’s still a solution and it reflects asymptotically the properties of the potential. Despite that the potential is localized, the functions at infinities feel the properties of the potential.\nThat’s actually the essence of scattering theory. You send a plane wave to your potential from minus infinity from the asymptotic regime. Then you check the properties of the wave on the other side asymptotically. It comes as a plane wave, but with a slightly different phase. This difference in the phase reflects the properties of the potential.\n\n\n\n\n\n\nThe asymptotic wave function for a symmetric potential well is: \\psi(x) \\sim \\cos(k|x| + \\delta_0) \\quad \\text{for} \\quad |x| \\gg R\nThe modulus |x| ensures symmetry, and \\delta_0 is the scattering phase shift encoding the potential’s effect at large distances.\n\n\n\nI believe one intuitive picture that I have in mind is that imagine you have a slider and you can tune the depth of the well. Here is -U_0 and you can tune this up, that becomes flat. So U_0 to zero. If U_0 is not there, the plane wave without this, any \\delta is a solution to this equation. Just \\cos(kx) , with \\delta = 0 , is a solution.\nWhat happens when U_0 appears? You make it bigger so the wave gets shifted. Essentially when U_0 is there, you have that solution. It’s not valid to use the same cosine inside of the well, because there is the x dependence of the potential. It’s only asymptotically valid.\nWhat we see is that on both sides there is the shift of the period of our wave function. That shift is exactly this \\delta_0 . The stronger your potential, the more it’s going to shift asymptotically the period of the wave. Since this is valid, to make it valid on both sides we have to put the modulus. The asymptotic wave function is \\psi(x) \\sim \\cos(k|x| + \\delta_0) for |x| \\gg R . For positive x this is like this. For the negative it’s a minus x to have it symmetric.\nMaybe that’s also a good moment to think what happens with these poles when we change the potential, that we had our slider right to move up and down the depth of the well. What happens with these poles? Clearly they are going to move continuously with the depth of the potential.\nWhen we make the potential shallower and shallower, these bound state poles are going to move towards the threshold and then disappear there. But in fact they don’t disappear. You know what happens? They’re going to wrap around the branch point and appear on the other analytic sheet. We know that function, due to this branch cut, has several Riemann sheets.\nEssentially what they do is to flip, go to the non-physical sheet and become virtual states. As soon as this pole wraps around the cut, it appears on the same location, but on the physical sheet we call them virtual states. It’s interesting actually.\nIt’s important to realize that as soon as the potential is in a regime that is already finite, it has a certain depth, but it cannot yet host a bound state. There are only virtual states. If attraction is not strong enough, there are no bound states in the potential. But still attraction could be felt by particles. That probably indicates that there are virtual states. With a certain depth there are 1, 2 and then even more states.\nWhat are resonances then? If you follow this logic, resonances are phenomena where particles with low energy feel the attraction more. What we want is that at certain energies we want to have peaks in the amplitudes. I think this potential does not have any resonance phenomena.\nBut the resonance phenomena could be seen if the probability to pass through the well increases for certain energies. If we have an energy here that is low, the probability to pass or the reflection—let’s maybe think of the reflection coefficient. Any wave gets reflected and this probability of reflection changes with the energy of the particle.\nThe resonance phenomena would correspond to the phenomena when you change the energy, the probability of reflection gets lower or higher and then back to the same value. If you have a strong dependence of the probability to get reflected on the frequency of the wave, you have a resonance phenomenon that corresponds to the poles that are in the traditional amplitude in the complex plane. A resonance corresponds to a pole at complex energy:\nE_{\\text{res}} = E_0 - i \\frac{\\Gamma}{2}\nwhere E_0 is the resonance energy and \\Gamma is the width.\n\n\n\n\n\n\nThe analytic structure of the scattering amplitude is key:\n\nThe continuum of scattering states corresponds to a branch cut along the positive real energy axis.\nBound states correspond to poles on the negative real axis.\nResonances correspond to complex poles (e.g., E_0 - i\\Gamma/2 ) on unphysical Riemann sheets, leading to peaks in cross-sections.\n\n\n\n\nNow we are ready to actually put this problem into the box. Solving in the box is also an academic problem. I’m not sure for this potential you can solve this in a closed form. But what changes is that you impose yet another condition.\nWe say a particle at the value L has to be the same as the one on the other side, as well as the derivative. These periodic boundary conditions are quite strong and change dramatically the phenomena that we observe:\n\\psi(L) = \\psi(-L), \\quad \\psi'(L) = \\psi'(-L)\nPeriodic boundary condition also can be seen as mirroring this picture on the left and on the right an infinite number of times. In the previous lecture I was talking about a lattice as a sort of this periodic boundary condition, as a sort of grid of repeated cells in which we do computations. Essentially this is a periodic boundary condition.\nWe will assume that the size of the well is much smaller than L . That’s important to use asymptotic formulas at the value of L . Let me do this."
  },
  {
    "objectID": "2025-Lecture-13.html#from-continuum-to-discrete-finite-volume-effects-and-lattice-spectroscopy",
    "href": "2025-Lecture-13.html#from-continuum-to-discrete-finite-volume-effects-and-lattice-spectroscopy",
    "title": "(2025) Lecture 13",
    "section": "4 From Continuum to Discrete: Finite Volume Effects and Lattice Spectroscopy",
    "text": "4 From Continuum to Discrete: Finite Volume Effects and Lattice Spectroscopy\nThe first condition does nothing—the function is symmetric, so it is already the same on both sides of the lattice.\nBut the second condition is actually important. We are still dealing with energies that are positive. From this boundary condition we realize that now, in fact, not every energy is possible. Since the energy is related to momentum by E = k^2 , only certain discrete values are allowed. In the continuum, most values become forbidden, and only a discrete spectrum appears.\nLet me first draw it as a line. I’m still going to have a bound state below the threshold crossing.\n\n\n\n\n\n\nFigure 3: This figure illustrates the energy spectrum of a quantum system in a finite box with periodic boundary conditions. On the left, the “bound states” are indicated by isolated crosses at negative energies, representing discrete, localized energy levels below the threshold ( E &lt; 0 ) of the potential well. To the right, along the positive energy axis ( E &gt; 0 ), there is a set of regularly spaced ticks labeled as the “discrete spectrum,” separated by intervals approximately 2\\pi/L , where L is the size of the box. Physically, this captures the replacement of the continuum of scattering states in infinite volume (where all positive energies are allowed) with a discrete set of allowed energies when the system is put into a finite periodic box. The spacing between these levels is inversely proportional to the box size, and as L \\to \\infty the spectrum approaches the continuum limit. The figure encapsulates the key idea that in finite volume, the energy spectrum consists of both bound states and a set of quantized scattering states—each energy level corresponds to a pole in the scattering amplitude, and their positions are shifted from the non-interacting values by the phase shift \\delta_0(k) associated with the underlying interaction potential. This setup is essential for applying the Lüscher method to extract scattering information from lattice simulations.\n\n\n\nBut now, even above the threshold, I have a discrete spectrum. You see how this transition happens.\nSo what effectively happens is that our branch point and the cut that starts from zero and goes to the positive real axis of energy gets replaced by a set of poles. Every allowed value of energy, if it’s isolated, corresponds to a pole in the scattering amplitude. A bizarre thing happens: we used to have a cut in the complex plane, and now it becomes an infinite number of poles along the real axis.\nAs the lattice size L increases, in the limit L \\to \\infty , we resemble the continuous limit—the limit of an infinite box. In this limit, we recover the infinite volume and the continuous spectrum. The distance between poles in the region that used to be continuous scales with 1/L , so they become very, very close to each other.\nAnother term I would like to highlight is the \\delta_0 term. That term, at asymptotic distances, remembers properties of a potential of infinite range. This term actually changes the discrete spectrum we have in the continuum, in the area that used to be continuous—there is a shift.\nThat’s related to the exercise we did. We took our potential and made it flat, setting U = 0 ; the phase shift \\delta_0 vanished. Then we pulled the potential down, and \\delta_0 became significant. What you see is that the spectrum of the energy—these states not only below the threshold but also above—gets adjusted and shifted.\nThis shift is related to the properties of the potential. That’s a key idea for our computations of scattering in finite volume. We have a way to solve the Schrödinger equation numerically, look at the asymptotic values, and find \\delta_0 .\nWe don’t need to do that manually, but what if we can set up… It’s critical when the potential is not analytically solvable. If we can perform a scattering experiment and only have access to the asymptotic form and the energy spectrum of the system, we can deduce the properties of the potential from the energy spectrum.\nWe check what energies are possible in the system when there is no interaction—a simple problem. We know the answer: for free particles in a periodic box of size L , the momenta are quantized as k_n = \\frac{2\\pi n}{L}, \\quad n \\in \\mathbb{Z}.\nThen we check numerically what the possible energies are when there is an interaction. By comparing these two spectra, we can deduce the value of the scattering phase shift \\delta_0(k) . So \\delta_0 depends on energy, and you probe it with different values of k .\n\n\n\n\n\n\nThis connection is encapsulated in the Lüscher quantization condition for finite-volume scattering. In a periodic box of size L , the discrete momenta k are determined by the scattering phase shift \\delta_0(k) : \\delta_0(k) = n\\pi - \\phi(kL), \\quad n \\in \\mathbb{Z},\nwhere \\phi is a geometric function from the periodic boundary conditions. This formula allows us to extract infinite-volume scattering data from the finite-volume energy spectrum. So far, despite quantum mechanics being a very well taught course, the connections with material that comes after—like quantum field theory and particle physics—are maybe not that easy to grasp.\n\n\n\n\n\n\n\n\n\nFigure 4: This figure illustrates the concept of a quantum field as it manifests on a space-time lattice in lattice field theory. Each box represents a spacetime site on the lattice. At every site, the quantum field can create or annihilate a \\pi meson (pion), as sketched within the circles labeled “π”. The arrows indicate how the quantum field links adjacent sites, encoding the propagation and interactions of pions across the lattice. This setup models how, in a discretized spacetime (the lattice), the quantum field provides the dynamical degrees of freedom that give rise to all possible particle configurations at each site, allowing for the calculation of correlation functions and ultimately the extraction of properties like the energy spectrum and scattering amplitudes, as discussed in the lecture. The annotation clarifies that what is being represented at each site is indeed the quantum field.\n\n\n\nI think it’s important to spell out and discuss all shared points to make the connection clear.\nIf you think of a finite box with periodic boundary conditions, like having two marbles interacting on a ring, then what plays the role of the lattice size L is the full circumference of the ring. The variable x is the distance between the two marbles. If there is an interaction potential, that’s precisely the setup we have. A periodic boundary condition means it doesn’t matter where they are; only the distance matters.\nIn lattice field theory, the quantity computed is the correlation of operators. This is the vacuum expectation value of the product of two operators: C_{ij}(t) = \\langle 0 | O_i(t) O_j^\\dagger(0) | 0 \\rangle.\nHere i and j label operators. Say we have five of them, or one, two, three, or four. We compute a 5 \\times 5 matrix of correlation functions as a function of Euclidean time t .\nThe expected form for this correlation is a sum over energy eigenstates: C_{ij}(t) = \\sum_n \\langle 0 | O_i | n \\rangle \\langle n | O_j^\\dagger | 0 \\rangle e^{-E_n t}.\nIf we insert a complete basis of states |n\\rangle , we get a combination of exponential functions with coefficients z_i^n = \\langle 0 | O_i | n \\rangle .\n\nTo get the meson spectrum, you would take O as a combination of quark and antiquark fields—with appropriate gamma matrices to match the desired quantum numbers—to create an object that looks like a meson. You compute its correlation as a function of time, extract the energy E , and that gives you the energy of the system. All possible meson energies appear, starting with the ground state.\nFor example, take a u\\bar{u} operator, run this correlation on the lattice, and the lowest energy that appears will be the mass of the \\pi meson.\n\nAn important aspect is that the higher the energy of a state, the faster its contribution decays. Therefore, if you wait long enough in time t , all higher-state contributions drop exponentially. What remains is only the ground state of the system: C(t) \\xrightarrow{t \\to \\infty} A_0 e^{-E_0 t}.\nIn the meson case, this works fine. For baryons, it can be more challenging due to noisier signals.\nHowever, there is more information stored in these correlations if your operator basis is larger. We can treat this as a general eigenvalue problem—a technique used to extract exponentials of the higher states.\nIt’s not overly complicated. You take the correlation matrix C_{ij}(t) , and for different values of t , you solve a generalized eigenvalue problem: C(t) v_n(t, t_0) = \\lambda_n(t, t_0) C(t_0) v_n(t, t_0).\nThe eigenvalues behave as \\lambda_n(t, t_0) \\propto e^{-E_n (t - t_0)} for large t , allowing you to access excited-state energies E_n .\n\nBy diagonalizing this matrix, you optimize the overlap of different operators with the true energy eigenstates. The diagonal elements of the diagonalized matrices give the time dependence of those higher states.\nThere are specialized algorithms to make these calculations less noisy.\n\nFor the operator that creates mesons, the operators must carry specific quantum numbers. If you want the spectrum of light spin-one mesons, the operators have 1^- quantum numbers. For other quantum numbers, you need different operators.\nWhat happens in practice on a finite lattice is that spin is not a good quantum number because you don’t have full rotational symmetry. The lattice has a discrete rotation group, so different spins mix. In practice, the whole meson spectrum is computed simultaneously.\nBy using a large matrix—with hundreds of operators spanning different sectors—you include overlaps between different spins in the off-diagonal elements. You then solve for a large number of eigenvalues (say, 30–40) and map the resulting energy values to the masses of the mesons."
  },
  {
    "objectID": "2025-Lecture-13.html#extracting-resonances-from-finite-volume-spectra",
    "href": "2025-Lecture-13.html#extracting-resonances-from-finite-volume-spectra",
    "title": "(2025) Lecture 13",
    "section": "5 Extracting Resonances from Finite-Volume Spectra",
    "text": "5 Extracting Resonances from Finite-Volume Spectra\nThere is one problem with that approach. The problem is that we know that in hadronic interactions most of the resonances above the thresholds decay. They are in fact not bound states; they are resonances. Excited mesons, like the rho meson and higher states, are resonances in the ππ interaction.\nStrictly speaking, the method of extracting eigenvalues from the exponential decay of correlators is not applicable above the two-pion threshold. If you wait long enough, you will see the ground state, so the mass of the pion is easy to measure. But as soon as you extract an energy above 2m_π , what you measure are the states of the two-pion system rather than a single stable particle. Therefore, values extracted above the open flavor threshold, above 2m_π , are not trustworthy or reliable.\nA different method is used to address the physics of resonances, such as determining what resonances appear in ππ scattering.\nInstead of using two-quark operators for single mesons, four-quark operators are used that represent meson-meson combinations, schematically O \\sim \\bar{q} Γ q \\; \\bar{q} Γ' q' . The energy spectrum of a meson-meson combination in a finite box is very rich and resembles the discrete spectrum we expect for two particles in a box. Above the threshold, in the continuum region, the spectrum is discrete with a small spacing on the order of 2\\pi/L .\nThe position of these discrete states deviates from the spectrum of a non-interacting two-particle system by a small value. This energy shift, \\Delta E_n = E_n - E_n^{(0)} , encodes the scattering information and is related to the scattering phase shift \\delta(k) .\n\n\n\n\n\n\nThis is where Lüscher’s finite-volume method is applied. It provides a direct link between the discrete energy levels E_n measured on the lattice and the infinite-volume scattering phase shift \\delta(k) .\n\n\n\n\n\n\n\n\n\nFigure 5: This figure depicts a finite, periodic box—a three-dimensional cubic lattice of size 2 \\, \\mathrm{fm} \\times 2 \\, \\mathrm{fm} \\times 2 \\, \\mathrm{fm} (where “fm” means femtometer or fermi, a common unit of length in nuclear and particle physics). In the context of the lecture, this box represents the finite spatial volume used in lattice field theory calculations. The grid illustrates the discretization of space (the “lattice”), with periodic boundary conditions implied on all sides. Physically, this setup mimics the environment for two particles (such as mesons or nucleons) interacting inside a finite, periodic domain. The box imposes discrete momentum values for the particles, modifies the energy spectrum (replacing the continuum by discrete levels), and enables the extraction of scattering information (such as phase shifts) via finite-volume methods like the Lüscher formalism. This mirrors the core idea discussed in the lecture: by confining particles to a finite box and analyzing the resulting discrete energy spectrum, one can infer properties of scattering and hadronic interactions relevant to QCD.\n\n\n\nFor a single channel in a periodic box, a simplified form of the quantization condition is: &gt; k \\cot \\delta(k) = \\frac{1}{\\pi L} S\\left( \\eta \\right), \\quad \\eta = \\left( \\frac{kL}{2\\pi} \\right)^2\n&gt; where S(\\eta) is a known kinematic function and k is the scattering momentum related to the total energy E .\nComputations are done, extracting all these discrete levels E_1, E_2, E_3, \\ldots , and then comparing them to the predictions for non-interacting particles. By looking at the difference between the non-interacting spectrum and the interacting spectrum, you deduce the asymptotic scattering phase shift \\delta(k) .\nA classical example using this technique is P-wave ππ scattering, where one extracts the phase shift and obtains a curve showing a tangent dependence characterizing a resonance. For physical quark masses, this resonance peaks at a specific value. The pion mass is 140 MeV, and the second threshold is at a value where the momentum k equals zero. The nominal mass, where the phase shift passes \\pi/2 (or 90 degrees), is 770 MeV. This is the nominal mass of the ρ meson.\n\nResonance Condition: Near a resonance, the phase shift follows a Breit-Wigner form: \\tan \\delta(k) = \\frac{\\Gamma/2}{E_R - E} , where \\Gamma is the width.\nResonance Pole: The fundamental property of a resonance is a pole in the complex energy plane: E_{\\text{res}} = E_0 - i \\frac{\\Gamma}{2} .\n\nThis is more or less the machinery used these days to study hadron spectroscopy on the lattice. The method is accurate as long as you can take into account all relevant channels. It works as follows:\n\nConstruct a large basis of operators with the appropriate quantum numbers.\nExtract the eigenvalues to get the energy spectrum of the two-meson system.\nCompare it to the non-interacting spectrum to extract \\delta(k) for different scattering momenta k .\n\n\n\n\n\n\n\nFigure 6: This figure illustrates the extraction of the scattering phase shift \\delta(k) as a function of the breakup momentum k in a finite volume—specifically as encountered in lattice QCD calculations. The phase shift curve (vertical axis) rises sharply with k , exhibiting a rapid change near a particular momentum, labeled k_{\\rm nominal} , where \\delta_0 = 90^\\circ . This point is associated with the resonance condition in scattering theory, corresponding to the physical mass of a resonance (for example, the \\rho meson in ππ scattering). The yellow X’s mark discrete energy levels \\Delta E_1, \\Delta E_2, \\Delta E_3, \\ldots determined from the finite-volume spectrum in the box. Each energy level gives a quantized value of k , and through the Lüscher quantization condition, each can be mapped to a value of the phase shift \\delta_0(k) at that k . The dashed line shows the characteristic tangent-shaped dependence of \\delta_0 on k near a resonance. The upward curvature represents the rapid change in the phase shift due to the presence of a resonance pole in the scattering amplitude, with k_{\\rm nominal} indicating the resonance energy where the phase shift passes through 90^\\circ . This construction allows lattice theorists to connect the finite-volume discrete energy spectrum to infinite-volume scattering observables, such as the location and width of a resonance.\n\n\n\nYou then plot these points, either on an Argand diagram or as the phase shift dependence on the breakup momentum k . From first principles—from the QCD Lagrangian—we thus obtain the spectrum of two-particle scattering and the properties of resonances.\nThere are many complications to this problem that come from coupled channels. As soon as another threshold opens, for example when the energy is above the two-kaon threshold, you have to take into account that the channels are coupled. The operator basis must then include not just pions, but also kaons and η' mesons. If you are above the three-pion threshold, you also have to include three-pion operators. It becomes large and complicated, but the core idea of using the energy shift remains the key.\nFor multi-channel scattering, the analysis generalizes to the ** K -matrix formalism**, where the scattering matrix S is related to a Hermitian K -matrix by S = (1 + iK)(1 - iK)^{-1} . This formalism is used by both lattice practitioners and experimental analysts to parameterize data and extract physical resonance poles and couplings.\nThe raw energy levels from the lattice are not yet the final properties of the resonances. Further analysis involves parameterizing the data to extract the pole position E_{\\text{res}} = E_0 - i\\Gamma/2 and the couplings. This final information—the pole positions and couplings—is what is important and what gets published in the Particle Data Group (PDG) for comparison between theory and experiment."
  },
  {
    "objectID": "2025-Lecture-13.html#lecture-conclusion",
    "href": "2025-Lecture-13.html#lecture-conclusion",
    "title": "(2025) Lecture 13",
    "section": "6 Lecture Conclusion",
    "text": "6 Lecture Conclusion\n\nAll right then, that’s all for today.\n\n\n\n\n\n\nThis concluding remark marks the end of the lecture segment. As noted in the supporting material, this specific chunk contains no substantive technical discussion, such as formulas related to nuclear physics concepts like decay rates, binding energy, or reaction cross-sections. This concludes the lecture for this session."
  }
]